
// === BACKEND EXPRESS SETUP (multi-agent + visitors + visits + OpenAI) ===
import "dotenv/config";
import express from "express";
import http from "http";
import { Server } from "socket.io";
import cors from "cors";
import bcrypt from "bcrypt"; // (kept if you add auth later)
import path from "path";
import { fileURLToPath } from "url";
import fs from "fs";
import OpenAI from "openai"; // (kept for future use)
import mysql from "mysql2/promise";
import { respondWithPrompt, respondWithPromptAndTools, getOpenaiDebug, createOpenAIClient, extractTextFromResponse } from "./lib/openaiResponses.js";
import { createPrestaClient, normalizePrestaCollection, pick } from "./lib/prestashop.js";
import crypto from "crypto";
import { WebSocketServer } from "ws";
import { createMcpTools } from "./lib/mcpTools.js";
import { createLogger } from "./src/core/logger.js";
import { createPool, ensureTables as ensureTablesMigration } from "./src/infrastructure/database/index.js";
import { textToSafeHTML, sanitizeAgentHtmlServer } from "./src/shared/safeHtml.js";
import { createAuthModule } from "./src/modules/auth/index.js";
import { createModuleManager } from "../modules/module-manager/backend/index.js";
import { loadModuleHooks, loadModuleRoutes } from "./src/modules/loader.js";
import { google } from "googleapis";
import pgPkg from 'pg';

// Feature flag: disable Jerome DB storage tables (queue, extracts, transfers)
const JEROME_STORAGE_DISABLED = /^(1|true|yes)$/i.test(String(process.env.GRB_JEROME_DISABLE_STORAGE || '1'));

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ---- LOG (defined early to avoid TDZ on first use)
const logger = createLogger({
  logFile: path.join(__dirname, "chat.log"),
  defaultEnabled: !/^(0|false|no)$/i.test(process.env.LOG_ENABLED || "1"),
  defaultStdout: /^(1|true|yes)$/i.test(process.env.LOG_STDOUT || ""),
});
const logToFile = (message) => logger.logToFile(message);
const getLogFilePath = () => logger.getLogFile();
const isLogEnabled = () => logger.isEnabled();
const setLogEnabled = (value) => logger.setEnabled(value);
const isLogStdout = () => logger.isStdout();
const setLogStdout = (value) => logger.setStdout(value);

// Global error handlers to surface file/stack for critical runtime issues
try {
  process.on('uncaughtException', (e) => {
    try { logToFile(`[uncaughtException] ${e?.stack || e}`); } catch {}
  });
  process.on('unhandledRejection', (e) => {
    try { logToFile(`[unhandledRejection] ${e?.stack || e}`); } catch {}
  });
} catch {}


// Directory for MCP uploads (declared early to avoid TDZ when used below)
const mcpUploadDir = path.join(__dirname, 'uploads', 'mcp');
const mcpDevUploadDir = path.join(__dirname, 'uploads', 'mcp-dev');
const grabbingPacketaDir = path.join(__dirname, 'uploads', 'grabbing-packeta');
// Allow explicit override of Jerome uploads directory; default remains under backend/uploads/grabbing-jerome
const grabbingJeromeDir = (process.env.GRABBING_JEROME_DIR && path.isAbsolute(process.env.GRABBING_JEROME_DIR))
  ? process.env.GRABBING_JEROME_DIR
  : path.join(__dirname, 'uploads', 'grabbing-jerome');
const grabbingJeromeQueueFile = path.join(grabbingJeromeDir, 'queue.json');
const grabbingJeromeTransfersFile = path.join(grabbingJeromeDir, 'transfers.json');
const grabbingJeromeConfigDir = path.join(grabbingJeromeDir, 'config');
const dbSummaryDir = path.join(__dirname, 'uploads', 'db-summaries');
const devTrackerUploadDir = path.join(__dirname, 'uploads', 'devtracker');
try { fs.mkdirSync(mcpUploadDir, { recursive: true }); } catch {}
try { fs.mkdirSync(mcpDevUploadDir, { recursive: true }); } catch {}
try { fs.mkdirSync(grabbingPacketaDir, { recursive: true }); } catch {}
try { fs.mkdirSync(grabbingJeromeDir, { recursive: true }); } catch {}
try { if (!fs.existsSync(grabbingJeromeQueueFile)) fs.writeFileSync(grabbingJeromeQueueFile, '[]'); } catch {}
try { if (!fs.existsSync(grabbingJeromeTransfersFile)) fs.writeFileSync(grabbingJeromeTransfersFile, '[]'); } catch {}
try { fs.mkdirSync(grabbingJeromeConfigDir, { recursive: true }); } catch {}
try { fs.mkdirSync(dbSummaryDir, { recursive: true }); } catch {}
try { fs.mkdirSync(devTrackerUploadDir, { recursive: true }); } catch {}

// === Optional PostgreSQL storage for Jerome (queue, extracts, transfers)
const usePgStore = /^(pg|postgres|postgresql)$/i.test(String(process.env.GRB_JEROME_STORE || process.env.JEROME_STORE || ''));
let pgPool = null;
// Auto-connect to Postgres whenever DATABASE_URL is present, even if JEROME_STORE is not set.
async function getPg() {
  if (pgPool) return pgPool;
  try {
    const { Pool } = pgPkg;
    // Defensive: if DATABASE_URL is not set due to cwd differences, try loading backend-local .env
    try {
      if (!process.env.DATABASE_URL && !process.env.PGHOST) {
        const localEnv = path.join(__dirname, '.env');
        if (fs.existsSync(localEnv)) {
          const dotenv = await import('dotenv');
          try { dotenv.config({ path: localEnv }); } catch {}
        }
      }
    } catch {}

    const url = String(process.env.DATABASE_URL || '').trim();
    // Enable PG if explicitly requested, or if any PG connection detail is present
    const enabled = usePgStore || !!url || !!process.env.PGHOST || !!process.env.PGDATABASE;
    if (!enabled) return null;
    const common = { connectionTimeoutMillis: 3000, idleTimeoutMillis: 30000 };
    if (url) pgPool = new Pool({ connectionString: url, ...common });
    else pgPool = new Pool({
      host: process.env.PGHOST || '127.0.0.1',
      port: Number(process.env.PGPORT || 5432),
      user: process.env.PGUSER || 'postgres',
      password: process.env.PGPASSWORD || '',
      database: process.env.PGDATABASE || 'postgres',
      ...common,
    });
    await pgPool.query('select 1');
    return pgPool;
  } catch (e) {
    try { logToFile(`[pg] connect_failed ${e?.message||e}`); } catch {}
    return null;
  }
}
async function ensurePgTables() {
  const pool = await getPg();
  if (!pool) return;
  // New canonical names: grabbing_jerome_*
  if (!JEROME_STORAGE_DISABLED) {
    await pool.query(`create table if not exists grabbing_jerome_queue (
      id text primary key,
      url text not null,
      status text not null default 'pending',
      added_at timestamptz not null default now()
    )`);
    await pool.query(`create table if not exists grabbing_jerome_extracts (
      id bigserial primary key,
      file_name text not null,
      mtime timestamptz not null default now(),
      size bigint default 0,
      download_url text,
      product_url text,
      price numeric,
      currency text,
      image text,
      declinaison text,
      json_data jsonb
    )`);
    try { await pool.query('alter table grabbing_jerome_extracts add column if not exists json_data jsonb'); } catch {}
    await pool.query(`create table if not exists grabbing_jerome_transfers (
      id bigserial primary key,
      when_at timestamptz not null default now(),
      id_product bigint,
      product_url text,
      image text,
      price numeric,
      currency text,
      declinaison text,
      file text,
      name text
    )`);
  }
  // Intentionally do not create grabbing_jerome_discover_* tables anymore.
  // Master domains registry (explicitly added domains)
  await pool.query(`create table if not exists grabbing_jerome_domains (
    domain text primary key,
    sitemap_url text,
    sitemaps jsonb,
    sitemap_total_urls integer default 0,
    created_at timestamptz not null default now(),
    updated_at timestamptz not null default now()
  )`);
  try { await pool.query('alter table grabbing_jerome_domains add column if not exists selected_sitemaps jsonb'); } catch {}
  try { await pool.query('alter table grabbing_jerome_domains add column if not exists config jsonb'); } catch {}
  // Config history table (for UI history viewer)
  try {
    await pool.query(`create table if not exists grabbing_jerome_domain_config_history (
      id bigserial primary key,
      domain text not null,
      config jsonb,
      saved_at timestamptz not null default now()
    )`);
    await pool.query('create index if not exists grabbing_jerome_domain_config_history_domain_idx on grabbing_jerome_domain_config_history (domain)');
    try { await pool.query('alter table grabbing_jerome_domain_config_history add column if not exists version integer'); } catch {}
    try { await pool.query('alter table grabbing_jerome_domain_config_history add column if not exists note text'); } catch {}
  } catch {}
  // Transfer config history (per domain/type)
  try {
    await pool.query(`create table if not exists grabbing_jerome_domain_config_transfert_history (
      id bigserial primary key,
      domain text not null,
      type text not null,
      config jsonb,
      saved_at timestamptz not null default now(),
      version integer
    )`);
    await pool.query('create index if not exists gj_dom_cfg_transfert_hist_domain_type_idx on grabbing_jerome_domain_config_transfert_history (domain, type)');
  } catch {}
  // Extracted URLs per domain
  await pool.query(`create table if not exists grabbing_jerome_domains_url (
    id bigserial primary key,
    domain text not null,
    url text not null,
    type text,
    title text,
    discovered_at timestamptz not null default now()
  )`);
  try { await pool.query('create index if not exists grabbing_jerome_domains_url_domain_idx on grabbing_jerome_domains_url (domain)'); } catch {}
  try { await pool.query('create unique index if not exists grabbing_jerome_domains_url_uq on grabbing_jerome_domains_url (domain, lower(trim(both from url)))'); } catch {}
  // Add explore-related columns if missing
  try { await pool.query('alter table public.grabbing_jerome_domains_url add column if not exists page_type text'); } catch {}
  try { await pool.query('alter table public.grabbing_jerome_domains_url add column if not exists meta jsonb'); } catch {}
  try { await pool.query('alter table public.grabbing_jerome_domains_url add column if not exists product jsonb'); } catch {}
  try { await pool.query('alter table public.grabbing_jerome_domains_url add column if not exists explored timestamptz'); } catch {}
  try { await pool.query('alter table public.grabbing_jerome_domains add column if not exists config_transfert jsonb'); } catch {}
  // Page explorer storage
  try { await pool.query(`create table if not exists grabbing_jerome_domains_url_page_explore (
    id bigserial primary key,
    domain text not null,
    url text not null,
    page_type text not null,
    meta jsonb,
    product jsonb,
    links_sample jsonb,
    explored_at timestamptz not null default now()
  )`); } catch {}
  try { await pool.query('create index if not exists grabbing_jerome_domains_url_page_explore_domain_idx on grabbing_jerome_domains_url_page_explore (domain)'); } catch {}
  try { await pool.query('create unique index if not exists grabbing_jerome_domains_url_page_explore_uq on grabbing_jerome_domains_url_page_explore (domain, lower(trim(both from url)))'); } catch {}
  try { await pool.query('alter table public.grabbing_jerome_domains_url_page_explore add column if not exists result_json jsonb'); } catch {}
  try { await pool.query('alter table public.grabbing_jerome_domains_url_page_explore add column if not exists config_version integer'); } catch {}
  // No dedup/index on grabbing_jerome_discover_item (table deprecated)
  // Ready-to-transfer normalized payloads for PrestaShop 8
  try {
    await pool.query(`create table if not exists grabbing_jerome_domains_url_ready_transfert (
      id bigserial primary key,
      domain text not null,
      url text not null,
      prepared_at timestamptz not null default now(),
      source_url_id bigint,
      page_type text,
      title text,
      meta jsonb,
      product_raw jsonb,
      mapped jsonb,
      status text not null default 'pending',
      notes text
    )`);
    await pool.query('create index if not exists grabbing_jerome_domains_url_ready_transfert_domain_idx on grabbing_jerome_domains_url_ready_transfert (domain)');
    await pool.query('create unique index if not exists grabbing_jerome_domains_url_ready_transfert_uq on grabbing_jerome_domains_url_ready_transfert (domain, lower(trim(both from url)))');
    await pool.query('alter table grabbing_jerome_domains_url_ready_transfert add column if not exists id_product bigint');
    await pool.query('create index if not exists grabbing_jerome_domains_url_ready_transfert_id_product_idx on grabbing_jerome_domains_url_ready_transfert (id_product)');
    await pool.query('alter table grabbing_jerome_domains_url_ready_transfert add column if not exists config_transfert_version integer');
  } catch {}
  // Backward compatibility: if legacy tables exist and new ones are empty, copy once
  if (!JEROME_STORAGE_DISABLED) {
    try {
      await pool.query(`insert into grabbing_jerome_queue(id,url,status,added_at)
        select id,url,status,added_at from jerome_queue
        on conflict (id) do nothing`);
    } catch {}
    try {
      await pool.query(`insert into grabbing_jerome_extracts(file_name,mtime,size,download_url,product_url,price,currency,image,declinaison)
        select file_name,mtime,size,download_url,product_url,price,currency,image,declinaison from grabbing_jerome_extracts`);
    } catch {}
    try {
      await pool.query(`insert into grabbing_jerome_transfers(when_at,id_product,product_url,image,price,currency,declinaison,file,name)
        select when_at,id_product,product_url,image,price,currency,declinaison,file,name from presta_transfers`);
    } catch {}
  }
  // No legacy copy for grabbing_jerome_discover_* (deprecated)
}
ensurePgTables().catch(()=>{});

// Best-effort mirror: keep legacy table grabbing_jerome_domains in sync, if it exists.
// Mirrors only: domain, sitemap_url, sitemaps, sitemap_total_urls, updated_at
async function mirrorLegacyDomain(pool, domain) {
  try {
    if (!pool || !domain) return;
    const chk = await pool.query("select to_regclass('public.grabbing_jerome_domains') as reg");
    if (!chk?.rows?.[0]?.reg) return; // legacy table not present
    const q = await pool.query(
      'select domain, sitemap_url, sitemaps, sitemap_total_urls from grabbing_jerome_discover_domain where domain=$1',
      [domain]
    );
    if (!q.rowCount) return;
    const r = q.rows[0];
    const sitemaps = Array.isArray(r.sitemaps) ? r.sitemaps : (r.sitemaps?.map ? r.sitemaps : []);
    await pool.query(
      `insert into grabbing_jerome_domains(domain, sitemap_url, sitemaps, sitemap_total_urls, updated_at)
       values($1,$2,$3::jsonb,$4, now())
       on conflict (domain) do update set sitemap_url=EXCLUDED.sitemap_url, sitemaps=EXCLUDED.sitemaps, sitemap_total_urls=EXCLUDED.sitemap_total_urls, updated_at=now()`,
      [r.domain, r.sitemap_url || null, JSON.stringify(sitemaps), Number(r.sitemap_total_urls||0)]
    );
  } catch {}
}

// --- Gateway (SMS/Call) runtime token (can be set from .env or DB settings)
let gatewayToken = String(process.env.GATEWAY_TOKEN || '').trim();
// Track gateway connectivity/activity
const gatewaySocketIds = new Set();
let gatewayConnectedAt = null; // timestamp (ms) when at least one gateway socket connected
let gatewayLastActivityAt = null; // timestamp (ms) of last gateway activity (HTTP or socket)

// Import Packeta/Zásilkovna CSV into DB table grabbing_zasilkovna
async function importZasilkovnaCsv(filePath) {
  try { await ensureTables(); } catch {}
  let text = '';
  try { text = fs.readFileSync(filePath, 'utf8'); } catch { return { ok:false, total:0 }; }
  if (!text) return { ok:false, total:0 };
  const stripBom = (s='') => (s.charCodeAt(0) === 0xFEFF ? s.slice(1) : s);
  const pickDelim = (headerLine='') => {
    const cands = [';', '\t', ','];
    let best = ';', bestCount = -1;
    for (const d of cands) { const c = (headerLine.split(d).length - 1); if (c > bestCount) { best = d; bestCount = c; } }
    return best;
  };
  const parseLine = (line, d) => {
    const out = [];
    let cur = '';
    let inQ = false;
    for (let i=0;i<line.length;i++) {
      const ch = line[i];
      if (inQ) {
        if (ch === '"') {
          if (line[i+1] === '"') { cur += '"'; i++; }
          else { inQ = false; }
        } else { cur += ch; }
      } else {
        if (ch === '"') inQ = true;
        else if (ch === d) { out.push(cur); cur = ''; }
        else cur += ch;
      }
    }
    out.push(cur);
    return out;
  };
  const lines = stripBom(text).split(/\r?\n/).filter((_,i,arr) => i < arr.length || true);
  if (!lines.length) return { ok:false, total:0 };
  const headerLine = lines[0];
  const d = pickDelim(headerLine);
  const headers = parseLine(headerLine, d).map(s => (s||'').trim());
  // Normalize accents without using Unicode property escapes (max compat)
  const norm = (s='') => s
    .normalize('NFKD')
    .replace(/[\u0300-\u036f]/g, '')
    .toLowerCase()
    .trim();
  const findIdx = (pats) => {
    const ps = pats.map(p => (typeof p === 'string' ? new RegExp(p, 'i') : p));
    for (let i=0;i<headers.length;i++) {
      const h = headers[i];
      const hn = norm(h);
      if (ps.some(re => re.test(h) || re.test(hn))) return i;
    }
    return -1;
  };
  const idx = {
    submission: findIdx([/submission/, /podani|podaci|podan/i, /entry/]),
    order: findIdx([/order/, /objedn|commande|pedido/i]),
    barcode: findIdx([/barcode|tracking|k[oó]d|code\s*barre/i]),
    name: findIdx([/recipient.*name|^name$|jmeno|prijemce/i]),
    surname: findIdx([/surname|last\s*name|prijmeni/i]),
    carrier: findIdx([/carrier|pick[-\s]?up|pickup|point|vydejni|poste/i]),
    sender: findIdx([/sender|odesilatel/i]),
    cod: findIdx([/\bCOD\b|cash\s*on\s*delivery|dobir/i]),
    currency: findIdx([/currency|mena|monnaie|valuta/i]),
    status: findIdx([/status|stav|etat/i]),
    ready_until: findIdx([/ready\s*for\s*pick\s*up.*until|vyzvedn|until/i]),
    delivered_on: findIdx([/delivered\s*on|doruc|livr/i]),
    consigned_date: findIdx([/consigned|podan|shipped|exped/i]),
    email: findIdx([/(^|\b)e[-\s]?mail\b|email/i]),
    packet_price: findIdx([/packet\s*price|^price$|cena|montant/i]),
  };
  const toNum = (s) => {
    if (s == null) return null;
    const t = String(s).replace(/[^0-9,.-]/g,'').replace(/\s+/g,'').replace(/,(?=\d{1,2}$)/, '.');
    const n = parseFloat(t);
    return Number.isFinite(n) ? n : null;
  };
  const toDate = (s) => {
    if (!s) return null;
    const t = String(s).trim();
    let m = /^(\d{1,2})[.\/](\d{1,2})[.\/](\d{4})(?:[ T](\d{1,2}):(\d{2})(?::(\d{2}))?)?$/.exec(t);
    if (m) {
      const [ , dd, mm, yyyy, HH='00', MM='00', SS='00'] = m;
      const iso = `${yyyy}-${String(mm).padStart(2,'0')}-${String(dd).padStart(2,'0')}T${String(HH).padStart(2,'0')}:${String(MM).padStart(2,'0')}:${String(SS).padStart(2,'0')}Z`;
      const d2 = new Date(iso);
      return isNaN(d2.getTime()) ? null : d2;
    }
    m = /^(\d{4})-(\d{2})-(\d{2})(?:[ T](\d{2}):(\d{2})(?::(\d{2}))?)?$/.exec(t);
    if (m) {
      const [ , yyyy, mm, dd, HH='00', MM='00', SS='00'] = m;
      const iso = `${yyyy}-${mm}-${dd}T${HH}:${MM}:${SS}Z`;
      const d2 = new Date(iso);
      return isNaN(d2.getTime()) ? null : d2;
    }
    const d2 = new Date(t);
    return isNaN(d2.getTime()) ? null : d2;
  };
  const get = (arr, i) => (i>=0 && i < arr.length ? String(arr[i] ?? '').trim() : '');
  const computeIdOrder = (orderStr='') => {
    const s = String(orderStr||'').trim();
    if (!s) return null;
    // 1) Pure number
    if (/^-?\d+$/.test(s)) return s.replace(/^0+/,'') || '0';
    // 2) Pattern like 16181/1 -> take the part before '/'
    const slashM = /^(\d+)\s*\//.exec(s);
    if (slashM && slashM[1]) return String(slashM[1]).replace(/^0+/,'') || '0';
    // 3) Contains -ZZ -> take digits before -ZZ
    const zzM = /(.*?)-\s*zz/i.exec(s);
    if (zzM && zzM[1]) {
      const digits = String(zzM[1]).replace(/\D+/g,'');
      if (digits) return digits.replace(/^0+/,'') || '0';
    }
    // 4) Fallback: leading digits at start if present
    const lead = /^(\d+)/.exec(s);
    if (lead && lead[1]) return lead[1].replace(/^0+/,'') || '0';
    // 5) Last resort: all digits
    const digits = s.replace(/\D+/g,'');
    return digits ? digits.replace(/^0+/,'') || '0' : null;
  };
  const computePacketId = (barcode='') => {
    if (!barcode) return null;
    const first = String(barcode).split(',')[0] || String(barcode);
    const digits = first.replace(/\D+/g,'');
    return digits || null;
  };
  const rows = [];
  for (let i=1;i<lines.length;i++) {
    const l = lines[i];
    if (l == null || l === '') continue;
    const arr = parseLine(l, d);
    if (!arr.length || arr.every(x => String(x||'').trim()==='')) continue;
    rows.push(arr);
  }
  let total = 0;
  let insertedCount = 0, updatedCount = 0, failedCount = 0, skippedCount = 0;
  const failedLines = [];
  const skippedLines = [];
  for (let ri = 0; ri < rows.length; ri++) {
    const arr = rows[ri];
    const csvLine = ri + 2; // +1 for 1-based, +1 to skip header
    total++;
    try {
      const submission = get(arr, idx.submission);
      if (!submission) { skippedCount++; skippedLines.push(csvLine); try { logToFile(`[zasilkovna_import_skip] line=${csvLine} reason=missing_submission`); } catch {} continue; }
      const orderRaw = get(arr, idx.order);
      if (!orderRaw) { skippedCount++; skippedLines.push(csvLine); try { logToFile(`[zasilkovna_import_skip] line=${csvLine} reason=missing_order`); } catch {} continue; }
      const idOrder = computeIdOrder(orderRaw);
      const barcode = get(arr, idx.barcode);
      const packetId = computePacketId(barcode);
      const name = get(arr, idx.name);
      const surname = get(arr, idx.surname);
      const carrier = get(arr, idx.carrier);
      const sender = get(arr, idx.sender);
      const cod = toNum(get(arr, idx.cod));
      const currency = get(arr, idx.currency) || null;
      const status = get(arr, idx.status);
      const readyUntil = toDate(get(arr, idx.ready_until));
      const deliveredOn = toDate(get(arr, idx.delivered_on));
      const consignedDate = toDate(get(arr, idx.consigned_date));
      const email = get(arr, idx.email);
      const packetPrice = toNum(get(arr, idx.packet_price));
      const vals = [
        submission,
        orderRaw || null,
        idOrder || null,
        barcode || null,
        packetId || null,
        name || null,
        surname || null,
        carrier || null,
        sender || null,
        cod,
        currency,
        status || null,
        readyUntil,
        deliveredOn,
        consignedDate,
        email || null,
        packetPrice,
      ];
      const upsertSql = `
        INSERT INTO grabbing_zasilkovna (
          submission_number, order_raw, id_order, barcode, packet_id, name, surname, carrier, sender,
          cod, currency, status, ready_for_pickup_until, delivered_on, consigned_date, customer_email, packet_price, created_at, updated_at
        ) VALUES (
          $1,$2,$3,$4,$5,$6,$7,$8,$9,
          $10,$11,$12,$13,$14,$15,$16,$17,NOW(),NOW()
        )
        ON CONFLICT (order_raw) DO UPDATE SET
          -- keep the original submission_number for this order to avoid clashes
          id_order = EXCLUDED.id_order,
          barcode = EXCLUDED.barcode,
          packet_id = EXCLUDED.packet_id,
          name = EXCLUDED.name,
          surname = EXCLUDED.surname,
          carrier = EXCLUDED.carrier,
          sender = EXCLUDED.sender,
          cod = EXCLUDED.cod,
          currency = EXCLUDED.currency,
          status = EXCLUDED.status,
          ready_for_pickup_until = EXCLUDED.ready_for_pickup_until,
          delivered_on = EXCLUDED.delivered_on,
          consigned_date = EXCLUDED.consigned_date,
          customer_email = EXCLUDED.customer_email,
          packet_price = EXCLUDED.packet_price,
          updated_at = NOW()
        RETURNING (xmax = 0) AS inserted, submission_number, order_raw, id_order, packet_id, barcode`;
      const r = await pool.query(upsertSql, vals);
      try {
        const row = r?.rows?.[0];
        if (row) {
          if (row.inserted) {
            insertedCount++;
            logToFile(`[zasilkovna_import_new] line=${csvLine} order_raw=${row.order_raw||orderRaw||''} submission=${row.submission_number||submission||''} id_order=${row.id_order||idOrder||''} packet_id=${row.packet_id||packetId||''} barcode=${row.barcode||barcode||''}`);
          } else {
            updatedCount++;
            logToFile(`[zasilkovna_import_update] line=${csvLine} order_raw=${row.order_raw||orderRaw||''} submission=${row.submission_number||submission||''} id_order=${row.id_order||idOrder||''} packet_id=${row.packet_id||packetId||''} barcode=${row.barcode||barcode||''}`);
          }
        }
      } catch {}
    } catch (e) {
      failedCount++;
      failedLines.push(csvLine);
      try { logToFile(`[zasilkovna_import_err] line=${csvLine} ${e?.message||e}`); } catch {}
    }
  }
  try {
    logToFile(`[zasilkovna_import] ${path.basename(filePath)} rows=${total} inserted=${insertedCount} updated=${updatedCount} skipped=${skippedCount} failed=${failedCount}`);
    if (failedCount > 0) logToFile(`[zasilkovna_import_failed_lines] ${failedLines.join(',')}`);
    if (skippedCount > 0) logToFile(`[zasilkovna_import_skipped_lines] ${skippedLines.join(',')}`);
  } catch {}
  return { ok:true, total, inserted: insertedCount, updated: updatedCount, skipped: skippedCount, failed: failedCount, failed_lines: failedLines, skipped_lines: skippedLines };
}

// ---- App & Socket.IO
const app = express();
app.set("trust proxy", true);
const server = http.createServer(app);
// Disable WS per-message compression to reduce CPU usage under load
const io = new Server(server, { path: "/socket", cors: { origin: "*" }, perMessageDeflate: false, allowEIO3: true });

app.use(cors());
// Allow passing admin token via query (?admin_token=...) as a fallback
app.use((req, _res, next) => {
  try {
    const q = req.query && (req.query.admin_token || req.query.ADMIN_TOKEN);
    if (q && !req.headers['x-admin-token']) req.headers['x-admin-token'] = String(q);
  } catch {}
  next();
});

// Helper: admin token check that doesn't write response
function hasAdminTokenNonDestructive(req) {
  try {
    const expected = process.env.ADMIN_TOKEN || '';
    if (expected) {
      const got = req.headers['x-admin-token'] || req.query?.admin_token;
      return String(got) === expected;
    }
    // If no token configured, allow only localhost
    return isLocalhost(req);
  } catch { return false; }
}

// Allow admin access to all /api/mcp2/* with either X-Admin-Token or session admin
app.use('/api/mcp2', (req, res, next) => {
  if (hasAdminTokenNonDestructive(req)) return next();
  const ok = requireAdminAuth(req, res);
  if (!ok) return; // requireAdminAuth wrote response
  next();
});

function requireAdminEither(req, res) {
  if (hasAdminTokenNonDestructive(req)) return true;
  const ok = requireAdminAuth(req, res);
  return !!ok;
}
// Defer JSON body parsing to specific route prefixes to avoid overhead on static/socket
// We'll mount JSON parsing later for ['\/api', '\/mcp', '\/messages'] only.

// Readiness flag: set to true after heavy init completes
let serverReady = false;

// ---- Upload size limits (default 512 MiB)
const MAX_UPLOAD_BYTES = (() => {
  const v = Number(process.env.MCP_MAX_FILE_BYTES || 0);
  return Number.isFinite(v) && v > 0 ? v : (512 * 1024 * 1024);
})();

// Serve built frontend (Vite dist) — allow override via FRONTEND_DIST_DIR
const distDir = path.resolve(process.env.FRONTEND_DIST_DIR || path.join(__dirname, "../frontend/dist"));
const indexHtml = path.join(distDir, "index.html");
const distExists = (() => { try { return fs.existsSync(indexHtml); } catch { return false; } })();
logToFile(`[static] distDir = ${distDir}`);
logToFile(`[static] index.html exists? ${distExists}`);
if (distExists) {
  app.use(express.static(distDir)); // /index.html, /assets/*
} else {
  logToFile(`[warn] Frontend dist missing. Serve placeholder until built.`);
}

// Mount JSON parser only for routes that need it
// Include /mcp-dev so its JSON endpoints receive parsed bodies
// Raise JSON limit to accommodate base64 payloads up to ~512MB files
// 512 MiB base64 expands to ~716 MiB; add a margin
app.use(["/api", "/mcp", "/mcp2", "/mcp-dev", "/mcp-dev-prestashop", "/messages"], express.json({ limit: "800mb" }));

// Early health endpoints and start listening ASAP to satisfy deploy smoke tests
// Note: Additional routes are registered below; Express allows adding routes after listen.
app.get("/__health", (_req, res) => {
  res.json({
    distDir,
    indexHtmlExists: fs.existsSync(indexHtml),
    cwd: process.cwd(),
    __dirname,
  });
});

// Admin: deploy status (lock, counter, backups, frontend build, recent logs)
app.get('/api/admin/deploy/status', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const lockFile = process.env.DEPLOY_LOCK_FILE || '/var/lock/livechat-deploy.lock';
    const countFile = process.env.DEPLOY_COUNT_FILE || '/var/lock/livechat-deploy.count';
    const backupRoot = process.env.BACKUP_ROOT || '/root/livechat-app-backup';
    const out = { ok: true };
    // Lock state
    let lockExists = false; try { lockExists = fs.existsSync(lockFile); } catch {}
    let lockFree = null;
    try {
      const cp = await import('child_process');
      const r = cp.spawnSync('flock', ['-n', lockFile, 'sh', '-c', 'true'], { stdio: 'ignore' });
      if (typeof r.status === 'number') lockFree = (r.status === 0);
    } catch {}
    // Counter
    let deployCount = null; try { const s = fs.readFileSync(countFile, 'utf8').trim(); if (s) deployCount = parseInt(s, 10); } catch {}
    // Backups
    let backups = [];
    try {
      backups = fs.readdirSync(backupRoot)
        .filter(n => /\.zip$|\.dump$/.test(n))
        .map(name => { try { const st = fs.statSync(path.join(backupRoot, name)); return { name, size: st.size, mtime: st.mtime }; } catch { return { name }; } })
        .sort((a, b) => (new Date(b.mtime) - new Date(a.mtime)))
        .slice(0, 10);
    } catch {}
    // Frontend build info
    let build = null; try {
      const distBase = process.env.FRONTEND_DIST_DIR || path.join(__dirname, '..', 'frontend', 'dist');
      const fp = path.join(distBase, '__build.json');
      const txt = fs.readFileSync(fp, 'utf8');
      build = JSON.parse(txt);
    } catch {}
    // Recent backend log tail
    let logTail = []; try { const p = getLogFilePath(); const t = fs.readFileSync(p, 'utf8'); const lines = t.split(/\r?\n/); logTail = lines.slice(-100); } catch {}

    return res.json({ ok: true, lock: { file: lockFile, exists: !!lockExists, free: lockFree }, counter: { file: countFile, count: deployCount }, backups, build, log_tail: logTail });
  } catch (e) {
    return res.status(500).json({ ok: false, error: 'status_failed', message: e?.message || String(e) });
  }
});
app.get("/health", (_req, res) => {
  res.json({ openai_ready: true });
});

// Gate critical auth route during boot to avoid 404/500 before routes/DB ready
app.post('/api/auth/login', (req, res, next) => {
  if (!serverReady) return res.status(503).json({ error: 'starting' });
  return next();
});

// ================= Grabbings (CRUD, DB-backed) =================
app.get('/api/grabbings', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try { await ensureTables(); const r = await pool.query(`SELECT id, name, target, options, enabled, created_at, updated_at FROM grabbing_config ORDER BY updated_at DESC`); return res.json({ ok:true, items: r.rows }); }
  catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.post('/api/grabbings', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    await ensureTables();
    const b = req.body || {};
    const id = (String(b.id||'').trim()) || `grb_${Date.now().toString(36)}_${Math.random().toString(36).slice(2,8)}`;
    const name = String(b.name || b.title || '').trim();
    if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });
    const target = (typeof b.target==='string' && b.target.trim()) || null;
    let options = null; try { if (b.options && typeof b.options==='object' && !Array.isArray(b.options)) options = b.options; else if (typeof b.options==='string' && b.options.trim()) options = JSON.parse(b.options); } catch {}
    const enabled = b.enabled === undefined ? true : !!b.enabled;
    try {
      const r = await pool.query(`INSERT INTO grabbing_config (id, name, target, options, enabled, created_at, updated_at) VALUES ($1,$2,$3,$4::json,$5,NOW(),NOW()) RETURNING id, name, target, options, enabled, created_at, updated_at`, [id, name, target, JSON.stringify(options||{}), enabled]);
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) {
      // If a config with the same unique name exists, return the existing row instead of failing
      if (e && (e.code === '23505' || /duplicate key value/i.test(String(e.message||'')))) {
        try {
          const r2 = await pool.query(`SELECT id, name, target, options, enabled, created_at, updated_at FROM grabbing_config WHERE name = $1 LIMIT 1`, [name]);
          if (r2.rowCount) return res.json({ ok:true, item: r2.rows[0], existed: true });
        } catch {}
        // Fall through if select failed
      }
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.get('/api/grabbings/:id', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try { await ensureTables(); const id = String(req.params.id||'').trim(); const r = await pool.query(`SELECT id, name, target, options, enabled, created_at, updated_at FROM grabbing_config WHERE id=$1 LIMIT 1`, [id]); if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' }); return res.json({ ok:true, item: r.rows[0] }); }
  catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.patch('/api/grabbings/:id', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    await ensureTables();
    const id = String(req.params.id||'').trim();
    const b = req.body || {};
    const ent = Object.entries(b).filter(([k,v]) => ['name','title','target','options','enabled'].includes(k));
    if (!ent.length) return res.status(400).json({ ok:false, error:'bad_request' });
    const entries = ent.map(([k,v]) => [k==='title'?'name':k, v]);
    const sets = entries.map(([k],i)=> (k==='options'?`${k} = $${i+1}::json`:`${k} = $${i+1}`));
    const vals = entries.map(([,v]) => (k => (k==='options' && typeof v==='object')? JSON.stringify(v): v)(entries[entries.length-1]?.[0]));
    // Recompute vals properly
    const vals2 = entries.map(([k,v]) => (k==='options' && v && typeof v==='object' ? JSON.stringify(v) : v));
    const r = await pool.query(`UPDATE grabbing_config SET ${sets.join(', ')}, updated_at=NOW() WHERE id = $${vals2.length+1} RETURNING id, name, target, options, enabled, created_at, updated_at`, [...vals2, id]);
    if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
    return res.json({ ok:true, item: r.rows[0] });
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.delete('/api/grabbings/:id', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`DELETE FROM grabbing_config WHERE id=$1`, [id]); return res.json({ ok:true }); }
  catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// =============== Grabbings: Packeta (Zásilkovna) CSV downloader ===============
// POST /api/grabbings/packeta/download -> { ok, file, download_url, message }
// GET  /api/grabbings/packeta/latest   -> { ok, items: [{name,size,mtime,download_url}] }
// GET  /api/grabbings/packeta/file/:name -> serves the CSV file
app.post('/api/grabbings/packeta/download', async (req, res) => {
  const email = String(process.env.PACKETA_EMAIL || req.body?.email || '').trim();
  const password = String(process.env.PACKETA_PASSWORD || req.body?.password || '').trim();
  const signInUrl = String(req.body?.sign_in_url || process.env.PACKETA_SIGNIN_URL || 'https://client.packeta.com/en/sign/in');
  const listUrl = String(req.body?.list_url || process.env.PACKETA_LIST_URL || 'https://client.packeta.com/en/packets/list');
  const debug = !!req.body?.debug;
  const snapshotHtml = !!(req.body?.snapshot_html || req.body?.snapshot);
  const includeEmail = !!req.body?.include_email;
  const deepEnrich = !!(req.body?.deep_enrich || req.body?.deep);
  const tableCsv = !!(req.body?.table_csv || req.body?.prefer_table_csv || req.body?.csv_from_table);
  if (!email || !password) {
    return res.status(400).json({ ok:false, error:'missing_credentials', message:'Set PACKETA_EMAIL and PACKETA_PASSWORD in backend .env or pass email/password in body.' });
  }
  let chromium;
  try { ({ chromium } = await import('playwright')); }
  catch (e) { return res.status(500).json({ ok:false, error:'playwright_missing', message:'Install Playwright in backend: npm i playwright && npx playwright install chromium', details: String(e?.message||e) }); }
  const out = { steps: [], console: [], net: [] };
  const shouldTrace = !!(debug || snapshotHtml);
  const step = (m) => { if (shouldTrace) { try { out.steps.push(m); } catch {} } try { logToFile(`[packeta] ${m}`); } catch {} };
  let browser, context, page;
  try {
    const haveDisplay = !!process.env.DISPLAY;
    const headless = !debug || !haveDisplay; // force headless if no X server
    step(`launch headless=${headless} slowMo=${debug?80:0} platform=${process.platform} display=${process.env.DISPLAY||''}`);
    if (debug && !haveDisplay) step('no_display_detected -> forcing_headless');
    const launchArgs = [];
    try { if (process.getuid && process.getuid() === 0) launchArgs.push('--no-sandbox'); } catch {}
    browser = await chromium.launch({ headless, slowMo: debug ? 80 : 0, args: launchArgs });
    step('context');
    context = await browser.newContext({ acceptDownloads: true });
    try { const ck = await context.cookies(); step(`cookies_initial=${ck?.length||0}`); } catch {}
    step('page');
    page = await context.newPage();
    if (shouldTrace) {
      try {
        page.on('console', (msg) => { try { out.console.push({ type: msg.type(), text: msg.text() }); } catch {} });
        page.on('response', async (resp) => {
          try {
            const url = resp.url();
            const status = resp.status();
            const ct = resp.headers()['content-type'] || '';
            if (/list-export|csv/i.test(url)) out.net.push({ url, status, content_type: ct });
          } catch {}
        });
      } catch {}
    }
    // Try explicit login flow first (reliable), then navigate to list
    try {
      step('goto sign-in');
      await page.goto(signInUrl, { waitUntil: 'domcontentloaded' });
      try { step(`signin_url: ${await page.url()}`); } catch {}
      // Cookie consent (include Cookiefirst)
      try {
        const consentSelectors = [
          '#onetrust-accept-btn-handler',
          'button:has-text("Accept all")',
          'button:has-text("Accept")',
          'button:has-text("I agree")',
          'button[aria-label*="accept" i]',
          'button[data-testid*="accept" i]',
          '.cookiefirst-root [data-cookiefirst-action="accept"]',
          '.cookiefirst-root button:has-text("Accept")'
        ];
        for (const cs of consentSelectors) {
          const loc = page.locator(cs).first();
          if (await loc.count()) { step(`cookie_consent_click ${cs}`); try { await loc.click({ timeout: 1500 }); break; } catch {} }
        }
        // As a fallback, remove overlays
        await page.evaluate(() => {
          const hide = (el) => { try { el.style.setProperty('pointer-events','none','important'); el.style.setProperty('display','none','important'); } catch {} };
          const remove = (sel) => { document.querySelectorAll(sel).forEach(el => { hide(el); try { el.remove(); } catch {} }); };
          remove('dialog.cookiefirst-root');
          remove('.cookiefirst-root');
          remove('#onetrust-consent-sdk');
          remove('#onetrust-banner-sdk');
        });
      } catch {}
      const emailSel = 'input[type="email"], input[name="email"], input#email, input[name="username"]';
      const passSel = 'input[type="password"], input#password';
      let emailCnt = await page.locator(emailSel).count();
      let passCnt = await page.locator(passSel).count();
      step(`email_fields=${emailCnt} password_fields=${passCnt}`);
      if (!emailCnt) { const altEmailSel = 'input[id*="email" i], input[name*="email" i]'; emailCnt = await page.locator(altEmailSel).count(); if (emailCnt) { step(`email_alt_fields=${emailCnt}`); await page.locator(altEmailSel).first().fill(email); } }
      else { await page.locator(emailSel).first().fill(email); }
      if (!passCnt) { const altPassSel = 'input[id*="password" i], input[name*="password" i]'; passCnt = await page.locator(altPassSel).count(); if (passCnt) { step(`password_alt_fields=${passCnt}`); await page.locator(altPassSel).first().fill(password); } }
      else { await page.locator(passSel).first().fill(password); }
      try { const cb = page.locator('input[type="checkbox"][name*="agree" i], input[type="checkbox"][name*="terms" i], input[type="checkbox"][name*="privacy" i]'); if (await cb.count()) await cb.first().check({ force:true }); } catch {}
      const submit = page.locator('button[type="submit"], button:has-text("Sign in"), button:has-text("Log in"), input[type="submit"]');
      step(`submit_buttons=${await submit.count()}`);
      try {
        await Promise.all([
          page.waitForLoadState('domcontentloaded'),
          submit.first().click(),
        ]);
      } catch {}
      try { const pw = page.locator(passCnt? passSel : 'input[id*="password" i], input[name*="password" i]').first(); await pw.press('Enter'); } catch {}
      // Small pause then continue
      try { await page.waitForTimeout(1000); } catch {}
      try { await page.waitForURL(/packets\/list/i, { timeout: 8000 }); } catch {}
      try {
        // Capture any inline auth error messages if present
        const errSel = page.locator('.alert-danger, .alert-error, [role="alert"], .error:visible');
        const n = await errSel.count();
        if (n) { const txt = (await errSel.first().innerText()).slice(0,200).replace(/\s+/g,' '); step(`login_alert: ${txt}`); }
      } catch {}
    } catch (e) {
      step('sign-in flow skipped or failed, will try from list');
    }
    // Ensure on packets list
    step('goto list');
    await page.goto(listUrl, { waitUntil: 'domcontentloaded' });
    try { step(`current_url: ${await page.url()}`); } catch {}

    // Dismiss cookie banners/overlays that may block clicks (e.g., Cookiefirst)
    try {
      // Try common acceptance buttons first
      const cookieAcceptors = [
        '#onetrust-accept-btn-handler',
        '.cookiefirst-root [data-cookiefirst-action="accept"]',
        '.cookiefirst-root button:has-text("Accept all")',
        '.cookiefirst-root button:has-text("Accept")',
        'dialog[aria-label*="cookie" i] button:has-text("Accept")',
        'button:has-text("I agree")',
      ];
      for (const sel of cookieAcceptors) {
        const loc = page.locator(sel).first();
        if (await loc.count()) { step(`cookie_banner_click ${sel}`); try { await loc.click({ timeout: 1500 }); break; } catch {} }
      }
      // As a last resort, hide/remove known cookie overlay containers
      await page.evaluate(() => {
        const hide = (el) => { try { el.style.setProperty('pointer-events','none','important'); el.style.setProperty('display','none','important'); } catch {} };
        const remove = (sel) => { document.querySelectorAll(sel).forEach(el => { hide(el); try { el.remove(); } catch {} }); };
        remove('dialog.cookiefirst-root');
        remove('.cookiefirst-root');
        remove('#onetrust-consent-sdk');
        remove('#onetrust-banner-sdk');
      });
    } catch {}

    // Always show all columns prior to scraping/export to ensure E‑mail and other fields are visible
    try {
      const cur = new URL(await page.url());
      const origin = cur.origin;
      const pathname = cur.pathname.replace(/\/$/, '');
      const baseFromList = `${origin}${pathname}`; // e.g., /en/packets/list
      const candidates = [];
      candidates.push(`${baseFromList}?do=list-showAllColumns`);
      candidates.push(`${baseFromList}?list-id=1&do=list-showAllColumns`);
      for (const lang of ['cs','fr','en']) {
        candidates.push(`${origin}/${lang}/packets/list?do=list-showAllColumns`);
        candidates.push(`${origin}/${lang}/packets/list?list-id=1&do=list-showAllColumns`);
      }
      let applied = false;
      for (const url of candidates) {
        try {
          const ck = await context.cookies(url);
          const cookieHeader2 = ck.map(c => `${c.name}=${c.value}`).join('; ');
          const r = await fetch(url, { headers: {
            'Cookie': cookieHeader2,
            'User-Agent': 'Mozilla/5.0 (PlaywrightBot)',
            'Referer': await page.url(),
            'Accept': 'text/html,*/*;q=0.8',
            'X-Requested-With': 'XMLHttpRequest',
          }});
          step(`email_show_all_try ${url} -> ${r.status}`);
          if (r.ok) { applied = true; break; }
        } catch {}
      }
      if (applied) { try { await page.reload({ waitUntil:'domcontentloaded' }); } catch {} }
    } catch {}

    // Ensure the E-mail column is visible before exporting (helps enrich mode)
    try {
      step('ensure_email_column');
      let toggleHref = '';
      try { toggleHref = await page.locator('a[href*="list-column=email"]').first().getAttribute('href'); } catch {}
      if (toggleHref) {
        const href = new URL(toggleHref, await page.url()).toString();
        if (/do=list-showColumn/i.test(href)) {
          // Currently hidden -> show it
          const ck = await context.cookies(href);
          const cookieHeader2 = ck.map(c => `${c.name}=${c.value}`).join('; ');
          const r = await fetch(href, { headers: {
            'Cookie': cookieHeader2,
            'User-Agent': 'Mozilla/5.0 (PlaywrightBot)',
            'Referer': await page.url(),
            'Accept': 'text/html,*/*;q=0.8',
            'X-Requested-With': 'XMLHttpRequest',
          }});
          step(`email_toggle_show -> ${r.status}`);
          try { await page.reload({ waitUntil:'domcontentloaded' }); } catch {}
        } else if (/do=list-hideColumn/i.test(href)) {
          step('email_column_state=visible');
        } else {
          step('email_toggle_link_unknown');
        }
      } else {
        // Fallback: construct a showColumn URL from the current list URL
        try {
          const cur = new URL(await page.url());
          const base = `${cur.origin}${cur.pathname.replace(/\/$/, '')}`;
          const guesses = [
            `${base}?list-column=email&do=list-showColumn`,
            `${base}?list-id=1&list-column=email&do=list-showColumn`,
          ];
          for (const u of guesses) {
            try {
              const ck = await context.cookies(u);
              const cookieHeader2 = ck.map(c => `${c.name}=${c.value}`).join('; ');
              const r = await fetch(u, { headers: {
                'Cookie': cookieHeader2,
                'User-Agent': 'Mozilla/5.0 (PlaywrightBot)',
                'Referer': await page.url(),
                'Accept': 'text/html,*/*;q=0.8',
                'X-Requested-With': 'XMLHttpRequest',
              }});
              step(`email_toggle_probe ${u} -> ${r.status}`);
              if (r.ok) { try { await page.reload({ waitUntil:'domcontentloaded' }); } catch {} break; }
            } catch {}
          }
        } catch {}
      }
      // already forced showAllColumns above
    } catch {}

    // If email enrichment or table CSV requested, try to increase per-page to capture more rows from the list
    if (includeEmail || tableCsv) {
      try {
        const cur = new URL(await page.url());
        cur.searchParams.set('list-perPage', cur.searchParams.get('list-perPage') || '500');
        cur.searchParams.set('list-page', cur.searchParams.get('list-page') || '1');
        const target = cur.toString();
        step(`email_per_page=${cur.searchParams.get('list-perPage')}`);
        await page.goto(target, { waitUntil: 'domcontentloaded' });
      } catch {}
    }

    // Optional: capture HTML snapshot of the list page(s)
    const maybeSnapshot = async (suffix) => {
      if (!(debug || snapshotHtml)) return;
      try {
        const stamp = new Date().toISOString().replace(/[:.]/g, '-');
        const name = `snapshot-${stamp}-${suffix}.html`;
        const pth = path.join(grabbingPacketaDir, name);
        fs.writeFileSync(pth, await page.content());
        out.debug_urls = out.debug_urls || [];
        out.debug_urls.push(`/api/grabbings/packeta/file/${encodeURIComponent(name)}`);
        step(`html_snapshot_saved=${name}`);
      } catch {}
    };
    await maybeSnapshot('list-page-1');

    // Helper to scrape email map from the current list table (Order/Barcode -> Email)
    const collectEmailMap = async () => {
      try {
        const rows = await page.evaluate(() => {
          const norm = (s) => (s||'').replace(/\s+/g,' ').trim();
          const normalizeHyphens = (s) => (s||'').replace(/[\u2010-\u2015]/g,'-');
          const headersFrom = (table) => Array.from(table.querySelectorAll('thead th')).map(th => normalizeHyphens(norm(th.innerText||th.textContent||'')));
          const findTable = () => {
            const tables = Array.from(document.querySelectorAll('table'));
            for (const t of tables) {
              const hs = headersFrom(t).join(' | ').toLowerCase();
              if (/barcode|tracking|objedn|order|submission|podání|podani/i.test(hs)) return t;
            }
            return tables[0] || null;
          };
          const table = findTable();
          const rowsSel = table ? Array.from(table.querySelectorAll('tbody tr')) : Array.from(document.querySelectorAll('tr[id^="snippet-list-item-"]'));
          const headers = table ? headersFrom(table) : [];
          const findIdx = (reList) => {
            const idx = headers.findIndex(h => reList.some(re => re.test(h)));
            return idx;
          };
          const reEmail = [/^e[-\s]?mail$/i, /e[-\s\u2010-\u2015]?mail/i, /^email$/i];
          const reOrder = [/^order$/i, /objedn/i, /commande/i, /col-number/i];
          const reBarcode = [/barcode/i, /tracking/i, /trasovací/i, /trasovaci/i, /kód/i, /code barre/i];
          const reSubmission = [/^submission/i, /podání/i, /podani/i, /entry/i];
          const idxEmail = headers.length ? findIdx(reEmail) : -1;
          const idxOrder = headers.length ? findIdx(reOrder) : -1;
          const idxBarcode = headers.length ? findIdx(reBarcode) : -1;
          const idxSub = headers.length ? findIdx(reSubmission) : -1;
          const out = [];
          rowsSel.forEach(tr => {
            const tds = Array.from(tr.querySelectorAll('td'));
            if (!tds.length) return;
            const get = (i) => (i>=0 && tds[i]) ? norm(tds[i].innerText||tds[i].textContent||'') : '';
            const q = (sel) => { const el = tr.querySelector(sel); return el ? norm(el.innerText||el.textContent||'') : ''; };
            const emailFromRow = () => {
              const tdEmail = tr.querySelector('td.col-email, td[class*="col-email" i]');
              if (tdEmail) {
                const a = tdEmail.querySelector('a[href^="mailto:"]');
                if (a) { const m = (a.getAttribute('href')||'').match(/mailto:([^?&#\s]+)/i); if (m) return norm(m[1]); }
                const t = norm(tdEmail.innerText||tdEmail.textContent||'');
                const m2 = t.match(/[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}/i); if (m2) return m2[0];
              }
              const a2 = tr.querySelector('a[href^="mailto:"]');
              if (a2) { const m = (a2.getAttribute('href')||'').match(/mailto:([^?&#\s]+)/i); if (m) return norm(m[1]); }
              const txt = norm(tr.innerText||tr.textContent||'');
              const m3 = txt.match(/[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}/i); if (m3) return m3[0];
              return '';
            };
            const email = emailFromRow() || get(idxEmail);
            const order = get(idxOrder) || q('td.col-number');
            const barcode = get(idxBarcode) || q('td.col-barcode');
            const submission = get(idxSub) || q('td.col-entryNumber') || q('td.col-submission');
            const rid = tr.getAttribute('data-id') || '';
            out.push({ order, barcode, submission, email, rid });
          });
          return out;
        });
        const n = rows.length;
        let nWith = 0;
        const map = { byOrder: new Map(), byOrderNorm: new Map(), byBarcode: new Map(), byBarcodeNorm: new Map(), bySubmission: new Map(), bySubmissionNorm: new Map(), byRowId: new Map() };
        const normDigits = (s='') => String(s).replace(/\D+/g,'');
        const normToken = (s='') => String(s).replace(/[^A-Za-z0-9]+/g,'').toUpperCase();
        const tokensFromBarcode = (s='') => {
          const tokens = [];
          const parts = String(s).split(/[\s,;|]+/).filter(Boolean);
          for (const p of parts) {
            const t = normToken(p);
            if (t.length >= 6) tokens.push(t);
          }
          const m = String(s).match(/[A-Za-z0-9]{6,}/g);
          if (m) for (const z of m) { const t = normToken(z); if (t.length>=6) tokens.push(t); }
          return Array.from(new Set(tokens));
        };
        for (const r of rows) {
          const em = String(r.email||'').trim();
          if (!em) continue;
          nWith++;
          if (r.order) { map.byOrder.set(r.order, em); const k = normDigits(r.order); if (k) map.byOrderNorm.set(k, em); }
          if (r.submission) { map.bySubmission.set(r.submission, em); const ks = normDigits(r.submission); if (ks) map.bySubmissionNorm.set(ks, em); }
          if (r.barcode) {
            map.byBarcode.set(r.barcode, em);
            const toks = tokensFromBarcode(r.barcode);
            for (const t of toks) if (t) map.byBarcodeNorm.set(t, em);
          }
          if (r.rid) { const rd = normDigits(r.rid); if (rd) map.byRowId.set(rd, em); }
        }
        step(`email_scraped_rows=${n} nonempty=${nWith}`);
        return map;
      } catch {
        return { byOrder: new Map(), byOrderNorm: new Map(), byBarcode: new Map(), byBarcodeNorm: new Map(), bySubmission: new Map(), bySubmissionNorm: new Map(), byRowId: new Map() };
      }
    };

    // Helper to extract the visible table (headers + rows) exactly as displayed
    const collectTableData = async () => {
      return await page.evaluate(() => {
        const norm = (s) => (s||'').replace(/\s+/g,' ').trim();
        const normalizeHyphens = (s) => (s||'').replace(/[\u2010-\u2015]/g,'-');
        const pickText = (el) => normalizeHyphens(norm(el ? (el.innerText||el.textContent||'') : ''));
        const labelFromTh = (th) => {
          // Clone and strip interactive/filter elements to avoid dumping dropdown options into headers
          const c = th.cloneNode(true);
          c.querySelectorAll('select,option,script,style,svg,button,input,textarea,ul,li,small,form,dialog').forEach(el => el.remove());
          // Prefer direct label anchor/span/strong text if present
          const pref = c.querySelector('a, span, strong, b');
          return pickText(pref || c);
        };
        const findTable = () => {
          const tables = Array.from(document.querySelectorAll('table'));
          for (const t of tables) {
            const head = pickText(t.querySelector('thead'));
            if (/barcode|order|objedn|submission|podání|podani/i.test(head)) return t;
          }
          return tables[0] || null;
        };
        const table = findTable();
        if (!table) return { headers: [], rows: [] };
        // Prefer the first thead row that looks like labels (no inputs/selects)
        const headRows = Array.from(table.querySelectorAll('thead tr'));
        let headTr = headRows.find(r => !r.querySelector('input,select,textarea')) || headRows[0] || null;
        const ths = headTr ? Array.from(headTr.querySelectorAll('th')) : Array.from(table.querySelectorAll('thead th'));
        const headers = ths.map(labelFromTh).map(h => h.replace(/^\*\s+/,'')).map(h => h === 'E‑mail' ? 'Email' : h);
        const rows = [];
        Array.from(table.querySelectorAll('tbody tr')).forEach(tr => {
          const tds = Array.from(tr.querySelectorAll('td'));
          if (!tds.length) return;
          const cells = tds.map(td => {
            if (td.classList.contains('col-email') || /col-email/i.test(td.className||'')) {
              const a = td.querySelector('a[href^="mailto:"]');
              if (a) return (a.getAttribute('href')||'').replace(/^mailto:/i,'');
            }
            return pickText(td);
          });
          rows.push(cells);
        });
        return { headers, rows };
      });
    };

    // If enrichment requested, paginate through list pages to gather email values for all rows
    let globalEmailMap = { byOrder: new Map(), byOrderNorm: new Map(), byBarcode: new Map(), byBarcodeNorm: new Map(), bySubmission: new Map(), bySubmissionNorm: new Map() };
    let tableHeaders = null; let tableRows = [];
    if (includeEmail || tableCsv) {
      try {
        // Determine last page number
        const pages = await page.evaluate(() => {
          const links = Array.from(document.querySelectorAll('a[href*="list-page="]')).map(a => a.getAttribute('href') || '');
          const nums = links.map(href => { const m = href.match(/(?:^|[?&])list-page=(\d+)/); return m ? Number(m[1]) : 0; }).filter(n => Number.isFinite(n) && n>0);
          const max = nums.length ? Math.max(...nums) : 1;
          return { max };
        });
        const curUrl = new URL(await page.url());
        const perPage = Number(curUrl.searchParams.get('list-perPage') || 500);
        const maxPages = Math.min(Number(process.env.PACKETA_MAX_PAGES || 20), pages.max || 1);
        step(`email_pages=${pages.max||1} per_page=${perPage}`);
        const snapLimit = Math.min(Number(process.env.PACKETA_SNAPSHOT_PAGES || 2), maxPages);
        for (let p = 1; p <= maxPages; p++) {
          try {
            const u = new URL(await page.url());
            u.searchParams.set('list-page', String(p));
            const uStr = u.toString();
            step(`email_page=${p}`);
            await page.goto(uStr, { waitUntil:'domcontentloaded' });
            // Re-apply showAllColumns on each page to ensure columns stay visible across pagination
            try {
              const base = `${u.origin}${u.pathname.replace(/\/$/, '')}`;
              const pageShowAll = [
                `${base}?do=list-showAllColumns`,
                `${base}?list-id=1&do=list-showAllColumns`,
              ];
              let applied = false;
              for (const url2 of pageShowAll) {
                try {
                  const ck2 = await context.cookies(url2);
                  const cookieHeader3 = ck2.map(c => `${c.name}=${c.value}`).join('; ');
                  const r2 = await fetch(url2, { headers: {
                    'Cookie': cookieHeader3,
                    'User-Agent': 'Mozilla/5.0 (PlaywrightBot)',
                    'Referer': uStr,
                    'Accept': 'text/html,*/*;q=0.8',
                    'X-Requested-With': 'XMLHttpRequest',
                  }});
                  step(`email_show_all_page_${p} ${url2} -> ${r2.status}`);
                  if (r2.ok) { applied = true; break; }
                } catch {}
              }
              if (applied) { try { await page.reload({ waitUntil:'domcontentloaded' }); } catch {} }
            } catch {}
            const pageMap = await collectEmailMap();
            if ((debug || snapshotHtml) && p <= snapLimit) {
              await maybeSnapshot(`list-page-${p}`);
            }
            if (includeEmail) {
              for (const [k,v] of pageMap.byOrder) globalEmailMap.byOrder.set(k,v);
              for (const [k,v] of pageMap.byOrderNorm) globalEmailMap.byOrderNorm.set(k,v);
              for (const [k,v] of pageMap.byBarcode) globalEmailMap.byBarcode.set(k,v);
              for (const [k,v] of pageMap.byBarcodeNorm) globalEmailMap.byBarcodeNorm.set(k,v);
              for (const [k,v] of pageMap.bySubmission) globalEmailMap.bySubmission.set(k,v);
              for (const [k,v] of pageMap.bySubmissionNorm) globalEmailMap.bySubmissionNorm.set(k,v);
            }
            if (tableCsv) {
              const data = await collectTableData();
              if (!tableHeaders && data && Array.isArray(data.headers) && data.headers.length) tableHeaders = data.headers;
              if (data && Array.isArray(data.rows) && data.rows.length) tableRows.push(...data.rows);
              step(`table_csv_rows_page_${p}=${(data&&Array.isArray(data.rows))?data.rows.length:0}`);
            }
          } catch {}
        }
      } catch {}
    }

    // If requested, build CSV directly from table (as displayed) and return early
    if (tableCsv) {
      try {
        const stamp = new Date().toISOString().replace(/[:.]/g, '-');
        const name = `${stamp}_packeta-table.csv`;
        const dest = path.join(grabbingPacketaDir, name);
        const headers = Array.isArray(tableHeaders) ? tableHeaders : [];
        const rows = Array.isArray(tableRows) ? tableRows : [];
        const delim = ';';
        const esc = (v) => {
          const s = String(v==null?'':v);
          if (/["\n\r;]/.test(s)) return '"' + s.replace(/"/g,'""') + '"';
          return s;
        };
        const lines = [];
        if (headers.length) lines.push(headers.map(esc).join(delim));
        // Force Phone column to be text in Excel by prefixing with a leading apostrophe
        const phoneIdx = (() => {
          const idx = headers.findIndex(h => /^(phone|téléphone|telefon|telefono)$/i.test(String(h||'')) || /phone/i.test(String(h||'')));
          return idx >= 0 ? idx : -1;
        })();
        for (const arr of rows) {
          const copy = Array.isArray(arr) ? [...arr] : [];
          if (phoneIdx >= 0 && copy[phoneIdx] != null) {
            const v = String(copy[phoneIdx]);
            if (v && !/^'/.test(v)) copy[phoneIdx] = `'` + v; // Excel treats leading apostrophe as text marker
          }
          const row = copy.map(esc).join(delim);
          lines.push(row);
        }
        fs.writeFileSync(dest, lines.join('\n'));
        step(`table_csv_cols=${headers.length} rows_total=${rows.length}`);
        step(`table_csv_saved=${name}`);
        try { await importZasilkovnaCsv(dest); } catch (e) { try { step(`zasilkovna_import_error=${String(e&&e.message||e)}`); } catch {} }
        return res.json({ ok:true, login_ok: true, file: { name, path: dest, size: fs.statSync(dest).size }, download_url: `/api/grabbings/packeta/file/${encodeURIComponent(name)}`, ...out });
      } catch (e) {
        step(`table_csv_error=${String(e&&e.message||e)}`);
        // Continue with normal export fallback
      }
    }

    // Deep enrich: visit detail pages to extract email when not present on list
    if (includeEmail && deepEnrich) {
      try {
        step('email_deep_collect_links');
        const curListUrl = await page.url();
        const detailRows = await page.evaluate(() => {
          const norm = (s) => (s||'').replace(/\s+/g,' ').trim();
          const headersFrom = (table) => Array.from(table.querySelectorAll('thead th')).map(th => norm(th.innerText||th.textContent||''));
          const findTable = () => {
            const tables = Array.from(document.querySelectorAll('table'));
            for (const t of tables) {
              const hs = headersFrom(t).join(' | ').toLowerCase();
              if (/barcode|tracking|objedn|order|submission|podání|podani/i.test(hs)) return t;
            }
            return tables[0] || null;
          };
          const table = findTable();
          if (!table) return [];
          const headers = headersFrom(table);
          const findIdx = (reList) => headers.findIndex(h => reList.some(re => re.test(h)));
          const idxOrder = findIdx([/order/i, /objedn/i, /commande/i]);
          const idxBarcode = findIdx([/barcode/i, /tracking/i, /trasovací/i, /trasovaci/i, /kód/i, /code barre/i]);
          const idxSubmission = findIdx([/submission/i, /podání/i, /podani/i, /entry/i]);
          const items = [];
          Array.from(table.querySelectorAll('tbody tr')).forEach(tr => {
            const tds = Array.from(tr.querySelectorAll('td'));
            if (!tds.length) return;
            const get = (i) => (i>=0 && tds[i]) ? norm(tds[i].innerText||tds[i].textContent||'') : '';
            let href = '';
            // Prefer links in the row that look like packet detail
            const cand = tr.querySelector('a[href*="/packets/"]') || tr.querySelector('a[href*="packet"]') || tr.querySelector('a[href*="detail"]') || tr.querySelector('a[href]');
            if (cand) href = cand.getAttribute('href') || '';
            items.push({ order: get(idxOrder), barcode: get(idxBarcode), submission: get(idxSubmission), href });
          });
          return items;
        });
        const limit = Math.min(Number(process.env.PACKETA_DEEP_LIMIT || 100), detailRows.length);
        const cookieHeader = (await (async () => {
          try { const ck = await context.cookies(curListUrl); return ck.map(c => `${c.name}=${c.value}`).join('; '); } catch { return ''; }
        })());
        const emailRe = /[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}/ig;
        let found = 0;
        const normDigits = (s='') => String(s).replace(/\D+/g,'');
        const normToken = (s='') => String(s).replace(/[^A-Za-z0-9]+/g,'').toUpperCase();
        const tokensFromBarcode = (s='') => {
          const tokens = [];
          const parts = String(s).split(/[\s,;|]+/).filter(Boolean);
          for (const p of parts) {
            const t = normToken(p);
            if (t.length >= 6) tokens.push(t);
          }
          const m = String(s).match(/[A-Za-z0-9]{6,}/g);
          if (m) for (const z of m) { const t = normToken(z); if (t.length>=6) tokens.push(t); }
          return Array.from(new Set(tokens));
        };
        const deepSnapLimit = Math.min(Number(process.env.PACKETA_DEEP_SNAPSHOT || 3), limit);
        for (let i=0; i<limit; i++) {
          const it = detailRows[i];
          if (!it || !it.href) continue;
          const abs = new URL(it.href, curListUrl).toString();
          try {
            const r = await fetch(abs, { headers: { 'Cookie': cookieHeader, 'User-Agent': 'Mozilla/5.0 (PlaywrightBot)', 'Referer': curListUrl, 'Accept': 'text/html,*/*;q=0.8' } });
            step(`email_deep_req ${abs} -> ${r.status}`);
            if (!r.ok) continue;
            const html = await r.text();
            if ((debug || snapshotHtml) && i < deepSnapLimit) {
              try {
                const stamp = new Date().toISOString().replace(/[:.]/g,'-');
                const name = `detail-${stamp}-${i+1}.html`;
                const pth = path.join(grabbingPacketaDir, name);
                fs.writeFileSync(pth, html);
                out.debug_urls = out.debug_urls || [];
                out.debug_urls.push(`/api/grabbings/packeta/file/${encodeURIComponent(name)}`);
              } catch {}
            }
            const mailto = (html.match(/mailto:([^"'\s]+)/i) || [,''])[1];
            const emails = [];
            if (mailto) emails.push(mailto);
            const m = html.match(emailRe); if (m) emails.push(...m);
            const email = (emails.find(e => /@/.test(e)) || '').replace(/^mailto:/i,'').trim();
            if (!email) continue;
            found++;
            const order = it.order || '';
            const submission = it.submission || '';
            const barcode = it.barcode || '';
            if (order) { globalEmailMap.byOrder.set(order, email); const k = normDigits(order); if (k) globalEmailMap.byOrderNorm.set(k, email); }
            if (submission) { const ks = normDigits(submission); if (ks) globalEmailMap.bySubmissionNorm.set(ks, email); globalEmailMap.bySubmission.set(submission, email); }
            if (barcode) {
              globalEmailMap.byBarcode.set(barcode, email);
              const toks = tokensFromBarcode(barcode);
              for (const t of toks) globalEmailMap.byBarcodeNorm.set(t, email);
            }
          } catch {}
        }
        step(`email_deep_scanned=${limit} found=${found}`);
      } catch {}
    }

    // Helper to merge the scraped email map into a CSV file (in-place)
    const mergeEmailIntoCsv = (filePath, map, label='E-mail') => {
      try {
        const text = fs.readFileSync(filePath, 'utf8');
        const lines = text.split(/\r?\n/);
        if (!lines.length) return false;
        const header = lines[0];
        const pickDelim = (h) => {
          const cands = [';', '\t', ','];
          let best = ';', bestCount = -1;
          for (const d of cands) { const c = h.split(d).length; if (c > bestCount) { best = d; bestCount = c; } }
          return best;
        };
        const d = pickDelim(header);
        const cols = header.split(d).map(s=>s.trim());
        const hasEmailCol = cols.some(c => /^(e[-\s]?mail|email)$/i.test(c));
        if (!hasEmailCol) cols.push(label);
        const idxOrder = cols.findIndex(c => /^(order|objedn|commande)/i.test(c));
        const idxBarcode = cols.findIndex(c => /(barcode|tracking|trasovací|trasovaci)/i.test(c));
        const idxSubmission = cols.findIndex(c => /(submission|podání|podani|entry)/i.test(c));
        const out = [cols.join(d)];
        let filled = 0;
        const normDigits = (s='') => String(s).replace(/\D+/g,'');
        const normToken = (s='') => String(s).replace(/[^A-Za-z0-9]+/g,'').toUpperCase();
        const tokensFromBarcode = (s='') => {
          const tokens = [];
          const parts = String(s).split(/[\s,;|]+/).filter(Boolean);
          for (const p of parts) {
            const t = normToken(p);
            if (t.length >= 6) tokens.push(t);
          }
          const m = String(s).match(/[A-Za-z0-9]{6,}/g);
          if (m) for (const z of m) { const t = normToken(z); if (t.length>=6) tokens.push(t); }
          return Array.from(new Set(tokens));
        };
        for (let i=1;i<lines.length;i++) {
          const l = lines[i]; if (l === '') { out.push(l); continue; }
          const parts = l.split(d);
          while (parts.length < cols.length - (hasEmailCol?0:1)) parts.push('');
          let emailVal = '';
          const order = idxOrder>=0 ? (parts[idxOrder]||'').trim() : '';
          const barcode = idxBarcode>=0 ? (parts[idxBarcode]||'').trim() : '';
          const submission = idxSubmission>=0 ? (parts[idxSubmission]||'').trim() : '';
          // Exact matches
          if (!emailVal && order && map.byOrder && map.byOrder.has(order)) emailVal = map.byOrder.get(order);
          if (!emailVal && barcode && map.byBarcode && map.byBarcode.has(barcode)) emailVal = map.byBarcode.get(barcode);
          if (!emailVal && submission && map.bySubmission && map.bySubmission.has(submission)) emailVal = map.bySubmission.get(submission);
          // Normalized matches
          if (!emailVal && order && map.byOrderNorm) { const k = normDigits(order); if (k && map.byOrderNorm.has(k)) emailVal = map.byOrderNorm.get(k); }
          if (!emailVal && submission && map.bySubmissionNorm) { const ks = normDigits(submission); if (ks && map.bySubmissionNorm.has(ks)) emailVal = map.bySubmissionNorm.get(ks); }
          if (!emailVal && barcode && map.byBarcodeNorm) {
            const toks = tokensFromBarcode(barcode);
            for (const t of toks) { if (map.byBarcodeNorm.has(t)) { emailVal = map.byBarcodeNorm.get(t); break; } }
          }
          // Row id fallback: use the first 6+ digit group from barcode (e.g., "2602640499")
          if (!emailVal && barcode && map.byRowId) {
            const rid = (barcode.match(/\d{6,}/g) || [])[0] || '';
            if (rid && map.byRowId.has(rid)) emailVal = map.byRowId.get(rid);
          }
          if (!hasEmailCol) parts.push(emailVal);
          else {
            const idxE = cols.findIndex(c => /^(e[-\s]?mail|email)$/i.test(c));
            if (idxE >= 0) parts[idxE] = emailVal;
          }
          if (emailVal) filled++;
          out.push(parts.join(d));
        }
        fs.writeFileSync(filePath, out.join('\n'));
        step(`email_csv_merge_filled=${filled}`);
        return true;
      } catch (e) { step(`email_csv_merge_error=${String(e&&e.message||e)}`); return false; }
    };

    // Detect login success heuristically
    let loginOk = false;
    try {
      // Presence of logout or account indicator
      const logoutLoc = page.locator('a:has-text("Sign out"), a:has-text("Log out"), a[href*="sign/out" i], button:has-text("Sign out")');
      if (await logoutLoc.count()) loginOk = true;
    } catch {}
    if (!loginOk) {
      try { await page.waitForURL(/packets\/list/i, { timeout: 8000 }); loginOk = true; } catch {}
    }
    step(`login_ok=${loginOk}`);
    try { const ck = await context.cookies(); step(`cookies_after_login=${ck?.length||0}; domains=${Array.from(new Set((ck||[]).map(c=>c.domain))).slice(0,3).join(',')}`); } catch {}
    // Try to find CSV export control; click triggers a download
    const triggers = [
      'a:has-text("CSV")',
      'a:has-text("CSV export")',
      'a[title*="CSV export" i]',
      'button:has-text("CSV")',
      'a[download$=".csv" i]',
      'a[href*="csv" i]',
      'a[href*="do=list-export" i]',
      'button:has-text("Export")',
      // French variants
      'a:has-text("Export des expéditions")',
      'a:has-text("Export des expéditions en format CSV")',
      'button:has-text("Exporter")',
    ];
    let clicked = false, download, exportUrl, usedSelector = '';
    for (const sel of triggers) {
      const loc = page.locator(sel).first();
      const cnt = await loc.count();
      step(`selector ${sel} count=${cnt}`);
      if (!cnt) continue;
      // Prefer reading the href and fetching directly to avoid overlays intercepting clicks
      try { exportUrl = await loc.getAttribute('href'); } catch {}
      if (!exportUrl) { try { exportUrl = await loc.evaluate(el => el && el.getAttribute('href')); } catch {} }
      usedSelector = sel;
      clicked = true; // mark as handled so we skip generic probes and use exportUrl fetch below
      // Try to click to capture a direct download when possible; if it fails, we'll still fetch via exportUrl
      try {
        const p1 = page.waitForEvent('download', { timeout: 30000 }).catch(()=>null);
        await loc.click({ timeout: 30000 });
        download = await p1;
      } catch (e) {
        try { step(`click_error ${String(e?.message||e).replace(/\s+/g,' ').slice(0,180)}`); } catch {}
      }
      break;
    }
    if (!clicked) {
      // As last resort, directly probe export endpoints and, if needed,
      // parse the HTML snippet that reveals the actual CSV export link.
      let candidates = [];
      try {
        const cur = new URL(listUrl || (await page.url()), await page.url());
        const origin = cur.origin;
        const pathname = cur.pathname.replace(/\/$/, '');
        const baseFromList = `${origin}${pathname}`; // e.g., /en/packets/list
        candidates.push(`${baseFromList}?do=list-export`);
        candidates.push(`${baseFromList}?list-id=1&do=list-export`);
        // Try common locales explicitly (include 'cs' due to Packeta default)
        for (const lang of ['cs','fr','en']) {
          candidates.push(`${origin}/${lang}/packets/list?do=list-export`);
          candidates.push(`${origin}/${lang}/packets/list?list-id=1&do=list-export`);
        }
      } catch {
        // Fallback to origin-based guesses
        const base = await page.url();
        const u = new URL(base);
        for (const lang of ['cs','fr','en']) {
          candidates.push(`${u.origin}/${lang}/packets/list?do=list-export`);
          candidates.push(`${u.origin}/${lang}/packets/list?list-id=1&do=list-export`);
        }
      }
      step(`no_button_try_fetch=${candidates.length}`);
      let fetched = null, urlUsed = '';
      for (const url of candidates) {
        try {
          const ck = await context.cookies(url);
          const cookieHeader2 = ck.map(c => `${c.name}=${c.value}`).join('; ');
          const r2 = await fetch(url, { headers: {
            'Cookie': cookieHeader2,
            'User-Agent': 'Mozilla/5.0 (PlaywrightBot)',
            'Referer': listUrl,
            'Accept': 'text/csv,application/octet-stream,text/html;q=0.9,*/*;q=0.8',
          } });
          step(`probe_export ${url} -> ${r2.status}`);
          if (!r2.ok) continue;
          const ct = r2.headers.get('content-type') || '';
          if (/csv|octet-stream/i.test(ct)) {
            // Direct CSV response
            fetched = Buffer.from(await r2.arrayBuffer());
            urlUsed = url;
            break;
          }
          // Some locales first return an HTML snippet with the real CSV link (e.g., '#snippet-list-exports').
          const text = await r2.text();
          // Try to extract the first anchor inside the exports snippet
          // Example: <span id="snippet-list-exports"><a ... href="/cs/packets/list?...&do=list-export">CSV export ...</a></span>
          let href = '';
          try {
            const m = text.match(/id=["']snippet-list-exports["'][^>]*>[\s\S]*?<a[^>]+href=["']([^"']+)["']/i);
            if (m && m[1]) href = m[1];
          } catch {}
          if (!href) {
            // Fallback: any anchor mentioning CSV or list-export
            const m2 = text.match(/<a[^>]+href=["']([^"']+do=list-export[^"']*)["'][^>]*>([^<]{0,120})<\/a>/i);
            if (m2 && m2[1]) href = m2[1];
          }
          if (href) {
            // Decode HTML entities for '&' if present
            href = href.replace(/&amp;/g, '&');
            const abs = new URL(href, url).toString();
            try {
              const r3 = await fetch(abs, { headers: {
                'Cookie': cookieHeader2,
                'User-Agent': 'Mozilla/5.0 (PlaywrightBot)',
                'Referer': listUrl,
                'Accept': 'text/csv,application/octet-stream,*/*;q=0.8',
              } });
              step(`probe_follow ${abs} -> ${r3.status}`);
              if (r3.ok) {
                const ct3 = r3.headers.get('content-type') || '';
                if (/csv|octet-stream/i.test(ct3)) {
                  fetched = Buffer.from(await r3.arrayBuffer());
                  urlUsed = abs;
                  break;
                }
              }
            } catch {}
          }
        } catch {}
      }
      if (!fetched) {
        // Provide debug artifacts when debug mode is enabled
        const debugUrls = [];
        if (debug && page) {
          try {
            const snapName = `debug-${new Date().toISOString().replace(/[:.]/g,'-')}.html`;
            const snapPath = path.join(grabbingPacketaDir, snapName);
            fs.writeFileSync(snapPath, await page.content());
            debugUrls.push(`/api/grabbings/packeta/file/${encodeURIComponent(snapName)}`);
          } catch {}
          try {
            const pngName = `debug-${new Date().toISOString().replace(/[:.]/g,'-')}.png`;
            const pngPath = path.join(grabbingPacketaDir, pngName);
            await page.screenshot({ path: pngPath, fullPage: true });
            debugUrls.push(`/api/grabbings/packeta/file/${encodeURIComponent(pngName)}`);
          } catch {}
        }
        return res.status(404).json({ ok:false, error:'csv_button_not_found', message:'Could not find CSV export control on page.' , debug_urls: debugUrls, ...out });
      }
      const stamp2 = new Date().toISOString().replace(/[:.]/g, '-');
      const name2 = `${stamp2}_packeta.csv`;
      const dest2 = path.join(grabbingPacketaDir, name2);
      fs.writeFileSync(dest2, fetched);
      step(`saved ${name2} via probe ${urlUsed}`);
      // Email enrichment (optional)
      let emailMap = globalEmailMap && (globalEmailMap.byOrder || globalEmailMap.byBarcode || globalEmailMap.bySubmission)
        ? globalEmailMap
        : { byOrder:new Map(), byBarcode:new Map(), bySubmission:new Map() };
      if (includeEmail) {
        try { mergeEmailIntoCsv(dest2, emailMap); } catch {}
      }
      try {
        const imp = await importZasilkovnaCsv(dest2);
        try { step(`zasilkovna_import_ok=${!!(imp&&imp.ok)} total=${imp?.total||0} inserted=${imp?.inserted||0} updated=${imp?.updated||0} skipped=${imp?.skipped||0} failed=${imp?.failed||0}`); } catch {}
        try { if (imp && Array.isArray(imp.failed_lines) && imp.failed_lines.length) step(`zasilkovna_import_failed_lines=${imp.failed_lines.join(',')}`); } catch {}
        try { if (imp && Array.isArray(imp.skipped_lines) && imp.skipped_lines.length) step(`zasilkovna_import_skipped_lines=${imp.skipped_lines.join(',')}`); } catch {}
      } catch (e) { try { step(`zasilkovna_import_error=${String(e&&e.message||e)}`); } catch {} }
      return res.json({ ok:true, login_ok: loginOk, file: { name: name2, path: dest2, size: fetched.length }, download_url: `/api/grabbings/packeta/file/${encodeURIComponent(name2)}`, ...out });
    }
    step(`export_selector_used=${usedSelector}`);
    const stamp = new Date().toISOString().replace(/[:.]/g, '-');
    // If Playwright generated a download, use it; else fall back to cookie-authenticated fetch
    if (download) {
      const suggested = download.suggestedFilename();
      const safe = (suggested || 'packeta.csv').replace(/[^a-zA-Z0-9_.-]/g, '_');
      const name = `${stamp}_${safe}`;
      const dest = path.join(grabbingPacketaDir, name);
      await download.saveAs(dest);
      step(`saved ${name} via download`);
      // Email enrichment (optional)
      let emailMap = globalEmailMap && (globalEmailMap.byOrder || globalEmailMap.byBarcode || globalEmailMap.bySubmission)
        ? globalEmailMap
        : { byOrder:new Map(), byBarcode:new Map(), bySubmission:new Map() };
      if (includeEmail) {
        try { mergeEmailIntoCsv(dest, emailMap); } catch {}
      }
      try {
        const imp = await importZasilkovnaCsv(dest);
        try { step(`zasilkovna_import_ok=${!!(imp&&imp.ok)} total=${imp?.total||0} inserted=${imp?.inserted||0} updated=${imp?.updated||0} skipped=${imp?.skipped||0} failed=${imp?.failed||0}`); } catch {}
        try { if (imp && Array.isArray(imp.failed_lines) && imp.failed_lines.length) step(`zasilkovna_import_failed_lines=${imp.failed_lines.join(',')}`); } catch {}
        try { if (imp && Array.isArray(imp.skipped_lines) && imp.skipped_lines.length) step(`zasilkovna_import_skipped_lines=${imp.skipped_lines.join(',')}`); } catch {}
      } catch (e) { try { step(`zasilkovna_import_error=${String(e&&e.message||e)}`); } catch {} }
      return res.json({ ok:true, login_ok: loginOk, file: { name, path: dest }, download_url: `/api/grabbings/packeta/file/${encodeURIComponent(name)}`, ...out });
    }
    // Build absolute export URL
    let abs = exportUrl ? new URL(exportUrl, await page.url()).toString() : await page.url();
    step(`export_url: ${abs}`);
    // Build Cookie header from browser context
    let cookieHeader = '';
    try {
      const ck = await context.cookies(abs);
      cookieHeader = ck.map(c => `${c.name}=${c.value}`).join('; ');
      step(`fetch_cookies_count=${ck?.length||0}`);
    } catch {}
    const r = await fetch(abs, { headers: { 'Cookie': cookieHeader, 'User-Agent': 'Mozilla/5.0 (PlaywrightBot)' } });
    if (!r.ok) {
      step(`fetch_status=${r.status}`);
      return res.status(502).json({ ok:false, login_ok: loginOk, error:'csv_fetch_failed', message:`HTTP ${r.status}`, export_url: abs, ...out });
    }
    const buf = Buffer.from(await r.arrayBuffer());
    const name = `${stamp}_packeta.csv`;
    const dest = path.join(grabbingPacketaDir, name);
    fs.writeFileSync(dest, buf);
    step(`saved ${name} via fetch (${buf.length} bytes)`);
    // Email enrichment (optional)
    let emailMap = globalEmailMap && (globalEmailMap.byOrder || globalEmailMap.byBarcode || globalEmailMap.bySubmission)
      ? globalEmailMap
      : { byOrder:new Map(), byBarcode:new Map(), bySubmission:new Map() };
    if (includeEmail) {
      try { mergeEmailIntoCsv(dest, emailMap); } catch {}
    }
    try {
      const imp = await importZasilkovnaCsv(dest);
      try { step(`zasilkovna_import_ok=${!!(imp&&imp.ok)} total=${imp?.total||0} inserted=${imp?.inserted||0} updated=${imp?.updated||0} skipped=${imp?.skipped||0} failed=${imp?.failed||0}`); } catch {}
      try { if (imp && Array.isArray(imp.failed_lines) && imp.failed_lines.length) step(`zasilkovna_import_failed_lines=${imp.failed_lines.join(',')}`); } catch {}
      try { if (imp && Array.isArray(imp.skipped_lines) && imp.skipped_lines.length) step(`zasilkovna_import_skipped_lines=${imp.skipped_lines.join(',')}`); } catch {}
    } catch (e) { try { step(`zasilkovna_import_error=${String(e&&e.message||e)}`); } catch {} }
    return res.json({ ok:true, login_ok: loginOk, file: { name, path: dest, size: buf.length }, download_url: `/api/grabbings/packeta/file/${encodeURIComponent(name)}`, ...out });
  } catch (e) {
    // Optional debug artifacts
    const stamp = new Date().toISOString().replace(/[:.]/g, '-');
    const debugUrls = [];
    if (debug && page) {
      try {
        const snapName = `debug-${stamp}.html`;
        const snapPath = path.join(grabbingPacketaDir, snapName);
        fs.writeFileSync(snapPath, await page.content());
        debugUrls.push(`/api/grabbings/packeta/file/${encodeURIComponent(snapName)}`);
      } catch {}
      try {
        const pngName = `debug-${stamp}.png`;
        const pngPath = path.join(grabbingPacketaDir, pngName);
        await page.screenshot({ path: pngPath, fullPage: true });
        debugUrls.push(`/api/grabbings/packeta/file/${encodeURIComponent(pngName)}`);
      } catch {}
    }
    try { step(`error: ${String(e?.message||e)}`); } catch {}
    return res.status(500).json({ ok:false, error:'packeta_download_failed', message:String(e?.message||e), debug_urls: debugUrls, ...out });
  } finally {
    try { await page?.close(); } catch {}
    try { await context?.close(); } catch {}
    try { await browser?.close(); } catch {}
  }
});

app.get('/api/grabbings/packeta/latest', async (_req, res) => {
  try {
    const files = fs.readdirSync(grabbingPacketaDir).filter(f => f && !f.startsWith('.'));
    const items = files.map(name => {
      const p = path.join(grabbingPacketaDir, name);
      const st = fs.statSync(p);
      return { name, size: st.size, mtime: st.mtime.toISOString(), download_url: `/api/grabbings/packeta/file/${encodeURIComponent(name)}` };
    }).sort((a,b)=> new Date(b.mtime) - new Date(a.mtime));
    res.json({ ok:true, items });
  } catch (e) { res.status(500).json({ ok:false, error:'list_failed', message:String(e?.message||e) }); }
});

// Delete downloaded Packeta CSV files (keeps non-CSV debug artifacts unless all=true)
app.post('/api/grabbings/packeta/cleanup', async (req, res) => {
  try {
    const removeAll = !!(req.body && (req.body.all === true || req.body.all === 'true'));
    const names = fs.readdirSync(grabbingPacketaDir).filter(f => f && !f.startsWith('.'));
    const removed = [];
    const kept = [];
    for (const name of names) {
      const ext = String(path.extname(name) || '').toLowerCase();
      const isCsv = ext === '.csv';
      if (removeAll || isCsv) {
        try { fs.unlinkSync(path.join(grabbingPacketaDir, name)); removed.push(name); } catch { kept.push(name); }
      } else kept.push(name);
    }
    res.json({ ok:true, removed_count: removed.length, kept_count: kept.length, removed, kept });
  } catch (e) {
    res.status(500).json({ ok:false, error:'cleanup_failed', message:String(e?.message||e) });
  }
});

app.get('/api/grabbings/packeta/file/:name', (req, res) => {
  try {
    const name = String(req.params.name||'');
    if (!/^[\w_.\-]+$/.test(name)) return res.status(400).send('bad name');
    const p = path.join(grabbingPacketaDir, name);
    if (!fs.existsSync(p)) return res.status(404).send('not found');
    const ext = String(path.extname(name) || '').toLowerCase();
    let ct = 'application/octet-stream';
    if (ext === '.csv') ct = 'text/csv; charset=utf-8';
    else if (ext === '.png') ct = 'image/png';
    else if (ext === '.html' || ext === '.htm') ct = 'text/html; charset=utf-8';
    res.setHeader('Content-Type', ct);
    const disp = (ext === '.png' || ext === '.html' || ext === '.htm') ? 'inline' : 'attachment';
    res.setHeader('Content-Disposition', `${disp}; filename="${name}"`);
    fs.createReadStream(p).pipe(res);
  } catch (e) { res.status(500).send('error'); }
});

// ===================== CRON JOBS (scheduler + API) ==========================
function makeCronId() { return `cron_${Date.now().toString(36)}_${Math.random().toString(36).slice(2,8)}`; }

function computeNextRunForJob(job, fromDate = new Date()) {
  try {
    const from = new Date(fromDate);
    if (Number.isFinite(Number(job.every_hours)) && Number(job.every_hours) > 0) {
      const hrs = Number(job.every_hours);
      const next = new Date(from.getTime() + hrs * 3600 * 1000);
      return next;
    }
    if (Number.isFinite(Number(job.every_days)) && Number(job.every_days) > 0) {
      const days = Number(job.every_days);
      const base = new Date(from.getTime());
      // Target time of day (HH:mm)
      let hh = 0, mm = 0;
      try {
        const m = /^\s*(\d{1,2})(?::(\d{1,2}))?\s*$/.exec(String(job.at_time||''));
        if (m) { hh = Math.min(23, Math.max(0, +m[1])); mm = Math.min(59, Math.max(0, +(m[2]||0))); }
      } catch {}
      // Set to today's target time; if already passed, add 'days' days
      const next = new Date(base.getTime());
      next.setHours(hh, mm, 0, 0);
      if (next <= base) next.setDate(next.getDate() + days);
      return next;
    }
  } catch {}
  // default: 1 hour later
  return new Date(Date.now() + 3600*1000);
}

async function ensureCronJobNextRun(id) {
  try {
    const r = await pool.query(`SELECT * FROM cron_job WHERE id=$1 LIMIT 1`, [id]);
    if (!r.rowCount) return;
    const j = r.rows[0];
    const next = computeNextRunForJob(j);
    await pool.query(`UPDATE cron_job SET next_run=$1, updated_at=NOW() WHERE id=$2`, [next, id]);
  } catch {}
}

const runningCronJobs = new Set();
async function executeCronTask(job) {
  const task = String(job.task||'');
  const opts = job.options && typeof job.options === 'object' ? job.options : {};
  // Build base URL for internal calls
  const port = Number(process.env.PORT || 3010);
  const base = `http://127.0.0.1:${port}`;
  try {
    if (task === 'packeta_download') {
      // Resolve effective options: prefer grabbing_config options when requested
      let eff = { ...opts };
      try {
        const useGrab = !!opts.use_grabbing;
        const gid = String(opts.grabbing_id||'').trim();
        if (useGrab && gid) {
          const r = await pool.query(`SELECT options FROM grabbing_config WHERE id=$1 LIMIT 1`, [gid]);
          if (r.rowCount) {
            let got = r.rows[0].options || {};
            if (typeof got === 'string') { try { got = JSON.parse(got); } catch {} }
            const packeta = got && got.packeta ? got.packeta : {};
            // Start with grabbing options, then allow explicit overrides in job options
            eff = { ...packeta, ...opts };
          }
        }
      } catch {}
      const body = {};
      if (eff.email) body.email = String(eff.email);
      if (eff.password) body.password = String(eff.password);
      if (eff.signInUrl || eff.sign_in_url) body.sign_in_url = String(eff.signInUrl || eff.sign_in_url);
      if (eff.listUrl || eff.list_url) body.list_url = String(eff.listUrl || eff.list_url);
      if (eff.debug) body.debug = true;
      if (eff.includeEmail || eff.include_email) body.include_email = true;
      if (eff.deepEnrich || eff.deep_enrich) body.deep_enrich = true;
      if (eff.snapshotHtml || eff.snapshot_html) body.snapshot_html = true;
      if (eff.tableCsv || eff.table_csv) body.table_csv = true;
      const r = await fetch(`${base}/api/grabbings/packeta/download`, { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(body) });
      const t = await r.text(); let j=null; try{ j=t?JSON.parse(t):null; }catch{}
      return { ok: r.ok && !!(j && j.ok), status: r.status, body: j || t };
    }
    if (task === 'packeta_cleanup') {
      const body = { all: !!opts.all };
      const r = await fetch(`${base}/api/grabbings/packeta/cleanup`, { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(body) });
      const t = await r.text(); let j=null; try{ j=t?JSON.parse(t):null; }catch{}
      return { ok: r.ok && !!(j && j.ok), status: r.status, body: j || t };
    }
  } catch (e) {
    return { ok:false, error: String(e?.message||e) };
  }
  return { ok:false, error:'unknown_task' };
}

async function runCronJob(job) {
  const id = job.id;
  if (runningCronJobs.has(id)) return;
  runningCronJobs.add(id);
  try {
    const result = await executeCronTask(job);
    const next = computeNextRunForJob(job, new Date());
    await pool.query(`UPDATE cron_job SET last_run=NOW(), next_run=$1, updated_at=NOW() WHERE id=$2`, [next, id]);
    try { logToFile(`[cron] job=${id} task=${job.task} ok=${!!result.ok}`); } catch {}
  } catch (e) {
    try { logToFile(`[cron_err] job=${id} ${e?.message||e}`); } catch {}
  } finally {
    runningCronJobs.delete(id);
  }
}

async function cronTick() {
  try {
    await ensureTables();
    // Ensure next_run exists for all enabled jobs
    try { await pool.query(`UPDATE cron_job SET next_run = COALESCE(next_run, NOW()) WHERE enabled = TRUE AND next_run IS NULL`); } catch {}
    const r = await pool.query(`SELECT * FROM cron_job WHERE enabled = TRUE AND (next_run IS NULL OR next_run <= NOW()) ORDER BY next_run NULLS FIRST LIMIT 4`);
    for (const job of r.rows) {
      runCronJob(job); // do not await; run in parallel with small limit
    }
  } catch (e) { try { logToFile(`[cron_tick_err] ${e?.message||e}`); } catch {} }
}

setInterval(cronTick, 60 * 1000);

// API: tasks and jobs CRUD
app.get('/api/cron/tasks', (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  res.json({ ok:true, tasks: [
    { id:'packeta_download', name:'Zásilkovna Download CSV', options: { email:'', password:'', sign_in_url:'', list_url:'', table_csv:true, include_email:true } },
    { id:'packeta_cleanup', name:'Zásilkovna Clean up CSVs', options: { all:false } },
  ]});
});

app.get('/api/cron/jobs', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    const r = await pool.query(`SELECT * FROM cron_job ORDER BY updated_at DESC`);
    res.json({ ok:true, items: r.rows });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
});

app.post('/api/cron/jobs', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    const b = req.body || {};
    const id = String(b.id||'').trim() || makeCronId();
    const name = String(b.name||'').trim();
    const task = String(b.task||'').trim();
    const every_hours = Number.isFinite(+b.every_hours) && +b.every_hours > 0 ? Math.floor(+b.every_hours) : null;
    const every_days = Number.isFinite(+b.every_days) && +b.every_days > 0 ? Math.floor(+b.every_days) : null;
    const at_time = typeof b.at_time === 'string' ? b.at_time.trim() : null;
    const options = (b.options && typeof b.options === 'object') ? b.options : null;
    const enabled = b.enabled === undefined ? true : !!b.enabled;
    if (!name || !task || (!every_hours && !every_days)) return res.status(400).json({ ok:false, error:'bad_request' });
    const next = computeNextRunForJob({ every_hours, every_days, at_time });
    const r = await pool.query(`
      INSERT INTO cron_job (id, name, task, every_hours, every_days, at_time, options, enabled, last_run, next_run, created_at, updated_at)
      VALUES ($1,$2,$3,$4,$5,$6,$7::json,$8,NULL,$9,NOW(),NOW())
      RETURNING *
    `, [id, name, task, every_hours, every_days, at_time, JSON.stringify(options||{}), enabled, next]);
    res.json({ ok:true, item: r.rows[0] });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
});

app.patch('/api/cron/jobs/:id', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    const id = String(req.params.id||'').trim();
    const b = req.body || {};
    const allowed = ['name','task','every_hours','every_days','at_time','options','enabled'];
    const ent = Object.entries(b).filter(([k]) => allowed.includes(k));
    if (!ent.length) return res.status(400).json({ ok:false, error:'bad_request' });
    const fields = ent.map(([k],i)=> (k==='options'?`${k} = $${i+1}::json`:`${k} = $${i+1}`));
    const vals = ent.map(([k,v]) => (k==='options' && v && typeof v==='object') ? JSON.stringify(v) : v);
    fields.push('updated_at = NOW()');
    const r = await pool.query(`UPDATE cron_job SET ${fields.join(', ')} WHERE id = $${vals.length+1} RETURNING *`, [...vals, id]);
    if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
    // Recompute next_run after update
    const next = computeNextRunForJob(r.rows[0]);
    await pool.query(`UPDATE cron_job SET next_run=$1 WHERE id=$2`, [next, id]);
    const r2 = await pool.query(`SELECT * FROM cron_job WHERE id=$1`, [id]);
    res.json({ ok:true, item: r2.rows[0] });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
});

app.post('/api/cron/jobs/:id/run', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    const id = String(req.params.id||'').trim();
    const r = await pool.query(`SELECT * FROM cron_job WHERE id=$1 LIMIT 1`, [id]);
    if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
    runCronJob(r.rows[0]);
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
});

app.delete('/api/cron/jobs/:id', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    const id = String(req.params.id||'').trim();
    await pool.query(`DELETE FROM cron_job WHERE id=$1`, [id]);
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
});


/* Moved to module: Smartsupp legacy routes
app.get('/api/smartsupp/download', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  const token = await resolveSmartsuppToken(req);
  if (!token) return res.status(400).json({ ok:false, error:'missing_token' });
  try {
    const size = Math.max(1, Math.min(Number(req.query?.size)||50, 500));
    const format = String(req.query?.format || 'json').toLowerCase();
    const payload = { size, sort: [{ createdAt: 'desc' }] };
    const r = await fetch(`${SM_BASE}/v2/conversations/search`, {
      method: 'POST', headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${token}` }, body: JSON.stringify(payload)
    });
    const j = await r.json().catch(()=>({}));
    if (!r.ok) return res.status(r.status).json({ ok:false, error:'upstream_error', message: j?.message || j?.error || `http_${r.status}`, data: j });
    const items = Array.isArray(j?.items) ? j.items : (Array.isArray(j?.hits) ? j.hits : (Array.isArray(j) ? j : []));
    if (format === 'csv') {
      const cols = ['id','createdAt','lastMessageAt','status','assigneeId','agentName','visitorName','visitorEmail'];
      const header = cols.join(',');
      const esc = (s) => '"' + String(s==null? "": s).replace(/"/g,'""') + '"';
      const lines = items.map(x => {
        const v = x?.visitor || x?.customer || {};
        const ass = x?.assignee || {};
        return [x?.id, x?.createdAt || x?.created_at, x?.lastMessageAt || x?.updatedAt, x?.status, ass?.id, ass?.name || ass?.email || '', v?.name || '', v?.email || ''].map(esc).join(',');
      });
      const csv = [header, ...lines].join('\n');
      res.setHeader('Content-Type', 'text/csv');
      res.setHeader('Content-Disposition', `attachment; filename="smartsupp_conversations_${Date.now()}.csv"`);
      return res.send(csv);
    } else {
      res.setHeader('Content-Type', 'application/json');
      res.setHeader('Content-Disposition', `attachment; filename="smartsupp_conversations_${Date.now()}.json"`);
      return res.send(JSON.stringify({ items }, null, 2));
    }
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Download all conversations within a date range [from, to] (inclusive)
// Query: from=YYYY-MM-DD[THH:mm[:SS]] to=YYYY-MM-DD[THH:mm[:SS]] format=json|csv size=100 max_pages=50
app.get('/api/smartsupp/download-range', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  const token = await resolveSmartsuppToken(req);
  if (!token) return res.status(400).json({ ok:false, error:'missing_token' });

  const parseDate = (v, endOfDay = false) => {
    if (!v) return null;
    try {
      const s = String(v).trim();
      if (!s) return null;
      // If only date provided, expand to start/end of day
      if (/^\d{4}-\d{2}-\d{2}$/.test(s)) {
        const iso = endOfDay ? `${s}T23:59:59.999Z` : `${s}T00:00:00.000Z`;
        const d = new Date(iso);
        return isNaN(d.getTime()) ? null : d;
      }
      // Support dd/mm/yyyy or dd-mm-yyyy
      let m = /^(\d{1,2})[\/.-](\d{1,2})[\/.-](\d{4})$/.exec(s);
      if (m) {
        const dd = parseInt(m[1], 10), MM = parseInt(m[2], 10), yyyy = parseInt(m[3], 10);
        if (yyyy > 1900 && MM >= 1 && MM <= 12 && dd >= 1 && dd <= 31) {
          const d = new Date(Date.UTC(yyyy, MM - 1, dd, endOfDay?23:0, endOfDay?59:0, endOfDay?59:0, endOfDay?999:0));
          return isNaN(d.getTime()) ? null : d;
        }
      }
      const d = new Date(s);
      return isNaN(d.getTime()) ? null : d;
    } catch { return null; }
  };
  try {
    const fmt = String(req.query?.format || 'json').toLowerCase();
    const size = Math.max(1, Math.min(Number(req.query?.size)||10000, 10000));
    const maxPages = Math.max(1, Math.min(Number(req.query?.max_pages)||50, 200));
    const fromDate = parseDate(req.query?.from, false);
    const toDate = parseDate(req.query?.to, true);
    if (!fromDate || !toDate) return res.status(400).json({ ok:false, error:'bad_request', message:'from and to are required (YYYY-MM-DD)' });
    // Build ISO without timezone suffix per Smartsupp docs
    const toIsoNoZ = (d) => {
      const y = d.getUTCFullYear();
      const m = String(d.getUTCMonth() + 1).padStart(2, '0');
      const da = String(d.getUTCDate()).padStart(2, '0');
      const HH = String(d.getUTCHours()).padStart(2, '0');
      const MM = String(d.getUTCMinutes()).padStart(2, '0');
      const SS = String(d.getUTCSeconds()).padStart(2, '0');
      return `${y}-${m}-${da}T${HH}:${MM}:${SS}`;
    };
    const startStr = toIsoNoZ(fromDate);
    const endStr = toIsoNoZ(toDate);

    const items = [];
    // Swap if user provided reversed dates
    let start = startStr, end = endStr;
    if (fromDate > toDate) { const tmp = start; start = end; end = tmp; }

    const timezone = String(req.query?.tz || 'UTC');
    const fieldsToTry = [ 'createdAt', 'finishedAt', 'updatedAt', 'lastMessageAt' ];
    let usedField = null;
    for (const field of fieldsToTry) {
      let pages = 0;
      let after = undefined;
      let totalAccum = 0;
      const firstPayload = { size, sort: [{ createdAt: 'asc' }], query: [{ field, value: [start, end] }], timezone };
      try { logToFile?.(`[smartsupp] try field=${field} payload=${JSON.stringify(firstPayload)}`); } catch {}
      while (pages < maxPages) {
        const payload = { size, sort: [{ createdAt: 'asc' }], query: [{ field, value: [start, end] }], timezone };
        if (after != null) payload.after = after;
        const r = await fetch(`${SM_BASE}/v2/conversations/search`, {
          method: 'POST', headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${token}` }, body: JSON.stringify(payload)
        });
        const text = await r.text();
        let j = null; try { j = text ? JSON.parse(text) : null; } catch {}
        if (!r.ok) {
          try { logToFile?.(`[smartsupp] upstream_error status=${r.status} body=${String(text).slice(0,2000)}`); } catch {}
          return res.status(r.status).json({ ok:false, error:'upstream_error', message: j?.message || j?.error || `http_${r.status}`, data: j || text, sent: payload });
        }
        const arr = Array.isArray(j?.items) ? j.items : (Array.isArray(j?.hits) ? j.hits : (Array.isArray(j) ? j : []));
        const got = Array.isArray(arr) ? arr.length : 0;
        totalAccum += got;
        try { logToFile?.(`[smartsupp] field=${field} page=${pages} got=${got} after=${JSON.stringify(j?.after||null)}`); } catch {}
        if (!got) break;
        // Local guard filter by createdAt if present
        const within = arr.filter(x => {
          const ca = x?.createdAt || x?.created_at || x?.created || null;
          if (!ca) return true; // don't drop if missing createdAt
          const d = new Date(ca);
          if (isNaN(d.getTime())) return true;
          return d >= fromDate && d <= toDate;
        });
        items.push(...within);
        after = (j && (j.after || j.next || null)) || null;
        if (!after) break;
        pages += 1;
      }
      if (items.length) { usedField = field; break; }
    }
    // If no items via API range filter, fallback: scan by createdAt desc without query and stop when older than fromDate
    if (!items.length) {
      try { logToFile?.(`[smartsupp] fallback scan without query sort=createdAt desc`); } catch {}
      let after2 = undefined; let pages2 = 0;
      while (pages2 < maxPages) {
        const payload = { size, sort: [{ createdAt: 'desc' }] };
        if (after2 != null) payload.after = after2;
        try { logToFile?.(`[smartsupp] fallback payload=${JSON.stringify(payload)}`); } catch {}
        const r = await fetch(`${SM_BASE}/v2/conversations/search`, { method:'POST', headers:{ 'Content-Type':'application/json', 'Authorization': `Bearer ${token}` }, body: JSON.stringify(payload) });
        const text = await r.text();
        let j = null; try { j = text ? JSON.parse(text) : null; } catch {}
        if (!r.ok) {
          try { logToFile?.(`[smartsupp] fallback upstream_error status=${r.status} body=${String(text).slice(0,2000)}`); } catch {}
          return res.status(r.status).json({ ok:false, error:'upstream_error', message: j?.message || j?.error || `http_${r.status}`, data: j || text, sent: payload });
        }
        const arr = Array.isArray(j?.items) ? j.items : (Array.isArray(j?.hits) ? j.hits : (Array.isArray(j) ? j : []));
        const got = Array.isArray(arr) ? arr.length : 0;
        if (!got) break;
        // append items within [fromDate, toDate]
        for (const x of arr) {
          const ca = x?.createdAt || x?.created_at || x?.created || x?.lastMessageAt || x?.updatedAt || null;
          if (!ca) continue;
          const d = new Date(ca);
          if (isNaN(d.getTime())) continue;
          if (d >= fromDate && d <= toDate) items.push(x);
        }
        // Stop when the oldest item on this page is before fromDate (since desc order)
        try {
          const oldest = arr[arr.length - 1];
          const ca = oldest?.createdAt || oldest?.created_at || oldest?.created || oldest?.lastMessageAt || oldest?.updatedAt || null;
          if (ca) {
            const d = new Date(ca);
            if (!isNaN(d.getTime()) && d < fromDate) break;
          }
        } catch {}
        after2 = (j && (j.after || j.next || null)) || null;
        if (!after2) break;
        pages2 += 1;
      }
    }
    try { logToFile?.(`[smartsupp] completed range download items=${items.length} field=${usedField||'unknown'} fallbackUsed=${!usedField && items.length>0}`); } catch {}

    // Always include messages for JSON exports
    if (fmt === 'json') {
      try { logToFile?.(`[smartsupp] expanding ${items.length} conversations with messages`); } catch {}
      for (const it of items) {
        const convId = it?.id || it?._id || it?.conversationId;
        if (!convId) continue;
        try {
          const url = `${SM_BASE}/v2/conversations/${encodeURIComponent(convId)}/messages`;
          const r = await fetch(url, { headers: { 'Authorization': `Bearer ${token}` } });
          const text = await r.text();
          let j = null; try { j = text ? JSON.parse(text) : null; } catch {}
          if (r.ok) {
            const msgs = Array.isArray(j?.items) ? j.items : (Array.isArray(j?.messages) ? j.messages : (Array.isArray(j) ? j : []));
            it.messages = msgs || [];
          } else {
            it.messages_error = j?.message || j?.error || `http_${r.status}`;
          }
        } catch (e) {
          it.messages_error = String(e?.message || e);
        }
      }
    }

    if (fmt === 'csv') {
      const cols = ['id','createdAt','lastMessageAt','status','assigneeId','agentName','visitorName','visitorEmail'];
      const header = cols.join(',');
      const esc = (s) => '"' + String(s==null? "": s).replace(/"/g,'""') + '"';
      const lines = items.map(x => {
        const v = x?.visitor || x?.customer || {};
        const ass = x?.assignee || {};
        return [x?.id, x?.createdAt || x?.created_at, x?.lastMessageAt || x?.updatedAt, x?.status, ass?.id, ass?.name || ass?.email || '', v?.name || '', v?.email || ''].map(esc).join(',');
      });
      const csv = [header, ...lines].join('\n');
      res.setHeader('Content-Type', 'text/csv');
      res.setHeader('Content-Disposition', `attachment; filename="smartsupp_conversations_${fromDate.toISOString().slice(0,10)}_${toDate.toISOString().slice(0,10)}.csv"`);
      return res.send(csv);
    }
    res.setHeader('Content-Type', 'application/json');
    res.setHeader('Content-Disposition', `attachment; filename="smartsupp_conversations_${fromDate.toISOString().slice(0,10)}_${toDate.toISOString().slice(0,10)}.json"`);
    return res.send(JSON.stringify({ items }, null, 2));
  } catch (e) {
    return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Save conversations for a date range to server storage and return metadata
// POST body: { from: 'YYYY-MM-DD', to: 'YYYY-MM-DD', size?:100, max_pages?:50, tz?:'UTC', token?:'...' }
app.post('/api/smartsupp/range/fetch', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  const token = await resolveSmartsuppToken(req);
  if (!token) return res.status(400).json({ ok:false, error:'missing_token' });
  const parseDate = (v, endOfDay = false) => {
    if (!v) return null;
    try {
      const s = String(v).trim();
      if (!s) return null;
      if (/^\d{4}-\d{2}-\d{2}$/.test(s)) {
        const iso = endOfDay ? `${s}T23:59:59.999Z` : `${s}T00:00:00.000Z`;
        const d = new Date(iso);
        return isNaN(d.getTime()) ? null : d;
      }
      const m = /^(\d{1,2})[\/.-](\d{1,2})[\/.-](\d{4})$/.exec(s);
      if (m) {
        const dd = parseInt(m[1], 10), MM = parseInt(m[2], 10), yyyy = parseInt(m[3], 10);
        if (yyyy > 1900 && MM >= 1 && MM <= 12 && dd >= 1 && dd <= 31) {
          const d = new Date(Date.UTC(yyyy, MM - 1, dd, endOfDay?23:0, endOfDay?59:0, endOfDay?59:0, endOfDay?999:0));
          return isNaN(d.getTime()) ? null : d;
        }
      }
      const d = new Date(s);
      return isNaN(d.getTime()) ? null : d;
    } catch { return null; }
  };
  try {
    const b = req.body || {};
    const size = Math.max(1, Math.min(Number(b.size)||10000, 10000));
    const maxPages = Math.max(1, Math.min(Number(b.max_pages)||50, 200));
    const tz = String(b.tz || 'UTC');
    const fromDate = parseDate(b.from, false);
    const toDate = parseDate(b.to, true);
    if (!fromDate || !toDate) return res.status(400).json({ ok:false, error:'bad_request', message:'from and to are required (YYYY-MM-DD)' });
    const toIsoNoZ = (d) => {
      const y = d.getUTCFullYear();
      const m = String(d.getUTCMonth() + 1).padStart(2, '0');
      const da = String(d.getUTCDate()).padStart(2, '0');
      const HH = String(d.getUTCHours()).padStart(2, '0');
      const MM = String(d.getUTCMinutes()).padStart(2, '0');
      const SS = String(d.getUTCSeconds()).padStart(2, '0');
      return `${y}-${m}-${da}T${HH}:${MM}:${SS}`;
    };
    let start = toIsoNoZ(fromDate);
    let end = toIsoNoZ(toDate);
    if (fromDate > toDate) { const t = start; start = end; end = t; }

    const items = [];
    const fieldsToTry = [ 'createdAt', 'finishedAt', 'updatedAt', 'lastMessageAt' ];
    let usedField = null;
    for (const field of fieldsToTry) {
      let pages = 0; let after = undefined;
      while (pages < maxPages) {
        const payload = { size, sort: [{ createdAt: 'asc' }], query: [{ field, value: [start, end] }], timezone: tz };
        if (after != null) payload.after = after;
        const r = await fetch(`${SM_BASE}/v2/conversations/search`, { method:'POST', headers:{ 'Content-Type':'application/json', 'Authorization': `Bearer ${token}` }, body: JSON.stringify(payload) });
        const text = await r.text(); let j = null; try { j = text ? JSON.parse(text) : null; } catch {}
        if (!r.ok) return res.status(r.status).json({ ok:false, error:'upstream_error', message: j?.message || j?.error || `http_${r.status}`, data: j || text, sent: payload });
        const arr = Array.isArray(j?.items) ? j.items : (Array.isArray(j?.hits) ? j.hits : (Array.isArray(j) ? j : []));
        if (!arr || !arr.length) break;
        // Append; local guard by createdAt if present
        for (const x of arr) {
          const ca = x?.createdAt || x?.created_at || x?.created || null;
          if (ca) {
            const d = new Date(ca);
            if (!isNaN(d.getTime()) && (d < fromDate || d > toDate)) continue;
          }
          items.push(x);
        }
        after = (j && (j.after || j.next || null)) || null;
        if (!after) break;
        pages += 1;
      }
      if (items.length) { usedField = field; break; }
    }
    // Fallback scan if necessary (progressively reduce size if needed)
    if (!items.length) {
      const trySizes = [Math.min(size, 1000), 500, 200, 100];
      for (const s of trySizes) {
        let after2 = undefined; let pages2 = 0; let added = 0;
        try { logToFile?.(`[smartsupp] fallback scan size=${s}`); } catch {}
        while (pages2 < maxPages) {
          const payload = { size: s, sort: [{ createdAt: 'desc' }] };
          if (after2 != null) payload.after = after2;
          const r = await fetch(`${SM_BASE}/v2/conversations/search`, { method:'POST', headers:{ 'Content-Type':'application/json', 'Authorization': `Bearer ${token}` }, body: JSON.stringify(payload) });
          const text = await r.text(); let j = null; try { j = text ? JSON.parse(text) : null; } catch {}
          if (!r.ok) return res.status(r.status).json({ ok:false, error:'upstream_error', message: j?.message || j?.error || `http_${r.status}`, data: j || text, sent: payload });
          const arr = Array.isArray(j?.items) ? j.items : (Array.isArray(j?.hits) ? j.hits : (Array.isArray(j) ? j : []));
          const got = Array.isArray(arr) ? arr.length : 0;
          try { logToFile?.(`[smartsupp] fallback page=${pages2} got=${got}`); } catch {}
          if (!got) break;
          for (const x of arr) {
            const ca = x?.createdAt || x?.created_at || x?.created || x?.lastMessageAt || x?.updatedAt || null;
            if (!ca) continue;
            const d = new Date(ca);
            if (isNaN(d.getTime())) continue;
            if (d >= fromDate && d <= toDate) { items.push(x); added++; }
          }
          const oldest = arr[arr.length-1];
          const ca = oldest?.createdAt || oldest?.created_at || oldest?.created || oldest?.lastMessageAt || oldest?.updatedAt || null;
          if (ca) { const d = new Date(ca); if (!isNaN(d.getTime()) && d < fromDate) break; }
          after2 = (j && (j.after || j.next || null)) || null;
          if (!after2) break;
          pages2 += 1;
        }
        if (added) break;
      }
    }
    // Expand messages for JSON stored file
    for (const it of items) {
      const convId = it?.id || it?._id || it?.conversationId; if (!convId) continue;
      try {
        const r = await fetch(`${SM_BASE}/v2/conversations/${encodeURIComponent(convId)}/messages`, { headers: { 'Authorization': `Bearer ${token}` } });
        const text = await r.text(); let j = null; try { j = text ? JSON.parse(text) : null; } catch {}
        if (r.ok) { const msgs = Array.isArray(j?.items) ? j.items : (Array.isArray(j?.messages) ? j.messages : (Array.isArray(j) ? j : [])); it.messages = msgs || []; }
      } catch {}
    }

    const fromTag = String((req.body?.from || '')).replace(/[^0-9-]/g,'').slice(0,10);
    const toTag = String((req.body?.to || '')).replace(/[^0-9-]/g,'').slice(0,10);
    const ts = new Date();
    const stamp = `${ts.getFullYear()}${String(ts.getMonth()+1).padStart(2,'0')}${String(ts.getDate()).padStart(2,'0')}-${String(ts.getHours()).padStart(2,'0')}${String(ts.getMinutes()).padStart(2,'0')}${String(ts.getSeconds()).padStart(2,'0')}`;
    const fname = `smartsupp_conversations_${fromTag}_${toTag}_${stamp}.json`;
    const fpath = path.join(smartsuppDir, fname);
    try { fs.writeFileSync(fpath, JSON.stringify({ items }, null, 2), 'utf8'); } catch (e) { return res.status(500).json({ ok:false, error:'save_failed', message: e?.message || String(e) }); }
    const st = fs.statSync(fpath);
    return res.json({ ok:true, file: { name: fname, size: st.size, mtime: st.mtime, url: `/api/smartsupp/file/${encodeURIComponent(fname)}` } });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// List stored Smartsupp files (optionally filter by date range in filename)
app.get('/api/smartsupp/files', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const from = String(req.query?.from || '').trim();
    const to = String(req.query?.to || '').trim();
    const all = (fs.readdirSync(smartsuppDir, { withFileTypes: true }) || []).filter(d => d.isFile() && /\.json$/i.test(d.name));
    const items = [];
    for (const d of all) {
      const name = d.name;
      const p = path.join(smartsuppDir, name);
      let st = null; try { st = fs.statSync(p); } catch { continue; }
      const m = /smartsupp_conversations_(\d{4}-\d{2}-\d{2})_(\d{4}-\d{2}-\d{2})_/i.exec(name);
      const meta = { name, size: st.size, mtime: st.mtime, url: `/api/smartsupp/file/${encodeURIComponent(name)}` };
      if (m) { meta.from = m[1]; meta.to = m[2]; }
      items.push(meta);
    }
    // Optional filter
    const filt = items.filter(it => {
      if (from && it.from && it.from < from) return false;
      if (to && it.to && it.to > to) return false;
      return true;
    }).sort((a,b) => (b.mtime - a.mtime));
    res.json({ ok:true, items: filt });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Serve a stored file (optionally download)
app.get('/api/smartsupp/file/:name', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const name = String(req.params.name || '').replace(/[^A-Za-z0-9._\-]/g,'');
    if (!name) return res.status(400).json({ ok:false, error:'bad_request' });
    const filePath = path.join(smartsuppDir, name);
    if (!fs.existsSync(filePath)) return res.status(404).json({ ok:false, error:'not_found' });
    const dl = /^(1|true|yes)$/i.test(String(req.query?.download || ''));
    res.setHeader('Content-Type','application/json');
    if (dl) res.setHeader('Content-Disposition', `attachment; filename="${name}"`);
    fs.createReadStream(filePath).pipe(res);
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Mass delete stored files
app.post('/api/smartsupp/files/delete', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const names = Array.isArray(req.body?.names) ? req.body.names : [];
    const deleted = []; const errors = [];
    for (const raw of names) {
      const name = String(raw || '').replace(/[^A-Za-z0-9._\-]/g,'');
      if (!name) continue;
      const filePath = path.join(smartsuppDir, name);
      try { if (fs.existsSync(filePath)) { fs.unlinkSync(filePath); deleted.push(name); } }
      catch (e) { errors.push({ name, message: e?.message || String(e) }); }
    }
    res.json({ ok:true, deleted, errors });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// ================== Assets (images/files) from stored Smartsupp JSON ==================
function extractUrlsFromObject(obj, urls) {
  if (!obj) return;
  const push = (u) => { try { const s = String(u||'').trim(); if (/^https?:\/\//i.test(s)) urls.add(s); } catch {} };
  if (typeof obj === 'string') {
    // Extract http(s) URLs from text
    const re = /(https?:\/\/[^\s"'<>]+)/g; let m;
    while ((m = re.exec(obj)) !== null) push(m[1]);
    return;
  }
  if (Array.isArray(obj)) { for (const it of obj) extractUrlsFromObject(it, urls); return; }
  if (typeof obj === 'object') {
    // Common fields
    if (obj.url) push(obj.url);
    if (obj.href) push(obj.href);
    if (obj.downloadUrl) push(obj.downloadUrl);
    if (obj.src) push(obj.src);
    // Dive into known containers
    for (const [k,v] of Object.entries(obj)) {
      if (v == null) continue;
      extractUrlsFromObject(v, urls);
    }
    return;
  }
}

function urlExt(u) {
  try {
    const p = new URL(u);
    const seg = p.pathname.split('/').filter(Boolean);
    const last = seg[seg.length-1] || '';
    const m = /\.([A-Za-z0-9]{1,6})$/.exec(last);
    return m ? m[1].toLowerCase() : '';
  } catch { return ''; }
}
function urlFile(u) {
  try {
    const p = new URL(u);
    const last = (p.pathname.split('/').filter(Boolean).pop() || '').replace(/[^A-Za-z0-9._-]/g,'_');
    return last || null;
  } catch { return null; }
}

app.post('/api/smartsupp/assets/fetch', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const name = String(req.body?.name || '').replace(/[^A-Za-z0-9._\-]/g,'');
    if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });
    const limit = Math.max(1, Math.min(Number(req.body?.limit)||10000, 50000));
    const onlyNew = req.body?.only_new !== false; // default true
    const filePath = path.join(smartsuppDir, name);
    if (!fs.existsSync(filePath)) return res.status(404).json({ ok:false, error:'not_found' });
    let jsonText = '';
    try { jsonText = fs.readFileSync(filePath, 'utf8'); } catch {}
    let data = null; try { data = JSON.parse(jsonText); } catch {}
    const items = Array.isArray(data?.items) ? data.items : [];
    const urls = new Set();
    for (const it of items) {
      extractUrlsFromObject(it?.messages, urls);
      extractUrlsFromObject(it?.attachments, urls);
      extractUrlsFromObject(it, urls); // fallback crude scan
    }
    // Determine allowed prefix
    let allowedPrefix = String(req.body?.prefix || process.env.SMARTSUPP_FILES_PREFIX || '').trim();
    const account = String(req.body?.account || '').trim();
    if (!allowedPrefix && account) allowedPrefix = `https://files.smartsuppcdn.com/files/accounts/${account}/uploads`;
    if (!allowedPrefix) allowedPrefix = 'https://files.smartsuppcdn.com/files/accounts/409828/uploads';
    const allowedLower = allowedPrefix.toLowerCase();
    // Filter by allowed prefix
    const candidates = Array.from(urls).filter(u => String(u||'').toLowerCase().startsWith(allowedLower));
    const group = name.replace(/\.json$/i,'');
    const outDir = path.join(smartsuppAssetsDir, group);
    try { fs.mkdirSync(outDir, { recursive: true }); } catch {}
    const results = [];
    let downloaded = 0, skipped = 0, errors = 0;
    for (const uurl of candidates.slice(0, limit)) {
      let fname = urlFile(uurl) || `file_${results.length+1}`;
      let fext = urlExt(uurl);
      let target = path.join(outDir, fname);
      if (!/\.[A-Za-z0-9]{1,6}$/.test(fname) && fext) target = path.join(outDir, `${fname}.${fext}`);
      // avoid overwrite collision
      let base = target, i = 1;
      while (fs.existsSync(target)) {
        if (onlyNew) { skipped++; results.push({ url: uurl, file: path.relative(__dirname, target), skipped:true }); target = null; break; }
        const ext = path.extname(base); const stem = base.slice(0, -ext.length);
        target = `${stem}_${i}${ext}`; i++;
      }
      if (!target) continue;
      try {
        const controller = new AbortController(); const timer = setTimeout(()=>{ try{controller.abort();}catch{} }, 30000);
        const r = await fetch(uurl, { signal: controller.signal });
        clearTimeout(timer);
        if (!r.ok) throw new Error(`http_${r.status}`);
        const ct = String(r.headers.get('content-type')||'');
        // Append extension from content-type if missing
        if (!path.extname(target)) {
          if (/image\/jpeg/i.test(ct)) target += '.jpg';
          else if (/image\/png/i.test(ct)) target += '.png';
          else if (/image\/gif/i.test(ct)) target += '.gif';
          else if (/image\/webp/i.test(ct)) target += '.webp';
        }
        const dest = fs.createWriteStream(target);
        try {
          if (r.body && typeof r.body.pipe === 'function') {
            await new Promise((resolve, reject) => { r.body.pipe(dest); r.body.on('error', reject); dest.on('finish', resolve); dest.on('error', reject); });
          } else if (r.body && typeof r.body.getReader === 'function') {
            const { Readable } = await import('stream');
            const nodeStream = Readable.fromWeb(r.body);
            await new Promise((resolve, reject) => { nodeStream.pipe(dest); nodeStream.on('error', reject); dest.on('finish', resolve); dest.on('error', reject); });
          } else {
            const buf = Buffer.from(await r.arrayBuffer());
            fs.writeFileSync(target, buf);
          }
        } catch (e) {
          try { dest.close?.(); } catch {}
          throw e;
        }
        const st = fs.statSync(target);
        downloaded++;
        results.push({ url: uurl, file: `/api/smartsupp/asset/${encodeURIComponent(group)}/${encodeURIComponent(path.basename(target))}`, size: st.size });
      } catch (e) {
        errors++;
        results.push({ url: uurl, error: String(e?.message||e) });
      }
    }
    res.json({ ok:true, group, prefix: allowedPrefix, total_urls: candidates.length, processed: results.length, downloaded, skipped, errors, items: results });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// List downloaded assets for a group (JSON file stem)
app.get('/api/smartsupp/assets', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const group = String(req.query?.group || '').replace(/[^A-Za-z0-9._\-]/g,'');
    const dir = path.join(smartsuppAssetsDir, group);
    if (!group || !fs.existsSync(dir)) return res.json({ ok:true, items: [] });
    const files = fs.readdirSync(dir, { withFileTypes: true }).filter(d => d.isFile());
    const items = files.map(d => {
      const p = path.join(dir, d.name); const st = fs.statSync(p);
      return { name: d.name, size: st.size, mtime: st.mtime, url: `/api/smartsupp/asset/${encodeURIComponent(group)}/${encodeURIComponent(d.name)}` };
    }).sort((a,b)=> (b.mtime - a.mtime));
    res.json({ ok:true, group, items });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Serve an asset file
app.get('/api/smartsupp/asset/:group/:name', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const group = String(req.params.group || '').replace(/[^A-Za-z0-9._\-]/g,'');
    const name = String(req.params.name || '').replace(/[^A-Za-z0-9._\-]/g,'');
    const p = path.join(smartsuppAssetsDir, group, name);
    if (!group || !name || !fs.existsSync(p)) return res.status(404).json({ ok:false, error:'not_found' });
    const dl = /^(1|true|yes)$/i.test(String(req.query?.download||''));
    const ct = {
      jpg: 'image/jpeg', jpeg:'image/jpeg', png:'image/png', gif:'image/gif', webp:'image/webp'
    }[String(path.extname(p).slice(1)).toLowerCase()] || 'application/octet-stream';
    res.setHeader('Content-Type', ct);
    if (dl) res.setHeader('Content-Disposition', `attachment; filename="${name}"`);
    fs.createReadStream(p).pipe(res);
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Note: Smartsupp API token admin endpoints migrated to module 'smartsupp-api'

// Start server only once (listen at the bottom)
// Previously we started early to expose /__health during init, but that caused
// duplicate listen attempts. We now rely on the single listen near the end.
// const EARLY_PORT = Number(process.env.PORT || 3010);
// if (!server.listening) {
//   try {
//     server.listen(EARLY_PORT, "0.0.0.0", () => {
//       console.log(`[startup] Listening on http://0.0.0.0:${EARLY_PORT}`);
//     });
//   } catch {}
// }

// ---- Postgres
const pool = createPool({
  connectionString:
    process.env.DATABASE_URL ||
    "postgresql://livechat_user:Alexcaroline12@127.0.0.1:5432/livechat",
  ssl:
    String(process.env.PGSSL || "").toLowerCase() === "true"
      ? { rejectUnauthorized: false }
      : false,
});

const auth = createAuthModule({ app, pool, logToFile });
const {
  signToken,
  verifyToken,
  parseCookie,
  authFromRequest,
  setAuthCookie,
  clearAuthCookie,
  requireAuth,
  requireAdmin: requireAdminAuth,
} = auth;
const requireAdmin = requireAdminAuth;


async function getSetting(key) {
  try {
    const res = await pool.query("SELECT value FROM settings WHERE key = $1 LIMIT 1", [key]);
    return res.rowCount ? res.rows[0].value : null;
  } catch (e) {
    logToFile(`❌ getSetting(${key}) error: ${e.code || ''} ${e.message}`);
    return null;
  }
}

async function setSetting(key, value) {
  const sql = `
    INSERT INTO settings (key, value, updated_at)
    VALUES ($1, $2, NOW())
    ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW()
  `;
  try {
    await pool.query(sql, [key, value]);
  } catch (e) {
    logToFile(`❌ setSetting(${key}) error: ${e.code || ''} ${e.message}`);
    throw e;
  }
}

// ---- Debug toggles & helper loggers
const DEBUG_CHAT = /^(1|true|yes)$/i.test(process.env.DEBUG_CHAT || "");
const DEBUG_SQL = /^(1|true|yes)$/i.test(process.env.DEBUG_SQL || "");
const DEBUG_API = /^(1|true|yes)$/i.test(process.env.DEBUG_API || "");
const DEBUG_SOCKET = /^(1|true|yes)$/i.test(process.env.DEBUG_SOCKET || "");
const DEBUG_GEO = /^(1|true|yes)$/i.test(process.env.DEBUG_GEO || "");
const DEBUG_MCP = /^(1|true|yes)$/i.test(process.env.DEBUG_MCP || "");
const DEBUG_WIDGET = /^(1|true|yes)$/i.test(process.env.DEBUG_WIDGET || "");
const DEBUG_WIDGET_RAW = /^(1|true|yes)$/i.test(process.env.DEBUG_WIDGET_RAW || "");
const WIDGET_LOG_MAX = Math.max(
  0,
  Number(process.env.WIDGET_LOG_MAX || process.env.DEBUG_WIDGET_MAX || 500)
);

function logJson(label, obj) {
  try {
    logToFile(`${label} ${JSON.stringify(obj)}`);
  } catch {
    logToFile(`${label} <failed to stringify>`);
  }
}

let geoipLite = null;
const ENABLE_GEOIP_LITE = /^(1|true|yes)$/i.test(process.env.ENABLE_GEOIP_LITE || "");
if (ENABLE_GEOIP_LITE) {
  try {
    const mod = await import("geoip-lite");
    geoipLite = mod?.default || mod;
    logToFile("🌐 geoip-lite enabled");
  } catch {
    logToFile("🌐 geoip-lite not installed; skipping");
  }
}

function safeObj(o, max = WIDGET_LOG_MAX) {
  if (!o || typeof o !== "object") return o;
  const out = {};
  for (const [k, v] of Object.entries(o)) {
    if (v == null) {
      out[k] = v;
      continue;
    }
    if (typeof v === "string") {
      out[k] =
        max > 0 && v.length > max ? `${v.slice(0, max)}…(${v.length})` : v;
    } else if (typeof v === "object") {
      out[k] = safeObj(v, max);
    } else {
      out[k] = v;
    }
  }
  return out;
}

function logWidget(label, payload) {
  if (!DEBUG_WIDGET && !DEBUG_WIDGET_RAW) return;
  if (DEBUG_WIDGET) logJson(label, safeObj(payload));
  if (DEBUG_WIDGET_RAW) logJson(`${label} [RAW]`, payload);
}

let mcpToken = String(process.env.MCP_TOKEN || "");
const getMcpToken = () => mcpToken;
async function loadMcpTokenFromDb() {
  const v = await getSetting("MCP_TOKEN");
  if (typeof v === "string") mcpToken = v;
}

let mcpDevToken = String(process.env.MCP_DEV_TOKEN || "");
const getMcpDevToken = () => mcpDevToken;
async function loadMcpDevTokenFromDb() {
  const v = await getSetting("MCP_DEV_TOKEN");
  if (typeof v === "string") mcpDevToken = v;
}
// Enable/disable flags
let mcpDevEnabled = !/^(0|false|no)$/i.test(process.env.MCP_DEV_ENABLED || "1");
const getMcpDevEnabled = () => mcpDevEnabled;
async function loadMcpDevEnabledFromDb() {
  const v = await getSetting("MCP_DEV_ENABLED");
  if (typeof v === 'string' && v !== '') mcpDevEnabled = !/^(0|false|no)$/i.test(v);
}

// PrestaShop Dev MCP token/public base
let mcpDevPrestaToken = String(process.env.MCP_DEV_PRESTA_TOKEN || "");
const getMcpDevPrestaToken = () => mcpDevPrestaToken;
async function loadMcpDevPrestaTokenFromDb() {
  const v = await getSetting("MCP_DEV_PRESTA_TOKEN");
  if (typeof v === "string") mcpDevPrestaToken = v;
}
let mcpDevPrestaEnabled = !/^(0|false|no)$/i.test(process.env.MCP_DEV_PRESTA_ENABLED || "1");
const getMcpDevPrestaEnabled = () => mcpDevPrestaEnabled;
async function loadMcpDevPrestaEnabledFromDb() {
  const v = await getSetting("MCP_DEV_PRESTA_ENABLED");
  if (typeof v === 'string' && v !== '') mcpDevPrestaEnabled = !/^(0|false|no)$/i.test(v);
}

let mcpPublicBase = String(
  process.env.MCP_PUBLIC_BASE || process.env.PUBLIC_BASE_URL || ""
);
const getMcpPublicBase = () => mcpPublicBase;
async function loadMcpPublicBaseFromDb() {
  const v = await getSetting("MCP_PUBLIC_BASE");
  if (typeof v === "string") mcpPublicBase = v;
  }

// If MCP‑DEV is disabled, short‑circuit all /mcp-dev and /mcp/mcp-dev requests with 404
// Place this middleware before /mcp-dev routes are registered so it runs first.
app.use(["/mcp-dev", "/mcp/mcp-dev"], (req, res, next) => {
  try {
    if (!getMcpDevEnabled()) {
      return res.status(404).type('text/plain; charset=utf-8').send('Not found');
    }
  } catch {}
  return next();
});

let mcpDevPublicBase = String(process.env.MCP_DEV_PUBLIC_BASE || "");
const getMcpDevPublicBase = () => mcpDevPublicBase;
async function loadMcpDevPublicBaseFromDb() {
  const v = await getSetting("MCP_DEV_PUBLIC_BASE");
  if (typeof v === "string") mcpDevPublicBase = v;
}

let mcpDevPrestaPublicBase = String(process.env.MCP_DEV_PRESTA_PUBLIC_BASE || "");
  const getMcpDevPrestaPublicBase = () => mcpDevPrestaPublicBase;
  async function loadMcpDevPrestaPublicBaseFromDb() {
    const v = await getSetting("MCP_DEV_PRESTA_PUBLIC_BASE");
    if (typeof v === "string") mcpDevPrestaPublicBase = v;
  }

let openaiApiKey = String(process.env.OPENAI_API_KEY || "");
  const getOpenaiApiKey = () => openaiApiKey;
  async function loadOpenaiApiKeyFromDb() {
    const v = await getSetting("OPENAI_API_KEY");
    if (typeof v === "string") {
      openaiApiKey = v;
      process.env.OPENAI_API_KEY = v;
    }
  }

  // ---- Minimal OpenAI HTTP helper (for endpoints not yet in SDK) ----
  function buildOpenAIHeaders(key, { organization, project } = {}) {
    const headers = {
      'Authorization': `Bearer ${key}`,
      'Content-Type': 'application/json',
    };
    try {
      const isProjectScoped = /^sk-proj-/.test(String(key));
      const org = organization || process.env.OPENAI_ORG || '';
      const proj = project || process.env.OPENAI_PROJECT || '';
      if (!isProjectScoped && org) headers['OpenAI-Organization'] = org;
      if (!isProjectScoped && proj) headers['OpenAI-Project'] = proj;
    } catch {}
    return headers;
  }
  function normalizeOpenAIBase(raw) {
    let b = (raw && String(raw).trim()) || '';
    if (!b) return 'https://api.openai.com/v1';
    // Must be absolute http(s) URL
    if (!/^https?:\/\//i.test(b)) return 'https://api.openai.com/v1';
    // If no path, ensure /v1
    try {
      const u = new URL(b);
      if (!u.pathname || u.pathname === '/' || u.pathname === '') {
        u.pathname = '/v1';
        b = u.toString().replace(/\/$/, '');
      }
    } catch { return 'https://api.openai.com/v1'; }
    return b.replace(/\/$/, '');
  }
  async function openaiHttp(path, { method = 'GET', body, apiKey, organization, project, baseURL, extraHeaders } = {}) {
    const key = (apiKey && String(apiKey).trim()) || getOpenaiApiKey() || process.env.OPENAI_API_KEY || '';
    if (!key) throw new Error('openai_key_missing');
    const base = normalizeOpenAIBase(baseURL || process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1');
    const url = `${base}${path.startsWith('/') ? '' : '/'}${path}`;
    const headers = { ...buildOpenAIHeaders(key, { organization, project }), ...(extraHeaders || {}) };
    const init = { method, headers };
    if (body !== undefined) init.body = JSON.stringify(body);
    setPromptsDebug({ lastOpenAI: { at: Date.now(), method, url, path, base } });
    const r = await fetch(url, init);
    const text = await r.text();
    let json = null; try { json = text ? JSON.parse(text) : null; } catch {}
    if (!r.ok) {
      const msg = json?.error?.message || json?.message || text || `http_${r.status}`;
      const err = new Error(String(msg));
      err.status = r.status;
      err.details = json || text;
      throw err;
    }
    return json;
  }

  // Compatibility helpers: try /prompts first, then /chat/prompts on 404
  async function openaiPromptCreate(body, opts) {
    try { return await openaiHttp('/prompts', { method:'POST', body, extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) }); }
    catch (e) {
      if (e?.status === 404) return await openaiHttp('/chat/prompts', { method:'POST', body, extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) });
      throw e;
    }
  }
  async function openaiPromptRetrieve(id, opts) {
    try { return await openaiHttp(`/prompts/${encodeURIComponent(id)}`, { method:'GET', extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) }); }
    catch (e) {
      if (e?.status === 404) return await openaiHttp(`/chat/prompts/${encodeURIComponent(id)}`, { method:'GET', extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) });
      throw e;
    }
  }
  async function openaiPromptListVersions(id, opts) {
    try { return await openaiHttp(`/prompts/${encodeURIComponent(id)}/versions`, { method:'GET', extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) }); }
    catch (e) {
      if (e?.status === 404) return await openaiHttp(`/chat/prompts/${encodeURIComponent(id)}/versions`, { method:'GET', extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) });
      throw e;
    }
  }
  async function openaiPromptCreateVersion(id, body, opts) {
    try { return await openaiHttp(`/prompts/${encodeURIComponent(id)}/versions`, { method:'POST', body, extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) }); }
    catch (e) {
      if (e?.status === 404) return await openaiHttp(`/chat/prompts/${encodeURIComponent(id)}/versions`, { method:'POST', body, extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) });
      throw e;
    }
  }
  async function openaiPromptPatch(id, body, opts) {
    try { return await openaiHttp(`/prompts/${encodeURIComponent(id)}`, { method:'PATCH', body, extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) }); }
    catch (e) {
      if (e?.status === 404) return await openaiHttp(`/chat/prompts/${encodeURIComponent(id)}`, { method:'PATCH', body, extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) });
      throw e;
    }
  }
  async function openaiPromptList(query = {}, opts) {
    const q = new URLSearchParams();
    if (query && query.limit) q.set('limit', String(query.limit));
    if (query && query.after) q.set('after', String(query.after));
    const qs = q.toString();
    const path = `/prompts${qs ? `?${qs}` : ''}`;
    const alt = `/chat/prompts${qs ? `?${qs}` : ''}`;
    try { return await openaiHttp(path, { method:'GET', extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) }); }
    catch (e) {
      if (e?.status === 404) return await openaiHttp(alt, { method:'GET', extraHeaders:{ 'OpenAI-Beta': 'prompts=v1' }, ...(opts||{}) });
      throw e;
    }
  }

  // ---- Prompts debug helpers ----
  if (!globalThis.__PROMPTS_DEBUG) globalThis.__PROMPTS_DEBUG = {};
  function setPromptsDebug(patch = {}) {
    try {
      const d = (globalThis.__PROMPTS_DEBUG = globalThis.__PROMPTS_DEBUG || {});
      Object.assign(d, patch);
    } catch {}
  }
  function getPromptsDebug() {
    try { return globalThis.__PROMPTS_DEBUG || {}; } catch { return {}; }
  }
  function captureReqMeta(req) {
    try {
      const xfProto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
      const xfHost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
      return {
        at: Date.now(),
        method: req.method,
        url: req.originalUrl || req.url,
        path: req.path,
        host: xfHost || req.headers.host || '',
        proto: (xfProto || req.protocol || '').toLowerCase(),
        ip: req.ip,
      };
    } catch { return { at: Date.now(), url: req?.originalUrl || '' }; }
  }
  function promptDbgOk(req, action, extra = {}) {
    const meta = captureReqMeta(req);
    const entry = { action, ok: true, ...meta, ...extra };
    setPromptsDebug({ lastOk: entry });
    try { logToFile(`[PROMPTS_OK] ${JSON.stringify(entry)}`); } catch {}
  }
  function promptDbgErr(req, action, e) {
    const meta = captureReqMeta(req);
    const entry = { action, ok: false, status: e?.status || 500, message: e?.message || String(e), details: e?.details || undefined, ...meta };
    setPromptsDebug({ lastError: entry });
    try { logToFile(`[PROMPTS_ERR] ${JSON.stringify(entry)}`); } catch {}
  }

// ---- Signed download links (for MCP files)
let fileSignSecret = String(process.env.FILE_SIGN_SECRET || "");
async function ensureFileSignSecret() {
  if (fileSignSecret) return fileSignSecret;
  try {
    const v = await getSetting('FILE_SIGN_SECRET');
    if (typeof v === 'string' && v) { fileSignSecret = v; return fileSignSecret; }
  } catch {}
  try {
    const s = crypto.randomBytes(32).toString('hex');
    await setSetting('FILE_SIGN_SECRET', s);
    fileSignSecret = s;
  } catch {
    // As a last resort, use a process-scoped secret (not persisted)
    fileSignSecret = crypto.randomBytes(32).toString('hex');
  }
  return fileSignSecret;
}
function hmacSha256Hex(key, data) {
  return crypto.createHmac('sha256', key).update(data).digest('hex');
}
  function constEq(a = '', b = '') {
    try {
      const ba = Buffer.from(String(a));
      const bb = Buffer.from(String(b));
      if (ba.length !== bb.length) return false;
      return crypto.timingSafeEqual(ba, bb);
    } catch { return false; }
  }

// ===================== MCP Server config helpers ===========================
async function getMcpServerConfigByKind(kind) {
  try {
    await ensureTables();
    const r = await pool.query(`SELECT * FROM mcp_server_config WHERE kind=$1 ORDER BY updated_at DESC LIMIT 1`, [kind]);
    return r.rowCount ? r.rows[0] : null;
  } catch { return null; }
}

function inferWsUrlFromBase(httpBase, path) {
  try {
    const u = new URL(httpBase);
    const wsScheme = u.protocol === 'https:' ? 'wss:' : 'ws:';
    return `${wsScheme}//${u.host}${path}`;
  } catch {
    return '';
  }
}

async function syncMcpServersFromLegacy() {
  try {
    // Allow disabling legacy auto-seed via environment variable
    const disabled = /^(1|true|yes)$/i.test(String(process.env.DISABLE_LEGACY_MCP_SEED || ''));
    if (disabled) { logToFile('ℹ️ Skipping MCP legacy auto-seed (DISABLE_LEGACY_MCP_SEED)'); return; }
    await ensureTables();
    const servers = [];
    // main
    {
      let httpBase = (getMcpPublicBase() || '').trim();
      let wsUrl = httpBase ? inferWsUrlFromBase(httpBase, '/mcp/ws') : '';
      const streamUrl = httpBase ? `${httpBase.replace(/\/$/, '')}/mcp/stream` : '';
      const sseUrl = httpBase ? `${httpBase.replace(/\/$/, '')}/mcp/events` : '';
      if (httpBase) servers.push({ name: 'MCP', kind: 'main', http_base: httpBase || null, ws_url: wsUrl || null, stream_url: streamUrl || null, sse_url: sseUrl || null, token: getMcpToken() || null, enabled: true, notes: null });
    }
    // dev
    {
      let httpBase = (getMcpDevPublicBase() || '').trim();
      let wsUrl = httpBase ? inferWsUrlFromBase(httpBase, '/mcp-dev/ws') : '';
      const streamUrl = httpBase ? `${httpBase.replace(/\/$/, '')}/mcp/mcp-dev/stream` : '';
      const sseUrl = httpBase ? `${httpBase.replace(/\/$/, '')}/mcp-dev/events` : '';
      if (httpBase) servers.push({ name: 'MCP-DEV', kind: 'dev', http_base: httpBase || null, ws_url: wsUrl || null, stream_url: streamUrl || null, sse_url: sseUrl || null, token: getMcpDevToken() || null, enabled: getMcpDevEnabled(), notes: null });
    }
    // dev-prestashop
    {
      let httpBase = (getMcpDevPrestaPublicBase() || '').trim();
      let wsUrl = httpBase ? inferWsUrlFromBase(httpBase, '/mcp-dev-prestashop/ws') : '';
      const streamUrl = httpBase ? `${httpBase.replace(/\/$/, '')}/mcp/mcp-dev-prestashop/stream` : '';
      const sseUrl = null; // no SSE path for Presta at this time
      if (httpBase) servers.push({ name: 'MCP-DEV-Prestashop', kind: 'dev-prestashop', http_base: httpBase || null, ws_url: wsUrl || null, stream_url: streamUrl || null, sse_url: sseUrl, token: getMcpDevPrestaToken() || null, enabled: getMcpDevPrestaEnabled(), notes: null });
    }
    for (const s of servers) {
      await pool.query(
        `INSERT INTO mcp_server_config (id, name, kind, http_base, ws_url, stream_url, sse_url, token, enabled, notes, created_at, updated_at)
         VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,NOW(),NOW())
         ON CONFLICT (name) DO UPDATE SET kind=EXCLUDED.kind, http_base=EXCLUDED.http_base, ws_url=EXCLUDED.ws_url, stream_url=EXCLUDED.stream_url, sse_url=EXCLUDED.sse_url, token=EXCLUDED.token, enabled=EXCLUDED.enabled, notes=EXCLUDED.notes, updated_at=NOW()`,
        [makeMcpServerId(), s.name, s.kind, s.http_base, s.ws_url, s.stream_url, s.sse_url, s.token, s.enabled, s.notes]
      );
    }
    logToFile('✅ MCP server config synced to DB');
  } catch (e) { logToFile(`⚠️ MCP server sync failed: ${e?.message || e}`); }
}

  // Quick ad-hoc migration helpers (safe to call repeatedly)
  async function ensureChatbotInstructions() {
    try {
      await pool.query(`ALTER TABLE chatbot_config ADD COLUMN IF NOT EXISTS instructions TEXT`);
    } catch {}
  }
  async function ensureChatbotMcpServerName() {
    try {
      await pool.query(`ALTER TABLE chatbot_config ADD COLUMN IF NOT EXISTS mcp_server_name TEXT`);
    } catch {}
  }
  async function ensureChatbotWelcomeMessage() {
    try {
      await pool.query(`ALTER TABLE chatbot_config ADD COLUMN IF NOT EXISTS welcome_message TEXT`);
    } catch {}
  }
  async function ensureChatbotWelcomeLinkTable() {
    try {
      await pool.query(`
        CREATE TABLE IF NOT EXISTS chatbot_welcome_link (
          id_bot TEXT PRIMARY KEY REFERENCES chatbot_config(id_bot) ON DELETE CASCADE,
          welcome_message_id TEXT NOT NULL,
          updated_at TIMESTAMP DEFAULT NOW()
        );
      `);
    } catch {}
  }
  async function ensureHubBotMapTable() {
    try {
      await pool.query(`
        CREATE TABLE IF NOT EXISTS hub_bot_map (
          assistant_id_ext TEXT PRIMARY KEY,
          id_bot TEXT NOT NULL REFERENCES chatbot_config(id_bot) ON DELETE CASCADE,
          updated_at TIMESTAMP DEFAULT NOW()
        );
      `);
    } catch {}
  }
  async function ensureChatbotWelcomeMessageId() {
    try {
      await pool.query(`ALTER TABLE chatbot_config ADD COLUMN IF NOT EXISTS welcome_message_id TEXT`);
    } catch {}
  }

createModuleManager({
  app,
  pool,
  requireAdmin: requireAdminAuth,
  getSetting,
  setSetting,
  logToFile,
});

// Load module hooks (decoupled mounting)
try {
  await loadModuleHooks({
    app,
    pool,
    requireAdmin: requireAdminAuth,
    getSetting,
    setSetting,
    logToFile,
    extras: { getLogFilePath, isLogEnabled, isLogStdout, setLogStdout }
  });
} catch (e) { try { logToFile('module hooks load failed: '+(e && e.message ? e.message : String(e))); } catch {} }

// Load module backend routes (each module can self-register)
try {
  await loadModuleRoutes({
    app,
    pool,
    requireAuth,
    requireAdmin: requireAdminEither,
    getSetting,
    setSetting,
    logToFile,
    dbSummaryDir,
  });
} catch (e) { try { logToFile('module routes load failed: '+(e && e.message ? e.message : String(e))); } catch {} }

// (logging already defined above)

async function ensureTables() {
  return ensureTablesMigration({ pool, logToFile });
}

// Ensure prompt_config supports multiple vector stores
async function ensurePromptVectorIdsColumn() {
  try {
    await pool.query(`ALTER TABLE prompt_config ADD COLUMN IF NOT EXISTS vector_store_ids JSON`);
  } catch (e) { try { logToFile(`?? ensure vector_store_ids column: ${e.code||''} ${e.message}`); } catch {} }
}

// Ensure prompt_config has a model column (optional per-prompt model override)
async function ensurePromptModelColumn() {
  try {
    await pool.query(`ALTER TABLE prompt_config ADD COLUMN IF NOT EXISTS model TEXT`);
  } catch (e) { try { logToFile(`?? ensure model column: ${e.code||''} ${e.message}`); } catch {} }
}

// List DB tables (admin only)
app.get('/api/debug/db/tables', async (req, res) => {
  if (!requireAdmin(req, res)) return;
  try {
    const r = await pool.query(`
      SELECT table_name
      FROM information_schema.tables
      WHERE table_schema = 'public'
      ORDER BY table_name
    `);
    res.json({ ok: true, tables: r.rows.map((x) => x.table_name) });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Legacy inlined handlers removed; see module for implementation.

// DB Manager helpers removed
// DB Manager config endpoints moved to module

// Test a connection (PostgreSQL only for now)
// DB Manager test endpoint moved to module

// List views from the app database (PostgreSQL)
// DB Manager views endpoints moved to module

// View details (SHOW CREATE VIEW) for configured DB only
// --- AI helper: Generate schema summary file (for large DBs, metadata-only)
function sanitizeFilename(name = '') {
  return String(name).replace(/[^a-zA-Z0-9_.-]+/g, '-').replace(/-+/g, '-').replace(/^-+|-+$/g, '') || 'file';
}

async function generateDbSummary(cfg, opts = {}) {
  const dialect = String(cfg?.dialect || 'mysql').toLowerCase();
  if (!['mysql', 'mariadb'].includes(dialect)) throw new Error('Only MySQL/MariaDB supported');
  const host = String(cfg.host || 'localhost');
  const port = Number(cfg.port || 3306);
  const dbName = String(cfg.database || '').trim();
  const user = String(cfg.user || '');
  const password = String(cfg.password || '');
  const ssl = cfg.ssl ? { rejectUnauthorized: false } : undefined;
  if (!dbName) throw new Error('database_not_set');

  const allData = !!(opts.allData || opts.includeAllData);
  const include = {
    tables: opts.tables !== false,
    columns: opts.columns !== false,
    foreignKeys: opts.foreignKeys !== false,
    views: !!opts.views,
    data: !!(opts.data || opts.includeData || allData),
  };
  const sampleRows = (() => {
    const n = Number(opts.sampleRows || (allData ? 1000000 : 5));
    const max = allData ? 1_000_000 : 50;
    return Number.isFinite(n) ? Math.max(1, Math.min(max, Math.trunc(n))) : (allData ? 1_000_000 : 5);
  })();
  const sampleTables = (() => {
    const n = Number(opts.sampleTables || (allData ? 100000 : 10));
    const max = allData ? 100_000 : 200;
    return Number.isFinite(n) ? Math.max(1, Math.min(max, Math.trunc(n))) : (allData ? 100_000 : 10);
  })();
  const MAX_DATA_TOTAL = (() => {
    const def = allData ? 2_000_000 : 120_000;
    const n = Number(opts.maxDataBytes || def);
    return Number.isFinite(n) ? Math.max(1000, Math.min(20_000_000, Math.trunc(n))) : def;
  })();
  const MAX_CELL_LEN = (() => { const n = Number(opts.maxCellLen || 160); return Number.isFinite(n) ? Math.max(20, Math.min(2000, Math.trunc(n))) : 160; })();

  const conn = await mysql.createConnection({ host, port, user, password, database: dbName, ssl });
  try {
    const [tables] = include.tables ? await conn.execute(`
      SELECT TABLE_NAME, TABLE_TYPE, ENGINE, TABLE_ROWS, CREATE_TIME, TABLE_COMMENT
      FROM information_schema.TABLES
      WHERE TABLE_SCHEMA = ?
      ORDER BY TABLE_NAME
    `, [dbName]) : [[]];

    const [cols] = include.columns ? await conn.execute(`
      SELECT TABLE_NAME, COLUMN_NAME, COLUMN_TYPE, DATA_TYPE, IS_NULLABLE, COLUMN_DEFAULT, COLUMN_KEY, EXTRA, COLUMN_COMMENT,
             CHARACTER_MAXIMUM_LENGTH, NUMERIC_PRECISION, NUMERIC_SCALE, ORDINAL_POSITION
      FROM information_schema.COLUMNS
      WHERE TABLE_SCHEMA = ?
      ORDER BY TABLE_NAME, ORDINAL_POSITION
    `, [dbName]) : [[]];

    const [fks] = include.foreignKeys ? await conn.execute(`
      SELECT CONSTRAINT_NAME, TABLE_NAME, COLUMN_NAME, REFERENCED_TABLE_NAME, REFERENCED_COLUMN_NAME
      FROM information_schema.KEY_COLUMN_USAGE
      WHERE TABLE_SCHEMA = ? AND REFERENCED_TABLE_NAME IS NOT NULL
      ORDER BY TABLE_NAME, COLUMN_NAME
    `, [dbName]) : [[]];

    const [views] = include.views ? await conn.execute(`
      SELECT TABLE_SCHEMA AS schema_name, TABLE_NAME AS name, VIEW_DEFINITION AS definition
      FROM information_schema.VIEWS
      WHERE TABLE_SCHEMA = ?
      ORDER BY TABLE_NAME
    `, [dbName]) : [[]];

    // Build maps
    const colByTable = new Map();
    for (const c of Array.isArray(cols) ? cols : []) {
      const t = c.TABLE_NAME; if (!colByTable.has(t)) colByTable.set(t, []);
      colByTable.get(t).push(c);
    }
    const fkByTable = new Map();
    for (const fk of Array.isArray(fks) ? fks : []) {
      const t = fk.TABLE_NAME; if (!fkByTable.has(t)) fkByTable.set(t, []);
      fkByTable.get(t).push(fk);
    }

    const nowIso = new Date().toISOString();
    let md = '';
    md += `# Database Overview: ${dbName}\n\n`;
    md += `- Dialect: ${dialect}\n`;
    md += `- Host: ${host}:${port}\n`;
    md += `- Generated at: ${nowIso}\n`;
    const dataNote = include.data ? 'with sample data rows (limited)' : 'no row data';
    md += `\n> This file summarizes the schema (${dataNote}). Use it to answer questions about table meanings, relationships, and where to query.\n`;

    if (Array.isArray(tables) && tables.length) {
      md += `\n## Tables\n`;
      for (const t of tables) {
        const tname = t.TABLE_NAME;
        const type = t.TABLE_TYPE || '';
        const engine = t.ENGINE || '';
        const approxRows = (t.TABLE_ROWS == null ? '' : String(t.TABLE_ROWS));
        const comment = t.TABLE_COMMENT || '';
        md += `\n### ${tname}\n`;
        const meta = [type && `Type: ${type}`, engine && `Engine: ${engine}`, approxRows && `Approx. rows: ${approxRows}`, comment && `Comment: ${comment}`].filter(Boolean).join(' | ');
        if (meta) md += `${meta}\n`;

        if (include.columns) {
          const colList = (colByTable.get(tname) || []).map((c) => {
            const parts = [];
            parts.push(`${c.COLUMN_NAME}: ${c.COLUMN_TYPE || c.DATA_TYPE}`);
            if (c.IS_NULLABLE === 'NO') parts.push('NOT NULL');
            if (c.COLUMN_DEFAULT != null) parts.push(`DEFAULT ${c.COLUMN_DEFAULT}`);
            if (c.COLUMN_KEY) parts.push(`KEY ${c.COLUMN_KEY}`);
            if (c.EXTRA) parts.push(c.EXTRA);
            if (c.COLUMN_COMMENT) parts.push(`-- ${c.COLUMN_COMMENT}`);
            return `- ${parts.join(' | ')}`;
          });
          if (colList.length) {
            md += `\nColumns:\n` + colList.join('\n') + '\n';
          }
        }

        if (include.foreignKeys) {
          const f = fkByTable.get(tname) || [];
          if (f.length) {
            md += `\nForeign Keys:\n`;
            for (const x of f) {
              md += `- ${x.COLUMN_NAME} → ${x.REFERENCED_TABLE_NAME}.${x.REFERENCED_COLUMN_NAME} (constraint ${x.CONSTRAINT_NAME})\n`;
            }
          }
        }
      }
    }

    if (include.views && Array.isArray(views) && views.length) {
      md += `\n## Views\n`;
      for (const v of views) {
        const vname = v.name || v.TABLE_NAME || '';
        let def = String(v.definition || '').trim();
        // Trim very long view bodies to keep file compact
        const MAX_DEF = 6000;
        if (def.length > MAX_DEF) def = def.slice(0, MAX_DEF) + `\n-- [truncated: ${def.length - MAX_DEF} chars omitted]`;
        md += `\n### ${vname}\n`;
        md += "```sql\n" + def + "\n```\n";
      }
    }

    if (include.data && Array.isArray(tables) && tables.length) {
      const toJsonSafe = (v) => {
        try {
          if (v == null) return null;
          if (Buffer.isBuffer(v)) return `[BLOB ${v.length}b]`;
          if (v instanceof Date) return v.toISOString();
          if (typeof v === 'bigint') return v.toString();
          if (typeof v === 'object') return v; // let JSON.stringify handle nested objects
          let s = String(v);
          if (s.length > MAX_CELL_LEN) s = s.slice(0, MAX_CELL_LEN) + '…';
          return s;
        } catch { return String(v); }
      };
      const clipRow = (row) => {
        const out = {};
        for (const [k, v] of Object.entries(row || {})) out[k] = toJsonSafe(v);
        return out;
      };
      const isBaseTable = (t) => String(t.TABLE_TYPE || '').toUpperCase() !== 'VIEW';
      const baseTables = tables.filter(isBaseTable).slice().sort((a,b)=> String(a.TABLE_NAME||'').localeCompare(String(b.TABLE_NAME||'')));
      const pick = baseTables.slice(0, sampleTables);
      if (pick.length) {
        md += `\n## Sample Data\n`;
        md += `\n> Up to ${sampleRows} rows per table; limited to ${sampleTables} table(s) to keep the file compact.\n`;
        let used = 0;
        for (const t of pick) {
          const tname = t.TABLE_NAME;
          let section = `\n### ${tname}\n`;
          try {
            // LIMIT cannot be parameterized in some MySQL variants; inline sanitized integer
            const lim = sampleRows;
            const [rows] = await conn.query(`SELECT * FROM \`${dbName}\`.\`${tname}\` LIMIT ${lim}`);
            const arr = Array.isArray(rows) ? rows : [];
            if (!arr.length) {
              section += `No rows.\n`;
            } else {
              const clipped = arr.map(clipRow);
              let js = '';
              try { js = JSON.stringify(clipped, null, 2); } catch { js = String(clipped); }
              if (js.length > MAX_DATA_TOTAL) js = js.slice(0, MAX_DATA_TOTAL) + `\n/* truncated */`;
              section += "```json\n" + js + "\n```\n";
            }
          } catch (e) {
            section += `Error: ${e?.message || String(e)}\n`;
          }
          if (used + section.length > MAX_DATA_TOTAL) { md += `\n-- [sample data truncated due to size limit]\n`; break; }
          md += section; used += section.length;
        }
      }
    }

    const ts = new Date();
    const pad = (n)=> String(n).padStart(2,'0');
    const stamp = `${ts.getFullYear()}${pad(ts.getMonth()+1)}${pad(ts.getDate())}-${pad(ts.getHours())}${pad(ts.getMinutes())}${pad(ts.getSeconds())}`;
    const fname = sanitizeFilename(`mydb-summary-${dbName}-${stamp}.md`);
    const fpath = path.join(dbSummaryDir, fname);
    await fs.promises.writeFile(fpath, md, 'utf8');
    const stats = await fs.promises.stat(fpath).catch(()=>null);
    return { filename: fname, path: fpath, size: stats?.size || md.length, content: md };
  } finally {
    try { await conn.end(); } catch {}
  }
}

app.post('/api/db-manager/ai/summary', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const raw = await getSetting(DBM_CFG_KEY);
    const cfg = raw ? JSON.parse(raw) : null;
    if (!cfg) return res.status(400).json({ ok:false, error:'no_config', message:'Configure DB Manager first.' });
    const opts = req.body || {};
    const out = await generateDbSummary(cfg, opts);
    return res.status(201).json({ ok:true, ...out });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Download a generated summary file by filename
app.get('/api/db-manager/ai/summary/:filename', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const fname = sanitizeFilename(String(req.params.filename||''));
    const fpath = path.join(dbSummaryDir, fname);
    if (!fs.existsSync(fpath)) return res.status(404).json({ ok:false, error:'not_found' });
    res.setHeader('Content-Type', 'text/markdown; charset=utf-8');
    res.setHeader('Content-Disposition', `attachment; filename="${fname}"`);
    fs.createReadStream(fpath).pipe(res);
  } catch (e) {
    return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Helper to generate local prompt IDs
function makeLocalPromptId() {
  try {
    const r = crypto.randomBytes(8).toString('hex');
    return `lpt_${r}`;
  } catch { return `lpt_${Date.now()}`; }
}

function makeMcpServerId() {
  try {
    const r = crypto.randomBytes(8).toString('hex');
    return `msrv_${r}`;
  } catch { return `msrv_${Date.now()}`; }
}

// MCP2 ID helpers
function makeMcp2KindId() {
  try { return `m2kind_${crypto.randomBytes(8).toString('hex')}`; } catch { return `m2kind_${Date.now()}`; }
}

// Helper: slug code from free text
function slugCode(s) {
  try { return String(s||'').trim().toLowerCase().replace(/[^a-z0-9]+/g,'-').replace(/^-+|-+$/g,''); } catch { return ''; }
}
function makeMcp2TypeId() {
  try { return `m2type_${crypto.randomBytes(8).toString('hex')}`; } catch { return `m2type_${Date.now()}`; }
}
function makeMcp2ServerId() {
  try { return `m2srv_${crypto.randomBytes(8).toString('hex')}`; } catch { return `m2srv_${Date.now()}`; }
}
function makeMcp2ToolId() {
  try { return `m2tool_${crypto.randomBytes(8).toString('hex')}`; } catch { return `m2tool_${Date.now()}`; }
}

// Derive MCP2 endpoints from http_base + server name
function deriveMcp2Endpoints(httpBase, name) {
  try {
    const base = String(httpBase || '').trim();
    const nm = String(name || '').trim();
    if (!base || !/^https?:\/\//i.test(base) || !nm) return {};
    const u = new URL(base.replace(/\/$/, ''));
    const wsScheme = u.protocol === 'https:' ? 'wss:' : 'ws:';
    const host = u.host;
    const http = `${u.protocol}//${host}`;
    const safe = encodeURIComponent(nm);
    return {
      ws_url: `${wsScheme}//${host}/mcp2/${safe}/ws`,
      stream_url: `${http}/mcp2/${safe}/stream`,
      sse_url: `${http}/mcp2/${safe}/events`,
    };
  } catch { return {}; }
}

// Known MCP2 type option schemas (for UI + validation)
const MCP2_TYPE_SCHEMAS = {
  // MariaDB PrestaShop database connection
  db_mariadb_prestashop: {
    title: 'MariaDB (PrestaShop) Connection',
    properties: {
      db_host: { type: 'string', title: 'DB Host', placeholder: '127.0.0.1' },
      db_port: { type: 'number', title: 'DB Port', default: 3306 },
      db_name: { type: 'string', title: 'Database', placeholder: 'prestashop' },
      db_user: { type: 'string', title: 'Username' },
      db_password: { type: 'string', title: 'Password', secret: true },
      table_prefix: { type: 'string', title: 'Table Prefix', default: 'ps_' },
      charset: { type: 'string', title: 'Charset', default: 'utf8mb4' },
      ssl: { type: 'boolean', title: 'SSL', default: false },
    },
    required: ['db_host','db_name','db_user','db_password'],
  },
};

async function getMcp2TypeCodeById(typeId) {
  try { const r = await pool.query(`SELECT code FROM mcp2_type WHERE id=$1 LIMIT 1`, [typeId]); return r.rowCount ? String(r.rows[0].code||'').trim() : ''; } catch { return ''; }
}

function validateTypeOptions(typeCode, values) {
  const code = String(typeCode||'').trim().toLowerCase();
  const schema = MCP2_TYPE_SCHEMAS[code];
  if (!schema) return { ok: true };
  const req = Array.isArray(schema.required) ? schema.required : [];
  const missing = [];
  for (const k of req) {
    const v = values ? values[k] : undefined;
    if (v === undefined || v === null || (typeof v === 'string' && v.trim() === '')) missing.push(k);
  }
  if (missing.length) return { ok: false, error: `missing_required`, fields: missing };
  return { ok: true };
}

// Default tool templates per MCP2 type (seeded on demand)
const MCP2_TYPE_DEFAULT_TOOLS = {
  db_mariadb_prestashop: [
    {
      name: 'db_list_tables',
      description: 'List database tables (MariaDB)',
      input_schema: { type: 'object', properties: {} },
      code: { kind: 'builtin', op: 'db_list_tables' },
      enabled: true,
      version: 1,
    },
    {
      name: 'db_query',
      description: 'Run a read-only SQL query (SELECT only)',
      input_schema: { type: 'object', properties: { sql: { type: 'string' } }, required: ['sql'] },
      code: { kind: 'builtin', op: 'db_query', read_only: true },
      enabled: true,
      version: 1,
    },
  ],
  api_prestashop: [
    {
      name: 'prestashop.get',
      description: 'HTTP GET a PrestaShop API path (e.g., /products?limit=10)',
      input_schema: { type: 'object', properties: { path: { type: 'string' }, query: { type: 'object' } }, required: ['path'] },
      code: { kind: 'http', method: 'GET' },
      enabled: true,
      version: 1,
    },
  ],
  zasilkovana_api: [
    {
      name: 'zasilkovana.track',
      description: 'Track a Zásilkovna shipment by number',
      input_schema: { type: 'object', properties: { number: { type: 'string' } }, required: ['number'] },
      code: { kind: 'http', method: 'GET', path: '/track' },
      enabled: true,
      version: 1,
    },
  ],
};

// Build a display name for an MCP server based on a base name, server type and options
function buildMcpServerDisplayName(baseName, serverType, options = {}, groupName = '') {
  try {
    const base = String(baseName || '').trim() || 'MCP';
    const t = String(serverType || '').toLowerCase();
    const opts = options && typeof options === 'object' ? options : {};
    const typeMap = { database: 'DB', files: 'Files', apis: 'API', ai: 'AI', custom: 'Custom' };
    const tLabel = typeMap[t] || (t ? t : '');
    let info = '';
    if (t === 'database') {
      info = String(opts.db_kind || '').toLowerCase();
      if (!info && typeof opts.connection_url === 'string') {
        try { const u = new URL(opts.connection_url); info = u.protocol.replace(':',''); } catch {}
      }
      if (!info) info = (opts.host ? String(opts.host) : 'db');
    } else if (t === 'apis') {
      if (typeof opts.base_url === 'string') { try { info = new URL(opts.base_url).host; } catch {} }
      if (!info) info = 'api';
    } else if (t === 'files') {
      let root = String(opts.root || '').trim();
      if (root) { root = root.replace(/\\/g, '/'); const parts = root.split('/').filter(Boolean); info = parts[parts.length - 1] || 'files'; }
      if (!info) info = 'files';
    } else if (t === 'ai') {
      if (typeof opts.api_base_url === 'string') { try { info = new URL(opts.api_base_url).host; } catch {} }
      if (!info) info = 'ai';
    } else if (t === 'custom') {
      info = String(opts.module || 'custom');
    }
    // Do not include group name in computed display name
    const segs = [];
    segs.push(base);
    if (tLabel) segs.push(tLabel);
    if (info) segs.push(String(info));
    return segs.join('_');
  } catch { return String(baseName || 'MCP'); }
}

function makeMcpGroupId() {
  try { return `mgp_${crypto.randomBytes(8).toString('hex')}`; }
  catch { return `mgp_${Date.now()}`; }
}

// Refer to src/shared/safeHtml.js for implementation.

// Implemented by src/modules/auth/index.js

const dbSchema = {
  loaded: false,
  visitors: {
    exists: false,
    idCol: null,
    hasCreatedAt: false,
    hasMeta: false,
    hasIdCol: false,
    hasVisitorIdCol: false,
    visitorIdNotNull: false,
    hasLastSeen: false,
    columns: [],
  },
  messages: {
    idType: null, // 'integer' | 'text' | 'uuid' | other
    hasContent: false,
    hasContentHtml: false,
    hasMessage: false,
    hasAgentId: false,
    hasVisitorId: false,
  },
  useDbDedup: false, // true if messages.id is text/uuid; false if integer
};

// Best-effort detection of tables/columns/types and constraints
async function introspectDb() {
  // Visitors: detect columns and constraints
  const vCols = await pool.query(
    `SELECT column_name, data_type, is_nullable
     FROM information_schema.columns
     WHERE table_schema='public' AND table_name='visitors'`
  );
  if (vCols.rowCount) {
    dbSchema.visitors.exists = true;
    dbSchema.visitors.columns = vCols.rows.map((r) => r.column_name);
    let hasId = false;
    let hasVisitorId = false;
    for (const r of vCols.rows) {
      if (r.column_name === "id") hasId = true;
      if (r.column_name === "visitor_id") {
        hasVisitorId = true;
        if (String(r.is_nullable).toLowerCase() === "no")
          dbSchema.visitors.visitorIdNotNull = true;
      }
      if (r.column_name === "created_at") dbSchema.visitors.hasCreatedAt = true;
      if (r.column_name === "last_seen") dbSchema.visitors.hasLastSeen = true;
      if (r.column_name === "meta") dbSchema.visitors.hasMeta = true;
    }
    dbSchema.visitors.hasIdCol = hasId;
    dbSchema.visitors.hasVisitorIdCol = hasVisitorId;

    // Which column is UNIQUE/PK?
    const uniq = await pool.query(`
      SELECT kcu.column_name, tc.constraint_type
      FROM information_schema.table_constraints tc
      JOIN information_schema.key_column_usage kcu
        ON tc.constraint_name = kcu.constraint_name
       AND tc.table_schema = kcu.table_schema
      WHERE tc.table_schema='public'
        AND tc.table_name='visitors'
        AND tc.constraint_type IN ('PRIMARY KEY','UNIQUE')
    `);
    const uniqCols = new Set(uniq.rows.map((r) => r.column_name));

    // Prefer column referenced by messages FK if present
    let referencedCol = null;
    try {
      const fk = await pool.query(`
        SELECT ccu.column_name AS visitors_col
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu
          ON tc.constraint_name = kcu.constraint_name
         AND tc.table_schema = kcu.table_schema
        JOIN information_schema.constraint_column_usage ccu
          ON ccu.constraint_name = tc.constraint_name
         AND ccu.table_schema = tc.table_schema
        WHERE tc.table_schema='public'
          AND tc.table_name='messages'
          AND tc.constraint_type='FOREIGN KEY'
          AND ccu.table_name='visitors'
          AND kcu.column_name='visitor_id'
      `);
      if (fk.rowCount) referencedCol = fk.rows[0].visitors_col || null;
    } catch {}

    if (
      referencedCol &&
      (referencedCol === "id" || referencedCol === "visitor_id")
    ) {
      dbSchema.visitors.idCol = referencedCol;
    } else if (uniqCols.has("visitor_id")) {
      dbSchema.visitors.idCol = "visitor_id";
    } else if (uniqCols.has("id")) {
      dbSchema.visitors.idCol = "id";
    } else if (hasVisitorId) {
      dbSchema.visitors.idCol = "visitor_id";
    } else if (hasId) {
      dbSchema.visitors.idCol = "id";
    }
  }

  // Do not auto-add visitors.meta; project now stores concrete columns only

  // Messages
  const mCols = await pool.query(
    `SELECT column_name, data_type
     FROM information_schema.columns
     WHERE table_schema='public' AND table_name='messages'`
  );
  for (const r of mCols.rows) {
    if (r.column_name === "id") dbSchema.messages.idType = r.data_type; // integer/text/uuid
    if (r.column_name === "content") dbSchema.messages.hasContent = true;
    if (r.column_name === "content_html") dbSchema.messages.hasContentHtml = true;
    if (r.column_name === "message") dbSchema.messages.hasMessage = true;
    if (r.column_name === "agent_id") dbSchema.messages.hasAgentId = true;
    if (r.column_name === "visitor_id") dbSchema.messages.hasVisitorId = true;
  }
  dbSchema.useDbDedup =
    dbSchema.messages.idType && dbSchema.messages.idType !== "integer";

  dbSchema.loaded = true;

  logToFile(
    `🧭 DB schema: visitors=${JSON.stringify(
      dbSchema.visitors
    )}, messages=${JSON.stringify(dbSchema.messages)}, useDbDedup=${
      dbSchema.useDbDedup
    }`
  );
}

await ensureTables().catch((e) =>
  logToFile(`⚠️ Auto-migrations failed: ${e.message}`)
);
await introspectDb().catch((e) =>
  logToFile(`⚠️ DB introspection failed: ${e.message}`)
);
// Load dynamic MCP token from DB when available
await loadMcpTokenFromDb().catch(() => {});
await loadMcpPublicBaseFromDb().catch(() => {});
await loadMcpDevTokenFromDb().catch(() => {});
await loadMcpDevPublicBaseFromDb().catch(() => {});
await loadMcpDevPrestaTokenFromDb().catch(() => {});
await loadMcpDevPrestaPublicBaseFromDb().catch(() => {});
  await loadOpenaiApiKeyFromDb().catch(() => {});
// init MaxMind after function and reader are defined (see below)

// Optional one-shot backfill from meta and drop the column if requested
async function maybeBackfillAndDropMeta() {
  try {
    const flag = String(process.env.DROP_VISITORS_META || "").toLowerCase();
    const enabled = flag === "1" || flag === "true" || flag === "yes";
    if (!enabled) return;
    if (!dbSchema.visitors.exists) return;

    // Re-introspect to ensure we have the latest column info
    try {
      await introspectDb();
    } catch {}
    if (!dbSchema.visitors.hasMeta) {
      logToFile("ℹ️ visitors.meta does not exist; nothing to drop");
      return;
    }

    const idCol =
      dbSchema.visitors.idCol ||
      (dbSchema.visitors.hasVisitorIdCol ? "visitor_id" : "id") ||
      "visitor_id";

    logToFile("🛠️ Backfilling visitors columns from meta before drop…");
    await pool.query(`
      UPDATE public.visitors
      SET
        customer_logged = COALESCE(
          customer_logged,
          NULLIF(meta->>'customer_logged','')::boolean,
          NULLIF(meta->'customer'->>'logged','')::boolean,
          NULLIF(meta->'customer'->>'is_logged','')::boolean
        ),
        customer_id = COALESCE(
          customer_id,
          NULLIF(meta->>'customer_id','')::int,
          NULLIF(meta->>'id_customer','')::int,
          NULLIF(meta->'customer'->>'id','')::int,
          NULLIF(meta->'customer'->>'customer_id','')::int
        ),
        customer_email = COALESCE(
          customer_email,
          NULLIF(meta->>'customer_email',''),
          NULLIF(meta->'customer'->>'email','')
        ),
        customer_firstname = COALESCE(
          customer_firstname,
          NULLIF(meta->>'customer_firstname',''),
          NULLIF(meta->'customer'->>'firstname',''),
          NULLIF(meta->'customer'->>'first_name','')
        ),
        customer_lastname = COALESCE(
          customer_lastname,
          NULLIF(meta->>'customer_lastname',''),
          NULLIF(meta->'customer'->>'lastname',''),
          NULLIF(meta->'customer'->>'last_name','')
        ),
        orders_count = COALESCE(
          orders_count,
          NULLIF(meta->>'orders_count','')::int,
          NULLIF(meta->'customer'->>'orders_count','')::int
        ),
        orders_amount = COALESCE(
          orders_amount,
          NULLIF(meta->>'orders_amount','')::numeric,
          NULLIF(meta->'customer'->>'orders_amount','')::numeric
        ),
        last_action = COALESCE(last_action, NULLIF(meta->>'last_action','')),
        last_action_at = COALESCE(last_action_at, NULLIF(meta->>'last_action_at','')::timestamp),
        city = COALESCE(city, NULLIF(meta->>'city','')),
        postcode = COALESCE(postcode, NULLIF(meta->>'postcode',''), NULLIF(meta->>'zip',''))
    `);

    logToFile("🧹 Dropping visitors.meta column…");
    await pool.query(`ALTER TABLE public.visitors DROP COLUMN IF EXISTS meta`);

    // Update in-memory schema flags
    dbSchema.visitors.hasMeta = false;
    logToFile("✅ visitors.meta dropped");
  } catch (e) {
    logToFile(`⚠️ Backfill/drop meta failed: ${e.code || ""} ${e.message}`);
  }
}

  // Optional geo debug logger
function geoDebugLog(ip) {
  if (!DEBUG_GEO || !ip) return;
  try {
    const lite = geoipLite?.lookup?.(ip);
    const liteOut = lite
      ? {
          country: lite.country,
          city: lite.city || null,
          zip: lite.zip || lite.postalCode || null,
        }
      : null;
    let mmOut = null;
    try {
      if (mmReader) {
        const r = mmReader.city(ip);
        mmOut = {
          country: r?.country?.isoCode || null,
          city:
            r?.city?.names?.fr || r?.city?.names?.en || r?.city?.name || null,
          postal: r?.postal?.code || null,
        };
      }
    } catch {}
    logToFile(
      `🛰️ GEO lookup ip=${ip} lite=${JSON.stringify(
        liteOut
      )} maxmind=${JSON.stringify(mmOut)}`
    );
  } catch (e) {
    logToFile(`⚠️ GEO debug failed for ip=${ip}: ${e.message}`);
  }
}

let mmReader = null; // @maxmind/geoip2-node Reader, if loaded
async function initMaxMind() {
  try {
    const dbPath = process.env.MAXMIND_DB_PATH || "";
    if (!dbPath) return;
    if (!fs.existsSync(dbPath)) {
      logToFile(`⚠️ MAXMIND_DB_PATH set but file not found: ${dbPath}`);
      return;
    }
    const mod = await import("@maxmind/geoip2-node");
    const buf = fs.readFileSync(dbPath);
    mmReader = mod.Reader.openBuffer(buf);
    logToFile(`🗺️  MaxMind GeoLite2 loaded from ${dbPath}`);
  } catch (e) {
    mmReader = null;
    logToFile(`⚠️ MaxMind init failed: ${e.message}`);
  }
}

function geoLookup(ip) {
  if (!ip) return { country_code: null, city: null, postcode: null };
  // Prefer MaxMind if available
  try {
    if (mmReader) {
      const r = mmReader.city(ip);
      const cc = (r && r.country && r.country.isoCode) || null;
      const city =
        (r &&
          r.city &&
          (r.city.names?.fr ||
            r.city.names?.en ||
            r.city.names?.de ||
            r.city.names?.es)) ||
        r?.city?.name ||
        null;
      const postcode = (r && r.postal && r.postal.code) || null;
      if (cc || city || postcode) return { country_code: cc, city, postcode };
    }
  } catch {}

  // Fallback to geoip-lite
  try {
    const g = geoipLite?.lookup?.(ip);
    const cc = (g && g.country) || null;
    const city = (g && g.city) || null;
    const postcode = (g && (g.zip || g.postalCode)) || null;
    return { country_code: cc, city, postcode };
  } catch {
    return { country_code: null, city: null, postcode: null };
  }
}

// Initialize MaxMind after declaration (avoids TDZ on mmReader)
await initMaxMind();

await maybeBackfillAndDropMeta();

// Lightweight in-memory cache for geo lookups to avoid repeated disk reads
const geoCache = new Map(); // key: ip, value: { country_code, city, postcode }
const GEO_TTL_MS = 24 * 60 * 60 * 1000; // 24h
function getCachedGeo(ip) {
  try {
    const item = geoCache.get(ip);
    if (!item) return null;
    if (Date.now() - item.t > GEO_TTL_MS) {
      geoCache.delete(ip);
      return null;
    }
    return item.v;
  } catch { return null; }
}
function setCachedGeo(ip, v) {
  try { geoCache.set(ip, { v, t: Date.now() }); } catch {}
}

// Public geo endpoint for frontend fallbacks
// Example: GET /api/geo?ip=109.164.51.45 -> { ip, country_code, city, postal }
app.get('/api/geo', (req, res) => {
  try {
    const ip = String(req.query.ip || '').trim();
    if (!ip) return res.status(400).json({ error: 'bad_request', message: 'ip required' });
    const cached = getCachedGeo(ip);
    if (cached) return res.json({ ip, ...cached, postal: cached.postcode });
    const g = geoLookup(ip) || { country_code: null, city: null, postcode: null };
    setCachedGeo(ip, g);
    return res.json({ ip, country_code: g.country_code, city: g.city, postal: g.postcode });
  } catch (e) {
    res.status(500).json({ error: 'server_error', message: e?.message || String(e) });
  }
});

// Mark server as ready: routes below are registered and DB/geo init completed
serverReady = true;

// Best-effort: seed DB with current MCP server config from legacy settings
try { await syncMcpServersFromLegacy(); } catch {}

// Initialize MCP tools registry (reused for WS + OpenAI tool-calling)
const MCP = createMcpTools({
  pool,
  io,
  dbSchema,
  ensureVisitorExists,
  sanitizeAgentHtmlServer,
  textToSafeHTML,
  upsertVisitorColumns,
  uploadDir: mcpUploadDir,
  verifyToken: async (token, ctx={}) => {
    const t = String(token || '').trim();
    if (!t) return false;
    // Global token matches
    const g = getMcpToken();
    if (g && t === g) return true;
    // Bot-specific token
    const botId = String(ctx.id_bot || '').trim();
    if (botId) {
      const r = await pool.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 AND COALESCE(mcp_token,'') <> '' AND mcp_token=$2 LIMIT 1`, [botId, t]);
      if (r.rowCount) return true;
    }
    // Any bot token
    const r = await pool.query(`SELECT 1 FROM chatbot_config WHERE COALESCE(mcp_token,'') <> '' AND mcp_token=$1 LIMIT 1`, [t]);
    return !!r.rowCount;
  },
  needsAuth: async (ctx={}) => {
    if (getMcpToken()) return true;
    const botId = String(ctx.id_bot || '').trim();
    if (botId) {
      const r = await pool.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 AND COALESCE(mcp_token,'') <> '' LIMIT 1`, [botId]);
      return !!r.rowCount;
    }
    const r = await pool.query(`SELECT 1 FROM chatbot_config WHERE COALESCE(mcp_token,'') <> '' LIMIT 1`);
    return !!r.rowCount;
  }
});

async function getVisitorRow(visitorId) {
  if (!dbSchema.visitors.exists) return null;
  const idCol =
    dbSchema.visitors.idCol ||
    (dbSchema.visitors.hasVisitorIdCol ? "visitor_id" : "id");
  if (!idCol) return null;
  try {
    const res = await pool.query(
      `SELECT * FROM visitors WHERE ${idCol} = $1 LIMIT 1`,
      [visitorId]
    );
    return res.rowCount ? res.rows[0] : null;
  } catch (e) {
    logToFile(`? getVisitorRow error: ${e.code || ""} ${e.message}`);
    return null;
  }
}
async function ensureVisitorExists(visitorId) {
  if (!dbSchema.visitors.exists) return; // nothing to do

  // Prefer inserting only into visitor_id to avoid type mismatches on id (some DBs use integer)
  let targetCol = null;
  if (dbSchema.visitors.hasVisitorIdCol) targetCol = 'visitor_id';
  else if (dbSchema.visitors.hasIdCol) targetCol = 'id';
  else if (dbSchema.visitors.idCol) targetCol = dbSchema.visitors.idCol;
  if (!targetCol) return;

  // Build columns to satisfy NOT NULL constraints: include both id and visitor_id when they exist
  const cols = [];
  const params = [];
  const ph = [];
  if (dbSchema.visitors.hasIdCol) { cols.push('id'); params.push(visitorId); ph.push(`$${params.length}`); }
  if (dbSchema.visitors.hasVisitorIdCol) { cols.push('visitor_id'); params.push(visitorId); ph.push(`$${params.length}`); }
  if (!cols.length) { cols.push(targetCol); params.push(visitorId); ph.push(`$${params.length}`); }
  if (dbSchema.visitors.hasCreatedAt) { cols.push('created_at'); ph.push('NOW()'); }

  const conflictCol = dbSchema.visitors.idCol || targetCol;
  const sql = `INSERT INTO visitors (${cols.join(', ')}) VALUES (${ph.join(', ')}) ON CONFLICT (${conflictCol}) DO NOTHING`;
  try {
    await pool.query(sql, params);
  } catch (e) {
    if (String(e.code) === '42P10') {
      // No unique constraint -> fallback WHERE NOT EXISTS
      const fb = `INSERT INTO visitors (${cols.join(', ')}) SELECT ${ph.join(', ')} WHERE NOT EXISTS (SELECT 1 FROM visitors WHERE ${targetCol} = $1)`;
      try { await pool.query(fb, params); logToFile('ℹ️ ensureVisitorExists fallback WHERE NOT EXISTS used'); return; } catch (e2) { logToFile(`❌ ensureVisitorExists fallback error: ${e2.code || ''} ${e2.message}`); }
    }
    logToFile(`❌ ensureVisitorExists error: ${e.code || ''} ${e.message}`);
  }

  // Optional: best-effort set id to same value when id column exists and compatible
  if (dbSchema.visitors.hasIdCol && targetCol !== 'id') {
    try { await pool.query(`UPDATE visitors SET id = $1 WHERE ${targetCol} = $1 AND id IS NULL`, [visitorId]); } catch {}
  }
}

// Hard-disable meta writes: legacy no-op after removing the column
async function upsertVisitorMeta(_visitorId, _patch = {}) {
  return; // intentionally no-op
}

// --- Hotfix: make ensureVisitorExists robust when visitors.id is NOT NULL/PRIMARY KEY
// Insert both id and visitor_id when present to satisfy constraints.
ensureVisitorExists = async function(visitorId) {
  if (!dbSchema.visitors.exists) return;

  const hasId = !!dbSchema.visitors.hasIdCol;
  const hasVid = !!dbSchema.visitors.hasVisitorIdCol;

  const cols = [];
  const params = [];
  const ph = [];

  if (hasId) { cols.push('id'); params.push(visitorId); ph.push(`$${params.length}`); }
  if (hasVid) { cols.push('visitor_id'); params.push(visitorId); ph.push(`$${params.length}`); }

  if (!cols.length && dbSchema.visitors.idCol) {
    cols.push(dbSchema.visitors.idCol);
    params.push(visitorId);
    ph.push(`$${params.length}`);
  }
  if (!cols.length) return;

  if (dbSchema.visitors.hasCreatedAt) { cols.push('created_at'); ph.push('NOW()'); }

  const conflictCol = dbSchema.visitors.idCol || (hasId ? 'id' : (hasVid ? 'visitor_id' : cols[0]));
  const sql = `INSERT INTO visitors (${cols.join(', ')}) VALUES (${ph.join(', ')}) ON CONFLICT (${conflictCol}) DO NOTHING`;
  try {
    await pool.query(sql, params);
  } catch (e) {
    if (String(e.code) === '42P10') {
      const targetCol = cols[0];
      const fb = `INSERT INTO visitors (${cols.join(', ')}) SELECT ${ph.join(', ')} WHERE NOT EXISTS (SELECT 1 FROM visitors WHERE ${targetCol} = $1)`;
      try { await pool.query(fb, params); logToFile('🟡 ensureVisitorExists fallback WHERE NOT EXISTS used'); return; } catch (e2) { logToFile(`❌ ensureVisitorExists fallback error: ${e2.code || ''} ${e2.message}`); }
    } else {
      logToFile(`❌ ensureVisitorExists error: ${e.code || ''} ${e.message}`);
    }
  }

  if (hasId && hasVid) {
    try { await pool.query(`UPDATE visitors SET id = $1 WHERE visitor_id = $1 AND id IS NULL`, [visitorId]); } catch {}
  }
}

  // Update concrete columns in visitors when they exist
  async function upsertVisitorColumns(visitorId, values = {}) {
  if (!dbSchema.visitors.exists) return;
  const colsAvailable = new Set(dbSchema.visitors.columns || []);
  const hasCols = colsAvailable.size > 0;
  const idCol =
    dbSchema.visitors.idCol ||
    (dbSchema.visitors.hasVisitorIdCol ? "visitor_id" : "id") ||
    "visitor_id";
  if (!idCol) return;

  const setters = [];
  const params = [visitorId];
  const push = (col, val) => {
    if (hasCols && !colsAvailable.has(col)) return;
    if (val === undefined || val === null) return;
    params.push(val);
    setters.push(`${col} = $${params.length}`);
  };
  // Avoid overwriting important identity fields with empty strings
  const pushNE = (col, val) => {
    if (val === undefined || val === null) return;
    if (typeof val === 'string' && val.trim() === '') return;
    push(col, val);
  };
  // Best-effort: if new columns are provided but not known in schema cache, try to add them
  const ensureCol = async (colName, ddl) => {
    if (!hasCols || colsAvailable.has(colName)) return;
    try {
      await pool.query(ddl);
      colsAvailable.add(colName);
      if (Array.isArray(dbSchema.visitors.columns)) dbSchema.visitors.columns.push(colName);
    } catch {}
  };
  if (values.conversation_status !== undefined && !colsAvailable.has('conversation_status')) {
    await ensureCol('conversation_status', `ALTER TABLE visitors ADD COLUMN IF NOT EXISTS conversation_status TEXT`);
  }
  if (values.archived !== undefined && !colsAvailable.has('archived')) {
    await ensureCol('archived', `ALTER TABLE visitors ADD COLUMN IF NOT EXISTS archived BOOLEAN DEFAULT FALSE`);
  }
  if (values.chatbot_id !== undefined && !colsAvailable.has('chatbot_id')) {
    await ensureCol('chatbot_id', `ALTER TABLE visitors ADD COLUMN IF NOT EXISTS chatbot_id TEXT`);
  }

  // Map provided values to columns
  push("ip", values.ip);
  push("country_code", values.country_code);
  push("user_agent", values.user_agent);
  push("language", values.lang || values.language);
  push("origin", values.origin);
  const pageUrlProvided = Boolean(values.page_url_last || values.page_url);
  push("page_url_last", values.page_url_last || values.page_url);
  push("referrer", values.referrer);
  push("title", values.title);
  push("time_zone", values.time_zone || values.timezone);
  push("screen_w", values.screen_w);
  push("screen_h", values.screen_h);
  push("screen_dpr", values.screen_dpr);
  push("id_shop", values.id_shop || values.shop_id);
  push("shop_name", values.shop_name);
  push("id_lang", values.id_lang);
  push("lang_iso", values.lang_iso || values.shop_lang_iso);
  push("lang_name", values.lang_name || values.shop_lang_name);
  push("currency", values.currency);
  push("cart_total", values.cart_total);
  push("assistant_id", values.assistant_id);
  push("chatbot_id", values.chatbot_id);
  push("openai_enabled", values.openai_enabled ?? values.assistant_enabled);
  push("archived", values.archived);
  push("conversation_status", values.conversation_status);
  push("first_seen", values.first_seen);
  // Customer/account context (if these columns exist in your schema)
  push("customer_logged", values.customer_logged);
  pushNE("customer_id", values.customer_id);
  pushNE("customer_email", values.customer_email);
  pushNE("customer_firstname", values.customer_firstname);
  pushNE("customer_lastname", values.customer_lastname);
  push("orders_count", values.orders_count);
  push("orders_amount", values.orders_amount);
  pushNE("city", values.city);
  pushNE("postcode", values.postcode || values.zip);
  const lastActionExplicit = values.last_action !== undefined && values.last_action !== null;
  const lastActionAtExplicit = values.last_action_at !== undefined && values.last_action_at !== null;
  push("last_action", values.last_action);
  push("last_action_at", values.last_action_at);

  // last_seen: set to NOW() if column exists, unless an explicit value provided
  if (colsAvailable.has("last_seen")) {
    if (values.last_seen) {
      push("last_seen", values.last_seen);
    } else {
      setters.push("last_seen = NOW()");
    }
  }

  // Derive screen_* from screen object if present
  if (values.screen && typeof values.screen === "object") {
    const sw = values.screen.width ?? values.screen.w;
    const sh = values.screen.height ?? values.screen.h;
    const sd = values.screen.pixelRatio ?? values.screen.dpr;
    push("screen_w", sw);
    push("screen_h", sh);
    push("screen_dpr", sd);
  }

  // Fallback: if we received a page URL but no explicit last_action(_at),
  // set sensible defaults only when the DB fields are currently NULL.
  if (pageUrlProvided) {
    if (colsAvailable.has("last_action") && !lastActionExplicit) {
      setters.push("last_action = COALESCE(last_action, 'page_view')");
    }
    if (colsAvailable.has("last_action_at") && !lastActionAtExplicit) {
      setters.push("last_action_at = COALESCE(last_action_at, NOW())");
    }
  }

  if (!setters.length) return;
  const sql = `UPDATE visitors SET ${setters.join(", ")} WHERE ${idCol} = $1`;
  try {
    await pool.query(sql, params);
  } catch (e) {
    logToFile(`❌ upsertVisitorColumns error: ${e.code || ""} ${e.message}`);
  }
}

// Env flags to control memory dedup when DB can't dedup by id
const MEM_DEDUP_ENABLED = !/^(0|false|no)$/i.test(process.env.CHAT_MEM_DEDUP || '1');
const MEM_DEDUP_LIMIT = Math.max(100, Number(process.env.CHAT_MEM_DEDUP_LIMIT || 10000));
const memDedup = new Set();
const memDedupQueue = [];
function rememberMsg(id) {
  if (!MEM_DEDUP_ENABLED) return;
  if (!id || memDedup.has(id)) return;
  memDedup.add(id);
  memDedupQueue.push(id);
  if (memDedupQueue.length > MEM_DEDUP_LIMIT) {
    const old = memDedupQueue.shift();
    memDedup.delete(old);
  }
}

function clientNetworkInfo(s) {
  const h = s.handshake.headers || {};
  const firstIp = (v) =>
    String(v || "")
      .split(",")
      .map((x) => x.trim())
      .filter(Boolean)[0] || null;
  // Prefer CDN/proxy-provided real client IPs
  const ip =
    h["cf-connecting-ip"] ||
    h["true-client-ip"] ||
    h["x-real-ip"] ||
    firstIp(h["x-forwarded-for"]) ||
    s.handshake.address ||
    null;
  const ua = h["user-agent"] || null;
  const lang = h["accept-language"] || null;
  return { ip, ua, lang };
}

io.on("connection", (socket) => {
  if (DEBUG_SOCKET) logToFile(`🟢 Socket connecté : ${socket.id}`);

  // Eviter les re-joins et handlers multiples
  let joinedVisitorId = null;
  socket.removeAllListeners("visitor_hello");
  socket.removeAllListeners("agent_hello");
  socket.removeAllListeners("chat_message");

  // --- Visitor joins their own room (only once) + persist meta
  socket.on("visitor_hello", async (data = {}) => {
    logWidget("🧾 WIDGET visitor_hello", data);
    const vid = typeof data.visitorId === "string" ? data.visitorId.trim() : "";
    if (!vid) return;
    if (joinedVisitorId === vid) return; // déjà joint
    joinedVisitorId = vid;
    socket.join(vid);

    await ensureVisitorExists(vid);

    const net = clientNetworkInfo(socket);
    geoDebugLog(net.ip);
    let country_code = null;
    let city = null;
    let postcode = null;
    if (net.ip) {
      const g = geoLookup(net.ip);
      country_code = g.country_code;
      city = g.city;
      postcode = g.postcode;
    }

    // Map customer fields (support nested shapes and aliases)
    const custHello =
      data && typeof data.customer === "object"
        ? data.customer
        : data && typeof data.account === "object"
        ? data.account
        : {};
    const hello_customer_logged =
      data.customer_logged ?? custHello.logged ?? custHello.is_logged ?? null;
    const hello_customer_id =
      data.customer_id ??
      data.id_customer ??
      custHello.id ??
      custHello.customer_id ??
      null;
    const hello_customer_email = data.customer_email ?? custHello.email ?? null;
    const hello_customer_firstname =
      data.customer_firstname ??
      custHello.firstname ??
      custHello.first_name ??
      null;
    const hello_customer_lastname =
      data.customer_lastname ??
      custHello.lastname ??
      custHello.last_name ??
      null;
    const hello_orders_count =
      data.orders_count ?? custHello.orders_count ?? null;
    const hello_orders_amount =
      data.orders_amount ?? custHello.orders_amount ?? null;

    const patch = {
      ip: net.ip || null,
      user_agent: net.ua || null,
      lang: data.lang || net.lang || null,
      time_zone: data.time_zone || null,
      screen: data.screen || null,
      origin: data.origin || null,
      page_url: data.page_url || null,
      page_url_last: data.page_url || null,
      title: data.title || null,
      referrer: data.referrer || null,
      currency: data.currency || null,
      shop_name: data.shop_name || null,
      id_shop: data.id_shop ?? data.shop_id ?? null,
      id_lang: data.id_lang ?? null,
      lang_iso: data.lang_iso ?? null,
      lang_name: data.lang_name ?? null,
      assistant_id: data.assistant_id || null,
      openai_enabled: data.assistant_enabled ?? null,
      customer_logged: hello_customer_logged,
      customer_id: hello_customer_id,
      customer_email: hello_customer_email,
      customer_firstname: hello_customer_firstname,
      customer_lastname: hello_customer_lastname,
      orders_count: hello_orders_count,
      orders_amount: hello_orders_amount,
      country_code,
      city,
      postcode,
      last_seen: new Date().toISOString(),
    };
    // Infer action on first hello
    if (data.page_url) {
      patch.last_action = "page_view";
      patch.last_action_at = new Date().toISOString();
    }
    // If explicit logout (false), record it but keep identity columns intact
    if (patch.customer_logged === false) {
      if (!patch.last_action) patch.last_action = "logout";
      if (!patch.last_action_at) patch.last_action_at = new Date().toISOString();
    }
    // Preserve existing customer_* data only when update is anonymous (no flag provided)
    try {
      const existing = await getVisitorRow(vid);
      if (
        existing &&
        existing.customer_logged === true &&
        (patch.customer_logged === null || patch.customer_logged === undefined)
      ) {
        patch.customer_id = undefined;
        patch.customer_email = undefined;
        patch.customer_firstname = undefined;
        patch.customer_lastname = undefined;
        patch.orders_count = undefined;
        patch.orders_amount = undefined;
      }
    } catch {}

    if (dbSchema.visitors.hasMeta) {
      await upsertVisitorMeta(vid, patch);
    }
    await upsertVisitorColumns(vid, {
      ip: patch.ip,
      user_agent: patch.user_agent,
      lang: patch.lang,
      time_zone: patch.time_zone,
      origin: patch.origin,
      page_url_last: patch.page_url_last,
      referrer: patch.referrer,
      currency: patch.currency,
      shop_name: patch.shop_name,
      id_shop: patch.id_shop,
      id_lang: patch.id_lang,
        lang_iso: patch.lang_iso,
        lang_name: patch.lang_name,
        chatbot_id: patch.chatbot_id,
      customer_logged: patch.customer_logged,
      customer_id: patch.customer_id,
      customer_email: patch.customer_email,
      customer_firstname: patch.customer_firstname,
      customer_lastname: patch.customer_lastname,
      orders_count: patch.orders_count,
      orders_amount: patch.orders_amount,
      country_code,
      city: patch.city,
      postcode: patch.postcode,
      screen: patch.screen,
      assistant_id: patch.assistant_id,
      openai_enabled: patch.openai_enabled,
      last_action: patch.last_action,
      last_action_at: patch.last_action_at,
    });

    // Optional: record visit for right panel history
    try {
      if (data.page_url) {
        await pool.query(
          `INSERT INTO visits (visitor_id, page_url, title, origin, referrer,
                               utm_source, utm_medium, utm_campaign, utm_term, utm_content)
           SELECT $1, $2, $3, $4, $5, $6, $7, $8, $9, $10
           WHERE NOT EXISTS (
             SELECT 1 FROM visits
             WHERE visitor_id=$1 AND page_url=$2 AND occurred_at >= NOW() - interval '2 minutes'
           )`,
          [
            vid,
            data.page_url || null,
            data.title || null,
            data.origin || null,
            data.referrer || null,
            data.utm_source || null,
            data.utm_medium || null,
            data.utm_campaign || null,
            data.utm_term || null,
            data.utm_content || null,
          ]
        );
      }
    } catch (e) {
      logToFile(`⚠️ visits insert failed: ${e.code || ""} ${e.message}`);
    }

    // If a real last_seen column exists, bump it
    if (dbSchema.visitors.hasLastSeen && dbSchema.visitors.idCol) {
      try {
        await pool.query(
          `UPDATE visitors SET last_seen = NOW() WHERE ${dbSchema.visitors.idCol} = $1`,
          [vid]
        );
      } catch {}
    }

    // Notify dashboards so right panel fills instantly
    io.to("agents").emit("visitor_update", { visitorId: vid, ...patch });

    if (DEBUG_SOCKET) logToFile(`👋 Visitor ${vid} joined room`);
  });

  // --- Rich context sent after hello (from your widget)
  socket.on("visitor_context", async (data = {}) => {
    logWidget("🧾 WIDGET visitor_context", data);
    try {
      const vid =
        (typeof data.visitorId === "string" && data.visitorId.trim()) ||
        joinedVisitorId;
      if (!vid) return;

      await ensureVisitorExists(vid);

      const net = clientNetworkInfo(socket);
      geoDebugLog(net.ip);
      let country_code = null;
      let city = null;
      let postcode = null;
      if (net.ip) {
        const g = geoLookup(net.ip);
        country_code = g.country_code;
        city = g.city;
        postcode = g.postcode;
      }

      // Normalize screen shape
      let screen = null;
      if (data.screen && typeof data.screen === "object") {
        const w = data.screen.width ?? data.screen.w ?? null;
        const h = data.screen.height ?? data.screen.h ?? null;
        const d = data.screen.pixelRatio ?? data.screen.dpr ?? null;
        screen = { w, h, dpr: d };
      }

      // Map customer fields (support nested shapes and aliases)
      const custCtx =
        data && typeof data.customer === "object"
          ? data.customer
          : data && typeof data.account === "object"
          ? data.account
          : {};
      const ctx_customer_logged =
        data.customer_logged ?? custCtx.logged ?? custCtx.is_logged ?? null;
      const ctx_customer_id =
        data.customer_id ??
        data.id_customer ??
        custCtx.id ??
        custCtx.customer_id ??
        null;
      const ctx_customer_email = data.customer_email ?? custCtx.email ?? null;
      const ctx_customer_firstname =
        data.customer_firstname ??
        custCtx.firstname ??
        custCtx.first_name ??
        null;
      const ctx_customer_lastname =
        data.customer_lastname ?? custCtx.lastname ?? custCtx.last_name ?? null;
      const ctx_orders_count =
        data.orders_count ?? custCtx.orders_count ?? null;
      const ctx_orders_amount =
        data.orders_amount ?? custCtx.orders_amount ?? null;

      // Build patch mapped to our meta fields
      const patch = {
        ip: net.ip || null,
        user_agent: data.user_agent || net.ua || null,
        lang: data.browser_languages || data.lang || net.lang || null,
        time_zone: data.timezone || data.time_zone || null,
        country_code: data.country_code || country_code || null,
        screen,
        origin:
          (data.first_url
            ? (() => {
                try {
                  return new URL(data.first_url).origin;
                } catch {
                  return null;
                }
              })()
            : null) || null,
        page_url: data.current_url || null,
        page_url_last: data.current_url || null,
        title: data.title || null,
        referrer: data.referrer || data.first_referrer || null,
        currency: data.currency || null,
        shop_name: data.shop_name || null,
        id_shop: data.shop_id ?? null,
        id_lang: data.id_lang ?? null,
        lang_iso: data.shop_lang_iso || data.lang_iso || null,
        lang_name: data.shop_lang_name || data.lang_name || null,
        chatbot_id: (typeof data.chatbot_id === 'string' && data.chatbot_id.trim())
          ? data.chatbot_id.trim()
          : (typeof data.chatbotId === 'string' && data.chatbotId.trim() ? data.chatbotId.trim() : null),
        cart_total: data.cart_total ?? null,
        assistant_id: data.assistant_id || null,
        openai_enabled: data.assistant_enabled ?? null,
        customer_logged: ctx_customer_logged,
        customer_id: ctx_customer_id,
        customer_email: ctx_customer_email,
        customer_firstname: ctx_customer_firstname,
        customer_lastname: ctx_customer_lastname,
        orders_count: ctx_orders_count,
        orders_amount: ctx_orders_amount,
        city: data.city || city || null,
        postcode: data.postcode || data.zip || postcode || null,
        last_seen: new Date().toISOString(),
      };

      // Infer and attach an action marker
      const inferredAction =
        (typeof data.action === "string" && data.action) ||
        (patch.customer_logged === true ? "login" : null) ||
        (patch.customer_logged === false ? "logout" : null) ||
        (typeof data.cart_total === "number" ? "cart_update" : null) ||
        (data.current_url ? "page_view" : null);
      if (inferredAction) {
        patch.last_action = inferredAction;
        patch.last_action_at = new Date().toISOString();
      }

      // Preserve existing customer_* data if this update is anonymous
      try {
        const existing = await getVisitorRow(vid);
        if (
          existing &&
          existing.customer_logged === true &&
          patch.customer_logged !== true
        ) {
          patch.customer_logged = undefined;
          patch.customer_id = undefined;
          patch.customer_email = undefined;
          patch.customer_firstname = undefined;
          patch.customer_lastname = undefined;
          patch.orders_count = undefined;
          patch.orders_amount = undefined;
        }
      } catch {}

      if (dbSchema.visitors.hasMeta) {
        await upsertVisitorMeta(vid, patch);
      }
      await upsertVisitorColumns(vid, {
        ip: patch.ip,
        user_agent: patch.user_agent,
        lang: patch.lang,
        time_zone: patch.time_zone,
        origin: patch.origin,
        page_url_last: patch.page_url_last,
        referrer: patch.referrer,
        currency: patch.currency,
        shop_name: patch.shop_name,
        id_shop: patch.id_shop,
        id_lang: patch.id_lang,
        lang_iso: patch.lang_iso,
        lang_name: patch.lang_name,
        chatbot_id: patch.chatbot_id,
        cart_total: patch.cart_total,
        assistant_id: patch.assistant_id,
        openai_enabled: patch.openai_enabled,
        customer_logged: patch.customer_logged,
        customer_id: patch.customer_id,
        customer_email: patch.customer_email,
        customer_firstname: patch.customer_firstname,
        customer_lastname: patch.customer_lastname,
        orders_count: patch.orders_count,
        orders_amount: patch.orders_amount,
        country_code: patch.country_code,
        city: patch.city,
        postcode: patch.postcode,
        screen: patch.screen,
        last_action: patch.last_action,
        last_action_at: patch.last_action_at,
      });

      // If a dedicated last_seen column exists, bump it
      if (dbSchema.visitors.hasLastSeen && dbSchema.visitors.idCol) {
        try {
          await pool.query(
            `UPDATE visitors SET last_seen = NOW() WHERE ${dbSchema.visitors.idCol} = $1`,
            [vid]
          );
        } catch {}
      }

      // Optional: record a visit for the right panel
      try {
        if (data.current_url) {
          await pool.query(
            `INSERT INTO visits (visitor_id, page_url, title, origin, referrer,
                                 utm_source, utm_medium, utm_campaign, utm_term, utm_content)
             SELECT $1, $2, $3, $4, $5, $6, $7, $8, $9, $10
             WHERE NOT EXISTS (
               SELECT 1 FROM visits
               WHERE visitor_id=$1 AND page_url=$2 AND occurred_at >= NOW() - interval '2 minutes'
             )`,
            [
              vid,
              data.current_url || null,
              data.title || null,
              patch.origin,
              patch.referrer,
              data.utm_source || null,
              data.utm_medium || null,
              data.utm_campaign || null,
              data.utm_term || null,
              data.utm_content || null,
            ]
          );
        }
      } catch (e) {
        logToFile(
          `⚠️ visits insert (context) failed: ${e.code || ""} ${e.message}`
        );
      }

      // Notify dashboards so the right panel updates instantly
      io.to("agents").emit("visitor_update", { visitorId: vid, ...patch });
    } catch (e) {
      logToFile(`❌ visitor_context error: ${e.message}`);
    }
  });

  // --- Agent joins dashboard room
  socket.on("agent_hello", () => {
    socket.join("agents");
    logToFile(`👨‍💻 Agent ${socket.id} joined room agents`);
  });

  // --- Visitor opens the chat UI (fires every open)
  socket.on("chat_opened", async (data = {}) => {
    try {
      const vid = (typeof data.visitorId === 'string' && data.visitorId.trim()) || joinedVisitorId;
      if (!vid) return;
      if (joinedVisitorId !== vid) {
        joinedVisitorId = vid;
        socket.join(vid);
      }
      await ensureVisitorExists(vid);
      // Mark last action for dashboards
      const nowIso = new Date().toISOString();
      await upsertVisitorColumns(vid, { last_action: 'chat_opened', last_action_at: nowIso });
      io.to("agents").emit("visitor_update", { visitorId: vid, last_action: 'chat_opened', last_action_at: nowIso });
      logToFile(`🟨 chat_opened from visitor ${vid}`);

      // Auto-greet immediately on open if this visitor has no messages yet
      try {
        const countRes = await pool.query(
          `SELECT COUNT(*)::int AS c FROM messages WHERE visitor_id = $1`,
          [vid]
        );
        const msgCount = (countRes.rows[0] && countRes.rows[0].c) || 0;
        if (msgCount === 0) {
          // Resolve welcome message with priority: visitor's chatbot_id (if allowed) -> Hub bots -> shop/lang fallback
          let welcomeText = null;
          let langIso = null;
          try {
            // Load Hub selection (allowed list)
            let allowedIds = [];
            try {
              const raw = await getSetting('conversation_hub_bots');
              const j = raw ? JSON.parse(raw) : null;
              if (j && Array.isArray(j.ids)) allowedIds = j.ids.map(String);
            } catch {}

            // Try visitor-specific chatbot first (mapping ext -> internal), enforcing whitelist if any
            try {
              const idCol = dbSchema.visitors.idCol || (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id' : 'id') || 'visitor_id';
              const vr = await pool.query(`SELECT chatbot_id, shop_name, lang_iso FROM visitors WHERE ${idCol} = $1 LIMIT 1`, [vid]);
              if (vr.rowCount) {
                const ext = (vr.rows[0].chatbot_id || '').trim();
                langIso = vr.rows[0].lang_iso || langIso;
                if (ext) {
                  let internalId = null;
                  try { await ensureHubBotMapTable(); const m = await pool.query(`SELECT id_bot FROM hub_bot_map WHERE assistant_id_ext=$1 LIMIT 1`, [ext]); if (m.rowCount) internalId = m.rows[0].id_bot; } catch {}
                  if (!internalId) { try { const chk = await pool.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [ext]); if (chk.rowCount) internalId = ext; } catch {} }
                  const allowed = (!allowedIds || !allowedIds.length) || allowedIds.includes(internalId);
                  if (internalId && allowed) {
                    const qr = await pool.query(
                      `SELECT wm.content, wm.enabled
                         FROM chatbot_welcome_link l
                         JOIN welcome_message wm ON wm.id_message = l.welcome_message_id
                        WHERE l.id_bot = $1
                        LIMIT 1`,
                      [internalId]
                    );
                    if (qr.rowCount) {
                      const w = qr.rows[0];
                      if (w && w.enabled && w.content && String(w.content).trim()) {
                        welcomeText = String(w.content).trim().slice(0, 2000);
                      }
                    }
                  }
                }
              }
            } catch {}

            // 2) Try Hub-selected chatbots
            if (!welcomeText && allowedIds && allowedIds.length) {
              for (const id of allowedIds) {
                const qr = await pool.query(
                  `SELECT wm.content, wm.enabled
                     FROM chatbot_welcome_link l
                     JOIN welcome_message wm ON wm.id_message = l.welcome_message_id
                    WHERE l.id_bot = $1
                    LIMIT 1`,
                  [id]
                );
                if (qr.rowCount) {
                  const w = qr.rows[0];
                  if (w && w.enabled && w.content && String(w.content).trim()) {
                    welcomeText = String(w.content).trim().slice(0, 2000);
                    break;
                  }
                }
              }
            }

            // 3) Fallback: welcome_message by (shop_name, lang_iso)
            if (!welcomeText) {
              const idCol = dbSchema.visitors.idCol || (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id' : 'id') || 'visitor_id';
              const r = await pool.query(
                `SELECT v.shop_name, v.lang_iso, wm.content, wm.enabled
                   FROM visitors v
                   LEFT JOIN welcome_message wm
                     ON wm.shop_name = v.shop_name AND wm.lang_iso = v.lang_iso
                  WHERE v.${idCol} = $1
                  LIMIT 1`,
                [vid]
              );
              if (r.rowCount) {
                const row = r.rows[0];
                langIso = row.lang_iso || null;
                if (row && row.enabled && row.content && String(row.content).trim()) {
                  welcomeText = String(row.content).trim().slice(0, 2000);
                }
              }
            }
          } catch {}

          if (!welcomeText) {
            const isFr = /^fr/i.test(String(langIso || ''));
            welcomeText = isFr
              ? "Bonjour ! Comment pouvons-nous vous aider ?"
              : "Hello! How can we help you today?";
          }

          // Insert greeting as agent message and emit
          const greetId =
            globalThis.crypto?.randomUUID?.() ||
            `${Date.now()}-${Math.random().toString(16).slice(2)}`;

          try {
            const cols = [];
            const params = [];
            const ph = [];
            let onConflict = "";
            if (dbSchema.useDbDedup) {
              cols.push("id");
              params.push(greetId);
              ph.push(`$${params.length}`);
              onConflict = " ON CONFLICT (id) DO NOTHING";
            }
            if (dbSchema.messages.hasVisitorId) {
              cols.push("visitor_id");
              params.push(vid);
              ph.push(`$${params.length}`);
            }
            cols.push("sender");
            params.push("agent");
            ph.push(`$${params.length}`);
            const msgCol = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
            cols.push(msgCol);
            params.push(welcomeText);
            ph.push(`$${params.length}`);
            if (dbSchema.messages.hasAgentId) {
              cols.push("agent_id");
              params.push(null);
              ph.push(`$${params.length}`);
            }
            const sql = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')})${onConflict} RETURNING id, created_at`;
            await pool.query(sql, params);

            // Update conversation status + notify agents
            const nowIso2 = new Date().toISOString();
            await upsertVisitorColumns(vid, {
              last_action: 'agent_message',
              last_action_at: nowIso2,
              conversation_status: 'waiting_visitor',
            });
            io.to("agents").emit("visitor_update", {
              visitorId: vid,
              conversation_status: 'waiting_visitor',
              last_action: 'agent_message',
              last_action_at: nowIso2,
            });

            const greetingOutgoing = {
              id: greetId,
              visitorId: vid,
              from: 'agent',
              message: welcomeText,
              html: textToSafeHTML(welcomeText),
              agentId: null,
              timestamp: Date.now(),
            };
            io.to(vid).emit("chat_message", greetingOutgoing);
            io.to("agents").emit("dashboard_message", greetingOutgoing);
            if (DEBUG_CHAT) {
              logJson("→ chat_message (greeting chat_opened)", greetingOutgoing);
              logJson("→ dashboard_message (greeting chat_opened)", greetingOutgoing);
            }
          } catch (e) {
            logToFile(`⚠️ auto-greeting (chat_opened) failed for ${vid}: ${e.message}`);
          }
        }
      } catch (e) {
        logToFile(`⚠️ chat_opened auto-greet check failed for ${vid}: ${e.message}`);
      }
    } catch (e) {
      logToFile(`⚠️ chat_opened handler error: ${e.message}`);
    }
  });

  // --- First-time chat start (one-time per browser via localStorage)
  socket.on("chat_started", async (data = {}) => {
    try {
      const vid = (typeof data.visitorId === 'string' && data.visitorId.trim()) || joinedVisitorId;
      if (!vid) return;
      if (joinedVisitorId !== vid) {
        joinedVisitorId = vid;
        socket.join(vid);
      }
      await ensureVisitorExists(vid);

      // If no messages yet, proactively greet to start the conversation
      const countRes = await pool.query(
        `SELECT COUNT(*)::int AS c FROM messages WHERE visitor_id = $1`,
        [vid]
      );
      const msgCount = (countRes.rows[0] && countRes.rows[0].c) || 0;
      if (msgCount === 0) {
        // Resolve welcome message with priority: visitor's chatbot_id (if allowed) -> Hub bots -> shop/lang fallback
        let welcomeText = null;
        let langIso = null;
        try {
          // Load Hub selection (allowed list)
          let allowedIds = [];
          try {
            const raw = await getSetting('conversation_hub_bots');
            const j = raw ? JSON.parse(raw) : null;
            if (j && Array.isArray(j.ids)) allowedIds = j.ids.map(String);
          } catch {}

          // Try visitor-specific chatbot first (mapping ext -> internal), enforcing whitelist if any
          try {
            const idCol = dbSchema.visitors.idCol || (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id' : 'id') || 'visitor_id';
            const vr = await pool.query(`SELECT chatbot_id, shop_name, lang_iso FROM visitors WHERE ${idCol} = $1 LIMIT 1`, [vid]);
            if (vr.rowCount) {
              const ext = (vr.rows[0].chatbot_id || '').trim();
              langIso = vr.rows[0].lang_iso || langIso;
              if (ext) {
                let internalId = null;
                try { await ensureHubBotMapTable(); const m = await pool.query(`SELECT id_bot FROM hub_bot_map WHERE assistant_id_ext=$1 LIMIT 1`, [ext]); if (m.rowCount) internalId = m.rows[0].id_bot; } catch {}
                if (!internalId) { try { const chk = await pool.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [ext]); if (chk.rowCount) internalId = ext; } catch {} }
                const allowed = (!allowedIds || !allowedIds.length) || allowedIds.includes(internalId);
                if (internalId && allowed) {
                  const qr = await pool.query(
                    `SELECT wm.content, wm.enabled
                       FROM chatbot_welcome_link l
                       JOIN welcome_message wm ON wm.id_message = l.welcome_message_id
                      WHERE l.id_bot = $1
                      LIMIT 1`,
                    [internalId]
                  );
                  if (qr.rowCount) {
                    const w = qr.rows[0];
                    if (w && w.enabled && w.content && String(w.content).trim()) {
                      welcomeText = String(w.content).trim().slice(0, 2000);
                    }
                  }
                }
              }
            }
          } catch {}

          // 2) Try Hub-selected chatbots
          if (!welcomeText && allowedIds && allowedIds.length) {
            for (const id of allowedIds) {
              const qr = await pool.query(
                `SELECT wm.content, wm.enabled
                   FROM chatbot_welcome_link l
                   JOIN welcome_message wm ON wm.id_message = l.welcome_message_id
                  WHERE l.id_bot = $1
                  LIMIT 1`,
                [id]
              );
              if (qr.rowCount) {
                const w = qr.rows[0];
                if (w && w.enabled && w.content && String(w.content).trim()) {
                  welcomeText = String(w.content).trim().slice(0, 2000);
                  break;
                }
              }
            }
          }

          // 3) Fallback: welcome_message by (shop_name, lang_iso)
          if (!welcomeText) {
            const idCol = dbSchema.visitors.idCol || (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id' : 'id') || 'visitor_id';
            const r = await pool.query(
              `SELECT v.shop_name, v.lang_iso, wm.content, wm.enabled
                 FROM visitors v
                 LEFT JOIN welcome_message wm
                   ON wm.shop_name = v.shop_name AND wm.lang_iso = v.lang_iso
                WHERE v.${idCol} = $1
                LIMIT 1`,
              [vid]
            );
            if (r.rowCount) {
              const row = r.rows[0];
              langIso = row.lang_iso || null;
              if (row && row.enabled && row.content && String(row.content).trim()) {
                welcomeText = String(row.content).trim().slice(0, 2000);
              }
            }
          }
        } catch {}

        if (!welcomeText) {
          const isFr = /^fr/i.test(String(langIso || ''));
          welcomeText = isFr
            ? "Bonjour ! Comment pouvons-nous vous aider ?"
            : "Hello! How can we help you today?";
        }

        const greetId =
          globalThis.crypto?.randomUUID?.() || `${Date.now()}-${Math.random().toString(16).slice(2)}`;

        try {
          // Insert greeting as agent message
          const cols = [];
          const params = [];
          const ph = [];
          let onConflict = "";
          if (dbSchema.useDbDedup) {
            cols.push("id");
            params.push(greetId);
            ph.push(`$${params.length}`);
            onConflict = " ON CONFLICT (id) DO NOTHING";
          }
          if (dbSchema.messages.hasVisitorId) {
            cols.push("visitor_id");
            params.push(vid);
            ph.push(`$${params.length}`);
          }
          cols.push("sender");
          params.push("agent");
          ph.push(`$${params.length}`);
          const msgCol = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
          cols.push(msgCol);
          params.push(welcomeText);
          ph.push(`$${params.length}`);
          if (dbSchema.messages.hasAgentId) {
            cols.push("agent_id");
            params.push(null);
            ph.push(`$${params.length}`);
          }
          const sql = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')})${onConflict} RETURNING id, created_at`;
          await pool.query(sql, params);

          // Update conversation status + notify agents
          const nowIso = new Date().toISOString();
          await upsertVisitorColumns(vid, {
            last_action: 'agent_message',
            last_action_at: nowIso,
            conversation_status: 'waiting_visitor',
          });
          io.to("agents").emit("visitor_update", {
            visitorId: vid,
            conversation_status: 'waiting_visitor',
            last_action: 'agent_message',
            last_action_at: nowIso,
          });

          // Emit greeting to visitor and mirror to dashboards
          const greetingOutgoing = {
            id: greetId,
            visitorId: vid,
            from: 'agent',
            message: welcomeText,
            html: textToSafeHTML(welcomeText),
            agentId: null,
            timestamp: Date.now(),
          };
          io.to(vid).emit("chat_message", greetingOutgoing);
          io.to("agents").emit("dashboard_message", greetingOutgoing);
          if (DEBUG_CHAT) {
            logJson("→ chat_message (greeting chat_started)", greetingOutgoing);
            logJson("→ dashboard_message (greeting chat_started)", greetingOutgoing);
          }
        } catch (e) {
          logToFile(`⚠️ auto-greeting (chat_started) failed for ${vid}: ${e.message}`);
        }
      }

      if (DEBUG_CHAT) logToFile(`🟩 chat_started from visitor ${vid}`);
    } catch (e) {
      logToFile(`⚠️ chat_started handler error: ${e.message}`);
    }
  });

  // --- Handle chat messages
  socket.on("chat_message", async (data = {}) => {
    if (DEBUG_CHAT) {
      logJson("💬 chat_message (in)", {
        from: data?.from,
        visitorId: data?.visitorId,
        len: (data?.message || "").length,
      });
    }
    if (data && data.from === "visitor") {
      logWidget("🧾 WIDGET chat_message", {
        id: data.id,
        visitorId: data.visitorId,
        message: typeof data.message === "string" ? data.message : "",
        timestamp: data.timestamp || Date.now(),
      });
    }
    // Normalisation
    const sender = data.from === "agent" ? "agent" : "visitor";
    const visitorId =
      typeof data.visitorId === "string" ? data.visitorId.trim() : "";
    if (!visitorId) return;

    // S'assurer que la room est join en cas de course au 1er message
    if (joinedVisitorId !== visitorId) {
      joinedVisitorId = visitorId;
      socket.join(visitorId);
    }

    await ensureVisitorExists(visitorId);

    // Accept multiple payload shapes from various widgets
    let raw = "";
    if (typeof data.message === "string") raw = data.message;
    else if (typeof data.content === "string") raw = data.content;
    else if (typeof data.text === "string") raw = data.text;
    else if (typeof data.body === "string") raw = data.body;
    const content = raw.trim().substring(0, 2000);
    if (!content) return;
    // Log: message received from visitor
    try {
      if (sender === 'visitor') {
        const sample = content.length > 160 ? content.slice(0, 160) + '…' : content;
        logToFile(`chat: message received from visitor visitorId=${visitorId} len=${content.length} text="${sample.replace(/\s+/g,' ').replace(/"/g,'\\"')}"`);
      }
    } catch {}

    // client-supplied id (UUID) used for routing and optional dedup
    const clientId =
      (typeof data.id === "string" && data.id) ||
      (typeof data.client_id === "string" && data.client_id) ||
      (typeof data.message_id === "string" && data.message_id) ||
      globalThis.crypto?.randomUUID?.() ||
      `${Date.now()}-${Math.random().toString(16).slice(2)}`;

    // If agent sent HTML (from rich editor), sanitize and keep tags; otherwise autolink plain text
    const looksHtml = /<\s*[a-z][\s\S]*>/i.test(content) || (typeof data.html === 'string' && data.html.trim().length > 0);
    const content_html = looksHtml ? sanitizeAgentHtmlServer((typeof data.html === 'string' && data.html.trim()) || content) : textToSafeHTML(content);
    const agentId = sender === "agent" ? data.agentId ?? null : null;

    // Build INSERT dynamically to match DB schema
    const cols = [];
    const params = [];
    const ph = [];

    // messages.id
    let onConflict = "";
    if (dbSchema.useDbDedup) {
      // DB can dedup by id (TEXT/UUID)
      cols.push("id");
      params.push(clientId);
      ph.push(`$${params.length}`);
      onConflict = " ON CONFLICT (id) DO NOTHING";
    } else {
      // DB id is integer -> optional memory dedup to avoid spamming
      if (MEM_DEDUP_ENABLED && memDedup.has(clientId)) {
        if (DEBUG_SQL) logToFile(`ℹ️  Duplicate (memory) ignored id=${clientId}`);
        return;
      }
    }

    // visitor_id
    if (dbSchema.messages.hasVisitorId) {
      cols.push("visitor_id");
      params.push(visitorId);
      ph.push(`$${params.length}`);
    }

    // sender
    cols.push("sender");
    params.push(sender);
    ph.push(`$${params.length}`);

    // content/message (store plain text – strip tags for readability if HTML)
    const msgCol = dbSchema.messages.hasContent
      ? "content"
      : dbSchema.messages.hasMessage
      ? "message"
      : "content"; // default
    const plain = looksHtml ? String(content).replace(/<[^>]+>/g, ' ').replace(/\s+/g,' ').trim() : content;
    cols.push(msgCol);
    params.push(plain);
    ph.push(`$${params.length}`);

    // content_html (optional)
    if (dbSchema.messages.hasContentHtml) {
      cols.push("content_html");
      params.push(content_html);
      ph.push(`$${params.length}`);
    }

    // agent_id (optional)
    if (dbSchema.messages.hasAgentId) {
      cols.push("agent_id");
      params.push(agentId);
      ph.push(`$${params.length}`);
    }

    const sql = `INSERT INTO messages (${cols.join(", ")})
                 VALUES (${ph.join(", ")})${onConflict}
                 RETURNING id, created_at`;
    const tryInsert = async () => {
      if (DEBUG_SQL) logToFile(sql);
      const ins = await pool.query(sql, params);
      if (DEBUG_SQL) {
        if (ins.rowCount) {
          logToFile(`✅ DB INSERT ok id=${clientId} visitor=${visitorId}`);
        } else {
          logToFile(`ℹ️  Duplicate message ignored id=${clientId}`);
        }
      }
      rememberMsg(clientId);
    };
    try {
      await tryInsert();
    } catch (e) {
      const code = String(e.code || '');
      if (code === "23503") {
        try {
          await ensureVisitorExists(visitorId);
          await tryInsert();
        } catch (e2) {
          logToFile(`❌ DB INSERT retry error: ${e2.code || ""} ${e2.message}`);
        }
      } else if (code === '42P10') {
        // No unique constraint for ON CONFLICT; retry without it
        try {
          const sqlNoConflict = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')}) RETURNING id, created_at`;
          if (DEBUG_SQL) logToFile(sqlNoConflict);
          const ins2 = await pool.query(sqlNoConflict, params);
          if (DEBUG_SQL && ins2.rowCount) logToFile(`✅ DB INSERT (no conflict) ok id=${clientId} visitor=${visitorId}`);
          rememberMsg(clientId);
        } catch (e3) {
          logToFile(`❌ DB INSERT (no conflict) error: ${e3.code || ''} ${e3.message}`);
        }
      } else {
        logToFile(
          `❌ DB INSERT error: ${e.code || ""} ${
            e.message
          }. Columns: [${cols.join(", ")}]`
        );
      }
    }

    // Update conversation status based on who sent the last message
    try {
      const nowIso = new Date().toISOString();
      const fromVisitor = sender === 'visitor';
      const status = sender === 'agent' ? 'waiting_visitor' : 'waiting_agent';
      const patchCols = {
        last_action: sender === 'agent' ? 'agent_message' : 'visitor_message',
        last_action_at: nowIso,
        conversation_status: status,
      };
      // If a (known) visitor writes, unarchive the conversation so it comes back to Actives
      if (fromVisitor) patchCols.archived = false;
      await upsertVisitorColumns(visitorId, patchCols);
      const patchEvent = {
        visitorId,
        conversation_status: status,
        last_action: patchCols.last_action,
        last_action_at: nowIso,
      };
      if (fromVisitor) patchEvent.archived = false;
      io.to("agents").emit("visitor_update", patchEvent);
    } catch {}

    // Persist assistant/lang context if provided with the message (some widgets include it here)
    if (sender === "visitor") {
      const payload = (data && data.payload) || {};
      const assistant_id = data.assistant_id || payload.assistant_id || null;
      const openai_enabled =
        data.assistant_enabled ?? payload.assistant_enabled ?? null;
      const id_lang = data.id_lang ?? payload.id_lang ?? null;
      if (assistant_id != null || openai_enabled != null || id_lang != null) {
        try {
          await upsertVisitorColumns(visitorId, {
            assistant_id,
            openai_enabled,
            id_lang,
          });
          if (dbSchema.visitors.hasMeta) {
            await upsertVisitorMeta(visitorId, {
              assistant_id,
              openai_enabled,
              id_lang,
            });
          }
        } catch (e) {
          logToFile(
            `⚠️ persist assistant_id from message failed: ${e.code || ""} ${
              e.message
            }`
          );
        }
      }
    }

    // Objet propre émis sur le réseau (keep clientId for frontend correlation)
    const outgoing = {
      id: clientId,
      visitorId,
      from: sender,
      message: plain,
      html: content_html,
      agentId,
      timestamp: Date.now(),
    };

    // Routage :
    if (sender === "visitor") {
      // ne pas renvoyer au visiteur (UI optimiste)
      io.to("agents").emit("dashboard_message", outgoing);
      if (DEBUG_CHAT) logJson("→ dashboard_message", outgoing);

      // Behaviour: auto_draft / auto_reply per chatbot_config for this visitor
      try {
        const vr = await pool.query(
          `SELECT shop_name, lang_iso FROM visitors WHERE (visitor_id = $1 OR id = $1) LIMIT 1`,
          [visitorId]
        );
        const shop = vr.rows?.[0]?.shop_name || null;
        const lang = vr.rows?.[0]?.lang_iso || null;
        if (shop && lang) {
          const botId = makeBotId(shop, lang);
          const br = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [botId]);
          if (br.rowCount) {
            const cfg = br.rows[0];
            if (cfg.openai_api_key && cfg.prompt_id && cfg.bot_behavior) {
              if (cfg.bot_behavior === 'auto_draft') {
                // generate draft and push to agents
                try {
                  const { text } = await respondWithPrompt({
                    apiKey: cfg.openai_api_key,
                    promptId: cfg.prompt_id,
                    promptVersion: cfg.prompt_version || undefined,
                    input: content || payload?.content || payload?.message || '',
                  });
                  if (text) io.to('agents').emit('assistant_draft', { visitorId, draft: text });
                } catch (e) { logToFile(`auto_draft error: ${e.message}`); }
              } else if (cfg.bot_behavior === 'auto_reply') {
                try {
                  // Log: message sent to OpenAI
                  try {
                    const inTxt = String(content || payload?.content || payload?.message || '');
                    const s = inTxt.length > 160 ? inTxt.slice(0,160) + '…' : inTxt;
                    logToFile(`chatbot: message sent to openai bot=${botId} visitor=${visitorId} len=${inTxt.length} text="${s.replace(/\s+/g,' ').replace(/"/g,'\\"')}"`);
                  } catch {}
                  const { text } = await respondWithPrompt({
                    apiKey: cfg.openai_api_key,
                    promptId: cfg.prompt_id,
                    promptVersion: cfg.prompt_version || undefined,
                    input: content || payload?.content || payload?.message || '',
                  });
                  // Log: reply from OpenAI
                  try {
                    const s = String(text || '');
                    const sm = s.length > 160 ? s.slice(0,160) + '…' : s;
                    logToFile(`chatbot: reply from openai bot=${botId} visitor=${visitorId} len=${s.length} text="${sm.replace(/\s+/g,' ').replace(/"/g,'\\"')}"`);
                  } catch {}
                  if (text) {
                    // Insert as agent message (respect DB schema columns)
                    const cols2 = [];
                    const params2 = [];
                    const ph2 = [];
                    if (dbSchema.messages.hasVisitorId) { cols2.push('visitor_id'); params2.push(visitorId); ph2.push(`$${params2.length}`); }
                    cols2.push('sender'); params2.push('agent'); ph2.push(`$${params2.length}`);
                    const msgCol2 = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
                    cols2.push(msgCol2); params2.push(text); ph2.push(`$${params2.length}`);
                    if (dbSchema.messages.hasContentHtml) { cols2.push('content_html'); params2.push(textToSafeHTML(text)); ph2.push(`$${params2.length}`); }
                    if (dbSchema.messages.hasAgentId) { cols2.push('agent_id'); params2.push(null); ph2.push(`$${params2.length}`); }
                    const sql2 = `INSERT INTO messages (${cols2.join(', ')}) VALUES (${ph2.join(', ')}) RETURNING id, created_at`;
                    const ins = await pool.query(sql2, params2);

                    const out2 = {
                      id: ins.rows?.[0]?.id || undefined,
                      visitorId,
                      from: 'agent',
                      message: text,
                      html: textToSafeHTML(text),
                      timestamp: Date.parse(ins.rows?.[0]?.created_at) || Date.now(),
                    };
                    io.to(visitorId).emit('chat_message', out2);
                    io.to('agents').emit('dashboard_message', out2);
                    // Log: message sent to visitor (auto_reply)
                    try { logToFile(`chat: message sent to visitor visitorId=${visitorId} from=agent kind=auto_reply id=${out2.id || ''}`); } catch {}
                  }
                } catch (e) { logToFile(`auto_reply error: ${e.message}`); }
              }
            }
          }
        }
      } catch (e) { logToFile(`behaviour hook error: ${e.message}`); }
    } else {
      io.to(visitorId).emit("chat_message", outgoing);
      io.to("agents").emit("dashboard_message", outgoing);
      if (DEBUG_CHAT) {
        logJson("→ chat_message (to visitor)", outgoing);
        logJson("→ dashboard_message (mirror)", outgoing);
      }
    }

    // Log: message sent to visitor (manual agent or mirrored outgoing)
    try { if (sender !== 'visitor') logToFile(`chat: message sent to visitor visitorId=${visitorId} from=${sender} id=${outgoing.id || ''}`); } catch {}

    // Auto-greeting when a visitor starts a chat (first message)
    try {
      if (sender === "visitor") {
        // Check if this is the first message in this conversation
        const countRes = await pool.query(
          `SELECT COUNT(*)::int AS c FROM messages WHERE visitor_id = $1`,
          [visitorId]
        );
        const msgCount = (countRes.rows[0] && countRes.rows[0].c) || 0;
        if (msgCount === 1) {
          // Find a welcome message for this visitor's shop/lang if configured
          let welcomeText = null;
          let langIso = null;
          try {
            const idCol = dbSchema.visitors.idCol || (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id' : 'id') || 'visitor_id';
            const r = await pool.query(
              `SELECT v.shop_name, v.lang_iso, wm.content, wm.enabled
               FROM visitors v
               LEFT JOIN welcome_message wm
                 ON wm.shop_name = v.shop_name AND wm.lang_iso = v.lang_iso
               WHERE v.${idCol} = $1
               LIMIT 1`,
              [visitorId]
            );
            if (r.rowCount) {
              const row = r.rows[0];
              langIso = row.lang_iso || null;
              if (row && row.enabled && row.content && String(row.content).trim()) {
                welcomeText = String(row.content).trim().slice(0, 2000);
              }
            }
          } catch {}

          if (!welcomeText) {
            const isFr = /^fr/i.test(String(langIso || ''));
            welcomeText = isFr
              ? "Bonjour ! Comment pouvons-nous vous aider ?"
              : "Hello! How can we help you today?";
          }

          // Insert the greeting as an agent message, then emit to visitor and dashboards
          const greetId =
            globalThis.crypto?.randomUUID?.() ||
            `${Date.now()}-${Math.random().toString(16).slice(2)}`;

          try {
            const cols2 = [];
            const params2 = [];
            const ph2 = [];
            let onConflict2 = "";
            if (dbSchema.useDbDedup) {
              cols2.push("id");
              params2.push(greetId);
              ph2.push(`$${params2.length}`);
              onConflict2 = " ON CONFLICT (id) DO NOTHING";
            }
            if (dbSchema.messages.hasVisitorId) {
              cols2.push("visitor_id");
              params2.push(visitorId);
              ph2.push(`$${params2.length}`);
            }
            cols2.push("sender");
            params2.push("agent");
            ph2.push(`$${params2.length}`);
            const msgCol2 = dbSchema.messages.hasContent
              ? "content"
              : dbSchema.messages.hasMessage
              ? "message"
              : "content";
            cols2.push(msgCol2);
            params2.push(welcomeText);
            ph2.push(`$${params2.length}`);
            if (dbSchema.messages.hasAgentId) {
              cols2.push("agent_id");
              params2.push(null);
              ph2.push(`$${params2.length}`);
            }
            const sql2 = `INSERT INTO messages (${cols2.join(", ")}) VALUES (${ph2.join(", ")})${onConflict2} RETURNING id, created_at`;
            await pool.query(sql2, params2);

            // Update conversation status for the agent message
            try {
              const nowIso2 = new Date().toISOString();
              await upsertVisitorColumns(visitorId, {
                last_action: 'agent_message',
                last_action_at: nowIso2,
                conversation_status: 'waiting_visitor',
              });
              io.to("agents").emit("visitor_update", {
                visitorId,
                conversation_status: 'waiting_visitor',
                last_action: 'agent_message',
                last_action_at: nowIso2,
              });
            } catch {}

            const greetingOutgoing = {
              id: greetId,
              visitorId,
              from: "agent",
              message: welcomeText,
              html: textToSafeHTML(welcomeText),
              agentId: null,
              timestamp: Date.now(),
            };
            io.to(visitorId).emit("chat_message", greetingOutgoing);
            io.to("agents").emit("dashboard_message", greetingOutgoing);
            if (DEBUG_CHAT) {
              logJson("→ chat_message (greeting)", greetingOutgoing);
              logJson("→ dashboard_message (greeting)", greetingOutgoing);
            }
          } catch (e) {
            logToFile(`⚠️ auto-greeting failed for ${visitorId}: ${e.message}`);
          }
        }
      }
    } catch {}
  });

  socket.on("disconnect", () => {
    if (DEBUG_SOCKET) logToFile(`🔴 Socket déconnecté : ${socket.id}`);
  });
});

app.use("/api", (req, _res, next) => {
  if (DEBUG_API) logToFile(`➡️ API HIT ${req.method} ${req.originalUrl}`);
  next();
});

// List latest conversation per visitor (optionally last N days; days=0 = all time)
app.get("/api/conversations", async (req, res) => {
  try {
    const days = Math.max(0, Number(req.query.days || 30));
    const limit = Math.max(1, Math.min(1000, Number(req.query.limit || 500)));

    const params = [];
    let where = "";
    if (days > 0) {
      params.push(days);
      where = `WHERE m.created_at >= NOW() - ($1::int || ' days')::interval`;
    }

    // Choose the right message column based on DB schema
    const msgExpr = dbSchema.messages.hasContent
      ? "m.content"
      : dbSchema.messages.hasMessage
      ? "m.message"
      : "m.message"; // fallback

    // Use DISTINCT ON for broader Postgres compatibility
    let sql;
    if (dbSchema.visitors.exists) {
      sql = `
        SELECT * FROM (
          SELECT DISTINCT ON (m.visitor_id)
            m.visitor_id,
            m.sender,
            ${msgExpr} AS content,
            m.created_at,
            m.created_at AS last_seen,
            v.archived,
            v.conversation_status
          FROM messages m
          LEFT JOIN visitors v ON v.${dbSchema.visitors.idCol || 'visitor_id'} = m.visitor_id
          ${where}
          ORDER BY m.visitor_id, m.created_at DESC
        ) AS t
        ORDER BY t.last_seen DESC
        LIMIT ${limit};
      `;
    } else {
      sql = `
        SELECT * FROM (
          SELECT DISTINCT ON (m.visitor_id)
            m.visitor_id,
            m.sender,
            ${msgExpr} AS content,
            m.created_at,
            m.created_at AS last_seen
          FROM messages m
          ${where}
          ORDER BY m.visitor_id, m.created_at DESC
        ) AS t
        ORDER BY t.last_seen DESC
        LIMIT ${limit};
      `;
    }
    const out = await pool.query(sql, params);
    res.json(out.rows || []);
  } catch (e) {
    logToFile(`❌ /api/conversations error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Full message history for one visitor
app.get("/api/conversations/:visitorId/messages", async (req, res) => {
  try {
    const visitorId = String(req.params.visitorId || "").trim();
    const limit = Math.max(1, Math.min(2000, Number(req.query.limit || 500)));
    if (!visitorId) return res.json([]);

    const msgExpr = dbSchema.messages.hasContent
      ? "COALESCE(content, '')"
      : dbSchema.messages.hasMessage
      ? "COALESCE(message, '')"
      : "COALESCE(message, '')";

    const htmlExpr = dbSchema.messages.hasContentHtml ? ", COALESCE(content_html,'') AS content_html" : "";

    const sql = `
      SELECT id, visitor_id, sender, ${msgExpr} AS content, agent_id, created_at${htmlExpr}
      FROM messages
      WHERE visitor_id = $1
      ORDER BY created_at ASC
      LIMIT ${limit};
    `;
    const out = await pool.query(sql, [visitorId]);
    res.json(out.rows || []);
  } catch (e) {
    logToFile(`❌ /api/conversations/:id/messages error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Recent visitors (optional helper for side panels)
app.get("/api/visitors/recent", async (_req, res) => {
  try {
    const idCol = dbSchema.visitors.idCol || "id";
    // If visitors table is missing, fall back to messages-only distinct list
    let out;
    if (!dbSchema.visitors.exists) {
      const sqlFallback = `
        SELECT visitor_id,
               MIN(created_at) AS first_seen,
               MAX(created_at) AS last_seen
        FROM messages
        GROUP BY visitor_id
        ORDER BY MAX(created_at) DESC
        LIMIT 200;
      `;
      out = await pool.query(sqlFallback);
    } else {
      const sql = `
        SELECT v.${idCol} AS visitor_id,
               MIN(v.created_at) AS first_seen,
               MAX(m.created_at) AS last_seen
        FROM visitors v
        LEFT JOIN messages m ON m.visitor_id = v.${idCol}
        GROUP BY v.${idCol}
        ORDER BY COALESCE(MAX(m.created_at), MIN(v.created_at)) DESC
        LIMIT 200;
      `;
      out = await pool.query(sql);
    }
    res.json(out.rows || []);
  } catch (e) {
    logToFile(`❌ /api/visitors/recent error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Ensure specific route is defined BEFORE the param route (/api/visitors/:visitorId)
// so that "/api/visitors/list" does not get captured as a :visitorId = "list".
app.get("/api/visitors/list", async (_req, res) => {
  try {
    const idCol =
      dbSchema.visitors.idCol ||
      (dbSchema.visitors.hasVisitorIdCol ? "visitor_id" : "id");
    const sql = `
      SELECT
        v.${idCol}               AS visitor_id,
        COALESCE(v.customer_firstname,'') AS customer_firstname,
        COALESCE(v.customer_lastname,'')  AS customer_lastname,
        COALESCE(v.customer_email,'')     AS customer_email,
        COALESCE(v.country_code,'')       AS country_code,
        COALESCE(v.lang_iso,'')           AS lang_iso,
        COALESCE(v.chatbot_id,'')         AS chatbot_id,
        v.last_seen,
        v.page_url_last,
        v.title,
        v.referrer,
        v.origin,
        (SELECT COUNT(*) FROM visits vi WHERE vi.visitor_id = v.${idCol}) AS visits_count,
        (SELECT COUNT(*) FROM messages m WHERE m.visitor_id = v.${idCol}) AS messages_count,
        (SELECT COUNT(*) FROM messages m WHERE m.visitor_id = v.${idCol} AND m.sender = 'agent') AS agent_messages_count
      FROM visitors v
      ORDER BY COALESCE(v.last_seen, v.created_at) DESC
      LIMIT 500`;
    const out = await pool.query(sql);
    res.json(out.rows || []);
  } catch (e) {
    logToFile(`❌ /api/visitors/list error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Minimal visitor info (fills right panel)
app.get("/api/visitors/:visitorId", async (req, res) => {
  try {
    const visitorId = String(req.params.visitorId || "").trim();
    if (!visitorId) return res.status(400).json({ error: "bad_request" });

    const idCol = dbSchema.visitors.idCol || "visitor_id";
    // Read the whole row safely as JSONB so we can use either real columns or meta
    const out = await pool.query(
      `SELECT to_jsonb(v) AS raw FROM visitors v WHERE ${idCol} = $1 LIMIT 1`,
      [visitorId]
    );
    const raw = (out.rows[0] && out.rows[0].raw) || {};
    const meta = raw.meta || {};

    const pick = (k, altK) =>
      raw[k] ?? (altK ? raw[altK] : undefined) ?? meta[k] ?? meta[altK] ?? null;

    const ip = pick("ip");
    let country_code = pick("country_code");
    if (!country_code && ip) {
      try {
        const g = geoip.lookup(ip);
        country_code = (g && g.country) || null;
      } catch {}
    }

    res.json({
      visitor_id: raw.visitor_id || raw.id || visitorId,
      created_at: raw.created_at || raw.first_seen || null,
      country_code,
      ip,
      city: pick("city"),
      postcode: pick("postcode"),
      lang: pick("language", "lang"),
      screen: pick("screen"),
      first_seen: raw.first_seen || raw.created_at || null,
      last_seen: raw.last_seen || meta.last_seen || null,
      last_action: pick("last_action"),
      last_action_at: pick("last_action_at"),
      archived: raw.archived ?? null,
      conversation_status: pick("conversation_status"),
      origin: pick("origin"),
      page_url: pick("page_url_last", "page_url"),
      title: pick("title"),
      referrer: pick("referrer"),
      currency: pick("currency"),
      cart_total: pick("cart_total"),
      shop_name: pick("shop_name"),
      user_agent: pick("user_agent"),
      id_shop: pick("id_shop"),
      id_lang: pick("id_lang"),
      lang_iso: pick("lang_iso"),
      lang_name: pick("lang_name"),
      screen_w: pick("screen_w"),
      screen_h: pick("screen_h"),
      screen_dpr: pick("screen_dpr"),
      openai_enabled: pick("openai_enabled"),
      assistant_id: pick("assistant_id"),
      // Customer/account context
      customer_logged: pick("customer_logged"),
      customer_id: pick("customer_id"),
      customer_email: pick("customer_email"),
      customer_firstname: pick("customer_firstname"),
      customer_lastname: pick("customer_lastname"),
      orders_count: pick("orders_count"),
      orders_amount: pick("orders_amount"),
    });
  } catch (e) {
    logToFile(`❌ /api/visitors/:id error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Visitors list with basic stats (for "Visiteurs" table)
app.get("/api/visitors/list", async (_req, res) => {
  try {
    const idCol = dbSchema.visitors.idCol || (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id' : 'id');
    const sql = `
      SELECT
        v.${idCol}               AS visitor_id,
        COALESCE(v.customer_firstname,'') AS customer_firstname,
        COALESCE(v.customer_lastname,'')  AS customer_lastname,
        COALESCE(v.customer_email,'')     AS customer_email,
        COALESCE(v.country_code,'')       AS country_code,
        COALESCE(v.lang_iso,'')           AS lang_iso,
        v.last_seen,
        v.page_url_last,
        v.title,
        v.referrer,
        v.origin,
        (SELECT COUNT(*) FROM visits vi WHERE vi.visitor_id = v.${idCol}) AS visits_count,
        (SELECT COUNT(*) FROM messages m WHERE m.visitor_id = v.${idCol}) AS messages_count,
        (SELECT COUNT(*) FROM messages m WHERE m.visitor_id = v.${idCol} AND m.sender = 'agent') AS agent_messages_count
      FROM visitors v
      ORDER BY COALESCE(v.last_seen, v.created_at) DESC
      LIMIT 500`;
    const out = await pool.query(sql);
    res.json(out.rows || []);
  } catch (e) {
    logToFile(`❌ /api/visitors/list error: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Archive/unarchive a visitor conversation
app.post("/api/visitors/:visitorId/archive", async (req, res) => {
  try {
    const visitorId = String(req.params.visitorId || "").trim();
    if (!visitorId) return res.status(400).json({ error: "bad_request" });
    const archived = Boolean(req.body?.archived ?? true);

    await ensureVisitorExists(visitorId);

    const status = archived ? 'archived' : 'open';
    // Tolerant WHERE: match by visitor_id or id to avoid schema drift
    const where = (dbSchema.visitors.hasVisitorIdCol && dbSchema.visitors.hasIdCol)
      ? '(visitor_id = $1 OR id = $1)'
      : (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id = $1' : (dbSchema.visitors.hasIdCol ? 'id = $1' : `${dbSchema.visitors.idCol || 'visitor_id'} = $1`));
    const sql = `UPDATE visitors SET archived = $2, conversation_status = $3 WHERE ${where}`;
    const result = await pool.query(sql, [visitorId, archived, status]);
    if (DEBUG_SQL) logToFile(`ARCHIVE rows=${result.rowCount} vid=${visitorId} -> archived=${archived}, status=${status}`);

    io.to("agents").emit("visitor_update", { visitorId, archived, conversation_status: status });
    if (result.rowCount === 0) {
      return res.status(404).json({ ok: false, error: "not_found", message: "No visitor matched id in DB" });
    }
    res.json({ ok: true, archived, rows: result.rowCount });
  } catch (e) {
    logToFile(`❌ /api/visitors/:id/archive error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// GET alias for quick testing: /api/visitors/:id/archive?archived=1
app.get("/api/visitors/:visitorId/archive", async (req, res) => {
  try {
    const visitorId = String(req.params.visitorId || "").trim();
    if (!visitorId) return res.status(400).json({ error: "bad_request" });
    const archivedParam = req.query.archived;
    const archived = archivedParam === undefined ? true : /^(1|true|yes)$/i.test(String(archivedParam));

    await ensureVisitorExists(visitorId);

    const status = archived ? 'archived' : 'open';
    const where = (dbSchema.visitors.hasVisitorIdCol && dbSchema.visitors.hasIdCol)
      ? '(visitor_id = $1 OR id = $1)'
      : (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id = $1' : (dbSchema.visitors.hasIdCol ? 'id = $1' : `${dbSchema.visitors.idCol || 'visitor_id'} = $1`));
    const sql = `UPDATE visitors SET archived = $2, conversation_status = $3 WHERE ${where}`;
    const result = await pool.query(sql, [visitorId, archived, status]);
    if (DEBUG_SQL) logToFile(`ARCHIVE(GET) rows=${result.rowCount} vid=${visitorId} -> archived=${archived}, status=${status}`);

    io.to("agents").emit("visitor_update", { visitorId, archived, conversation_status: status });
    if (result.rowCount === 0) return res.status(404).json({ ok: false, error: "not_found" });
    res.json({ ok: true, archived, rows: result.rowCount });
  } catch (e) {
    logToFile(`❌ /api/visitors/:id/archive (GET) error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Recent visits for one visitor (stub for UI; replace with real SELECT when you track visits)
app.get("/api/visitors/:visitorId/visits", async (_req, res) => {
  try {
    const visitorId = String(_req.params.visitorId || "").trim();
    if (!visitorId) return res.json([]);
    const limit = Math.max(1, Math.min(200, Number(_req.query.limit || 50)));
    const out = await pool.query(
      `SELECT visitor_id, page_url, title, origin, referrer,
              utm_source, utm_medium, utm_campaign, utm_term, utm_content,
              occurred_at
       FROM visits
       WHERE visitor_id = $1
       ORDER BY occurred_at DESC
       LIMIT ${limit}`,
      [visitorId]
    );
    res.json(out.rows || []);
  } catch (e) {
    logToFile(`❌ /api/visitors/:id/visits error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Upsert customer fields explicitly (use from PrestaShop on login)
app.post("/api/visitors/:visitorId/customer", async (req, res) => {
  try {
    const visitorId = String(req.params.visitorId || "").trim();
    if (!visitorId) return res.status(400).json({ error: "bad_request" });

    await ensureVisitorExists(visitorId);

    const b = req.body || {};
    // Support both flat and nested payloads
    const c = typeof b.customer === "object" && b.customer ? b.customer : b;

    const patch = {
      customer_logged: c.customer_logged ?? c.logged ?? c.is_logged ?? true,
      customer_id: c.customer_id ?? c.id_customer ?? c.id ?? null,
      customer_email: c.customer_email ?? c.email ?? null,
      customer_firstname:
        c.customer_firstname ?? c.firstname ?? c.first_name ?? null,
      customer_lastname:
        c.customer_lastname ?? c.lastname ?? c.last_name ?? null,
      orders_count: c.orders_count ?? null,
      orders_amount: c.orders_amount ?? null,
      last_action: c.last_action || "login",
      last_action_at: new Date().toISOString(),
    };

    if (dbSchema.visitors.hasMeta) {
      await upsertVisitorMeta(visitorId, patch);
    }
    await upsertVisitorColumns(visitorId, patch);

    // If a dedicated last_seen column exists, bump it
    if (dbSchema.visitors.hasLastSeen && dbSchema.visitors.idCol) {
      try {
        await pool.query(
          `UPDATE visitors SET last_seen = NOW() WHERE ${dbSchema.visitors.idCol} = $1`,
          [visitorId]
        );
      } catch {}
    }

    io.to("agents").emit("visitor_update", { visitorId, ...patch });
    res.json({ ok: true });
  } catch (e) {
    logToFile(`❌ POST /api/visitors/:id/customer error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Backfill named columns from existing meta for one visitor
app.post("/api/visitors/:visitorId/backfill_columns", async (req, res) => {
  try {
    const visitorId = String(req.params.visitorId || "").trim();
    if (!visitorId) return res.status(400).json({ error: "bad_request" });

    await ensureVisitorExists(visitorId);

    const idCol =
      dbSchema.visitors.idCol ||
      (dbSchema.visitors.hasVisitorIdCol ? "visitor_id" : "id");
    if (!idCol) return res.status(500).json({ error: "schema_error" });

    const out = await pool.query(
      `SELECT to_jsonb(v) AS raw FROM visitors v WHERE ${idCol} = $1 LIMIT 1`,
      [visitorId]
    );
    if (!out.rowCount) return res.status(404).json({ error: "not_found" });

    const raw = out.rows[0].raw || {};
    const meta = raw.meta || {};
    const nested =
      typeof meta.customer === "object" && meta.customer ? meta.customer : {};

    const pick = (k, ...alts) => {
      const tryKeys = [k, ...alts].filter(Boolean);
      for (const key of tryKeys) {
        if (raw[key] != null) return raw[key];
        if (meta[key] != null) return meta[key];
        if (nested[key] != null) return nested[key];
      }
      return null;
    };

    const values = {
      customer_logged: pick("customer_logged", "logged", "is_logged"),
      customer_id: pick("customer_id", "id_customer", "id", "customer_id"),
      customer_email: pick("customer_email", "email"),
      customer_firstname: pick("customer_firstname", "firstname", "first_name"),
      customer_lastname: pick("customer_lastname", "lastname", "last_name"),
      orders_count: pick("orders_count"),
      orders_amount: pick("orders_amount"),
      last_action: pick("last_action"),
      last_action_at: pick("last_action_at"),
      city: pick("city"),
      postcode: pick("postcode", "zip"),
    };

    await upsertVisitorColumns(visitorId, values);

    io.to("agents").emit("visitor_update", { visitorId, ...values });
    res.json({
      ok: true,
      updated: Object.keys(values).filter((k) => values[k] != null),
    });
  } catch (e) {
    logToFile(`❌ POST /api/visitors/:id/backfill_columns error: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Simple health used by the dashboard to show IA badge
app.get("/health", (_req, res) => {
  res.json({ openai_ready: true });
});

app.get("/__health", (_req, res) => {
  res.json({
    distDir,
    indexHtmlExists: fs.existsSync(indexHtml),
    cwd: process.cwd(),
    __dirname,
  });
});

// Regenerate product images via Presta CLI (optional)
// Requires env PRESTA_ROOT pointing to PrestaShop root and PHP available
app.post('/api/presta/images/regenerate', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  const root = String(process.env.PRESTA_ROOT || '').trim();
  if (!root) return res.status(412).json({ ok:false, error:'presta_root_missing', message:'Set PRESTA_ROOT env to your PrestaShop root path' });
  try {
    const { exec } = await import('child_process');
    const cmd = `php bin/console prestashop:image:regenerate --type=products --force`;
    exec(cmd, { cwd: root }, (err, stdout, stderr) => {
      if (err) return res.status(500).json({ ok:false, error:'regenerate_failed', message: String(stderr||err.message||err) });
      return res.json({ ok:true, stdout });
    });
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// =============== Grabbings: Jerome URL Discovery =================
// POST /api/grabbings/jerome/discover -> { ok, base_url, urls:[{url,type,title?}], file, download_url, steps? }
// GET  /api/grabbings/jerome/discover/latest -> { ok, items:[{name,size,mtime,download_url}] }
app.post('/api/grabbings/jerome/discover', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  const baseUrl = String(req.body?.url || '').trim();
  const debug = !!req.body?.debug;
  const sameHostOnly = (req.body?.same_host_only !== undefined) ? !!req.body?.same_host_only : true;
  const useSitemap = (req.body?.use_sitemap !== undefined) ? !!req.body?.use_sitemap : false;
  const includePatterns = Array.isArray(req.body?.include_patterns) ? req.body.include_patterns.filter(Boolean) : [];
  const excludePatterns = Array.isArray(req.body?.exclude_patterns) ? req.body.exclude_patterns.filter(Boolean) : [];
  const includeRegex = Array.isArray(req.body?.include_regex) ? req.body.include_regex.filter(Boolean) : [];
  const excludeRegex = Array.isArray(req.body?.exclude_regex) ? req.body.exclude_regex.filter(Boolean) : [];
  // Lifted hard caps for broader crawling
  const maxPages = Math.max(1, Math.min(Number(req.body?.max_pages || process.env.JEROME_DISCOVER_MAX_PAGES || 5), 100));
  const maxUrls = Math.max(10, Math.min(Number(req.body?.max_urls || process.env.JEROME_DISCOVER_MAX_URLS || 100), 10000));
  const classify = (req.body?.classify !== undefined) ? !!req.body?.classify : true;
  const classifyLimit = Math.max(1, Math.min(Number(req.body?.classify_limit || process.env.JEROME_DISCOVER_CLASSIFY_LIMIT || 25), 200));
  if (!/^https?:\/\//i.test(baseUrl)) return res.status(400).json({ ok:false, error:'bad_request', message:'Valid url required' });
  let chromium;
  let needBrowser = !useSitemap;
  const out = { steps: [] };
const step = (m) => { try { out.steps.push(m); } catch {} try { logToFile(`[jerome:discover] ${m}`); } catch {} };
  let browser, context, page;
  // Sitemap-first discovery path; fall back to crawler if empty or error
  if (useSitemap) {
    try {
      const origin = new URL(baseUrl);
      const domain = origin.hostname.toLowerCase();
      const steps = out.steps;
      const sitemaps = new Set();
      const seenUrls = new Set();
      const visited = new Set();
      const queue = [];
      const incRes = includeRegex.slice(0, 20).map(p => { try { return new RegExp(String(p), 'i'); } catch { return null; } }).filter(Boolean);
      const excRes = excludeRegex.slice(0, 20).map(p => { try { return new RegExp(String(p), 'i'); } catch { return null; } }).filter(Boolean);
      const passes = (abs) => {
        try {
          const s = String(abs || '');
          if (excludePatterns.length && excludePatterns.some(p => p && s.includes(p))) return false;
          if (excRes.length && excRes.some(re => re.test(s))) return false;
          if (includePatterns.length && !includePatterns.some(p => p && s.includes(p))) return false;
          if (incRes.length && !incRes.some(re => re.test(s))) return false;
          return true;
        } catch { return true; }
      };
      const addUrl = (u) => {
        try {
          const abs = new URL(u, origin).toString();
          if (!/^https?:\/\//i.test(abs)) return;
          if (sameHostOnly && new URL(abs).hostname !== origin.hostname) return;
          if (!passes(abs)) return;
          if (!seenUrls.has(abs) && seenUrls.size < maxUrls) seenUrls.add(abs);
        } catch {}
      };
      const parseXml = (xml) => {
        const locs = Array.from(String(xml||'').matchAll(/<loc>\s*([^<\s][^<]*)\s*<\/loc>/gi)).map(m => (m && m[1] ? m[1].trim() : '')).filter(Boolean);
        const isIndex = /<sitemapindex[\s>]/i.test(String(xml||''));
        return { isIndex, locs };
      };
      const gunzipMaybe = async (buf, url) => {
        try {
          if (/\.gz($|\?)/i.test(url)) { const z = await import('zlib'); return z.gunzipSync(Buffer.from(buf)).toString('utf8'); }
        } catch {}
        return Buffer.isBuffer(buf) ? buf.toString('utf8') : String(buf);
      };
      // Discover sitemaps from robots.txt and default /sitemap.xml
      try {
        const robotsUrl = new URL('/robots.txt', origin).toString();
        const r = await fetch(robotsUrl, { method: 'GET' });
        if (r.ok) {
          const txt = await r.text();
          for (const line of txt.split(/\r?\n/)) {
            const m = line.match(/^\s*Sitemap:\s*(.+)\s*$/i);
            if (m && m[1]) { try { sitemaps.add(new URL(m[1], origin).toString()); } catch {} }
          }
          step(`robots_sitemaps ${sitemaps.size}`);
        }
      } catch {}
      try { sitemaps.add(new URL('/sitemap.xml', origin).toString()); } catch {}
      for (const sm of Array.from(sitemaps)) queue.push(sm);
      let fetched = 0;
      while (queue.length && fetched < Math.max(1, Math.min(Number(req.body?.max_sitemaps || 100), 1000)) && seenUrls.size < maxUrls) {
        const sm = queue.shift();
        if (!sm || visited.has(sm)) continue;
        visited.add(sm); fetched++;
        try {
          const resp = await fetch(sm, { method: 'GET' });
          if (!resp.ok) { step(`fetch_fail ${sm} ${resp.status}`); continue; }
          const arrBuf = Buffer.from(await resp.arrayBuffer());
          const xml = await gunzipMaybe(arrBuf, sm);
          const { isIndex, locs } = parseXml(xml);
          if (!locs.length) { step(`no_locs ${sm}`); continue; }
          if (isIndex) {
            for (const loc of locs) { if (queue.length < 1000) { try { queue.push(new URL(loc, origin).toString()); } catch {} } }
            step(`index_add ${locs.length}`);
          } else {
            for (const loc of locs) { addUrl(new URL(loc, origin).toString()); }
            step(`urlset_add ${locs.length}`);
          }
        } catch (e) { step(`error ${sm} ${e?.message||String(e)}`); }
      }
      const items = Array.from(seenUrls).slice(0, maxUrls).map(u => ({ url: u, type: '' }));
      if (items.length > 0) {
        // Store to DB if available
        let pool = await getPg();
        if (pool) {
          const ins = await pool.query('insert into grabbing_jerome_discover(base_url, domain) values($1, $2) returning id, created_at', [baseUrl, domain]);
          const did = ins.rows[0].id;
          if (items.length) {
            let idx = 1; const values = []; let sql = 'insert into grabbing_jerome_discover_item(discover_id,url,type,title) values ';
            for (let i=0;i<items.length;i++) { const it = items[i]; sql += `($${idx++},$${idx++},$${idx++},$${idx++})` + (i<items.length-1?',':''); values.push(did, it.url||'', it.type||'', ''); }
            await pool.query(sql + ' on conflict on constraint grabbing_jerome_discover_item_url_uq do nothing', values);
          }
          // Recompute aggregates for this domain
          try { await upsertDomainAggregates(pool, domain); } catch {}
          const result = { ok:true, base_url: baseUrl, total_urls: items.length, urls: items.slice(0,200), file: `grabbing-jerome-db-${did}.json`, download_url: `/api/grabbings/jerome/discover/export/${did}`, steps };
          if (debug) result.steps = steps;
          return res.json(result);
        }
        // Fallback to file when no DB available
        const now = new Date();
        const safeHost = domain.replace(/[^a-z0-9.-]/gi,'_');
        const fname = `jerome-discover-${safeHost}-${now.toISOString().replace(/[:.]/g,'-')}.json`;
        const full = path.join(grabbingJeromeDir, fname);
        try { fs.writeFileSync(full, JSON.stringify({ base_url: baseUrl, max_pages: maxPages, max_urls: maxUrls, same_host_only: sameHostOnly, classify, items }, null, 2)); } catch {}
        const download_url = `/api/grabbings/jerome/file/${encodeURIComponent(fname)}`;
        const result = { ok:true, base_url: baseUrl, total_urls: items.length, urls: items, file: fname, download_url };
        if (debug) result.steps = steps;
        return res.json(result);
      }
      // Sitemap provided no URLs → mark fallback to crawler
      step('sitemap_empty_fallback');
      needBrowser = true;
    } catch (e) {
      // Error parsing sitemap → fallback to crawler as well
      try { step(`sitemap_error_fallback ${e?.message||String(e)}`); } catch {}
      needBrowser = true;
    }
  }
  // If a browser is needed (no sitemap or sitemap empty/error), ensure Playwright is available
  if (needBrowser) {
    try { ({ chromium } = await import('playwright')); }
    catch (e) { return res.status(500).json({ ok:false, error:'playwright_missing', message:'Install Playwright in backend: npm i playwright && npx playwright install chromium', details: String(e?.message||e) }); }
  }
  async function upsertDomainAggregates(pool, domain) {
    if (!pool || !domain) return;
    try {
      const q = await pool.query(
        `select count(*)::int as urls,
                array_remove(array_agg(distinct lower(nullif(i.type,''))), NULL) as types
           from grabbing_jerome_discover d
           left join grabbing_jerome_discover_item i on i.discover_id = d.id
          where d.domain = $1`,
        [domain]
      );
      const urls = Number(q.rows?.[0]?.urls || 0);
      const types = Array.isArray(q.rows?.[0]?.types) ? q.rows[0].types : [];
      await pool.query(
        `insert into grabbing_jerome_discover_domain(domain, total_discovered_urls, types, updated_at)
         values($1,$2,$3::jsonb, now())
         on conflict (domain) do update set total_discovered_urls = EXCLUDED.total_discovered_urls, types = EXCLUDED.types, updated_at = now()`,
        [domain, urls, JSON.stringify(types)]
      );
      try { await mirrorLegacyDomain(pool, domain); } catch {}
    } catch {}
  }
  try {
    const headless = true;
    const launchArgs = []; try { if (process.getuid && process.getuid() === 0) launchArgs.push('--no-sandbox'); } catch {}
    browser = await chromium.launch({ headless, args: launchArgs });
    context = await browser.newContext({});
    page = await context.newPage();
    // Pre-create/refresh domain row so new domains are tracked even if crawl fails
    let pool = await getPg();
    try {
      if (pool) {
        let domainEarly = '';
        try { domainEarly = new URL(baseUrl).hostname.toLowerCase(); } catch {}
        if (domainEarly) {
          await pool.query(
            `insert into grabbing_jerome_domains(domain, updated_at)
             values($1, now())
             on conflict (domain) do update set updated_at = now()`,
            [domainEarly]
          );
        }
      }
    } catch {}

    const origin = new URL(baseUrl);
    const seen = new Set();
    const queue = [];
    const visited = new Set();
    // Precompile regex with guardrails
    const incRes = includeRegex.slice(0, 20).map(p => { try { return new RegExp(String(p), 'i'); } catch { return null; } }).filter(Boolean);
    const excRes = excludeRegex.slice(0, 20).map(p => { try { return new RegExp(String(p), 'i'); } catch { return null; } }).filter(Boolean);
    const passesFilters = (abs) => {
      try {
        const s = String(abs || '');
        if (excludePatterns.length && excludePatterns.some(p => p && s.includes(p))) return false;
        if (excRes.length && excRes.some(re => re.test(s))) return false;
        if (includePatterns.length && !includePatterns.some(p => p && s.includes(p))) return false;
        if (incRes.length && !incRes.some(re => re.test(s))) return false;
        return true;
      } catch { return true; }
    };
    const enqueue = (u) => {
      if (!u) return;
      try {
        const abs = new URL(u, origin).toString();
        if (!/^https?:\/\//i.test(abs)) return;
        if (sameHostOnly && new URL(abs).hostname !== origin.hostname) return;
        if (!passesFilters(abs)) return;
        if (!seen.has(abs) && seen.size < maxUrls) { seen.add(abs); queue.push(abs); }
      } catch {}
    };
    // Optional: seed queue from sitemap.xml and robots.txt sitemaps
    if (useSitemap) {
      const addSitemapUrls = async () => {
        try {
          const sitemaps = new Set();
          // robots.txt discovery
          try {
            const robotsUrl = new URL('/robots.txt', origin).toString();
            const r = await fetch(robotsUrl, { method: 'GET' });
            if (r.ok) {
              const txt = await r.text();
              for (const line of txt.split(/\r?\n/)) {
                const m = line.match(/^\s*Sitemap:\s*(.+)\s*$/i);
                if (m && m[1]) { try { sitemaps.add(new URL(m[1], origin).toString()); } catch {} }
              }
            }
          } catch {}
          // default /sitemap.xml
          try { sitemaps.add(new URL('/sitemap.xml', origin).toString()); } catch {}
          let added = 0;
          for (const sm of Array.from(sitemaps).slice(0, 5)) {
            if (seen.size >= maxUrls) break;
            try {
              const resp = await fetch(sm, { method: 'GET' });
              if (!resp.ok) continue;
              const xml = await resp.text();
              // naive parse of <loc> values
              const locs = Array.from(xml.matchAll(/<loc>\s*([^<\s][^<]*)\s*<\/loc>/gi)).map(m => m[1]);
              for (const loc of locs) {
                if (seen.size >= maxUrls) break;
                enqueue(loc);
                added++;
              }
            } catch {}
          }
          step(`sitemap_seeded ${added}`);
        } catch {}
      };
      await addSitemapUrls();
    }
    const extractLinks = async () => await page.evaluate(() => Array.from(document.querySelectorAll('a[href]')).map(a => a.getAttribute('href')));
    enqueue(baseUrl);
    let pagesVisited = 0;
    while (queue.length && pagesVisited < maxPages && seen.size < maxUrls) {
      const next = queue.shift();
      if (!next || visited.has(next)) continue;
      visited.add(next);
      pagesVisited++;
      step(`goto ${next}`);
      try {
        await page.goto(next, { waitUntil: 'domcontentloaded', timeout: 30000 });
        try { await page.waitForLoadState('networkidle', { timeout: 5000 }); } catch {}
        // Try dismiss common cookie banners to reveal links
        try {
          await page.evaluate(() => {
            const qs = (s) => Array.from(document.querySelectorAll(s));
            const clickIf = (sel) => { const b = document.querySelector(sel); if (b) { try { b.click(); } catch {} } };
            const hide = (el) => { try { el.style.setProperty('display','none','important'); el.style.setProperty('pointer-events','none','important'); } catch {} };
            [
              '#onetrust-accept-btn-handler',
              '.cookiefirst-root [data-cookiefirst-action="accept"]',
              'button[aria-label*="accept" i]',
              'button:has-text("Accept")'
            ].forEach(clickIf);
            qs('dialog.cookiefirst-root, .cookiefirst-root, .ot-sdk-container, #onetrust-banner-sdk').forEach(hide);
          });
        } catch {}
        // Auto-scroll to trigger lazy content
        try {
          await page.evaluate(async () => {
            const sleep = (t)=>new Promise(r=>setTimeout(r,t));
            for (let i=0;i<6;i++) { window.scrollBy(0, window.innerHeight); await sleep(400); }
          });
        } catch {}
      } catch (e) { step(`goto_fail ${e?.message||String(e)}`); continue; }
      const hrefs = await extractLinks();
      for (const h of hrefs) { if (seen.size >= maxUrls) break; enqueue(h); }
    }
    const urls = Array.from(seen);
    const classifyHeuristic = (u) => {
      const p = u.toLowerCase();
      if (/product|prod|item|sku|\/p\//.test(p)) return 'product?';
      if (/collection|category|categ|cat|\/c\//.test(p)) return 'category?';
      return 'page';
    };
    const items = urls.map(u => ({ url: u, type: classify ? classifyHeuristic(u) : 'page' }));
    if (classify) {
      const sample = items.slice(0, classifyLimit);
      for (let i=0;i<sample.length;i++) {
        const it = sample[i];
        try {
          await page.goto(it.url, { waitUntil: 'domcontentloaded', timeout: 20000 });
          try { await page.waitForLoadState('networkidle', { timeout: 3000 }); } catch {}
          const typ = await page.evaluate(() => {
            const hasProductLd = Array.from(document.querySelectorAll('script[type="application/ld+json"]')).some(s => {
              try { const j = JSON.parse(s.textContent||'{}'); const arr = Array.isArray(j)? j : [j]; return arr.some(x => x && (x['@type']==='Product' || (Array.isArray(x['@type']) && x['@type'].includes('Product')))); } catch { return false; }
            });
            const ogType = document.querySelector('meta[property="og:type"]')?.getAttribute('content')?.toLowerCase() || '';
            const title = document.title || '';
            if (hasProductLd || ogType.includes('product')) return { type:'product', title };
            if (ogType.includes('collection') || ogType.includes('website') || ogType.includes('article')) return { type:'category', title };
            return { type:'page', title };
          });
          it.type = typ?.type || it.type;
          if (typ?.title) it.title = typ.title;
        } catch (e) { step(`classify_fail ${it.url} ${e?.message||String(e)}`); }
      }
    }
    // pool may already be initialized above
    if (!pool) pool = await getPg();
    if (pool) {
      // Store discovery session in Postgres
      let domain = '';
      try { domain = new URL(baseUrl).hostname.toLowerCase(); } catch {}
      const ins = await pool.query('insert into grabbing_jerome_discover(base_url, domain) values($1, $2) returning id, created_at', [baseUrl, domain]);
      const did = ins.rows[0].id;
      const values = [];
      let idx = 1;
      let sql = 'insert into grabbing_jerome_discover_item(discover_id,url,type,title) values ';
      for (let i=0;i<items.length;i++) {
        const it = items[i];
        sql += `($${idx++},$${idx++},$${idx++},$${idx++})` + (i<items.length-1?',':'');
        values.push(did, it.url||'', it.type||'', it.title||'');
      }
      if (items.length) await pool.query(sql + ' on conflict on constraint grabbing_jerome_discover_item_url_uq do nothing', values);
      // Update per-domain aggregates (defensive recompute in case of new domains)
      try {
        const typeSet = new Set(items.map(it => String(it.type||'').toLowerCase()).filter(Boolean));
        let mergedTypes = Array.from(typeSet);
        try {
          const prev = await pool.query('select types from grabbing_jerome_discover_domain where domain=$1', [domain]);
          if (prev && prev.rows && prev.rows[0] && prev.rows[0].types) {
            const prevArr = Array.isArray(prev.rows[0].types) ? prev.rows[0].types : (prev.rows[0].types?.map ? prev.rows[0].types : []);
            for (const t of prevArr) { if (t && !typeSet.has(String(t).toLowerCase())) mergedTypes.push(t); }
          }
        } catch {}
        await pool.query(
          `insert into grabbing_jerome_discover_domain(domain, total_discovered_urls, types, updated_at)
           values($1,$2,$3::jsonb, now())
           on conflict (domain) do update set total_discovered_urls = grabbing_jerome_discover_domain.total_discovered_urls + EXCLUDED.total_discovered_urls, types = $3::jsonb, updated_at = now()`,
          [domain, items.length, JSON.stringify(mergedTypes)]
        );
        // Guarantee row reflects totals from DB
        await upsertDomainAggregates(pool, domain);
      } catch {}
      const file = `grabbing-jerome-db-${did}.json`;
      const download_url = `/api/grabbings/jerome/discover/export/${did}`;
      const result = { ok:true, base_url: baseUrl, total_urls: items.length, urls: items.slice(0,200), file, download_url };
      if (debug) result.steps = out.steps;
      return res.json(result);
    } else {
      const now = new Date();
      const safeHost = new URL(baseUrl).hostname.replace(/[^a-z0-9.-]/gi,'_');
      const fname = `jerome-discover-${safeHost}-${now.toISOString().replace(/[:.]/g,'-')}.json`;
      const full = path.join(grabbingJeromeDir, fname);
      try { fs.writeFileSync(full, JSON.stringify({ base_url: baseUrl, max_pages: maxPages, max_urls: maxUrls, same_host_only: sameHostOnly, classify, items }, null, 2)); } catch {}
      const download_url = `/api/grabbings/jerome/file/${encodeURIComponent(fname)}`;
      const result = { ok:true, base_url: baseUrl, total_urls: items.length, urls: items, file: fname, download_url };
      if (debug) result.steps = out.steps;
      return res.json(result);
    }
  } catch (e) {
    return res.status(500).json({ ok:false, error:'discover_failed', message: e?.message || String(e) });
  } finally {
    try { await page?.close(); } catch {}
    try { await context?.close(); } catch {}
    try { await browser?.close(); } catch {}
  }
});

// Sitemap-only URL counting (no crawling)
// POST /api/grabbings/jerome/sitemap/count -> { ok, base_url, domain, sitemaps:[...], totals:{ total_urls, unique_urls }, per_domain:[{domain, urls}], sample:[...], steps? }
app.post('/api/grabbings/jerome/sitemap/count', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  const baseUrl = String(req.body?.url || '').trim();
  const sameHostOnly = (req.body?.same_host_only !== undefined) ? !!req.body?.same_host_only : true;
  const includePatterns = Array.isArray(req.body?.include_patterns) ? req.body.include_patterns.filter(Boolean) : [];
  const excludePatterns = Array.isArray(req.body?.exclude_patterns) ? req.body.exclude_patterns.filter(Boolean) : [];
  const includeRegex = Array.isArray(req.body?.include_regex) ? req.body.include_regex.filter(Boolean) : [];
  const excludeRegex = Array.isArray(req.body?.exclude_regex) ? req.body.exclude_regex.filter(Boolean) : [];
  const maxSitemaps = Math.max(1, Math.min(Number(req.body?.max_sitemaps || 100000), 1000000));
  const maxUrls = Math.max(100, Math.min(Number(req.body?.max_urls || 100000), 1000000));
  if (!/^https?:\/\//i.test(baseUrl)) return res.status(400).json({ ok:false, error:'bad_request', message:'Valid url required' });
  const steps = [];
  const step = (m) => { try { steps.push(m); } catch {} try { logToFile(`[jerome:sitemap] ${m}`); } catch {} };
  try {
    const origin = new URL(baseUrl);
    const domain = origin.hostname.toLowerCase();
    const passesFilters = (abs) => {
      try {
        const s = String(abs || '');
        if (excludePatterns.length && excludePatterns.some(p => p && s.includes(p))) return false;
        if (excludeRegex.length) {
          for (const r of excludeRegex) { try { if (new RegExp(String(r), 'i').test(s)) return false; } catch {} }
        }
        if (includePatterns.length && !includePatterns.some(p => p && s.includes(p))) return false;
        if (includeRegex.length) {
          let ok = false; for (const r of includeRegex) { try { if (new RegExp(String(r), 'i').test(s)) { ok = true; break; } } catch {} }
          if (!ok) return false;
        }
        return true;
      } catch { return true; }
    };
    const sitemaps = new Set();
    // robots.txt discovery
    try {
      const robotsUrl = new URL('/robots.txt', origin).toString();
      const r = await fetch(robotsUrl, { method: 'GET' });
      if (r.ok) {
        const txt = await r.text();
        for (const line of txt.split(/\r?\n/)) {
          const m = line.match(/^\s*Sitemap:\s*(.+)\s*$/i);
          if (m && m[1]) { try { sitemaps.add(new URL(m[1], origin).toString()); } catch {} }
        }
        step(`robots_sitemaps ${(Array.from(sitemaps)).length}`);
      }
    } catch {}
    // default /sitemap.xml
    try { sitemaps.add(new URL('/sitemap.xml', origin).toString()); } catch {}
    // also queue the provided URL itself (supports direct sitemap index URLs)
    try { if (/^https?:\/\//i.test(baseUrl)) sitemaps.add(new URL(baseUrl).toString()); } catch {}
    const visited = new Set();
    const queue = Array.from(sitemaps);
    const perDomain = new Map();
    const seenUrls = new Set();
    const addUrl = (u) => {
      try {
        if (!/^https?:\/\//i.test(u)) return;
        const abs = new URL(u).toString();
        if (sameHostOnly && new URL(abs).hostname.toLowerCase() !== domain) return;
        if (!passesFilters(abs)) return;
        if (seenUrls.size >= maxUrls) return;
        if (!seenUrls.has(abs)) {
          seenUrls.add(abs);
          const d = new URL(abs).hostname.toLowerCase();
          perDomain.set(d, 1 + (perDomain.get(d) || 0));
        }
      } catch {}
    };
    const parseXml = (xml) => {
      const locs = Array.from(xml.matchAll(/<loc>\s*([^<\s][^<]*)\s*<\/loc>/gi)).map(m => (m && m[1] ? m[1].trim() : '')).filter(Boolean);
      const isIndex = /<sitemapindex[\s>]/i.test(xml);
      return { isIndex, locs };
    };
    const gunzipMaybe = async (buf, url) => {
      try {
        if (/\.gz($|\?)/i.test(url)) {
          const z = await import('zlib');
          return z.gunzipSync(Buffer.from(buf)).toString('utf8');
        }
      } catch {}
      return Buffer.isBuffer(buf) ? buf.toString('utf8') : String(buf);
    };
    let fetched = 0;
    while (queue.length && fetched < maxSitemaps && seenUrls.size < maxUrls) {
      const sm = queue.shift();
      if (!sm || visited.has(sm)) continue;
      visited.add(sm); fetched++;
      try {
        const r = await fetch(sm, { method: 'GET' });
        if (!r.ok) { step(`fetch_fail ${sm} ${r.status}`); continue; }
        const arrBuf = Buffer.from(await r.arrayBuffer());
        const xml = await gunzipMaybe(arrBuf, sm);
        const { isIndex, locs } = parseXml(xml || '');
        // Always record the sitemap URL we just fetched
        try { sitemaps.add(new URL(sm, origin).toString()); } catch {}
        if (!locs.length) { step(`no_locs ${sm}`); continue; }
        if (isIndex) {
          for (const loc of locs) {
            if (queue.length < maxSitemaps) {
              try {
                const abs = new URL(loc, origin).toString();
                queue.push(abs);
                sitemaps.add(abs);
              } catch {}
            }
          }
          step(`index_add ${locs.length}`);
        } else {
          for (const loc of locs) { addUrl(new URL(loc, origin).toString()); }
          step(`urlset_add ${locs.length}`);
        }
      } catch (e) { step(`error ${sm} ${e?.message||String(e)}`); }
    }
    const per_domain = Array.from(perDomain.entries()).map(([d, n]) => ({ domain: d, urls: n })).sort((a,b)=> b.urls - a.urls);
    const sample = Array.from(seenUrls).slice(0, 50);
    // Persist/update per-domain sitemap info (base domain only)
    try {
      const pool = await getPg();
      if (pool) {
        const sArr = Array.from(sitemaps);
        const baseCount = (perDomain.get(domain) || 0);
        await pool.query(
          `insert into grabbing_jerome_domains(domain, sitemap_url, sitemaps, sitemap_total_urls, updated_at)
           values($1,$2,$3::jsonb,$4, now())
           on conflict (domain) do update set sitemap_url = EXCLUDED.sitemap_url, sitemaps = EXCLUDED.sitemaps, sitemap_total_urls = EXCLUDED.sitemap_total_urls, updated_at = now()`,
          [domain, (sArr[0] || null), JSON.stringify(sArr), baseCount]
        );
      }
    } catch {}
    return res.json({ ok:true, base_url: baseUrl, domain, sitemaps: Array.from(sitemaps), totals: { total_urls: per_domain.reduce((a,c)=>a+c.urls,0), unique_urls: seenUrls.size }, per_domain, sample, steps });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'sitemap_failed', message: e?.message || String(e) });
  }
});

app.get('/api/grabbings/jerome/discover/latest', async (_req, res) => {
  try {
    const pool = await getPg();
    if (pool) {
      const { rows } = await pool.query(`
        select d.id, d.base_url, d.domain, d.created_at, coalesce(count(i.id),0) as url_count
        from grabbing_jerome_discover d
        left join grabbing_jerome_discover_item i on i.discover_id = d.id
        group by d.id
        order by d.created_at desc
        limit 50
      `);
      const items = rows.map(r => ({
        // Backward-compatible fields for existing UIs
        name: `grabbing-jerome-db-${r.id}.json`,
        size: 0,
        mtime: r.created_at,
        download_url: `/api/grabbings/jerome/discover/export/${r.id}`,
        // Extended fields
        id: r.id,
        base_url: r.base_url,
        domain: r.domain || (function(){ try { return new URL(r.base_url).hostname; } catch { return ''; } })(),
        url_count: Number(r.url_count||0)
      }));
      return res.json({ ok:true, items });
    }
    const names = fs.readdirSync(grabbingJeromeDir).filter(n => /^jerome-discover-.*\.json$/i.test(n));
    const items = names.map(n => { const p = path.join(grabbingJeromeDir, n); const st = fs.statSync(p); return { name:n, size: st.size, mtime: st.mtime, download_url: `/api/grabbings/jerome/file/${encodeURIComponent(n)}` }; }).sort((a,b)=> b.mtime - a.mtime).slice(0,50);
    return res.json({ ok:true, items });
  } catch (e) { return res.status(500).json({ ok:false, error:'list_failed', message: e?.message || String(e) }); }
});

// Discovery stats: totals and per-domain aggregates
// GET /api/grabbings/jerome/discover/stats -> { ok, totals:{domains,sessions,urls}, by_domain:[{domain,sessions,urls,last_seen,latest_session_id}] }
app.get('/api/grabbings/jerome/discover/stats', async (_req, res) => {
  try {
    const pool = await getPg();
    if (!pool) return res.json({ ok:true, totals:{ domains:0, sessions:0, urls:0 }, by_domain: [] });
    const totals = (await pool.query(`
      select
        count(distinct d.domain) as domains,
        count(distinct d.id) as sessions,
        count(distinct lower(trim(i.url))) filter (where trim(i.url) <> '') as urls
      from grabbing_jerome_discover d
      left join grabbing_jerome_discover_item i on i.discover_id = d.id
    `)).rows[0] || { domains:0, sessions:0, urls:0 };
    const byDomain = (await pool.query(`
      with per_session as (
        select d.domain, d.id as session_id, max(d.created_at) as created_at,
               count(i.id) as urls
        from grabbing_jerome_discover d
        left join grabbing_jerome_discover_item i on i.discover_id = d.id
        group by d.domain, d.id
      )
      select
        domain,
        count(*) as sessions,
        coalesce(sum(urls),0) as urls,
        max(created_at) as last_seen,
        (array_agg(session_id order by created_at desc))[1] as latest_session_id
      from per_session
      group by domain
      order by urls desc nulls last, domain asc
    `)).rows.map(r => ({
      domain: r.domain || '',
      sessions: Number(r.sessions||0),
      urls: Number(r.urls||0),
      last_seen: r.last_seen,
      latest_session_id: r.latest_session_id
    }));
    return res.json({ ok:true, totals: { domains: Number(totals.domains||0), sessions: Number(totals.sessions||0), urls: Number(totals.urls||0) }, by_domain: byDomain });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'stats_failed', message: e?.message || String(e) });
  }
});

// Discovery sessions for a specific domain (with per-session URL counts)
// GET /api/grabbings/jerome/discover/domain/:domain -> { ok, domain, sessions:[{id, base_url, created_at, url_count, download_url}] }
app.get('/api/grabbings/jerome/discover/domain/:domain', async (req, res) => {
  try {
    const pool = await getPg();
    if (!pool) return res.json({ ok:true, domain: String(req.params.domain||''), sessions: [] });
    const dom = String(req.params.domain||'').toLowerCase();
    const { rows } = await pool.query(`
      select d.id, d.base_url, d.domain, d.created_at, coalesce(count(i.id),0) as url_count
      from grabbing_jerome_discover d
      left join grabbing_jerome_discover_item i on i.discover_id = d.id
      where lower(coalesce(d.domain,'')) = $1
      group by d.id
      order by d.created_at desc
      limit 500
    `, [dom]);
    const sessions = rows.map(r => ({
      id: r.id,
      base_url: r.base_url,
      created_at: r.created_at,
      url_count: Number(r.url_count||0),
      download_url: `/api/grabbings/jerome/discover/export/${r.id}`
    }));
    return res.json({ ok:true, domain: dom, sessions });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'domain_failed', message: e?.message || String(e) });
  }
});

// Per-domain discovery table: domain, sitemap url(s), sitemap totals, discovered totals, types
// GET /api/grabbings/jerome/discover/domains -> { ok, items:[{domain,sitemap_url,sitemap_total_urls,total_discovered_urls,types,updated_at}] }
  app.get('/api/grabbings/jerome/discover/domains', async (_req, res) => {
  try {
    const pool = await getPg();
    if (!pool) return res.json({ ok:true, items: [] });
    try { res.setHeader('Cache-Control', 'no-store, no-cache, must-revalidate'); } catch {}
    try { await ensurePgTables(); } catch {}
    // Always read from grabbing_jerome_domains and enrich with discovery aggregates.
    // If the legacy table is absent, return an empty list.
    try {
      const { rows } = await pool.query(`
        select domain, sitemap_url, sitemaps, sitemap_total_urls, updated_at
          from grabbing_jerome_domains
         order by updated_at desc, domain asc
      `);
      const items = rows.map(r => ({
        domain: r.domain,
        sitemap_url: r.sitemap_url || '',
        sitemap_total_urls: Number(r.sitemap_total_urls||0),
        total_discovered_urls: 0,
        types: [],
        updated_at: r.updated_at,
      }));
      return res.json({ ok:true, items });
    } catch {
      return res.json({ ok:true, items: [] });
    }
  } catch (e) {
    return res.status(500).json({ ok:false, error:'domains_failed', message: e?.message || String(e) });
  }
});

// Alias: canonical domains list (same as above) for clients using /api/grabbings/jerome/domains
  app.get('/api/grabbings/jerome/domains', async (_req, res) => {
  try {
    const pool = await getPg();
    if (!pool) return res.json({ ok:true, items: [] });
    try { res.setHeader('Cache-Control', 'no-store, no-cache, must-revalidate'); } catch {}
    const { rows } = await pool.query(`
      select domain, sitemap_url, sitemaps, sitemap_total_urls, updated_at
        from grabbing_jerome_domains
       order by updated_at desc, domain asc
    `);
    const items = rows.map(r => ({
      domain: r.domain,
      sitemap_url: r.sitemap_url || '',
      sitemap_total_urls: Number(r.sitemap_total_urls||0),
      total_discovered_urls: 0,
      types: [],
      updated_at: r.updated_at,
    }));
    return res.json({ ok:true, items });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'domains_failed', message: e?.message || String(e) });
  }
});

// Canonical domains list: pull from grabbing_jerome_domains and enrich with discovered totals/types when available
// GET /api/grabbings/jerome/domains -> { ok, items:[{domain,sitemap_url,sitemap_total_urls,total_discovered_urls,types,updated_at}] }
app.get('/api/grabbings/jerome/domains', async (_req, res) => {
  try {
    const pool = await getPg();
    if (!pool) return res.json({ ok:true, items: [] });
    try { await ensurePgTables(); } catch {}
    const { rows } = await pool.query(`
      select d.domain,
             d.sitemap_url,
             d.sitemaps,
             d.selected_sitemaps,
             coalesce(d.sitemap_total_urls, 0) as sitemap_total_urls,
             dd.total_discovered_urls,
             dd.types,
             greatest(d.updated_at, coalesce(dd.updated_at, d.updated_at)) as updated_at
        from grabbing_jerome_domains d
        left join grabbing_jerome_discover_domain dd on dd.domain = d.domain
       order by d.updated_at desc, d.domain asc
    `);
    const items = rows.map(r => ({
      domain: r.domain,
      sitemap_url: r.sitemap_url || '',
      sitemaps: Array.isArray(r.sitemaps) ? r.sitemaps : (r.sitemaps && r.sitemaps.map ? r.sitemaps : []),
      selected_sitemaps: Array.isArray(r.selected_sitemaps) ? r.selected_sitemaps : (r.selected_sitemaps && r.selected_sitemaps.map ? r.selected_sitemaps : []),
      sitemap_total_urls: Number(r.sitemap_total_urls||0),
      total_discovered_urls: Number(r.total_discovered_urls||0),
      types: Array.isArray(r.types) ? r.types : (r.types && r.types.map ? r.types : []),
      updated_at: r.updated_at,
    }));
    return res.json({ ok:true, items });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'domains_failed', message: e?.message || String(e) });
  }
});

// POST /api/grabbings/jerome/discover/domains/recompute -> recompute totals/types per domain
app.post('/api/grabbings/jerome/discover/domains/recompute', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const pool = await getPg();
    if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    // Pull distinct domains present in discovery sessions
    const ds = await pool.query(`select lower(trim(domain)) as domain from grabbing_jerome_discover where trim(coalesce(domain,''))<>'' group by 1`);
    let updated = 0;
    for (const r of ds.rows) {
      const domain = r.domain;
      try {
        const q = await pool.query(
          `select count(*)::int as urls,
                  array_remove(array_agg(distinct lower(nullif(i.type,''))), NULL) as types
             from grabbing_jerome_discover d
             left join grabbing_jerome_discover_item i on i.discover_id = d.id
            where d.domain = $1`,
          [domain]
        );
        const urls = Number(q.rows?.[0]?.urls || 0);
        const types = Array.isArray(q.rows?.[0]?.types) ? q.rows[0].types : [];
        await pool.query(
          `insert into grabbing_jerome_discover_domain(domain, total_discovered_urls, types, updated_at)
           values($1,$2,$3::jsonb, now())
           on conflict (domain) do update set total_discovered_urls = EXCLUDED.total_discovered_urls, types = EXCLUDED.types, updated_at = now()`,
          [domain, urls, JSON.stringify(types)]
        );
        try { await mirrorLegacyDomain(pool, domain); } catch {}
        updated++;
      } catch {}
    }
    return res.json({ ok:true, updated });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'recompute_failed', message: e?.message || String(e) });
  }
});

// Delete domain row from Domain State (removes from both canonical and legacy tables)
// POST /api/grabbings/jerome/discover/domains/delete -> { ok, deleted }
app.post('/api/grabbings/jerome/discover/domains/delete', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const pool = await getPg();
    if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    try { await ensurePgTables(); } catch {}
    const raw = String(req.body?.domain || '').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./, '');
    if (!/^[a-z0-9.-]+$/.test(domain)) return res.status(400).json({ ok:false, error:'bad_request', message:'invalid domain' });
    // Delete from active tables and log details
    let dDomains = 0, dUrls = 0;
    try {
      const r = await pool.query('delete from grabbing_jerome_domains where domain=$1', [domain]);
      dDomains = r.rowCount|0;
    } catch (e) {
      try { logToFile(`[jerome:delete] error deleting from grabbing_jerome_domains for domain=${domain}: ${e?.message||e}`); } catch {}
    }
    try {
      const r = await pool.query('delete from public.grabbing_jerome_domains_url where domain=$1', [domain]);
      dUrls = r.rowCount|0;
    } catch (e) {
      try { logToFile(`[jerome:delete] error deleting from grabbing_jerome_domains_url for domain=${domain}: ${e?.message||e}`); } catch {}
    }
    try { logToFile(`[jerome:delete] domain=${domain} deleted grabbing_jerome_domains=${dDomains} grabbing_jerome_domains_url=${dUrls}`); } catch {}
    return res.json({ ok:true, domain, deleted_domains: dDomains, deleted_urls: dUrls, deleted: dDomains + dUrls });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'delete_failed', message: e?.message || String(e) });
  }
});


// POST /api/grabbings/jerome/discover/domains/backfill
// 1) Backfill missing d.domain from d.base_url
// 2) Recompute per-domain totals/types into grabbing_jerome_discover_domain
app.post('/api/grabbings/jerome/discover/domains/backfill', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const pool = await getPg();
    if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    // Backfill domain from base_url when empty
    await pool.query(
      `update grabbing_jerome_discover
          set domain = lower(regexp_replace(base_url, '^[a-z]+://([^/]+).*$', '\\1'))
        where (domain is null or trim(domain) = '')
          and base_url ~* '^[a-z]+://'
      `
    );
    // Recompute per-domain totals and types
    const ds = await pool.query(`select lower(trim(domain)) as domain from grabbing_jerome_discover where trim(coalesce(domain,''))<>'' group by 1`);
    let updated = 0;
    for (const r of ds.rows) {
      const domain = r.domain;
      try {
        const q = await pool.query(
          `select count(*)::int as urls,
                  array_remove(array_agg(distinct lower(nullif(i.type,''))), NULL) as types
             from grabbing_jerome_discover d
             left join grabbing_jerome_discover_item i on i.discover_id = d.id
            where d.domain = $1`,
          [domain]
        );
        const urls = Number(q.rows?.[0]?.urls || 0);
        const types = Array.isArray(q.rows?.[0]?.types) ? q.rows[0].types : [];
        await pool.query(
          `insert into grabbing_jerome_discover_domain(domain, total_discovered_urls, types, updated_at)
           values($1,$2,$3::jsonb, now())
           on conflict (domain) do update set total_discovered_urls = EXCLUDED.total_discovered_urls, types = EXCLUDED.types, updated_at = now()`,
          [domain, urls, JSON.stringify(types)]
        );
        try { await mirrorLegacyDomain(pool, domain); } catch {}
        updated++;
      } catch {}
    }
    return res.json({ ok:true, updated });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'backfill_failed', message: e?.message || String(e) });
  }
});

// Add a domain to grabbing_jerome_discover_domain and try to detect sitemaps
// POST /api/grabbings/jerome/discover/domains/add -> { ok, item }
app.post('/api/grabbings/jerome/discover/domains/add', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const raw = String(req.body?.domain || '').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { const u = new URL(/^https?:\/\//i.test(raw) ? raw : `https://${raw}`); domain = u.hostname.toLowerCase(); } catch {}
    const pool = await getPg();
    if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    // Try to detect sitemaps quickly (robots.txt + /sitemap.xml)
    let sitemaps = [];
    try {
      const base = new URL(`https://${domain}`);
      try {
        const robotsUrl = new URL('/robots.txt', base).toString();
        const r = await fetch(robotsUrl);
        if (r.ok) {
          const txt = await r.text();
          for (const line of txt.split(/\r?\n/)) {
            const m = line.match(/^\s*Sitemap:\s*(.+)\s*$/i);
            if (m && m[1]) { try { sitemaps.push(new URL(m[1], base).toString()); } catch {} }
          }
        }
      } catch {}
      try { sitemaps.push(new URL('/sitemap.xml', new URL(`https://${domain}`)).toString()); } catch {}
      // dedupe and clamp
      sitemaps = Array.from(new Set(sitemaps.filter(Boolean))).slice(0, 10);
    } catch {}
    const sm = sitemaps[0] || null;
    await pool.query(
      `insert into grabbing_jerome_domains(domain, sitemap_url, sitemaps, updated_at)
       values($1,$2,$3::jsonb, now())
       on conflict (domain) do update set sitemap_url=EXCLUDED.sitemap_url, sitemaps=EXCLUDED.sitemaps, updated_at=now()`,
      [domain, sm, JSON.stringify(sitemaps)]
    );
    const rsel = await pool.query(
      `select domain, sitemap_url, sitemaps, sitemap_total_urls, updated_at
         from grabbing_jerome_domains where domain=$1`,
      [domain]
    );
    const item = rsel.rows && rsel.rows[0] ? { ...rsel.rows[0], total_discovered_urls: 0, types: [] } : null;
    return res.json({ ok:true, item });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'add_failed', message: e?.message || String(e) });
  }
});

// Save selected sitemap(s) for a domain (path used by UI without '/discover')
// POST /api/grabbings/jerome/domains/select -> { ok }
app.post('/api/grabbings/jerome/domains/select', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    let domain = String(req.body?.domain || '').trim().toLowerCase();
    if (!domain) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let sitemaps = Array.isArray(req.body?.sitemaps) ? req.body.sitemaps.filter(Boolean) : [];
    if (sitemaps.length > 50) sitemaps = sitemaps.slice(0, 50);
    const sitemap_url = sitemaps[0] || null;
    const pool = await getPg();
    if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    await pool.query(
      `insert into grabbing_jerome_domains(domain, sitemap_url, sitemaps, updated_at)
       values($1,$2,$3::jsonb, now())
       on conflict (domain) do update set sitemap_url=EXCLUDED.sitemap_url, sitemaps=EXCLUDED.sitemaps, updated_at=now()`,
      [domain, sitemap_url, JSON.stringify(sitemaps)]
    );
    // Also persist selection to legacy table if present
    try {
      await pool.query(
        `insert into grabbing_jerome_domains(domain, selected_sitemaps, updated_at)
         values($1,$2::jsonb, now())
         on conflict (domain) do update set selected_sitemaps = EXCLUDED.selected_sitemaps, updated_at = now()`,
        [domain, JSON.stringify(sitemaps)]
      );
    } catch {}
    return res.json({ ok:true });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'save_failed', message: e?.message || String(e) });
  }
});

// POST /api/grabbings/jerome/discover/domains/extract
// Body: { domain: string, max_sitemaps?: number, max_urls?: number }
// Discovers sitemap(s) for domain, fetches, parses <loc>, and upserts into grabbing_jerome_domains_url
app.post('/api/grabbings/jerome/discover/domains/extract', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const pool = await getPg();
    if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    try { await ensurePgTables(); } catch {}
    // Normalize domain
    const rawIn = String(req.body?.domain || '').trim();
    if (!rawIn) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = rawIn.toLowerCase();
    try { if (/^https?:\/\//i.test(rawIn)) { const u = new URL(rawIn); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./, '');
    if (!/^[a-z0-9.-]+$/.test(domain)) return res.status(400).json({ ok:false, error:'bad_request', message:'invalid domain' });

    const maxSitemaps = Math.max(1, Math.min(Number(req.body?.max_sitemaps || 100000), 1000000));
    const maxUrls = Math.max(1, Math.min(Number(req.body?.max_urls || 100000000), 100000000));
    const includePatterns = Array.isArray(req.body?.include_patterns) ? req.body.include_patterns.filter(Boolean) : [];
    const excludePatterns = Array.isArray(req.body?.exclude_patterns) ? req.body.exclude_patterns.filter(Boolean) : [];
    const includeRegex = Array.isArray(req.body?.include_regex) ? req.body.include_regex.filter(Boolean) : [];
    const excludeRegex = Array.isArray(req.body?.exclude_regex) ? req.body.exclude_regex.filter(Boolean) : [];

    // Load selected sitemaps from body, else previously stored, else auto-discover
    const smSet = new Set();
    const bodyList = Array.isArray(req.body?.sitemaps) ? req.body.sitemaps : [];
    if (bodyList.length) {
      for (const s of bodyList) {
        try { const abs = new URL(String(s), `https://${domain}`).toString(); smSet.add(abs); } catch {}
        if (smSet.size >= Math.max(1, Math.min(Number(req.body?.max_sitemaps || 100000), 1000000))) break;
      }
    }
    try {
      if (!smSet.size) {
        const r = await pool.query('select sitemap_url, sitemaps, selected_sitemaps from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
        if (r.rowCount) {
          const row = r.rows[0];
          const sel = Array.isArray(row.selected_sitemaps) ? row.selected_sitemaps : (row.selected_sitemaps && row.selected_sitemaps.map ? row.selected_sitemaps : []);
          const arr = Array.isArray(row.sitemaps) ? row.sitemaps : (row.sitemaps && row.sitemaps.map ? row.sitemaps : []);
          const order = sel.length ? sel : [row.sitemap_url, ...arr];
          for (const s of order) { try { if (s) smSet.add(String(s)); } catch {} }
        }
      }
    } catch {}
    const discoverSitemaps = async () => {
      const out = new Set();
      const tryFetch = async (url) => { try { const r = await fetch(url, { method:'GET' }); return r && r.ok ? r : null; } catch { return null; } };
      const probeBase = async (scheme) => {
        const base = `${scheme}://${domain}`;
        const robots = await tryFetch(`${base}/robots.txt`);
        if (robots) {
          try {
            const txt = await robots.text();
            for (const line of txt.split(/\r?\n/)) {
              const m = line.match(/^\s*Sitemap:\s*(.+)\s*$/i);
              if (m && m[1]) { try { out.add(new URL(m[1], base).toString()); } catch {} }
            }
          } catch {}
        }
        const candidates = ['/sitemap.xml', '/sitemap_index.xml', '/sitemap-index.xml', '/sitemap1.xml', '/sitemap.xml.gz'];
        for (const p of candidates) { const url = `${base}${p}`; const r = await tryFetch(url); if (r) out.add(url); }
      };
      await probeBase('https'); if (!out.size) await probeBase('http');
      return Array.from(out);
    };
    if (!smSet.size) { try { for (const s of await discoverSitemaps()) smSet.add(s); } catch {} }
    const sitemaps = Array.from(smSet).slice(0, maxSitemaps);
    if (!sitemaps.length) return res.json({ ok:true, domain, total_urls: 0, inserted: 0, skipped: 0, sitemaps_used: [] });

    // Helpers
    const parseXml = (xml) => {
      const s = String(xml || '');
      const isIndex = /<sitemapindex[\s>]/i.test(s);
      // Match namespaced <loc>, optional attrs, allow CDATA or text, tolerate whitespace
      const re = /<(?:[\w.-]+:)?loc[^>]*>\s*(?:<!\[CDATA\[([\s\S]*?)\]\]>|([^<]*))\s*<\/(?:[\w.-]+:)?loc>/gi;
      const locs = [];
      let m;
      while ((m = re.exec(s)) !== null) {
        const val = (m[1] || m[2] || '').trim();
        if (val) locs.push(val);
      }
      // Fallback: very permissive match if none found
      if (!locs.length) {
        const re2 = /<loc[^>]*>([\s\S]*?)<\/loc>/gi;
        let n;
        while ((n = re2.exec(s)) !== null) {
          let v = String(n[1] || '').trim();
          if (/^<!\[CDATA\[/i.test(v)) v = v.replace(/^<!\[CDATA\[/i, '').replace(/\]\]>$/i, '').trim();
          if (v) locs.push(v);
        }
      }
      return { isIndex, locs };
    };
    const gunzipMaybe = async (buf, url, headers) => {
      try {
        const enc = String(headers?.get ? headers.get('content-encoding') : headers?.['content-encoding'] || '').toLowerCase();
        const byExt = /\.gz($|\?)/i.test(url);
        if (enc.includes('gzip') || byExt) {
          const z = await import('zlib');
          return z.gunzipSync(Buffer.from(buf)).toString('utf8');
        }
      } catch {}
      return Buffer.isBuffer(buf) ? buf.toString('utf8') : String(buf);
    };

    // Fetch and collect URLs
    const visited = new Set();
    const queue = [...sitemaps];
    const urls = new Set();
    let fetched = 0;
    const allowCrossHost = true; // always accept cross-host URLs present in sitemaps
    while (queue.length && fetched < maxSitemaps && urls.size < maxUrls) {
      const sm = queue.shift(); if (!sm || visited.has(sm)) continue; visited.add(sm); fetched++;
      try {
        const r = await fetch(sm, { method:'GET', redirect: 'follow', headers: { 'user-agent': 'Mozilla/5.0 (compatible; LivechatBot/1.0; +https://example.local)' } });
        if (!r || !r.ok) { try { logToFile(`[jerome:extract] fetch_fail url=${sm} status=${r?.status||0}`); } catch {} continue; }
        const arrBuf = Buffer.from(await r.arrayBuffer());
        const xml = await gunzipMaybe(arrBuf, sm, r.headers);
        const { isIndex, locs } = parseXml(xml);
        // Pre-filter diagnostics
        const rawCount = locs.length;
        let kept = 0;
        // We only compute kept for leaf sitemaps (where filtering applies)
        try { logToFile(`[jerome:extract] sitemap url=${sm} status=${r.status} bytes=${arrBuf.length} isIndex=${isIndex} locs=${rawCount}`); } catch {}
        if (!rawCount) continue;
        if (isIndex) {
          for (const loc of locs) {
            if (queue.length < maxSitemaps) {
              try { queue.push(new URL(loc, `https://${domain}`).toString()); } catch { try { queue.push(String(loc)); } catch {} }
            }
          }
        } else {
          for (const loc of locs) {
            try {
              const abs = new URL(loc, `https://${domain}`).toString();
              if (!allowCrossHost && new URL(abs).hostname.toLowerCase() !== domain) continue;
              // Skip asset URLs (images, media, docs, archives, code/assets, fonts, feeds)
              try {
                const p = new URL(abs).pathname.toLowerCase();
                if (/\.(jpg|jpeg|png|gif|webp|bmp|svg|ico|tif|tiff|avif|mp4|webm|avi|mov|mkv|mp3|wav|ogg|flac|pdf|docx?|xlsx?|pptx?|txt|csv|zip|rar|7z|tar|gz|bz2|css|js|mjs|ts|tsx|map|json|xml|rss|atom|woff2?|ttf|otf|eot)(\?|#|$)/i.test(p)) {
                  continue;
                }
              } catch {}
              // Apply filters
              const s = String(abs);
              if (excludePatterns.length && excludePatterns.some(p => p && s.includes(p))) continue;
              if (excludeRegex.length) {
                let blocked = false; for (const r of excludeRegex) { try { if (new RegExp(String(r), 'i').test(s)) { blocked = true; break; } } catch {} }
                if (blocked) continue;
              }
              if (includePatterns.length && !includePatterns.some(p => p && s.includes(p))) continue;
              if (includeRegex.length) {
                let ok = false; for (const r of includeRegex) { try { if (new RegExp(String(r), 'i').test(s)) { ok = true; break; } } catch {} }
                if (!ok) continue;
              }
              if (!urls.has(abs)) urls.add(abs);
              kept++;
              if (urls.size >= maxUrls) break;
            } catch {}
          }
          try { logToFile(`[jerome:extract] sitemap_kept url=${sm} kept=${kept} of ${rawCount}`); } catch {}
        }
      } catch {}
    }

    const list = Array.from(urls);
    let inserted = 0, skipped = 0;
    if (list.length) {
      // Count before
      let before = 0;
      try {
        const { rows } = await pool.query('select count(*)::int as c from public.grabbing_jerome_domains_url where domain=$1', [domain]);
        before = Number(rows?.[0]?.c || 0);
      } catch {}
      // Bulk insert with ON CONFLICT on normalized unique index
      let idx = 1;
      const chunk = 1000;
      for (let off = 0; off < list.length; off += chunk) {
        const part = list.slice(off, off + chunk);
        let sql = 'insert into public.grabbing_jerome_domains_url(domain,url) values ';
        const vals = [];
        for (let i=0;i<part.length;i++) { sql += `($${idx++},$${idx++})` + (i<part.length-1?',':''); vals.push(domain, part[i]); }
        try { await pool.query(sql + ' on conflict (domain, (lower(trim(both from url)))) do nothing', vals); } catch {}
        idx = 1;
      }
      // Count after and compute delta
      try {
        const { rows } = await pool.query('select count(*)::int as c from public.grabbing_jerome_domains_url where domain=$1', [domain]);
        const after = Number(rows?.[0]?.c || 0);
        inserted = Math.max(0, after - before);
        skipped = Math.max(0, list.length - inserted);
      } catch {}
    }
    // Update domains table totals
    try { await pool.query('update grabbing_jerome_domains set sitemap_total_urls=$2, updated_at=now() where domain=$1 and $2>coalesce(sitemap_total_urls,0)', [domain, list.length]); } catch {}
    try { logToFile(`[jerome:extract] domain=${domain} sitemaps=${sitemaps.length} urls_total=${list.length} inserted=${inserted} skipped=${skipped}`); } catch {}
    return res.json({ ok:true, domain, total_urls: list.length, inserted, skipped, sitemaps_used: sitemaps, sample: list.slice(0, 20) });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'extract_failed', message: e?.message || String(e) });
  }
});

  // Page Explorer: fetch a page, classify type, extract meta/product/links
  // POST /api/grabbings/jerome/page/explore -> { ok, url, page_type, meta, product?, links_sample }
  // Optional body flags:
  //  - preview: true     -> do not persist to DB (return only)
  //  - config_override: {} -> override per-domain config for this call only
  app.post('/api/grabbings/jerome/page/explore', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const rawUrl = String(req.body?.url || '').trim();
    if (!/^https?:\/\//i.test(rawUrl)) return res.status(400).json({ ok:false, error:'bad_request', message:'Valid url required' });
    const urlObj = new URL(rawUrl);
    const domain = urlObj.hostname.toLowerCase().replace(/^www\./,'');
    const preview = !!req.body?.preview;
    // Restrict to selected domains only: must exist in grabbing_jerome_domains with selected_sitemaps present (or any sitemaps)
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    let allowed = false;
    try {
      const r = await pool.query('select domain, coalesce(jsonb_array_length(coalesce(selected_sitemaps, sitemaps)),0)::int as cnt from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
      allowed = !!(r.rowCount && Number(r.rows[0].cnt||0) >= 0); // allow if row exists; adjust to >0 if strictly require selection
    } catch {}
    if (!allowed) return res.status(403).json({ ok:false, error:'forbidden', message:'domain_not_selected' });

    // Fetch page
    const r = await fetch(rawUrl, { method:'GET', redirect:'follow', headers:{ 'user-agent':'Mozilla/5.0 (compatible; LivechatBot/1.0; +https://example.local)' } });
    if (!r.ok) return res.status(502).json({ ok:false, error:'fetch_failed', status:r.status });
    const html = await r.text();

    // Basic extraction helpers
    const pickMeta = (name) => {
      const re = new RegExp(`<meta[^>]+(?:name|property)=["']${name}["'][^>]*content=["']([^"']*)["'][^>]*>`, 'i');
      const m = html.match(re); return m && m[1] ? m[1].trim() : '';
    };
    const getTitle = () => { const m = html.match(/<title[^>]*>([\s\S]*?)<\/title>/i); return m && m[1] ? m[1].trim() : ''; };
    const getCanonical = () => { const m = html.match(/<link[^>]+rel=["']canonical["'][^>]*href=["']([^"']+)["'][^>]*>/i); return m && m[1] ? m[1].trim() : ''; };
    // Try JSON-LD blocks
    let ld = [];
    try { ld = Array.from(html.matchAll(/<script[^>]+type=["']application\/ld\+json["'][^>]*>([\s\S]*?)<\/script>/gi)).map(m=>{ try { return JSON.parse(m[1]); } catch { return null; } }).filter(Boolean); } catch {}

    // Page type heuristic (improved)
    // Load per-domain config; allow one-shot override for preview/testing
    let cfg = await loadJeromeDomainConfigAsync(domain);
    let overrideUsed = false;
    try {
      const over = req.body?.config_override;
      if (over && typeof over === 'object') {
        // Shallow merge (callers should pass full sections if needed)
        cfg = { ...(cfg || {}), ...over };
        overrideUsed = true;
      }
    } catch {}
    // Best-effort: resolve current stored version
    let cfgVersion = null;
    try {
      const poolV = await getPg();
      if (poolV) {
        const vr = await poolV.query('select max(version) as v from grabbing_jerome_domain_config_history where domain=$1', [domain]);
        cfgVersion = Number(vr.rows?.[0]?.v || 0) || null;
      }
    } catch {}
    const lower = html.toLowerCase();
    const pathLower = (urlObj.pathname || '').toLowerCase();
    const ldTypes = [];
    try { for (const node of ld) {
      if (!node) continue;
      const t = node['@type'] || node.type || node['@graph']?.map?.(g=>g['@type']).filter(Boolean);
      const arr = Array.isArray(t) ? t : (t ? [t] : []);
      for (const v of arr) if (typeof v === 'string') ldTypes.push(v.toLowerCase());
    } } catch {}
    const ogType = (()=>{ const m = html.match(/<meta[^>]+property=["']og:type["'][^>]*content=["']([^"']+)["'][^>]*>/i); return m && m[1] ? m[1].trim().toLowerCase() : ''; })();
    const canonicalHref = (()=>{ const m = html.match(/<link[^>]+rel=["']canonical["'][^>]*href=["']([^"']+)["'][^>]*>/i); return m && m[1] ? m[1].trim() : ''; })();
    const canonicalPath = (()=>{ try { return new URL(canonicalHref, urlObj).pathname.toLowerCase(); } catch { return ''; } })();
    const hasPrice = /(itemprop=\"price\"|"price"\s*:\s*\d|data-price=|eur|€|usd|\$)/i.test(html);
    const productJsonCount = ldTypes.filter(t=> t.includes('product')).length;
    const hasProductSchema = productJsonCount > 0 || ogType === 'product';
    const hasArticle = /<article[\s>]|property=["']article:/i.test(html) || ldTypes.includes('article');
    const hasBreadcrumbList = ldTypes.includes('breadcrumblist');
    const hasCollectionSignals = ldTypes.includes('itemlist') || ldTypes.includes('collectionpage') || /category|collections|catalog|listing/.test(pathLower);

    // Decide with priority rules; avoid false product on collection pages containing product snippets
    let page_type = 'generic';
    let type_reason = '';
    const looksProductByPath = /\/product|\/products\//.test(pathLower) || /\/product|\/products\//.test(canonicalPath);
    if (hasCollectionSignals && !looksProductByPath && (productJsonCount > 1 || ogType !== 'product')) {
      page_type = 'category';
      type_reason = 'collection_signals';
    } else if (looksProductByPath || (hasProductSchema && hasPrice)) {
      page_type = 'product';
      type_reason = looksProductByPath ? 'path_products' : 'schema_price';
    } else if (hasArticle) {
      page_type = 'article';
      type_reason = 'article_signals';
    } else if (hasBreadcrumbList || hasCollectionSignals) {
      page_type = 'category';
      type_reason = hasBreadcrumbList ? 'breadcrumbs' : 'path_collections';
    }
    // Strengthen: if multiple distinct SKU markers appear and URL looks like a product, treat as product
    try {
      if (page_type !== 'product') {
        const skuMatches = Array.from(html.matchAll(/(?:itemprop=\"sku\"|["']sku["']\s*:\s*|data-sku=)["']?([A-Za-z0-9_\-\.\/:]+)/gi)).map(m=>String(m[1]||'').trim()).filter(Boolean);
        const uniqSkus = Array.from(new Set(skuMatches));
        if (uniqSkus.length > 1 && looksProductByPath) { page_type = 'product'; type_reason = 'multiple_sku'; }
      }
    } catch (e) {
      try { logToFile(`[presta] variant_import_warn ${e?.message||e}`); } catch {}
      try {
        if (debugLog && debugLog.data) {
          if (!Array.isArray(debugLog.data.warnings)) debugLog.data.warnings = [];
          debugLog.data.warnings.push(`variant_import_warn: ${String(e?.message||e)}`);
        }
      } catch {}
    }
    // Config overrides for type
    try {
      if (cfg?.classify?.force && typeof cfg.classify.force === 'string') {
        const t = cfg.classify.force.toLowerCase();
        if (['product','category','article','page','generic'].includes(t)) { page_type = t; type_reason = 'config_force'; }
      }
      if (Array.isArray(cfg?.classify?.path_rules)) {
        for (const rule of cfg.classify.path_rules) {
          const pat = String(rule?.pattern||''); const t = String(rule?.type||'').toLowerCase();
          if (!pat || !t) continue;
          try { if (new RegExp(pat,'i').test(urlObj.pathname)) { page_type = t; type_reason = 'config_rule'; break; } } catch {}
        }
      }
    } catch {}

    // Meta
    const meta = {
      title: getTitle(),
      description: pickMeta('description') || pickMeta('og:description') || '',
      canonical: getCanonical(),
      og_title: pickMeta('og:title') || '',
      og_image: pickMeta('og:image') || ''
    };

    // Extract page documents (pdf/doc/xls/zip) and a text sample
    let pageDocuments = [];
    try {
      const docMatches = [...html.matchAll(/<a[^>]+href=[\"\']([^\"\']+\.(?:pdf|doc|docx|xls|xlsx|zip))(?:\?[^\"\']*)?[\"\'][^>]*>([\s\S]*?)<\/a>/gi)];
      for (const m of docMatches) {
        const abs = new URL(m[1], urlObj).toString();
        let text = m[2] ? String(m[2]).replace(/<[^>]+>/g,'').trim() : '';
        if (!text) { try { text = new URL(abs).pathname.split('/').pop(); } catch { text = abs; } }
        pageDocuments.push({ url: abs, text });
      }
    } catch {}
    // Optionally download documents to local storage when enabled via config
    try {
      const wantDownload = !!(cfg && cfg.documents && (cfg.documents.download === true));
      if (wantDownload && pageDocuments.length) {
        const limit = Math.min(10, pageDocuments.length);
        for (let i=0; i<limit; i++) {
          const d = pageDocuments[i];
          try {
            const resp = await fetch(d.url, { method:'GET' });
            if (!resp.ok) continue;
            const ab = await resp.arrayBuffer();
            const buf = Buffer.from(ab);
            // 10 MB safety
            if (buf.length > 10*1024*1024) continue;
            const safeDomain = domain.replace(/[^a-z0-9.-]/gi,'_');
            const base = (new URL(d.url).pathname.split('/').pop() || 'file').replace(/[^A-Za-z0-9._%-]+/g,'_');
            const fname = `doc-${safeDomain}-${Date.now()}-${i}-${base}`;
            const fpath = path.join(grabbingJeromeDir, fname);
            fs.writeFileSync(fpath, buf);
            d.file = fname;
            d.download_url = `/api/grabbings/jerome/doc/${encodeURIComponent(fname)}`;
          } catch {}
        }
      }
    } catch {}
    // Attach to meta so it persists
    try { if (pageDocuments.length) meta.documents = pageDocuments; } catch {}
    try {
      // crude text extraction: drop scripts/styles, strip tags, collapse whitespace
      const cleaned = html
        .replace(/<script[\s\S]*?<\/script>/gi, ' ')
        .replace(/<style[\s\S]*?<\/style>/gi, ' ')
        .replace(/<noscript[\s\S]*?<\/noscript>/gi, ' ')
        .replace(/<[^>]+>/g, ' ')
        .replace(/[\r\n\t]+/g, ' ')
        .replace(/\s{2,}/g, ' ')
        .trim();
      if (cleaned) meta.text_sample = cleaned.slice(0, 8000);
    } catch {}
    // Extract SKU candidates from page content (e.g., S272CD-ORP-MA/10/TL/TL)
    let skuCandidates = [];
    try {
      const sources = [];
      try { sources.push(html); } catch {}
      try { if (meta.text_sample) sources.push(meta.text_sample); } catch {}
      const set = new Set();
      const re = /\b[A-Z0-9][A-Z0-9\-]+(?:\/[A-Z0-9\-]+){2,}\b/gi; // at least two slash-separated parts
      for (const s of sources) {
        if (!s) continue;
        let m;
        while ((m = re.exec(s))) {
          const val = String(m[0] || '').trim();
          if (val && /[A-Z]/i.test(val) && val.length >= 6 && val.length <= 128) set.add(val);
          if (set.size >= 100) break;
        }
        if (set.size >= 100) break;
      }
      if (set.size) skuCandidates = Array.from(set);
    } catch {}
    try {
      const hs = [];
      const h1 = [...html.matchAll(/<h1[^>]*>([\s\S]*?)<\/h1>/gi)].map(m=>String(m[1]||'').replace(/<[^>]+>/g,'').trim()).filter(Boolean);
      const h2 = [...html.matchAll(/<h2[^>]*>([\s\S]*?)<\/h2>/gi)].map(m=>String(m[1]||'').replace(/<[^>]+>/g,'').trim()).filter(Boolean);
      if (h1.length) hs.push({ level:1, items:h1.slice(0,10) });
      if (h2.length) hs.push({ level:2, items:h2.slice(0,20) });
      if (hs.length) meta.headings = hs;
    } catch {}

    // Build ordered content blocks (best-effort, domain-aware but without extra deps)
    try {
      const blocks = [];
      const pushPara = (text, section) => { const t = String(text||'').trim(); if (t) blocks.push({ type:'paragraph', text:t, section }); };
      const strip = (s='') => String(s).replace(/<\s*(script|style|noscript)[\s\S]*?<\/\s*\1\s*>/gi,' ').replace(/<[^>]+>/g,' ').replace(/\s+/g,' ').trim();
      const listItems = (htmlPart) => { const out=[]; try { const re=/<li[^>]*>([\s\S]*?)<\/li>/gi; let m; while((m=re.exec(htmlPart))) { const it=strip(m[1]||''); if (it) out.push(it); } } catch {} return out; };

      // 1) Gallery images in order
      try {
        const gal = [...html.matchAll(/woocommerce-product-gallery__image[^>]*>\s*<a[^>]+href=["']([^"']+)["']/gi)].map(m=>m[1]);
        for (const src of gal) { blocks.push({ type:'image', src, section:'gallery' }); }
      } catch {}

      // 2) Summary column (title/price/short text/bullets)
      try {
        const m = html.match(/<div[^>]+class=["'][^"']*summary[^"']*["'][^>]*>([\s\S]*?)<\/div>/i);
        if (m && m[1]) {
          const sum = m[1];
          // paragraphs in order
          const ps = [...sum.matchAll(/<p[^>]*>([\s\S]*?)<\/p>/gi)];
          for (const p of ps) pushPara(strip(p[1]||''), 'summary');
          // bullet lists
          const uls = [...sum.matchAll(/<ul[^>]*>([\s\S]*?)<\/ul>/gi)];
          for (const u of uls) {
            const items = listItems(u[1]||'');
            if (items.length) blocks.push({ type:'list', items, section:'summary' });
          }
        }
      } catch {}

      // 3) Tabs/sections in the order they appear on the page by scanning headings (config-aware)
      const addSection = (label, content, key) => {
        if (!content) return;
        // Apply exclude filters from config
        try {
          const excl = (cfg && cfg.content && Array.isArray(cfg.content.exclude)) ? cfg.content.exclude : [];
          for (const pat of excl) {
            try { const re = new RegExp(String(pat), 'gi'); content = content.replace(re, ' '); } catch {}
          }
        } catch {}
        // paragraphs
        for (const p of content.matchAll(/<p[^>]*>([\s\S]*?)<\/p>/gi)) pushPara(strip(p[1]||''), key||label);
        // lists
        for (const u of content.matchAll(/<ul[^>]*>([\s\S]*?)<\/ul>/gi)) {
          const items = listItems(u[1]||'');
          if (items.length) blocks.push({ type:'list', items, section:key||label });
        }
        // documents
        for (const a of content.matchAll(/<a[^>]+href=["']([^"']+\.(?:pdf|docx?|xlsx?))(?:\?[^"']*)?["'][^>]*>([\s\S]*?)<\/a>/gi)) {
          const href = new URL(a[1], urlObj).toString();
          const text = strip(a[2]||'');
          blocks.push({ type:'document', href, label: text || href, section:key||label });
        }
      };

      // If per-domain ordered roots provided, use them first
      try {
        const roots = (cfg && cfg.content && Array.isArray(cfg.content.roots)) ? cfg.content.roots : [];
        const useRoots = roots.filter(Boolean);
        const pickBetweenH2 = (needle) => {
          try {
            // Find H2 that contains the needle and capture until the next H2/section end
            const re = new RegExp(`<h2[^>]*>\\s*([^<]*${needle}[^<]*)<\\/h2>([\\s\\S]*?)(?:(<h2)|<\\/div>|$)`, 'i');
            const m = html.match(re);
            if (m) return m[2] || '';
          } catch {}
          return '';
        };
        for (const sel of useRoots) {
          let content = '';
          let key = '';
          if (/^#/.test(sel)) {
            const id = sel.replace(/^#/, '');
            const re = new RegExp(`<[^>]+id=["']${id}["'][^>]*>([\\s\\S]*?)<\\/[^>]+>`, 'i');
            const m = html.match(re);
            if (m) { content = m[1] || ''; key = id; }
          } else if (/^\.product.*summary/.test(sel)) {
            const m = html.match(/<div[^>]+class=["'][^"']*summary[^"']*["'][^>]*>([\s\S]*?)<\/div>/i);
            if (m) { content = m[1] || ''; key = 'summary'; }
          } else if (/^h2:contains\(/i.test(sel)) {
            const needle = sel.replace(/^h2:contains\((.*)\)$/i, '$1').replace(/["']/g,'').trim();
            content = pickBetweenH2(needle);
            key = needle.toLowerCase().replace(/\s+/g,'_');
          }
          if (content) addSection(key||sel, content, key||sel);
        }
      } catch {}
      try {
        const desc = (html.match(/<div[^>]+id=["']tab-description["'][^>]*>([\s\S]*?)<\/div>/i)||[])[1];
        if (desc) addSection('Product Information', desc, 'product_information');
      } catch {}
      try {
        const params = (html.match(/<h2[^>]*>\s*Parameters?\s*&?\s*Applications?\s*<\/h2>([\s\S]*?)(?:<h2|<\/div>)/i)||[])[1];
        if (params) addSection('Parameters & Applications', params, 'parameters_applications');
      } catch {}
      try {
        const tech = (html.match(/<h2[^>]*>\s*Technical\s+Specifications?\s*<\/h2>([\s\S]*?)(?:<h2|<\/div>)/i)||[])[1];
        if (tech) addSection('Technical Specifications', tech, 'technical_specifications');
      } catch {}
      try {
        const downloads = (html.match(/<h2[^>]*>\s*Product\s+Downloads?\s*<\/h2>([\s\S]*?)(?:<h2|<\/div>)/i)||[])[1];
        if (downloads) addSection('Product Downloads', downloads, 'product_downloads');
      } catch {}

      // 4) As a tail, include documents detected globally maintaining find order
      if (Array.isArray(meta.documents)) {
        for (const d of meta.documents) { blocks.push({ type:'document', href: d.url, label: d.text||d.url, download_url: d.download_url||'', section: 'documents' }); }
      }
      if (blocks.length) meta.content = blocks.map((b,i)=> ({ order:i, ...b }));
    } catch {}

    // Try to extract common product sections (WooCommerce and generic)
    try {
      const clean = (s='') => String(s).replace(/<\s*(script|style|noscript)[\s\S]*?<\/\s*\1\s*>/gi,' ').replace(/\s+/g,' ').trim();
      const sections = {};
      // WooCommerce description tab (Product Information)
      const descMatch = html.match(/<div[^>]+id=["']tab-description["'][^>]*>([\s\S]*?)<\/div>/i);
      if (descMatch && descMatch[1]) sections.product_information = clean(descMatch[1]);
      // Additional information table
      const addlMatch = html.match(/<h2[^>]*>\s*Additional\s+Information\s*<\/h2>[\s\S]*?<table[\s\S]*?<\/table>/i) || html.match(/<div[^>]+id=["']tab-additional_information["'][^>]*>([\s\S]*?)<\/div>/i);
      if (addlMatch) {
        const block = addlMatch[0] || addlMatch[1] || '';
        const rows = [];
        const rowRe = /<tr[^>]*>[\s\S]*?<th[^>]*>([\s\S]*?)<\/th>[\s\S]*?<td[^>]*>([\s\S]*?)<\/td>[\s\S]*?<\/tr>/gi;
        let rm;
        while ((rm = rowRe.exec(block))) {
          const k = clean(rm[1]||'');
          const v = clean(rm[2]||'');
          if (k || v) rows.push({ name:k, value:v });
        }
        if (rows.length) sections.additional_information = rows;
      }
      // Parameters & Applications
      const paramMatch = html.match(/<h2[^>]*>\s*Parameters?\s*&?\s*Applications?\s*<\/h2>[\s\S]*?(?:<h2|<\/div>)/i);
      if (paramMatch && paramMatch[0]) {
        const content = paramMatch[0].split(/<h2[^>]*>/i)[0];
        sections.parameters_applications = clean(content);
      }
      // Technical Specifications
      const techMatch = html.match(/<h2[^>]*>\s*Technical\s+Specifications?\s*<\/h2>[\s\S]*?(?:<h2|<\/div>)/i);
      if (techMatch && techMatch[0]) {
        const content = techMatch[0].split(/<h2[^>]*>/i)[0];
        sections.technical_specifications = clean(content);
      }
      // Generic: if no product_information, try first paragraph near title
      if (!sections.product_information) {
        const firstP = html.match(/<div[^>]+class=["'][^"']*(entry-content|woocommerce-product-details_short-description)[^"']*["'][^>]*>([\s\S]*?)<\/div>/i) || html.match(/<p>([\s\S]*?)<\/p>/i);
        if (firstP) sections.product_information = clean(firstP[2]||firstP[1]||'');
      }
      if (Object.keys(sections).length) meta.sections = sections;
    } catch {}

    // Product (best-effort)
    const debugInfo = { variant_source: 'none', variant_count: 0, handle: '' };
    let product = null;
    if (page_type === 'product') {
      const name = pickMeta('og:title') || pickMeta('twitter:title') || getTitle();
      // Price extraction heuristics
      let price = '';
      let currency = '';
      try {
        const pm = html.match(/(?:data-price|itemprop=\"price\"|"price"\s*:)\s*([0-9]+[\.,]?[0-9]*)/i);
        if (pm) price = pm[1].replace(',', '.');
        const cm = html.match(/(?:itemprop=\"priceCurrency\"|"priceCurrency"\s*:\s*|content=)\s*([A-Z]{3}|€|\$)/i);
        if (cm) currency = cm[1];
      } catch {}
      // SKU
      let sku = ''; try { const sm = html.match(/(?:itemprop=\"sku\"|"sku"\s*:\s*|data-sku=)["']?([A-Za-z0-9_\-\.\/:]+)["']?/i); if (sm) sku = sm[1]; } catch {}
      // Images
      let images = []; try { images = Array.from(html.matchAll(/<img[^>]*src=["']([^"']+)["'][^>]*>/gi)).map(m=>m[1]).slice(0,10); } catch {}
      // Apply image exclude filters from config
      try {
        const ex = Array.isArray(cfg?.images?.exclude_regex) ? cfg.images.exclude_regex : [];
        if (ex.length) {
          images = images.filter(u => {
            for (const r of ex) { try { if (new RegExp(String(r),'i').test(String(u||''))) return false; } catch {} }
            return true;
          });
        }
      } catch {}

      // Shopify variants (if applicable)
      let variants = [];
      try {
        const path = urlObj.pathname || '';
        // Support both /products/<handle> and /collections/.../products/<handle>
        let handle = '';
        if (/\/products\//i.test(path)) {
          handle = path.split('/products/').pop() || '';
          handle = handle.replace(/\?.*$/, '').replace(/\/$/, '');
        }
        if (handle) {
          debugInfo.handle = handle;
          if (handle) {
            const base = `${urlObj.protocol}//${urlObj.hostname}`;
            const pj = await fetch(`${base}/products/${handle}.js`, { method:'GET', redirect:'follow', headers:{ 'user-agent':'Mozilla/5.0 (compatible; LivechatBot/1.0; +https://example.local)' } });
            if (pj.ok) {
              const data = await pj.json();
              const pv = Array.isArray(data?.variants) ? data.variants : (Array.isArray(data?.product?.variants) ? data.product.variants : []);
              const rawOptions = (Array.isArray(data?.options) ? data.options : (Array.isArray(data?.product?.options) ? data.product.options : [])) || [];
              const optNames = rawOptions.map(o => (typeof o === 'string') ? o : (o && o.name) || '').map(s => String(s||'').trim());
              variants = pv.map(v => {
                const vid = v.id || v.variant_id || v.admin_graphql_api_id || '';
                const vtitle = v.title || [v.option1, v.option2, v.option3].filter(Boolean).join(' / ');
                const vprice = String(v.price || v.price_min || '').replace(',', '.');
                const vcap = v.compare_at_price || v.compare_at_price_max || '';
                const vsku = v.sku || '';
                const vimg = (v.featured_image && (v.featured_image.src || v.featured_image.url)) || '';
                const vurl = vid ? `${base}/products/${handle}?variant=${vid}` : `${base}/products/${handle}`;
                const attributes = {};
                try { for (let i=0;i<optNames.length;i++){ const n=String(optNames[i]||'').trim(); const val=String(v[`option${i+1}`]||'').trim(); if(n && val) attributes[n]=val; } } catch {}
                return { id: vid, sku: vsku, title: vtitle, price: vprice, compare_at_price: vcap || '', available: Boolean(v.available || v.available_for_sale || v.in_stock), image: vimg, url: vurl, attributes };
              });
              try { logToFile(`[jerome:explore] shopify_js_variants handle=${handle} count=${variants.length}`); } catch {}
              if (variants.length) { debugInfo.variant_source = 'shopify_js'; debugInfo.variant_count = variants.length; }
            }
            // .json fallback
            if (!variants.length) {
              try {
                const pj2 = await fetch(`${base}/products/${handle}.json`, { method:'GET', redirect:'follow', headers:{ 'user-agent':'Mozilla/5.0 (compatible; LivechatBot/1.0; +https://example.local)' } });
                if (pj2.ok) {
                  const data2 = await pj2.json();
                  const pv2 = Array.isArray(data2?.product?.variants) ? data2.product.variants : [];
                  const rawOptions2 = (Array.isArray(data2?.product?.options) ? data2.product.options : []) || [];
                  const optNames2 = rawOptions2.map(o => (typeof o === 'string') ? o : (o && o.name) || '').map(s => String(s||'').trim());
                  variants = pv2.map(v => {
                    const vid = v.id || v.variant_id || '';
                    const vtitle = v.title || [v.option1, v.option2, v.option3].filter(Boolean).join(' / ');
                    const vprice = String(v.price || v.price_min || '').replace(',', '.');
                    const vcap = v.compare_at_price || v.compare_at_price_max || '';
                    const vsku = v.sku || '';
                    const vimg = (v.featured_image && (v.featured_image.src || v.featured_image.url)) || '';
                    const vurl = vid ? `${base}/products/${handle}?variant=${vid}` : `${base}/products/${handle}`;
                    const attributes = {};
                    try { for (let i=0;i<optNames2.length;i++){ const n=String(optNames2[i]||'').trim(); const val=String(v[`option${i+1}`]||'').trim(); if(n && val) attributes[n]=val; } } catch {}
                    return { id: vid, sku: vsku, title: vtitle, price: vprice, compare_at_price: vcap || '', available: Boolean(v.available || v.available_for_sale || v.in_stock), image: vimg, url: vurl, attributes };
                  });
                  try { logToFile(`[jerome:explore] shopify_json_variants handle=${handle} count=${variants.length}`); } catch {}
                  if (variants.length) { debugInfo.variant_source = 'shopify_json'; debugInfo.variant_count = variants.length; }
                }
              } catch {}
            }
            // Fallback: parse embedded product JSON scripts if .js not available or empty
            if (!variants.length) {
              try {
                const embedded = Array.from(html.matchAll(/<script[^>]+type=["']application\/json["'][^>]*>([\s\S]*?)<\/script>/gi)).map(m=>m[1]);
                for (const raw of embedded) {
                  try {
                    const obj = JSON.parse(raw);
                    const pv = Array.isArray(obj?.variants) ? obj.variants : (Array.isArray(obj?.product?.variants) ? obj.product.variants : []);
                    if (Array.isArray(pv) && pv.length) {
                      variants = pv.map(v => {
                        const vid = v.id || v.variant_id || v.admin_graphql_api_id || '';
                        const vtitle = v.title || [v.option1, v.option2, v.option3].filter(Boolean).join(' / ');
                        const vprice = String(v.price || v.price_min || '').replace(',', '.');
                        const vcap = v.compare_at_price || v.compare_at_price_max || '';
                        const vsku = v.sku || '';
                        const vimg = (v.featured_image && (v.featured_image.src || v.featured_image.url)) || '';
                        const vurl = vid ? `${base}/products/${handle}?variant=${vid}` : `${base}/products/${handle}`;
                        return { id: vid, sku: vsku, title: vtitle, price: vprice, compare_at_price: vcap || '', available: Boolean(v.available || v.available_for_sale || v.in_stock), image: vimg, url: vurl };
                      });
                      debugInfo.variant_source = 'embedded_json';
                      debugInfo.variant_count = variants.length;
                      break;
                    }
                  } catch {}
                }
              } catch {}
            }
          }
        }
      } catch {}

      // Determine default variant (ID/SKU/URL) from URL, DOM, or first-available
      let defaultVariantId = null;
      let defaultVariantSku = '';
      let defaultVariantUrl = '';
      let defaultVariantImage = '';
      try {
        // 1) URL query param
        try { const vq = urlObj.searchParams ? urlObj.searchParams.get('variant') : null; if (vq) defaultVariantId = String(vq).replace(/[^0-9]/g,''); } catch {}
        // 2) DOM-selected variant markers
        if (!defaultVariantId) {
          try { const m = html.match(/<input[^>]+name=["']id["'][^>]*value=["'](\d+)["']/i); if (m && m[1]) defaultVariantId = m[1]; } catch {}
        }
        if (!defaultVariantId) {
          try { const m = html.match(/<select[^>]+name=["']id["'][\s\S]*?<option[^>]+selected[^>]*value=["'](\d+)["']/i); if (m && m[1]) defaultVariantId = m[1]; } catch {}
        }
        // 3) Pick from parsed variants
        let dv = null;
        if (Array.isArray(variants) && variants.length) {
          if (defaultVariantId) dv = variants.find(v => String(v && v.id) === String(defaultVariantId)) || null;
          if (!dv) dv = variants.find(v => v && (v.available || v.available_for_sale || v.in_stock)) || null;
          if (!dv) dv = variants[0] || null;
        }
        if (dv) {
          defaultVariantId = dv.id || defaultVariantId;
          defaultVariantSku = dv.sku || '';
          defaultVariantUrl = dv.url || '';
          defaultVariantImage = dv.image || '';
        }
      } catch {}

      // WooCommerce/Generic variant extraction (after Shopify fallbacks)
      if (!variants.length) {
        try {
          // data-product_variations attribute payload
          const attrMatch = html.match(/data-product_variations=\"([^\"]+)\"/i) || html.match(/data-product_variations='([^']+)'/i);
          if (attrMatch && attrMatch[1]) {
            let jsonText = attrMatch[1]
              .replace(/&amp;quot;/g, '"')
              .replace(/&quot;/g, '"')
              .replace(/&#34;/g, '"')
              .replace(/&#39;/g, "'")
              .replace(/&amp;/g, '&');
            try {
              const arr = JSON.parse(jsonText);
              if (Array.isArray(arr) && arr.length) {
                variants = arr.map(v => {
                  const vid = v.variation_id || v.id || '';
                  const vsku = v.sku || '';
                  const vprice = String(v.display_price || v.price || '').replace(',', '.');
                  const vimg = (v.image && (v.image.src || v.image.url)) || '';
                  const attrs = v.attributes || {};
                  const title = Object.values(attrs).filter(Boolean).join(' / ');
                  return { id: vid, sku: vsku, title, price: vprice, image: vimg };
                });
                if (variants.length) { debugInfo.variant_source = 'woocommerce_attr'; debugInfo.variant_count = variants.length; }
              }
            } catch {}
          }
          // product_variations JS variable
          if (!variants.length) {
            const jsBlocks = Array.from(html.matchAll(/<script[^>]*>([\s\S]*?)<\/script>/gi)).map(m=>m[1]||'');
            for (const block of jsBlocks) {
              const m = block.match(/product_variations\s*=\s*(\[\s*[\s\S]*?\])/i);
              if (m && m[1]) {
                try {
                  const arr = JSON.parse(m[1]);
                  if (Array.isArray(arr) && arr.length) {
                    variants = arr.map(v => {
                      const vid = v.variation_id || v.id || '';
                      const vsku = v.sku || '';
                      const vprice = String(v.display_price || v.price || '').replace(',', '.');
                      const vimg = (v.image && (v.image.src || v.image.url)) || '';
                      const attrs = v.attributes || {};
                      const title = Object.values(attrs).filter(Boolean).join(' / ');
                      return { id: vid, sku: vsku, title, price: vprice, image: vimg };
                    });
                    debugInfo.variant_source = 'woocommerce_js';
                    debugInfo.variant_count = variants.length;
                    break;
                  }
                } catch {}
              }
            }
          }
          // Generic: JSON with "variations": [...]
          if (!variants.length) {
            const jsBlocks = Array.from(html.matchAll(/<script[^>]*>([\s\S]*?)<\/script>/gi)).map(m=>m[1]||'');
            for (const block of jsBlocks) {
              const m = block.match(/\"variations\"\s*:\s*(\[[\s\S]*?\])/i);
              if (m && m[1]) {
                try {
                  const arr = JSON.parse(m[1]);
                  if (Array.isArray(arr) && arr.length) {
                    variants = arr.map(v => {
                      const vid = v.variation_id || v.id || '';
                      const vsku = v.sku || '';
                      const vprice = String(v.display_price || v.price || '').replace(',', '.');
                      const vimg = (v.image && (v.image.src || v.image.url)) || '';
                      const attrs = v.attributes || {};
                      const title = Object.values(attrs).filter(Boolean).join(' / ');
                      return { id: vid, sku: vsku, title, price: vprice, image: vimg };
                    });
                    debugInfo.variant_source = 'json_variations_field';
                    debugInfo.variant_count = variants.length;
                    break;
                  }
                } catch {}
              }
            }
          }
          // JSON-LD offers fallback to emulate variants
          if (!variants.length) {
            try {
              const offers = [];
              for (const node of ld) {
                const off = node?.offers;
                const list = Array.isArray(off) ? off : (off && off['@type'] ? [off] : []);
                for (const o of list) {
                  const sku2 = o?.sku || '';
                  const price2 = String(o?.price || '').replace(',', '.');
                  const title2 = o?.name || '';
                  if (sku2 || price2 || title2) offers.push({ sku: sku2, price: price2, title: title2 });
                }
              }
              if (offers.length > 1) {
                variants = offers.map((o, i) => ({ id: o.sku || String(i+1), sku: o.sku || '', title: o.title || '', price: o.price || '' }));
                debugInfo.variant_source = 'jsonld_offers';
                debugInfo.variant_count = variants.length;
              }
            } catch {}
          }
        } catch {}
      }

      // Additional WooCommerce fallback: derive variants from <select> options in variations_form
      if (!variants.length) {
        try {
          const form = (html.match(/<form[^>]+class=["'][^"']*variations_form[^"']*["'][^>]*>([\s\S]*?)<\/form>/i) || [])[1] || '';
          if (form) {
            const selects = Array.from(form.matchAll(/<select[^>]+name=["']attribute_([^"']+)["'][^>]*>([\s\S]*?)<\/select>/gi));
            const attrs = [];
            for (const m of selects) {
              const rawName = m[1] || '';
              const optsHtml = m[2] || '';
              // try to find a nearby label (best-effort)
              let name = rawName.replace(/^pa[_-]/,'').replace(/[_-]+/g,' ').replace(/\s+/g,' ').trim();
              const lbl = form.substring(0, form.indexOf(m[0])).match(/<label[^>]*>([\s\S]*?)<\/label>\s*$/i);
              if (lbl && lbl[1]) {
                const txt = String(lbl[1]).replace(/<[^>]+>/g,'').trim(); if (txt) name = txt;
              }
              name = name.replace(/\b\w/g, (c) => c.toUpperCase());
              const opts = Array.from(optsHtml.matchAll(/<option[^>]*value=["']([^"']+)["'][^>]*>([\s\S]*?)<\/option>/gi))
                .map(o => {
                  const val = (o[1] || '').trim();
                  let txt = (o[2] || '').replace(/<[^>]+>/g,'').trim();
                  if (!txt) txt = val;
                  return val ? { value: val, label: txt } : null;
                })
                .filter(Boolean);
              if (opts.length) attrs.push({ name, raw: rawName, options: opts });
            }
            if (attrs.length) {
              const combine = (lists) => lists.reduce((acc, cur) => {
                const out = [];
                for (const a of acc) for (const b of cur.options) out.push([...a, { name: cur.name, raw: cur.raw, option: b }]);
                return out;
              }, [[]]);
              const combos = combine(attrs);
              variants = combos.slice(0, 100).map((pair) => {
                const title = pair.map(p => `${p.name}: ${p.option.label}`).join(' / ');
                return { id: null, sku: '', title, price: '', image: '' };
              });
              if (variants.length) { debugInfo.variant_source = 'woocommerce_selects'; debugInfo.variant_count = variants.length; }
            }
          }
        } catch {}
      }

      // WooCommerce AJAX enrichment for variants (prices/SKU/image) when possible
      if (Array.isArray(variants) && variants.length) {
        try {
          // Find product_id
          let productId = '';
          try {
            const m1 = html.match(/name=["']product_id["'][^>]*value=["'](\d+)["']/i);
            if (m1 && m1[1]) productId = m1[1];
          } catch {}
          if (!productId) {
            try { const m2 = html.match(/data-product_id=["'](\d+)["']/i); if (m2 && m2[1]) productId = m2[1]; } catch {}
          }
          // Find wc-ajax endpoint
          let ajaxBase = '';
          try {
            const m = html.match(/wc_ajax_url\"\s*:\s*\"([^\"]+)\"/i) || html.match(/wc_ajax_url\'\s*:\s*\'([^\']+)\'/i);
            if (m && m[1]) ajaxBase = m[1].replace(/\\\//g,'/');
          } catch {}
          let endpoint = '';
          try {
            if (ajaxBase && ajaxBase.includes('%%endpoint%%')) endpoint = ajaxBase.replace('%%endpoint%%', 'get_variation');
          } catch {}
          if (!endpoint) endpoint = `${urlObj.protocol}//${urlObj.host}/?wc-ajax=get_variation`;

          const parsePrice = (v) => {
            if (typeof v === 'number') return v;
            const s = String(v||'').replace(/<[^>]*>/g,'').replace(/[^0-9.,-]/g,'').replace(/,(?=\d{3}\b)/g,'');
            const n = parseFloat((s.lastIndexOf(',') > s.lastIndexOf('.') ? s.replace(/,/g,'.') : s));
            return isFinite(n) ? n : null;
          };

          // If we have attribute combos from selects, enrich up to 50 to be gentle
          let enriched = 0;
          const maxEnrich = Math.min(50, variants.length);
          // Rebuild attribute combos from selects again to maintain mapping
          const form = (html.match(/<form[^>]+class=["'][^"']*variations_form[^"']*["'][^>]*>([\s\S]*?)<\/form>/i) || [])[1] || '';
          const selects = Array.from(form.matchAll(/<select[^>]+name=["']attribute_([^"']+)["'][^>]*>([\s\S]*?)<\/select>/gi));
          const attrs = selects.map(m => ({ raw: m[1] || '', opts: Array.from((m[2]||'').matchAll(/<option[^>]*value=["']([^"']+)["'][^>]*>([\s\S]*?)<\/option>/gi)).map(o=>({ value:(o[1]||'').trim(), label:String(o[2]||'').replace(/<[^>]+>/g,'').trim() })).filter(x=>x.value) }));
          const combine = (lists) => lists.reduce((acc, cur) => { const out=[]; for (const a of acc) for (const b of cur.opts) out.push([...a, { raw: cur.raw, value: b.value, label: b.label }]); return out; }, [[]]);
          const combos = attrs.length ? combine(attrs).slice(0, maxEnrich) : [];

          const enrichOne = async (combo) => {
            const params = new URLSearchParams();
            params.set('product_id', productId);
            for (const p of combo) params.set(`attributes[attribute_${p.raw}]`, p.value);
            const resp = await fetch(endpoint, { method:'POST', headers:{ 'Content-Type':'application/x-www-form-urlencoded; charset=UTF-8', 'user-agent':'Mozilla/5.0 (compatible; LivechatBot/1.0)' }, body: params.toString(), redirect:'follow' });
            if (!resp.ok) return null;
            const data = await resp.json().catch(()=>null);
            return data;
          };

          for (const combo of combos) {
            if (!productId || enriched >= maxEnrich) break;
            try {
              const data = await enrichOne(combo);
              if (data && (data.variation_id || data.price_html || data.display_price)) {
                const title = combo.map(p => `${p.raw.replace(/^pa[_-]/,'').replace(/[_-]+/g,' ').replace(/\b\w/g, c=>c.toUpperCase())}: ${p.label}`).join(' / ');
                const price = parsePrice(data.display_price || data.price_html || '');
                const image = (data.image && (data.image.full_src || data.image.src)) || '';
                const sku = data.sku || '';
                const vid = data.variation_id || '';
                const query = combo.map(p => `attribute_${encodeURIComponent(p.raw)}=${encodeURIComponent(p.value)}`).join('&');
                const vurl = `${urlObj.protocol}//${urlObj.host}${urlObj.pathname}?${query}`;
                variants.push({ id: vid, sku, title, price, image, url: vurl, available: Boolean(data.is_in_stock) });
                enriched++;
              }
            } catch {}
          }
          if (enriched > 0) { debugInfo.variant_source = 'woocommerce_ajax'; debugInfo.variant_count = variants.length; }
        } catch {}
      }

      // Improve images: merge gallery anchors, og:image, data-src, srcset
      try {
        const toAbs = (u) => { try { return new URL(String(u), urlObj).toString(); } catch { return String(u||''); } };
        const gal2 = Array.from(html.matchAll(/woocommerce-product-gallery__image[^>]*>\s*<a[^>]+href=["']([^"']+)["']/gi)).map(m=>toAbs(m[1]));
        const dataSrc = Array.from(html.matchAll(/<img[^>]*data-src=["']([^"']+)["'][^>]*>/gi)).map(m=>toAbs(m[1]));
        const srcset = Array.from(html.matchAll(/<img[^>]*srcset=["']([^"']+)["'][^>]*>/gi)).flatMap(m => {
          const list = String(m[1]||'').split(',').map(s=>s.trim().split(' ')[0]).filter(Boolean);
          return list.map(toAbs);
        });
        const extra = [];
        if (meta.og_image) extra.push(toAbs(meta.og_image));
        let merged = [...images.map(toAbs), ...gal2, ...dataSrc, ...srcset, ...extra];
        // Deduplicate while keeping order
        const seen = new Set();
        merged = merged.filter(u => { const k = u.trim(); if (!k || seen.has(k)) return false; seen.add(k); return true; });
        // Re-apply image exclude filters from config to the merged set
        try {
          const ex = Array.isArray(cfg?.images?.exclude_regex) ? cfg.images.exclude_regex : [];
          if (ex.length) {
            merged = merged.filter(u => {
              for (const r of ex) { try { if (new RegExp(String(r),'i').test(String(u||''))) return false; } catch {}
              }
              return true;
            });
          }
        } catch {}
        // Keep a sane limit
        images = merged.slice(0, 12);
      } catch {}

      // Optionally download a few images locally for reference (does not affect Presta import)
      try {
        const wantDownloadImg = (cfg && cfg.images && cfg.images.download === false) ? false : true; // default true
        if (wantDownloadImg && images && images.length) {
          const limit = Math.min(8, images.length);
          const list = [];
          for (let i=0;i<limit;i++) {
            try {
              const u = images[i];
              const resp = await fetch(u, { method:'GET' });
              if (!resp.ok) continue;
              const ab = await resp.arrayBuffer();
              const buf = Buffer.from(ab);
              if (buf.length > 8*1024*1024) continue; // 8MB safety
              const safeDomain = domain.replace(/[^a-z0-9.-]/gi,'_');
              const base = (()=>{ try { const p=new URL(u).pathname; const b=p.split('/').pop()||'image.jpg'; return b.replace(/[^A-Za-z0-9._%-]+/g,'_'); } catch { return 'image.jpg'; } })();
              const fname = `img-${safeDomain}-${Date.now()}-${i}-${base}`;
              const fpath = path.join(grabbingJeromeDir, fname);
              fs.writeFileSync(fpath, buf);
              list.push({ url: u, file: fname, download_url: `/api/grabbings/jerome/doc/${encodeURIComponent(fname)}` });
            } catch {}
          }
          if (list.length) {
            if (!product) product = { name:'', price:'', currency:'', sku:'', images:[], variants:[] };
            product.images_local = list;
          }
        }
      } catch {}

      // Normalize product defaults so "default variant" represents the product itself
      try {
        // 1) Reorder variants to put the default first
        if (Array.isArray(variants) && variants.length) {
          const idx = (defaultVariantId!=null)
            ? variants.findIndex(v => String(v && v.id) === String(defaultVariantId))
            : (defaultVariantSku ? variants.findIndex(v => String(v && v.sku) === String(defaultVariantSku)) : -1);
          if (idx > 0) {
            const [dv] = variants.splice(idx, 1);
            variants.unshift(dv);
          }
        }
        // 2) Prefer default variant SKU as product SKU when available
        if (defaultVariantSku) {
          try { if (!sku || String(sku).trim() === '') sku = defaultVariantSku; } catch { sku = defaultVariantSku; }
        }
        // 3) Prefer default variant price when explicit
        try {
          if (!price || String(price).trim() === '') {
            const dvObj = (Array.isArray(variants) ? variants.find(v => (defaultVariantId!=null? String(v && v.id)===String(defaultVariantId) : (defaultVariantSku? String(v && v.sku)===String(defaultVariantSku) : false))) : null) || (Array.isArray(variants)? variants[0] : null);
            if (dvObj && dvObj.price) price = String(dvObj.price);
          }
        } catch {}
        // 4) Ensure default variant image appears first in images
        try {
          const preferImg = defaultVariantImage || (Array.isArray(variants) && variants.length ? (variants[0].image || '') : '');
          if (preferImg) {
            const toAbs = (u) => { try { return new URL(String(u), urlObj).toString(); } catch { return String(u||''); } };
            const abs = toAbs(preferImg);
            if (abs) {
              const arr = Array.isArray(images) ? images.slice() : [];
              const pos = arr.findIndex(u => String(u||'').trim() === abs.trim());
              if (pos === -1) images = [abs, ...arr];
              else if (pos > 0) { arr.splice(pos, 1); images = [abs, ...arr]; }
            }
          }
        } catch {}
      } catch {}

      // If variants still empty but multiple distinct SKUs detected on page, synthesize simple variants
      try {
        if (!Array.isArray(variants) || variants.length === 0) {
          const skuMatches = Array.from(html.matchAll(/(?:itemprop=\"sku\"|["']sku["']\s*:\s*|data-sku=)["']?([A-Za-z0-9_\-\.\/:]+)/gi)).map(m=>String(m[1]||'').trim()).filter(Boolean);
          const uniqSkus = Array.from(new Set(skuMatches));
          if (uniqSkus.length > 1) {
            variants = uniqSkus.slice(0, 100).map((s, i) => ({ id: s || String(i+1), sku: s, title: s, price: '' }));
          }
        }
      } catch {}

      // Merge previously collected fields (e.g., images_local) but keep freshly extracted values
      product = { ...(product || {}), name, price, currency, sku, images, variants };
      try {
        if (defaultVariantId != null || defaultVariantSku || defaultVariantUrl || defaultVariantImage) {
          product.default_variant_id = defaultVariantId || null;
          if (defaultVariantSku) product.default_variant_sku = defaultVariantSku;
          if (defaultVariantUrl) product.default_variant_url = defaultVariantUrl;
          if (defaultVariantImage) product.default_variant_image = defaultVariantImage;
        }
      } catch {}
      try { if (Array.isArray(skuCandidates) && skuCandidates.length) product.sku_candidates = skuCandidates; } catch {}
      // Fallback variants for sensorex.com: build variants from SKU candidates when no Woo variations are present
      try {
        if ((domain && /sensorex\.com$/i.test(domain)) && (!Array.isArray(product.variants) || product.variants.length === 0)) {
          const candidatesSrc = Array.isArray(skuCandidates) ? skuCandidates : [];
          const seen = new Set();
          const candidates = candidatesSrc
            .map(s => String(s||'').trim())
            .filter(Boolean)
            .filter(s => { const k=s.toUpperCase(); if (seen.has(k)) return false; seen.add(k); return true; })
            .slice(0, 10);
          if (candidates.length) {
            // Infer price/currency when missing
            let pval = product.price || '';
            let pcur = product.currency || '';
            if (!pval) {
              try {
                const m = html.match(/(?:\$|€|USD|EUR)\s*([0-9]+(?:[.,][0-9]{1,2})?)/i);
                if (m) pval = m[1].replace(',', '.');
                const cm = html.match(/(?:itemprop=\"priceCurrency\"|\bpriceCurrency\b\s*:\s*|content=)\s*([A-Z]{3}|€|\$)/i);
                if (cm) pcur = cm[1];
                else if (/€/.test(html)) pcur = 'EUR';
                else if (/\$/.test(html)) pcur = 'USD';
              } catch {}
            }
            const img0 = (Array.isArray(product.images) && product.images[0]) || meta.og_image || '';
            const fallback = candidates.map(skuCode => ({ id: null, sku: skuCode, title: skuCode, price: pval || '', image: img0 || '', url: rawUrl, available: true }));
            product.variants = fallback;
            if (pcur && !product.currency) product.currency = pcur;
          }
        }
      } catch {}
    }

    // Links sample (same-domain only)
    let links_sample = [];
    try {
      const a = Array.from(html.matchAll(/<a[^>]*href=["']([^"']+)["'][^>]*>/gi)).map(m=>m[1]);
      const same = [];
      for (const h of a) {
        try {
          const abs = new URL(h, urlObj).toString();
          if (new URL(abs).hostname.toLowerCase().replace(/^www\./,'') === domain) { same.push(abs); }
        } catch {}
        if (same.length >= 15) break;
      }
      links_sample = Array.from(new Set(same));
    } catch {}

    // Attach config summary before returning (affects preview too)
    try {
      if (type_reason) meta.type_reason = type_reason;
      if (cfg && typeof cfg === 'object') {
        const force = cfg?.classify?.force || '';
        const prules = Array.isArray(cfg?.classify?.path_rules) ? cfg.classify.path_rules.length : 0;
        const roots = Array.isArray(cfg?.content?.roots) ? cfg.content.roots.length : 0;
        const cex = Array.isArray(cfg?.content?.exclude) ? cfg.content.exclude.length : 0;
        const iex = Array.isArray(cfg?.images?.exclude_regex) ? cfg.images.exclude_regex.length : 0;
        const imgDl = !!(cfg?.images?.download);
        const docDl = !!(cfg?.documents?.download);
        meta.config_used = { force, path_rules: prules, content_roots: roots, content_exclude: cex, images_exclude: iex, images_download: imgDl, documents_download: docDl, override_used: !!overrideUsed, version: cfgVersion };
      }
    } catch {}

    // Persist with upserts (history + canonical URLs), unless preview mode
    try {
      if (preview) {
        try { logToFile(`[jerome:explore:preview] domain=${domain} type=${page_type} url=${rawUrl}`); } catch {}
        return res.json({ ok:true, url: rawUrl, page_type, type_reason, meta, product, links_sample, debug: debugInfo, preview: true });
      }
      // Include lightweight config/debug info inside meta before saving
      try {
        if (type_reason) meta.type_reason = type_reason;
        if (cfg && typeof cfg === 'object') {
          const force = cfg?.classify?.force || '';
          const prules = Array.isArray(cfg?.classify?.path_rules) ? cfg.classify.path_rules.length : 0;
          const roots = Array.isArray(cfg?.content?.roots) ? cfg.content.roots.length : 0;
          const cex = Array.isArray(cfg?.content?.exclude) ? cfg.content.exclude.length : 0;
          const iex = Array.isArray(cfg?.images?.exclude_regex) ? cfg.images.exclude_regex.length : 0;
          const imgDl = !!(cfg?.images?.download);
          const docDl = !!(cfg?.documents?.download);
          meta.config_used = { force, path_rules: prules, content_roots: roots, content_exclude: cex, images_exclude: iex, images_download: imgDl, documents_download: docDl, override_used: !!overrideUsed, version: cfgVersion };
        }
      } catch {}
      // History table snapshot
      // Persist only full result JSON as latest snapshot for this URL
      try {
        const resultJson = {
          ok: true,
          url: rawUrl,
          page_type,
          meta,
          product,
          links_sample,
          debug: debugInfo,
          preview: false,
        };
        await pool.query(
          `insert into public.grabbing_jerome_domains_url_page_explore
             (domain, url, page_type, result_json, config_version, explored_at)
           values ($1, $2, $3, $4::jsonb, $5, now())
           on conflict (domain, (lower(trim(both from url))))
           do update set
             page_type      = EXCLUDED.page_type,
             result_json    = EXCLUDED.result_json,
             config_version = EXCLUDED.config_version,
             explored_at    = now()`,
          [domain, rawUrl, page_type, JSON.stringify(resultJson), (cfgVersion==null? null : Number(cfgVersion))]
        );
      } catch {}
      // Canonical URLs table enrichment + mark explored done
      await pool.query(
        `insert into public.grabbing_jerome_domains_url(domain,url,type,title,page_type,meta,product,explored)
         values($1,$2,$3,$4,$3,$5::jsonb,$6::jsonb, now())
         on conflict (domain, (lower(trim(both from url))))
         do update set type = EXCLUDED.type, title = EXCLUDED.title, page_type = EXCLUDED.page_type, meta = EXCLUDED.meta, product = EXCLUDED.product, explored = now()`,
        [domain, rawUrl, page_type, meta?.title || null, JSON.stringify(meta), JSON.stringify(product)]
      );
    } catch (e) { try { logToFile(`[jerome:explore] upsert_error domain=${domain} url=${rawUrl} err=${e?.message||e}`); } catch {} }

    try { logToFile(`[jerome:explore] domain=${domain} type=${page_type} url=${rawUrl}`); } catch {}
    return res.json({ ok:true, url: rawUrl, page_type, type_reason, meta, product, links_sample, debug: debugInfo });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'explore_failed', message: e?.message || String(e) });
  }
});

// Export discovery results from DB as JSON with similar shape to file-based export
app.get('/api/grabbings/jerome/discover/export/:id', async (req, res) => {
  try {
    const pool = await getPg();
    const id = Number(req.params.id||0);
    if (!pool || !id) return res.status(404).end('not_found');
    const one = await pool.query('select base_url, created_at from grabbing_jerome_discover where id=$1', [id]);
    if (!one.rows.length) return res.status(404).end('not_found');
    const base_url = one.rows[0].base_url;
    const items = (await pool.query('select url, type, title from grabbing_jerome_discover_item where discover_id=$1 order by id asc', [id])).rows;
    const payload = { base_url, urls: items };
    const buf = Buffer.from(JSON.stringify(payload, null, 2));
    res.setHeader('Content-Type', 'application/json; charset=utf-8');
    res.setHeader('Content-Length', String(buf.length));
    return res.end(buf);
  } catch (e) { return res.status(500).end('server_error'); }
});

// List latest Jerome extract files (non-discovery)
// GET /api/grabbings/jerome/latest -> { ok, items:[{name,size,mtime,download_url}] }
app.get('/api/grabbings/jerome/latest', async (_req, res) => {
  try {
    if (JEROME_STORAGE_DISABLED) return res.json({ ok:true, items: [] });
    const pool = await getPg();
    if (pool) {
      const { rows } = await pool.query('select file_name as name, extract(epoch from mtime)*1000 as mtime_ms, size, download_url from grabbing_jerome_extracts order by mtime desc limit 50');
      const items = rows.map(r => ({ name: r.name, size: Number(r.size||0), mtime: new Date(Number(r.mtime_ms||Date.now())), download_url: r.download_url }));
      return res.json({ ok:true, items });
    }
    const names = fs.readdirSync(grabbingJeromeDir).filter((n) => /\.json$/i.test(n) && !/^jerome-discover-/i.test(n));
    const items = names.map((n) => { const p = path.join(grabbingJeromeDir, n); const st = fs.statSync(p); return { name:n, size: st.size, mtime: st.mtime, download_url: `/api/grabbings/jerome/file/${encodeURIComponent(n)}` }; }).sort((a,b)=> b.mtime - a.mtime).slice(0,50);
    return res.json({ ok:true, items });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'list_failed', message: e?.message || String(e) });
  }
});

// === Presta transfers (minimal stub to support UI) ===
function loadPrestaTransfers() {
  try { const t = fs.readFileSync(grabbingJeromeTransfersFile, 'utf8'); const arr = JSON.parse(t||'[]'); return Array.isArray(arr)? arr: []; } catch { return []; }
}
function savePrestaTransfers(items) {
  try { fs.writeFileSync(grabbingJeromeTransfersFile, JSON.stringify(Array.isArray(items)? items: [], null, 2), 'utf8'); } catch {}
}

app.get('/api/presta/transfers', async (_req, res) => {
  try {
    const pool = await getPg();
    if (pool) {
      if (JEROME_STORAGE_DISABLED) return res.json({ ok:true, items: [] });
      const { rows } = await pool.query('select when_at as "when", id_product, product_url, image, price, currency, declinaison, file, name from grabbing_jerome_transfers order by when_at desc limit 100');
      return res.json({ ok:true, items: rows });
    }
    const items = loadPrestaTransfers().map(x => ({
      when: x.when || x.added_at,
      id_product: x.id_product,
      product_url: x.product_url,
      image: x.image,
      price: x.price,
      currency: x.currency,
      declinaison: x.declinaison,
      file: x.file,
      name: x.name,
    })).sort((a,b)=> new Date(b.when||0) - new Date(a.when||0)).slice(0,100);
    return res.json({ ok:true, items });
  } catch (e) { return res.status(500).json({ ok:false, error:'transfers_list_failed', message: e?.message || String(e) }); }
});

// Presta product import: creates a minimal product in the configured Presta DB and logs transfer
app.post('/api/presta/products/import', async (req, res) => {
  let conn = null;
  try {
    const body = req.body || {};
    const data = body.data || {};
    const source_file = String(body.source_file||'');
    const wantDebug = true; // always-on debug log
    const debugLog = { tables: [], data: {}, queries: [] };
    // Normalize incoming money-like numbers (cents -> euros)
    const normalizeMoney = (n) => {
      const x = Number(n);
      if (!Number.isFinite(x)) return 0;
      // Treat integer values >= 100 (or any very large values) as cents
      if ((Number.isInteger(x) && x >= 100) || x >= 1000) return Math.round((x / 100) * 100) / 100;
      return x;
    };
    const toAbsUrl = (u) => {
      try {
        const s = String(u||'').trim();
        if (!s) return '';
        if (/^https?:\/\//i.test(s)) return s;
        const base = publicBaseFromReq(req) || '';
        if (base) return new URL(s, base).toString();
        return s;
      } catch { return String(u||''); }
    };

    // Resolve Presta DB config (active profile first, then base config)
    let cfg = null;
    try {
      const active = await getSetting('PRESTA_DB_ACTIVE');
      if (active) {
        const profilesRaw = await getSetting('PRESTA_DB_PROFILES');
        const profiles = profilesRaw ? JSON.parse(profilesRaw) : [];
        const prof = Array.isArray(profiles) ? profiles.find(x => x && x.name === active) : null;
        if (prof) cfg = { ...prof };
      }
    } catch {}
    if (!cfg) {
      try { const raw = await getSetting('PRESTA_DB_JSON'); cfg = raw ? JSON.parse(raw) : null; } catch {}
    }
    if (!cfg || !cfg.host || !cfg.user || !cfg.database) {
      // No DB configured: fallback to logging-only with deterministic id
      const id_product = Math.abs([...String(data?.product?.sku||data?.meta?.title||Date.now())].reduce((a,c)=>((a<<5)-a+c.charCodeAt(0))|0,0)) || Math.floor(100000+Math.random()*900000);
      const rec = {
        when: new Date().toISOString(),
        id_product,
        product_url: String(data?.page?.url || data?.meta?.url || ''),
        image: (Array.isArray(data?.product?.images) && data.product.images.length ? data.product.images[0] : (data?.meta?.image || '')),
        price: normalizeMoney(data?.product?.price || 0) || '',
        currency: String(data?.product?.currency || ''),
        declinaison: (data?.product?.sku ? `SKU: ${data.product.sku}` : '-'),
        file: source_file || '',
        name: String(data?.product?.name || data?.meta?.title || ''),
      };
      try { if (!JEROME_STORAGE_DISABLED) { const pool = await getPg(); if (pool) await pool.query('insert into grabbing_jerome_transfers(when_at,id_product,product_url,image,price,currency,declinaison,file,name) values($1,$2,$3,$4,$5,$6,$7,$8,$9)', [new Date(rec.when), rec.id_product, rec.product_url, rec.image, rec.price||null, rec.currency||null, rec.declinaison||null, rec.file||'', rec.name||'']); } } catch {}
      const items = loadPrestaTransfers(); items.unshift(rec); savePrestaTransfers(items);
      return res.json({ ok:true, id_product, transfer: rec, note:'no_presta_db_configured' });
    }

    const mysql2 = await import('mysql2/promise');
    conn = await mysql2.createConnection({ host: cfg.host, port: Number(cfg.port||3306), user: cfg.user, password: cfg.password, database: cfg.database, multipleStatements: true });
    // Always capture executed SQL (once) and record per-query status
    try {
      if (conn && typeof conn.execute === 'function' && !conn.__dbgWrap) {
        const orig = conn.execute.bind(conn);
        conn.__dbgWrap = true;
        conn.execute = async (sql, params=[]) => {
          const entry = { sql: String(sql||''), params: Array.isArray(params)? params: [] };
          try { (debugLog.queries||(debugLog.queries=[])).push(entry); } catch {}
          try { const r = await orig(sql, params); try { entry.ok = true; } catch {} return r; }
          catch (e) {
            try { (debugLog.error||(debugLog.error=[])).push(e?.message||String(e)); entry.err = e?.message||String(e); } catch {}
            throw e;
          }
        };
      }
    } catch {}
    const pfx = String(cfg.table_prefix||'ps_');
    // Preflight: ensure AUTO_INCREMENT on critical tables; if missing, fall back to manual ID allocation
    let noAIProduct = false, noAIImage = false, noAIProdAttr = false;
    try {
      const required = [
        { table: 'product', id: 'id_product', key: 'product' },
        { table: 'image', id: 'id_image', key: 'image' },
        { table: 'product_attribute', id: 'id_product_attribute', key: 'product_attribute' },
      ];
      const missing = [];
      for (const t of required) {
        try {
          const [rows] = await conn.execute(
            `SELECT EXTRA FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = DATABASE() AND TABLE_NAME = ? AND COLUMN_NAME = ? LIMIT 1`,
            [`${pfx}${t.table}`.replace(/`/g,''), t.id]
          );
          const row = (Array.isArray(rows) && rows.length) ? rows[0] : null;
          const extra = row && (row.EXTRA || row.Extra || row.extra || '');
          const ai = typeof extra === 'string' && /auto_increment/i.test(extra);
          if (!ai) missing.push({ table: `${pfx}${t.table}`, column: t.id, extra: String(extra||'') });
        } catch (e) {
          missing.push({ table: `${pfx}${t.table}`, column: t.id, error: e?.message || String(e) });
        }
      }
      if (missing.length) {
        try { debugLog.data = { ...(debugLog.data||{}), schema_missing_ai: missing }; } catch {}
        noAIProduct   = missing.some(m => /`?product`?$/i.test(String(m.table||'')));
        noAIImage     = missing.some(m => /`?image`?$/i.test(String(m.table||'')));
        noAIProdAttr  = missing.some(m => /product_attribute/i.test(String(m.table||'')));
      }
    } catch {}
    // Normalize shop list: accept array or comma-separated string
    let idShops = [];
    if (Array.isArray(cfg.default_shop_ids)) idShops = cfg.default_shop_ids.map(n=>Number(n)).filter(n=>!isNaN(n)&&n>0);
    else idShops = String(cfg.default_shop_ids||'1').split(',').map(s=>Number(s.trim())).filter(n=>!isNaN(n)&&n>0);
    if (!idShops.length) idShops = [1];
    const idShopDefault = idShops[0];
    const idLang = Number(cfg.default_lang_id||1) || 1;
    const taxGroupId = Number(cfg.default_tax_rules_group_id||0) || 0;
    const activeFlag = (cfg.default_active ? 1 : 0);
    const visibility = String(cfg.default_visibility||'both');

    const name = String(data?.product?.name || data?.meta?.title || 'Imported Product').slice(0,255);
    const description = String(data?.product?.description || '');
    const reference = String(data?.product?.sku || '').slice(0,64);
    const price = normalizeMoney(data?.product?.price || 0);
    const idCategory = Number(cfg.default_category_id||2) || 2;
    // Manufacturer/Supplier resolve
    let idManufacturer = Number(cfg.default_manufacturer_id||0)||0;
    let idSupplier = Number(cfg.default_supplier_id||0)||0;
    const manufacturerName = String(data?.product?.manufacturer || data?.product?.brand || '').trim();
    const supplierName = String(data?.product?.supplier || '').trim();

    await conn.beginTransaction();
    // Create manufacturer if needed
    try {
      if (!idManufacturer && manufacturerName) {
        const [mr] = await conn.execute(`SELECT id_manufacturer FROM \`${pfx}manufacturer\` WHERE name=? LIMIT 1`, [manufacturerName]);
        if (Array.isArray(mr) && mr.length) idManufacturer = mr[0].id_manufacturer; else {
          const [insM] = await conn.execute(`INSERT INTO \`${pfx}manufacturer\` (name, active, date_add, date_upd) VALUES (?,1,NOW(),NOW())`, [manufacturerName]);
          idManufacturer = insM.insertId;
          for (const s of idShops) { try { await conn.execute(`INSERT INTO \`${pfx}manufacturer_shop\` (id_manufacturer,id_shop) VALUES (?,?)`, [idManufacturer, s]); } catch {} }
        }
      }
    } catch {}
    // Create supplier if needed
    try {
      if (!idSupplier && supplierName) {
        const [sr] = await conn.execute(`SELECT id_supplier FROM \`${pfx}supplier\` WHERE name=? LIMIT 1`, [supplierName]);
        if (Array.isArray(sr) && sr.length) idSupplier = sr[0].id_supplier; else {
          const [insS] = await conn.execute(`INSERT INTO \`${pfx}supplier\` (name, active, date_add, date_upd) VALUES (?,1,NOW(),NOW())`, [supplierName]);
          idSupplier = insS.insertId;
          for (const s of idShops) { try { await conn.execute(`INSERT INTO \`${pfx}supplier_shop\` (id_supplier,id_shop) VALUES (?,?)`, [idSupplier, s]); } catch {} }
        }
      }
    } catch {}
    let idProduct = 0;
    if (noAIProduct) {
      // Manual ID allocation without LOCK TABLES (retry on duplicate)
      const tryInsert = async (id) => {
        return await conn.execute(`INSERT INTO \`${pfx}product\` (id_product,id_manufacturer,id_supplier,id_category_default,id_shop_default,reference,price,id_tax_rules_group,active,date_add,date_upd,isbn,upc,ean13,mpn) VALUES (?,?,?,?,?,?,?,?,?,NOW(),NOW(),?,?,?,?)`, [id, idManufacturer||0, idSupplier||0, idCategory, idShopDefault, reference, price, taxGroupId, activeFlag, '', '', '', '']);
      };
      let next = 1;
      try { const [r] = await conn.execute(`SELECT IFNULL(MAX(id_product),0)+1 AS next FROM \`${pfx}product\``); next = Number((Array.isArray(r)&&r[0]?.next)||1)||1; } catch {}
      for (let i=0;i<5;i++) {
        try { const [ins] = await tryInsert(next); idProduct = ins.insertId || next; break; }
        catch (e) { const code = e && (e.code || e.errno); if (String(code)==='ER_DUP_ENTRY' || Number(code)===1062) { next++; continue; } throw e; }
      }
      if (!idProduct) { const [ins] = await tryInsert(next); idProduct = ins.insertId || next; }
    } else {
      const [insProd] = await conn.execute(`INSERT INTO \`${pfx}product\` (id_manufacturer,id_supplier,id_category_default,id_shop_default,reference,price,id_tax_rules_group,active,date_add,date_upd,isbn,upc,ean13,mpn) VALUES (?,?,?,?,?,?,?,?,NOW(),NOW(),?,?,?,?)`, [idManufacturer||0, idSupplier||0, idCategory, idShopDefault, reference, price, taxGroupId, activeFlag, '', '', '', '']);
      idProduct = insProd.insertId;
    }

    // product_shop for each configured shop
    for (const s of idShops) {
      await conn.execute(`INSERT INTO \`${pfx}product_shop\` (id_product,id_shop,id_category_default,price,active,visibility,id_tax_rules_group,date_upd,date_add) VALUES (?,?,?,?,?,?,?,NOW(),NOW())`, [idProduct, s, idCategory, price, activeFlag, visibility, taxGroupId]);
    }
    // Guard: if for any reason no product_shop rows were created, fall back to all active shops
    try {
      const [chkPs] = await conn.execute(`SELECT COUNT(*) AS c FROM \`${pfx}product_shop\` WHERE id_product=?`, [idProduct]);
      const countPs = Array.isArray(chkPs) && chkPs.length ? Number(chkPs[0].c||0) : 0;
      if (!countPs) {
        const [activeShops] = await conn.execute(`SELECT id_shop FROM \`${pfx}shop\` WHERE active=1`);
        const fallbacks = (Array.isArray(activeShops)? activeShops: []).map(r=>Number(r.id_shop||0)).filter(n=>n>0);
        for (const s of fallbacks) {
          await conn.execute(`INSERT INTO \`${pfx}product_shop\` (id_product,id_shop,id_category_default,price,active,visibility,id_tax_rules_group,date_upd,date_add) VALUES (?,?,?,?,?,?,?,NOW(),NOW())`, [idProduct, s, idCategory, price, activeFlag, visibility, taxGroupId]);
        }
      }
    } catch {}
    // Update manufacturer/supplier on product (safe guard)
    try { await conn.execute(`UPDATE \`${pfx}product\` SET id_manufacturer=?, id_supplier=? WHERE id_product=?`, [idManufacturer||0, idSupplier||0, idProduct]); } catch {}

    // Check if product_lang has id_shop
    let hasIdShop = false;
    try { const [cols] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}product_lang\``); hasIdShop = Array.isArray(cols) && cols.some(c => (c.Field||c.COLUMN_NAME) === 'id_shop'); } catch {}
    if (hasIdShop) {
      for (const s of idShops) {
        await conn.execute(`INSERT INTO \`${pfx}product_lang\` (id_product,id_shop,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?,?)`, [idProduct, s, idLang, name, description, '', name.toLowerCase().replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'').slice(0,128)||'imported-product']);
        // Update meta fields if present
        try { await conn.execute(`UPDATE \`${pfx}product_lang\` SET meta_title=?, meta_description=? WHERE id_product=? AND id_shop=? AND id_lang=?`, [name.slice(0,128), (data?.meta?.description||'').slice(0,512), idProduct, s, idLang]); } catch {}
      }
    } else {
      await conn.execute(`INSERT INTO \`${pfx}product_lang\` (id_product,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?)`, [idProduct, idLang, name, description, '', name.toLowerCase().replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'').slice(0,128)||'imported-product']);
      try { await conn.execute(`UPDATE \`${pfx}product_lang\` SET meta_title=?, meta_description=? WHERE id_product=? AND id_lang=?`, [name.slice(0,128), (data?.meta?.description||'').slice(0,512), idProduct, idLang]); } catch {}
    }
    // Ensure product_lang rows exist for all active languages across selected shops (schema-aware)
    try {
      let hasMetaTitle = false, hasMetaDescription = false;
      try {
        const [cols2] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}product_lang\``);
        if (Array.isArray(cols2)) {
          hasMetaTitle = cols2.some(c => (c.Field||c.COLUMN_NAME) === 'meta_title');
          hasMetaDescription = cols2.some(c => (c.Field||c.COLUMN_NAME) === 'meta_description');
        }
      } catch {}
      const [langs] = await conn.execute(`SELECT id_lang FROM \`${pfx}lang\` WHERE active=1`);
      const linkRewrite = name.toLowerCase().replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'').slice(0,128) || 'imported-product';
      const metaTitle = name.slice(0,128);
      const metaDesc = String(data?.meta?.description||'').slice(0,512);
      for (const row of (langs||[])) {
        const lid = Number(row.id_lang);
        if (!lid) continue;
        if (hasIdShop) {
          for (const s of idShops) {
            const [exists] = await conn.execute(`SELECT 1 FROM \`${pfx}product_lang\` WHERE id_product=? AND id_lang=? AND id_shop=? LIMIT 1`, [idProduct, lid, s]);
            if (!exists || !exists.length) {
              if (hasMetaTitle || hasMetaDescription) {
                // Insert with meta columns when present
                const cols = ['id_product','id_shop','id_lang','name','description','description_short','link_rewrite'];
                const vals = [idProduct, s, lid, name, description, '', linkRewrite];
                if (hasMetaTitle) { cols.push('meta_title'); vals.push(metaTitle); }
                if (hasMetaDescription) { cols.push('meta_description'); vals.push(metaDesc); }
                const ph = cols.map(()=> '?').join(',');
                await conn.execute(`INSERT INTO \`${pfx}product_lang\` (${cols.join(',')}) VALUES (${ph})`, vals);
              } else {
                await conn.execute(`INSERT INTO \`${pfx}product_lang\` (id_product,id_shop,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?,?)`, [idProduct, s, lid, name, description, '', linkRewrite]);
              }
            }
          }
        } else {
          const [exists] = await conn.execute(`SELECT 1 FROM \`${pfx}product_lang\` WHERE id_product=? AND id_lang=? LIMIT 1`, [idProduct, lid]);
          if (!exists || !exists.length) {
            if (hasMetaTitle || hasMetaDescription) {
              const cols = ['id_product','id_lang','name','description','description_short','link_rewrite'];
              const vals = [idProduct, lid, name, description, '', linkRewrite];
              if (hasMetaTitle) { cols.push('meta_title'); vals.push(metaTitle); }
              if (hasMetaDescription) { cols.push('meta_description'); vals.push(metaDesc); }
              const ph = cols.map(()=> '?').join(',');
              await conn.execute(`INSERT INTO \`${pfx}product_lang\` (${cols.join(',')}) VALUES (${ph})`, vals);
            } else {
              await conn.execute(`INSERT INTO \`${pfx}product_lang\` (id_product,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?)`, [idProduct, lid, name, description, '', linkRewrite]);
            }
          }
        }
      }
    } catch {}
    // Optional: download and register product images if PRESTA_ROOT is set
    let createdImages = [];
    try {
      const root = String(process.env.PRESTA_ROOT || '').trim();
      const imgs = Array.isArray(data?.product?.images) ? data.product.images : [];
      if (root && imgs && imgs.length) {
        const http = await import('http');
        const https = await import('https');
        const makePath = (id) => {
          const parts = String(id).split('');
          const dir = path.join(root, 'img', 'p', ...parts);
          const file = path.join(dir, `${id}.jpg`);
          return { dir, file };
        };
        const copyToFile = async (src, dest) => {
          return await new Promise((resolve) => {
            try {
              const done = () => resolve();
              const write = () => {
                try {
                  const ws = fs.createWriteStream(dest);
                  ws.on('finish', done);
                  ws.on('error', done);
                  return ws;
                } catch { return null; }
              };
              const maxRedirects = 5;
              const s = String(src||'');
              if (/^https?:\/\//i.test(s)) {
                const doGet = (u, n) => {
                  try {
                    const h = String(u).startsWith('https') ? https : http;
                    const req2 = h.get(u, { headers: { 'User-Agent': 'Mozilla/5.0 (compatible; Livechat/1.0)' } }, (resp) => {
                      const sc = Number(resp.statusCode||0);
                      if (sc >= 300 && sc < 400 && resp.headers && resp.headers.location && n < maxRedirects) {
                        try { resp.resume(); } catch {}
                        let nextUrl = '';
                        try { nextUrl = new URL(resp.headers.location, u).toString(); } catch { nextUrl = resp.headers.location; }
                        return doGet(nextUrl, n+1);
                      }
                      if (sc >= 400) { try { resp.resume(); } catch {} return done(); }
                      const ws = write(); if (!ws) { try { resp.resume(); } catch {} return done(); }
                      resp.pipe(ws);
                    });
                    req2.on('error', done);
                    req2.setTimeout(20000, () => { try { req2.destroy(); } catch {} done(); });
                  } catch { done(); }
                };
                doGet(s, 0);
              } else {
                try {
                  if (!s || !fs.existsSync(s)) return done();
                  const rs = fs.createReadStream(s);
                  rs.on('error', done);
                  rs.on('open', () => { const ws = write(); if (!ws) return done(); rs.pipe(ws); });
                } catch { done(); }
              }
            } catch { resolve(); }
          });
        };
        // Normalize sources (absolute URLs or existing local files)
        // Include variant images too
        const vimgs = (Array.isArray(data?.product?.variants) ? data.product.variants : []).map(v=> (v && (v.image||'')) || '').filter(Boolean);
        const merged = Array.from(new Set([...(imgs||[]), ...vimgs]));
        const sources = merged.map(v => {
          try {
            const s = toAbsUrl(typeof v === 'string' ? v : (v && (v.download_url||v.url||v.href)) || '');
            if (s && /^https?:\/\//i.test(s)) return s;
            if (s && fs.existsSync(s)) return s;
            return '';
          } catch { return ''; }
        }).filter(Boolean).slice(0, 10);
        let pos = 0;
        // Fetch active languages for image legends
        let activeLangIdsImg = [idLang];
        try { const [lng] = await conn.execute(`SELECT id_lang FROM \`${pfx}lang\` WHERE active=1`); if (Array.isArray(lng) && lng.length) activeLangIdsImg = lng.map(r=>Number(r.id_lang||0)).filter(n=>n>0); } catch {}
        const legendDefault = String(name || '').trim();
        for (const src of sources) {
          pos++;
          const cover = pos === 1 ? 1 : null;
          let idImage = 0;
          if (noAIImage) {
            const tryInsertImg = async (id) => {
              return await conn.execute(`INSERT INTO \`${pfx}image\` (id_image,id_product, position, cover) VALUES (?,?,?,?)`, [id, idProduct, pos, cover]);
            };
            let nextImg = 1;
            try { const [r] = await conn.execute(`SELECT IFNULL(MAX(id_image),0)+1 AS next FROM \`${pfx}image\``); nextImg = Number((Array.isArray(r)&&r[0]?.next)||1)||1; } catch {}
            for (let i=0;i<5;i++) {
              try { const [insI] = await tryInsertImg(nextImg); idImage = insI.insertId || nextImg; break; }
              catch (e) { const code = e && (e.code || e.errno); if (String(code)==='ER_DUP_ENTRY' || Number(code)===1062) { nextImg++; continue; } throw e; }
            }
            if (!idImage) { const [insI] = await tryInsertImg(nextImg); idImage = insI.insertId || nextImg; }
          } else {
            const [insI] = await conn.execute(`INSERT INTO \`${pfx}image\` (id_product, position, cover) VALUES (?,?,?)`, [idProduct, pos, cover]);
            idImage = insI.insertId;
          }
          for (const s of idShops) {
            await conn.execute(`INSERT INTO \`${pfx}image_shop\` (id_product,id_image,id_shop,cover) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE cover=VALUES(cover)`, [idProduct, idImage, s, cover ? 1 : null]);
          }
          try {
            for (const lid of activeLangIdsImg) { await conn.execute(`INSERT INTO \`${pfx}image_lang\` (id_image,id_lang,legend) VALUES (?,?,?) ON DUPLICATE KEY UPDATE legend=VALUES(legend)`, [idImage, lid, legendDefault]); }
          } catch {}
          const { dir, file } = makePath(idImage);
          try { fs.mkdirSync(dir, { recursive: true }); } catch {}
          // Set directory permissions/owner when available
          try { fs.chmodSync(dir, 0o775); fs.chownSync(dir, 33, 33); } catch {}
          await copyToFile(src, file);
          // Set file permissions/owner when available
          try { fs.chmodSync(file, 0o775); fs.chownSync(file, 33, 33); } catch {}
          // Generate Presta thumbnails (jpg/webp) using active image types
          try {
            // Local helpers mirroring re-send implementation
            const parseThumbFormats = () => {
              try {
                const envVal = String(process.env.PRESTA_THUMB_FORMATS || 'jpg,webp');
                const list = envVal.split(',').map(s=>String(s||'').trim().toLowerCase()).filter(Boolean);
                const set = new Set(list);
                if (set.has('jpeg')) { set.delete('jpeg'); set.add('jpg'); }
                return Array.from(set.size ? set : new Set(['jpg','webp']));
              } catch { return ['jpg','webp']; }
            };
            const generateThumbs = async (srcPath, outDir, idImg) => {
              try {
                let sharpMod = null;
                try { const m = await import('sharp'); sharpMod = m?.default || m; } catch {}
                if (!sharpMod) return;
                const fmts = parseThumbFormats();
                const wantJpg = fmts.includes('jpg');
                const wantWebp = fmts.includes('webp');
                const [types] = await conn.execute(`SELECT name,width,height FROM \`${pfx}image_type\` WHERE products=1 ORDER BY name`);
                const tasks = [];
                for (const t of (Array.isArray(types)? types: [])) {
                  const w = Number(t.width||0), h = Number(t.height||0);
                  if (wantJpg) {
                    const out = path.join(outDir, `${idImg}-${t.name}.jpg`);
                    try {
                      tasks.push(
                        sharpMod(srcPath)
                          .resize(w, h, { fit:'contain', position:'centre', background:{ r:255, g:255, b:255, alpha:1 } })
                          .flatten({ background: '#ffffff' })
                          .jpeg({ quality:85, mozjpeg:true })
                          .toFile(out)
                          .catch(()=>{})
                      );
                    } catch {}
                  }
                  if (wantWebp) {
                    const out = path.join(outDir, `${idImg}-${t.name}.webp`);
                    try {
                      tasks.push(
                        sharpMod(srcPath)
                          .resize(w, h, { fit:'contain', position:'centre', background:{ r:255, g:255, b:255, alpha:1 } })
                          .flatten({ background: '#ffffff' })
                          .webp({ quality:80 })
                          .toFile(out)
                          .catch(()=>{})
                      );
                    } catch {}
                  }
                }
                await Promise.all(tasks);
              } catch {}
            };
            await generateThumbs(file, dir, idImage);
          } catch {}
          try { createdImages.push({ src: String(src), id_image: idImage, position: pos, cover }); } catch {}
        }
      }
    } catch (e) {
      try { logToFile(`[presta] image_import_warn ${e?.message||e}`); } catch {}
      try {
        if (debugLog && debugLog.data) {
          if (!Array.isArray(debugLog.data.warnings)) debugLog.data.warnings = [];
          debugLog.data.warnings.push(`image_import_warn: ${String(e?.message||e)}`);
        }
      } catch {}
    }
    // stock + category
    for (const s of idShops) {
      await conn.execute(`INSERT INTO \`${pfx}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, 0, s, 0]);
    }
    await conn.execute(`INSERT INTO \`${pfx}category_product\` (id_category,id_product,position) VALUES (?,?,0)`, [idCategory, idProduct]);

    // Optional: features and tags ingestion
    try {
      // Features: data.product.features -> [{ name, value }]
      const feats = Array.isArray(data?.product?.features) ? data.product.features : [];
      for (const f of feats) {
        try {
          const fname = String(f?.name||'').trim();
          const fval = String(f?.value||'').trim();
          if (!fname || !fval) continue;
          // Ensure feature
          let idFeature = 0;
          const [fr] = await conn.execute(`SELECT fl.id_feature FROM \`${pfx}feature_lang\` fl WHERE fl.name=? AND fl.id_lang=? LIMIT 1`, [fname, idLang]);
          if (Array.isArray(fr) && fr.length) idFeature = fr[0].id_feature; else {
            const [insF] = await conn.execute(`INSERT INTO \`${pfx}feature\` (position) VALUES (0)`);
            idFeature = insF.insertId;
            await conn.execute(`INSERT INTO \`${pfx}feature_lang\` (id_feature,id_lang,name) VALUES (?,?,?)`, [idFeature, idLang, fname]);
          }
          // Ensure feature value
          let idFeatureValue = 0;
          const [fvr] = await conn.execute(`SELECT fvl.id_feature_value FROM \`${pfx}feature_value_lang\` fvl JOIN \`${pfx}feature_value\` fv ON fv.id_feature_value=fvl.id_feature_value WHERE fvl.value=? AND fvl.id_lang=? AND fv.id_feature=? LIMIT 1`, [fval, idLang, idFeature]);
          if (Array.isArray(fvr) && fvr.length) idFeatureValue = fvr[0].id_feature_value; else {
            const [insFV] = await conn.execute(`INSERT INTO \`${pfx}feature_value\` (id_feature,custom) VALUES (?,0)`, [idFeature]);
            idFeatureValue = insFV.insertId;
            await conn.execute(`INSERT INTO \`${pfx}feature_value_lang\` (id_feature_value,id_lang,value) VALUES (?,?,?)`, [idFeatureValue, idLang, fval]);
          }
          // Link product to feature value
          try {
            await conn.execute(`INSERT INTO \`${pfx}feature_product\` (id_feature,id_product,id_feature_value) VALUES (?,?,?) ON DUPLICATE KEY UPDATE id_feature_value=VALUES(id_feature_value)`, [idFeature, idProduct, idFeatureValue]);
          } catch {}
        } catch {}
      }
      // Tags: data.product.tags -> [string]
      const tags = Array.isArray(data?.product?.tags) ? data.product.tags : [];
      for (const t of tags) {
        try {
          const nameTag = String(t||'').trim(); if (!nameTag) continue;
          let idTag = 0;
          const [tr] = await conn.execute(`SELECT id_tag FROM \`${pfx}tag\` WHERE name=? AND id_lang=? LIMIT 1`, [nameTag, idLang]);
          if (Array.isArray(tr) && tr.length) idTag = tr[0].id_tag; else {
            const [insT] = await conn.execute(`INSERT INTO \`${pfx}tag\` (id_lang,name) VALUES (?,?)`, [idLang, nameTag]);
            idTag = insT.insertId;
          }
          await conn.execute(`INSERT IGNORE INTO \`${pfx}product_tag\` (id_product,id_tag) VALUES (?,?)`, [idProduct, idTag]);
        } catch {}
      }
    } catch (e) {
      try { logToFile(`[presta] features_tags_warn ${e?.message||e}`); } catch {}
      try {
        if (debugLog && debugLog.data) {
          if (!Array.isArray(debugLog.data.warnings)) debugLog.data.warnings = [];
          debugLog.data.warnings.push(`features_tags_warn: ${String(e?.message||e)}`);
        }
      } catch {}
    }

    // Variants/combinations creation (mirrors re-send logic, simplified create-only)
    try {
      let variants = Array.isArray(data?.product?.variants) ? data.product.variants : [];
      if (!variants.length) {
        try {
          const urlHint = String(data?.page?.url || data?.meta?.url || '').trim();
          if (urlHint) {
            const pool = await getPg();
            if (pool) {
              let domain = '';
              try { const u = new URL(urlHint); domain = (u.hostname||'').toLowerCase().replace(/^www\./,''); } catch {}
              if (domain) {
                const q = await pool.query(
                  `select page_type, mapped, meta, product_raw
                     from public.grabbing_jerome_domains_url_ready_transfert
                    where domain=$1 and lower(trim(both from url))=lower(trim(both from $2))
                    limit 1`,
                  [domain, urlHint]
                );
                if (q.rows && q.rows.length) {
                  const row = q.rows[0] || {};
                  let mapped = row.mapped || null;
                  const meta2 = row.meta || {};
                  const product2 = row.product_raw || {};
                  const t = String(row.page_type||'product').toLowerCase();
                  if (!mapped) {
                    let cfgTransfert = null;
                    try {
                      const rCfg = await pool.query('select config_transfert from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
                      const all = rCfg.rows?.[0]?.config_transfert || {};
                      if (all && typeof all === 'object') cfgTransfert = all[t] || all['product'] || null;
                    } catch {}
                    mapped = applyTransferConfig(mapProductForPresta(meta2, product2), meta2, product2, cfgTransfert || {});
                  }
                  if (mapped && Array.isArray(mapped.variants)) {
                    // Merge attributes from raw variants when missing
                    try {
                      const rv = Array.isArray(product2?.variants) ? product2.variants : [];
                      if (rv.length) {
                        const byKey = (v) => { const id=(v&&v.id!=null)?String(v.id):''; const sku=(v&&v.sku)?String(v.sku):''; return `${id}#${sku}`; };
                        const rawMap = new Map(rv.map(x=>[byKey(x), x]));
                        variants = mapped.variants.map(x=>{ const k=byKey(x); const src=rawMap.get(k); if (src && !x.attributes && src.attributes) return { ...x, attributes: src.attributes }; return x; });
                      } else { variants = mapped.variants; }
                    } catch { variants = mapped.variants; }
                  }
                }
              }
            }
          }
        } catch {}
      }
        if (variants.length) {
        // Fetch active languages so we insert group/value translations for all languages
        let activeLangIds = [idLang];
        try {
          const [langs] = await conn.execute(`SELECT id_lang FROM \`${pfx}lang\` WHERE active = 1`);
          const ids = Array.isArray(langs) ? langs.map(r => Number(r.id_lang||0)).filter(n=>n>0) : [];
          if (ids.length) activeLangIds = ids;
        } catch {}
        // Default combination is the first variant
        const defaultIndex = 0;
        // Ensure attribute group 'Variant'
        let idAttrGroup = 0;
        const [ag] = await conn.execute(`SELECT ag.id_attribute_group FROM \`${pfx}attribute_group_lang\` ag WHERE ag.name=? AND ag.id_lang=? LIMIT 1`, ['Variant', idLang]);
        if (Array.isArray(ag) && ag.length) idAttrGroup = ag[0].id_attribute_group; else {
          const [insG] = await conn.execute(`INSERT INTO \`${pfx}attribute_group\` (is_color_group, group_type, position) VALUES (0,'select',0)`);
          idAttrGroup = insG.insertId;
          for (const lid of activeLangIds) {
            try {
              await conn.execute(`INSERT INTO \`${pfx}attribute_group_lang\` (id_attribute_group,id_lang,name,public_name) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name), public_name=VALUES(public_name)`, [idAttrGroup, lid, 'Variant', 'Variant']);
            } catch {}
          }
          for (const s of idShops) { await conn.execute(`INSERT INTO \`${pfx}attribute_group_shop\` (id_attribute_group,id_shop) VALUES (?,?)`, [idAttrGroup, s]); }
        }
        // Finalize default combination flags and cache_default_attribute to ensure BO linkage
        try {
          // If no default_on=1 exists, promote the first combination as default
          const [hasDef] = await conn.execute(`SELECT id_product_attribute FROM \`${pfx}product_attribute\` WHERE id_product=? AND default_on=1 LIMIT 1`, [idProduct]);
          let defId = Array.isArray(hasDef) && hasDef.length ? Number(hasDef[0].id_product_attribute||0) : 0;
          if (!defId) {
            const [first] = await conn.execute(`SELECT id_product_attribute FROM \`${pfx}product_attribute\` WHERE id_product=? ORDER BY id_product_attribute ASC LIMIT 1`, [idProduct]);
            defId = Array.isArray(first) && first.length ? Number(first[0].id_product_attribute||0) : 0;
            if (defId) {
              try { await conn.execute(`UPDATE \`${pfx}product_attribute\` SET default_on=1 WHERE id_product_attribute=?`, [defId]); } catch {}
            }
          }
          if (defId) {
            try { await conn.execute(`UPDATE \`${pfx}product\` SET cache_default_attribute=? WHERE id_product=?`, [defId, idProduct]); } catch {}
            // Apply cache_default_attribute to ALL product_shop rows for this product
            try { await conn.execute(`UPDATE \`${pfx}product_shop\` SET cache_default_attribute=? WHERE id_product=?`, [defId, idProduct]); } catch {}
            // Ensure exactly one default_on per shop: clear then set for the chosen combination across all shops
            try { await conn.execute(`UPDATE \`${pfx}product_attribute_shop\` SET default_on=NULL WHERE id_product=?`, [idProduct]); } catch {}
            try { await conn.execute(`UPDATE \`${pfx}product_attribute_shop\` SET default_on=1 WHERE id_product=? AND id_product_attribute=?`, [idProduct, defId]); } catch {}
          }
        } catch {}
        // Shop groups for stock_available
        const shopGroups = new Map();
        try {
          if (idShops.length) {
            const placeholders = idShops.map(()=>'?').join(',');
            const [sgRows] = await conn.execute(`SELECT id_shop, id_shop_group FROM \`${pfx}shop\` WHERE id_shop IN (${placeholders})`, idShops);
            for (const r of (sgRows||[])) shopGroups.set(Number(r.id_shop), Number(r.id_shop_group||0));
          }
        } catch {}
        // Update product_type when column exists (older schemas may not have it)
        let hasProdType = false, hasProdShopType = false;
        try { const [colsPT] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}product\``); hasProdType = Array.isArray(colsPT) && colsPT.some(c => (c.Field||c.COLUMN_NAME) === 'product_type'); } catch {}
        try { const [colsPST] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}product_shop\``); hasProdShopType = Array.isArray(colsPST) && colsPST.some(c => (c.Field||c.COLUMN_NAME) === 'product_type'); } catch {}
        try { if (hasProdType) await conn.execute(`UPDATE \`${pfx}product\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
        try { if (hasProdShopType) await conn.execute(`UPDATE \`${pfx}product_shop\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
        // Helper to match image url to created id_image
        const norm = (u='') => { try { const x=new URL(String(u)); return x.origin + x.pathname; } catch { return String(u).replace(/\?.*$/, ''); } };
        let isFirst = true;
        let defaultPA = 0;
        for (let i = 0; i < variants.length; i++) {
          const v = variants[i];
          const title = String(v?.title || v?.sku || '').trim() || 'Default';
          const vSku = String(v?.sku || '').trim();
          let vPrice = 0; try { vPrice = (typeof v?.price === 'object' && v?.price && ('value' in v.price)) ? Number(v.price.value||0)||0 : Number(v?.price||0)||0; vPrice = normalizeMoney(vPrice); } catch {}
        // Build attributes list: prefer explicit v.attributes map (multi-attr), else single "Variant" attribute using title
        const attrPairs = [];
        if (v && typeof v.attributes === 'object' && v.attributes) {
          for (const k of Object.keys(v.attributes)) {
            const gName = String(k||'').trim();
            const val = String(v.attributes[k]||'').trim();
            if (gName && val) attrPairs.push({ group: gName, value: val });
          }
        }
        if (!attrPairs.length) attrPairs.push({ group: 'Variant', value: title });
        // Ensure all attribute groups/values and collect their ids
        const idAttrs = [];
        for (const pair of attrPairs) {
          // group
          let grpId = 0;
          const [gq] = await conn.execute(`SELECT ag.id_attribute_group FROM \`${pfx}attribute_group_lang\` ag WHERE ag.name=? AND ag.id_lang=? LIMIT 1`, [pair.group, idLang]);
          if (Array.isArray(gq) && gq.length) { grpId = gq[0].id_attribute_group; 
            // Ensure group translations exist for all languages
            for (const lid of activeLangIds) { try { await conn.execute(`INSERT INTO \`${pfx}attribute_group_lang\` (id_attribute_group,id_lang,name,public_name) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name), public_name=VALUES(public_name)`, [grpId, lid, pair.group, pair.group]); } catch {} }
          } else {
            const [ig] = await conn.execute(`INSERT INTO \`${pfx}attribute_group\` (is_color_group, group_type, position) VALUES (0,'select',0)`);
            grpId = ig.insertId;
            for (const lid of activeLangIds) { try { await conn.execute(`INSERT INTO \`${pfx}attribute_group_lang\` (id_attribute_group,id_lang,name,public_name) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name), public_name=VALUES(public_name)`, [grpId, lid, pair.group, pair.group]); } catch {} }
            for (const s of idShops) { await conn.execute(`INSERT INTO \`${pfx}attribute_group_shop\` (id_attribute_group,id_shop) VALUES (?,?)`, [grpId, s]); }
          }
          // value
          // Always create a new attribute value for this product's combination, and translate it for all languages
          let idAttr = 0;
          const [insA] = await conn.execute(`INSERT INTO \`${pfx}attribute\` (id_attribute_group, color, position) VALUES (?,?,0)`, [grpId, '']);
          idAttr = insA.insertId;
          for (const lid of activeLangIds) { try { await conn.execute(`INSERT INTO \`${pfx}attribute_lang\` (id_attribute,id_lang,name) VALUES (?,?,?)`, [idAttr, lid, pair.value]); } catch {} }
          for (const s of idShops) { await conn.execute(`INSERT IGNORE INTO \`${pfx}attribute_shop\` (id_attribute,id_shop) VALUES (?,?)`, [idAttr, s]); }
          idAttrs.push({ idAttr, grpId });
        }
        const delta = Math.max(0, (Number.isFinite(vPrice) ? vPrice : 0) - price);
        const defOn = (i === 0) ? 1 : null;
          let idPA = 0;
          if (noAIProdAttr) {
            const tryInsertPA = async (id) => {
              return await conn.execute(`INSERT INTO \`${pfx}product_attribute\` (id_product_attribute,id_product, reference, price, weight, default_on, ean13, upc, isbn) VALUES (?,?,?,?,?,?,?,?,?)`, [id, idProduct, vSku||'', delta, 0, defOn, '', '', '']);
            };
            let nextPA = 1;
            try { const [r] = await conn.execute(`SELECT IFNULL(MAX(id_product_attribute),0)+1 AS next FROM \`${pfx}product_attribute\``); nextPA = Number((Array.isArray(r)&&r[0]?.next)||1)||1; } catch {}
            for (let i=0;i<5;i++) {
              try { const [insPA] = await tryInsertPA(nextPA); idPA = insPA.insertId || nextPA; break; }
              catch (e) { const code = e && (e.code || e.errno); if (String(code)==='ER_DUP_ENTRY' || Number(code)===1062) { nextPA++; continue; } throw e; }
            }
            if (!idPA) { const [insPA] = await tryInsertPA(nextPA); idPA = insPA.insertId || nextPA; }
          } else {
            const [insPA] = await conn.execute(`INSERT INTO \`${pfx}product_attribute\` (id_product, reference, price, weight, default_on, ean13, upc, isbn) VALUES (?,?,?,?,?,?,?,?)`, [idProduct, vSku||'', delta, 0, defOn, '', '', '']);
            idPA = insPA.insertId;
          }
          if (i === 0 && !defaultPA) defaultPA = idPA;
        for (const s of idShops) {
          await conn.execute(`INSERT INTO \`${pfx}product_attribute_shop\` (id_product,id_product_attribute,id_shop,price,default_on) VALUES (?,?,?,?,?)`, [idProduct, idPA, s, delta, defOn]);
        }
        for (const { idAttr } of idAttrs) {
          await conn.execute(`INSERT INTO \`${pfx}product_attribute_combination\` (id_attribute,id_product_attribute) VALUES (?,?)`, [idAttr, idPA]);
          try { await conn.execute(`INSERT INTO \`${pfx}attribute_impact\` (id_product,id_attribute,weight,price) VALUES (?,?,0,?) ON DUPLICATE KEY UPDATE price=VALUES(price), weight=VALUES(weight)`, [idProduct, idAttr, delta]); } catch {}
        }
          // stock per combination
          await conn.execute(`INSERT INTO \`${pfx}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, idPA, 0, 0]);
          for (const s of idShops) { const sg = shopGroups.get(s) || 0; await conn.execute(`INSERT INTO \`${pfx}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, idPA, s, sg]); }
          try {
            for (const lid of (Array.isArray(activeLangIds)? activeLangIds : [idLang])) {
              try { await conn.execute(`INSERT IGNORE INTO \`${pfx}product_attribute_lang\` (id_product_attribute,id_lang,available_now,available_later) VALUES (?,?,NULL,NULL)`, [idPA, lid]); } catch {}
            }
          } catch {}
          // Variant image association (robust matching)
          try {
            const vimg = String(v?.image||'').trim();
            if (vimg && Array.isArray(createdImages) && createdImages.length) {
              const keyFrom = (u='') => {
                try {
                  const s = String(u).split('?')[0];
                  const base = s.split('/').pop() || '';
                  // Drop size suffixes like _467x700 or -467x700
                  const noSize = base.replace(/([_-])\d+x\d+(?=\.[A-Za-z0-9]+$)/, '');
                  // Remove extension
                  const stem = noSize.replace(/\.[A-Za-z0-9]+$/, '');
                  return stem.toLowerCase();
                } catch { return String(u||'').toLowerCase(); }
              };
              const vKey = keyFrom(vimg);
              let nid = 0;
              // 1) exact normalized URL
              nid = createdImages.find(ci => norm(ci.src) === norm(vimg))?.id_image || 0;
              // 2) basename key match (ignoring size and host)
              if (!nid) nid = createdImages.find(ci => keyFrom(ci.src) === vKey)?.id_image || 0;
              // 3) contains match as a last resort
              if (!nid) nid = createdImages.find(ci => keyFrom(ci.src).includes(vKey) || vKey.includes(keyFrom(ci.src)))?.id_image || 0;
              if (nid) {
                await conn.execute(`INSERT IGNORE INTO \`${pfx}product_attribute_image\` (id_product_attribute,id_image) VALUES (?,?)`, [idPA, nid]);
                try {
                  const legendVar = String(v?.title || v?.sku || name || '').slice(0,128);
                  // Legend for all active languages
                  let lids = [idLang];
                  try { const [lng] = await conn.execute(`SELECT id_lang FROM \`${pfx}lang\` WHERE active=1`); if (Array.isArray(lng)&&lng.length) lids = lng.map(r=>Number(r.id_lang||0)).filter(n=>n>0); } catch {}
                  for (const lid of lids) { await conn.execute(`INSERT INTO \`${pfx}image_lang\` (id_image,id_lang,legend) VALUES (?,?,?) ON DUPLICATE KEY UPDATE legend=VALUES(legend)`, [nid, lid, legendVar]); }
                } catch {}
              }
            }
          } catch {}
          // Specific price from compare_at_price (override to final vPrice)
          try {
            let cap = 0; // compare_at_price numeric (normalized)
            if (v && v.compare_at_price != null && v.compare_at_price !== '') {
              const raw = String(v.compare_at_price).replace(',', '.');
              const n = Number(raw);
              cap = Number.isFinite(n) ? normalizeMoney(n) : 0;
            }
            if (cap && vPrice && cap > vPrice) {
              for (const s of idShops) {
                try {
                  await conn.execute(
                    `INSERT INTO \`${pfx}specific_price\` (id_product,id_shop,id_cart,id_currency,id_country,id_group,id_customer,id_product_attribute,price,from_quantity,reduction,reduction_tax,reduction_type,` +
                    `\`from\`,\`to\`)
                     VALUES (?,?,?,?,?,?,?,?,?,?,?,?,'amount','1970-01-01 00:00:00','0000-00-00 00:00:00')`,
                    [idProduct, s, 0, 0, 0, 0, 0, idPA, vPrice, 1, 0, 1]
                  );
                } catch {}
              }
            }
          } catch {}
          isFirst = false;
        }
        // Update cache_default_attribute for product and product_shop
        if (defaultPA) {
          try { await conn.execute(`UPDATE \`${pfx}product\` SET cache_default_attribute=? WHERE id_product=?`, [defaultPA, idProduct]); } catch {}
          // Update all product_shop rows for this product
          try { await conn.execute(`UPDATE \`${pfx}product_shop\` SET cache_default_attribute=? WHERE id_product=?`, [defaultPA, idProduct]); } catch {}
        }
      }
    } catch (e) {
      try { logToFile(`[presta] variant_import_warn ${e?.message||e}`); } catch {}
      try {
        if (debugLog && debugLog.data) {
          if (!Array.isArray(debugLog.data.warnings)) debugLog.data.warnings = [];
          debugLog.data.warnings.push(`variant_import_warn: ${String(e?.message||e)}`);
        }
      } catch {}
    }

    // Attachments: create ps_attachment/_lang and link via ps_product_attachment
    try {
      const root = String(process.env.PRESTA_ROOT || '').trim();
      const docsA = Array.isArray(data?.product?.documents) ? data.product.documents : [];
      const docsB = Array.isArray(data?.documents) ? data.documents : [];
      const docs = [...docsA, ...docsB].filter(Boolean);
      if (root && docs.length) {
        // Detect ps_attachment columns
        let hasFileNameCol = false, hasFileSize = false, hasMime = false;
        try {
          const [cols] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}attachment\``);
          if (Array.isArray(cols)) {
            hasFileNameCol = cols.some(c => (c.Field||c.COLUMN_NAME) === 'file_name');
            hasFileSize = cols.some(c => (c.Field||c.COLUMN_NAME) === 'file_size');
            hasMime = cols.some(c => (c.Field||c.COLUMN_NAME) === 'mime');
          }
        } catch {}
        const dlDir = path.join(root, 'download');
        try { fs.mkdirSync(dlDir, { recursive: true }); } catch {}
        // Minimal downloader
        const http = await import('http');
        const https = await import('https');
        const fetchToFile = async (url, dest) => new Promise((resolve) => {
          try {
            const h = String(url).startsWith('https') ? https : http;
            const req2 = h.get(url, { headers: { 'User-Agent': 'Mozilla/5.0 (compatible; Livechat/1.0)' } }, (resp) => {
              if ((resp.statusCode||0) >= 400) { try { resp.resume(); } catch {} return resolve(false); }
              const ws = fs.createWriteStream(dest);
              ws.on('finish', () => resolve(true));
              ws.on('error', () => resolve(false));
              resp.pipe(ws);
            });
            req2.on('error', () => resolve(false));
            req2.setTimeout(20000, () => { try { req2.destroy(); } catch {} resolve(false); });
          } catch { resolve(false); }
        });
        const hex = (len=40) => Array.from({length:len},()=>Math.floor(Math.random()*16).toString(16)).join('');
        const guessMime = (n='') => (/\.pdf$/i.test(n)?'application/pdf':/\.docx?$/i.test(n)?'application/vnd.openxmlformats-officedocument.wordprocessingml.document':/\.xlsx?$/i.test(n)?'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet':/\.zip$/i.test(n)?'application/zip':'application/octet-stream');
        for (const d of docs.slice(0, 15)) {
          try {
            const url = String(d?.download_url || d?.url || d?.href || '').trim();
            if (!/^https?:\/\//i.test(url)) continue;
            const orig = (()=>{ try { const u=new URL(url); return (u.pathname.split('/').pop()||'file'); } catch { return 'file'; } })();
            const fileHash = hex(40);
            const dest = path.join(dlDir, fileHash);
            const ok = await fetchToFile(url, dest);
            let size = 0; try { size = fs.statSync(dest).size||0; } catch {}
            if (!ok || size <= 0) { try { fs.unlinkSync(dest); } catch {} continue; }
            const mime = guessMime(orig);
            // Insert attachment row
            let idAtt = 0;
            if (hasFileNameCol || hasFileSize || hasMime) {
              const cols = ['file']; const params = [fileHash];
              if (hasFileNameCol) { cols.push('file_name'); params.push(orig); }
              if (hasMime) { cols.push('mime'); params.push(mime); }
              if (hasFileSize) { cols.push('file_size'); params.push(size); }
              const ph = cols.map(()=> '?').join(',');
              const sql = `INSERT INTO \`${pfx}attachment\` (${cols.join(',')}) VALUES (${ph})`;
              const [ins] = await conn.execute(sql, params);
              idAtt = ins.insertId;
            } else {
              const [ins] = await conn.execute(`INSERT INTO \`${pfx}attachment\` (file) VALUES (?)`, [fileHash]);
              idAtt = ins.insertId;
            }
            // attachment_lang name/description
            try {
              const label = String(d?.label || d?.text || orig).slice(0,128);
              await conn.execute(`INSERT INTO \`${pfx}attachment_lang\` (id_attachment,id_lang,name,description) VALUES (?,?,?,?)`, [idAtt, idLang, label, '']);
            } catch {}
            // link to product
            try { await conn.execute(`INSERT IGNORE INTO \`${pfx}product_attachment\` (id_product,id_attachment) VALUES (?,?)`, [idProduct, idAtt]); } catch {}
          } catch {}
        }
      }
    } catch (e) { try { logToFile(`[presta] attachments_warn ${e?.message||e}`); } catch {} }

    // Post‑flight: build a schema summary (before closing conn)
    try {
      if (conn) {
        const q = async (sql, params=[]) => { try { const [rows] = await conn.execute(sql, params); return Array.isArray(rows) ? rows : []; } catch { return []; } };
        const summary = {};
        let hasPT=false, hasPST=false;
        try { const [colsPT] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}product\``); hasPT = Array.isArray(colsPT)&&colsPT.some(c=> (c.Field||c.COLUMN_NAME)==='product_type'); } catch {}
        try { const [colsPST] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}product_shop\``); hasPST = Array.isArray(colsPST)&&colsPST.some(c=> (c.Field||c.COLUMN_NAME)==='product_type'); } catch {}
        const prodCols = hasPT ? 'id_product, id_tax_rules_group, product_type, cache_default_attribute' : 'id_product, id_tax_rules_group, cache_default_attribute';
        const shopCols = hasPST ? 'id_shop, id_category_default, price, active, visibility, product_type, cache_default_attribute' : 'id_shop, id_category_default, price, active, visibility, cache_default_attribute';
        summary.product = (await q(`SELECT ${prodCols} FROM \`${pfx}product\` WHERE id_product=?`, [idProduct]))[0] || null;
        summary.product_shop = await q(`SELECT ${shopCols} FROM \`${pfx}product_shop\` WHERE id_product=? ORDER BY id_shop`, [idProduct]);
        // Determine if product_lang has id_shop column
        let plHasIdShop = false;
        try {
          const [colsPL] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}product_lang\``);
          plHasIdShop = Array.isArray(colsPL) && colsPL.some(c => (c.Field||c.COLUMN_NAME) === 'id_shop');
        } catch {}
        if (plHasIdShop) {
          summary.product_lang = await q(`SELECT id_lang, id_shop FROM \`${pfx}product_lang\` WHERE id_product=?`, [idProduct]);
        } else {
          summary.product_lang = await q(`SELECT id_lang FROM \`${pfx}product_lang\` WHERE id_product=?`, [idProduct]);
        }
        summary.images = await q(`SELECT id_image, position, cover FROM \`${pfx}image\` WHERE id_product=? ORDER BY position`, [idProduct]);
        summary.combinations = await q(`SELECT id_product_attribute, reference, price, default_on FROM \`${pfx}product_attribute\` WHERE id_product=? ORDER BY id_product_attribute`, [idProduct]);
        const combIds = summary.combinations.map(r=>r.id_product_attribute).filter(Boolean);
        if (combIds.length) {
          const ph = combIds.map(()=>'?').join(',');
          summary.combination_attributes = await q(`SELECT pac.id_product_attribute, pac.id_attribute FROM \`${pfx}product_attribute_combination\` pac WHERE pac.id_product_attribute IN (${ph}) ORDER BY pac.id_product_attribute`, combIds);
          summary.combination_images = await q(`SELECT id_product_attribute, id_image FROM \`${pfx}product_attribute_image\` WHERE id_product_attribute IN (${ph}) ORDER BY id_product_attribute`, combIds);
        } else { summary.combination_attributes = []; summary.combination_images = []; }
        summary.counts = {
          pac: (await q(`SELECT COUNT(*) AS c FROM \`${pfx}product_attribute_combination\` pac JOIN \`${pfx}product_attribute\` pa ON pa.id_product_attribute=pac.id_product_attribute WHERE pa.id_product=?`, [idProduct]))[0]?.c || 0,
          pai: (await q(`SELECT COUNT(*) AS c FROM \`${pfx}product_attribute_image\` pai JOIN \`${pfx}product_attribute\` pa ON pa.id_product_attribute=pai.id_product_attribute WHERE pa.id_product=?`, [idProduct]))[0]?.c || 0,
          stock_attributes: (await q(`SELECT COUNT(*) AS c FROM \`${pfx}stock_available\` WHERE id_product=? AND id_product_attribute>0`, [idProduct]))[0]?.c || 0,
          specific_price: (await q(`SELECT COUNT(*) AS c FROM \`${pfx}specific_price\` WHERE id_product=?`, [idProduct]))[0]?.c || 0,
          attachments: (await q(`SELECT COUNT(*) AS c FROM \`${pfx}product_attachment\` WHERE id_product=?`, [idProduct]))[0]?.c || 0,
          features: (await q(`SELECT COUNT(*) AS c FROM \`${pfx}feature_product\` WHERE id_product=?`, [idProduct]))[0]?.c || 0,
          tags: (await q(`SELECT COUNT(*) AS c FROM \`${pfx}product_tag\` WHERE id_product=?`, [idProduct]))[0]?.c || 0
        };
        debugLog.data = { ...(debugLog.data||{}), summary };
      }
    } catch {}

    // Guard: if any SQL error was captured, abort before final commit/response
    try {
      if (debugLog && Array.isArray(debugLog.error) && debugLog.error.length) {
        const first = debugLog.error[0];
        try { await conn.rollback(); } catch {}
        try { await conn.end(); } catch {}
        return res.status(500).json({ ok:false, error:'resend_failed', message: String(first||'SQL error'), debug_log: debugLog });
      }
    } catch {}
    await conn.commit();
    // Optional: run shell permission fixer after successful import
    try {
      if (String(process.env.PRESTA_PERMS_SH||'') === '1') {
        const root = String(process.env.PRESTA_ROOT||'').trim();
        const shPath = path.join(__dirname, 'scripts', 'presta-fix-perms.sh');
        if (root && fs.existsSync(shPath)) {
          const { exec } = await import('child_process');
          const cmd = `bash -lc 'PRESTA_ROOT="${root.replace(/'/g, "'\\''")}" "${shPath}"'`;
          exec(cmd, { env: { ...process.env, PRESTA_ROOT: root } }, (err, stdout, stderr) => {
            try { logToFile(`[presta:perms:create] exit=${err? (err.code||1):0} stdout=${String(stdout||'').trim()} stderr=${String(stderr||'').trim()}`); } catch {}
          });
        }
      }
    } catch {}
    // Build summary for debug if requested
    try {
      if (wantDebug) {
        const q = async (sql, params=[]) => { try { const [rows] = await conn.execute(sql, params); return Array.isArray(rows) ? rows : []; } catch { return []; } };
        const summary = {};
        // Second summary block for non-prefixed 'p' variant
        let hasPT2=false, hasPST2=false;
        try { const [colsPT] = await conn.execute(`SHOW COLUMNS FROM \`${p}product\``); hasPT2 = Array.isArray(colsPT)&&colsPT.some(c=> (c.Field||c.COLUMN_NAME)==='product_type'); } catch {}
        try { const [colsPST] = await conn.execute(`SHOW COLUMNS FROM \`${p}product_shop\``); hasPST2 = Array.isArray(colsPST)&&colsPST.some(c=> (c.Field||c.COLUMN_NAME)==='product_type'); } catch {}
        const prodCols2 = hasPT2 ? 'id_product, id_tax_rules_group, product_type, cache_default_attribute' : 'id_product, id_tax_rules_group, cache_default_attribute';
        const shopCols2 = hasPST2 ? 'id_shop, id_category_default, price, active, visibility, product_type, cache_default_attribute' : 'id_shop, id_category_default, price, active, visibility, cache_default_attribute';
        summary.product = (await q(`SELECT ${prodCols2} FROM \`${p}product\` WHERE id_product=?`, [idProduct]))[0] || null;
        summary.product_shop = await q(`SELECT ${shopCols2} FROM \`${p}product_shop\` WHERE id_product=? ORDER BY id_shop`, [idProduct]);
        summary.product_lang = await q(`SELECT id_lang FROM \`${p}product_lang\` WHERE id_product=? LIMIT 100`, [idProduct]);
        summary.images = await q(`SELECT id_image, position, cover FROM \`${p}image\` WHERE id_product=? ORDER BY position`, [idProduct]);
        summary.combinations = await q(`SELECT id_product_attribute, reference, price, default_on FROM \`${p}product_attribute\` WHERE id_product=? ORDER BY id_product_attribute`, [idProduct]);
        const combIds = summary.combinations.map(r=>r.id_product_attribute).filter(Boolean);
        if (combIds.length) {
          const ph = combIds.map(()=>'?').join(',');
          summary.combination_attributes = await q(`SELECT pac.id_product_attribute, pac.id_attribute FROM \`${p}product_attribute_combination\` pac WHERE pac.id_product_attribute IN (${ph}) ORDER BY pac.id_product_attribute`, combIds);
          summary.combination_images = await q(`SELECT id_product_attribute, id_image FROM \`${p}product_attribute_image\` WHERE id_product_attribute IN (${ph}) ORDER BY id_product_attribute`, combIds);
        } else { summary.combination_attributes = []; summary.combination_images = []; }
        summary.counts = {
          pac: (await q(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_combination\` pac JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pac.id_product_attribute WHERE pa.id_product=?`, [idProduct]))[0]?.c || 0,
          pai: (await q(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_image\` pai JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pai.id_product_attribute WHERE pa.id_product=?`, [idProduct]))[0]?.c || 0,
          stock_attributes: (await q(`SELECT COUNT(*) AS c FROM \`${p}stock_available\` WHERE id_product=? AND id_product_attribute>0`, [idProduct]))[0]?.c || 0,
          specific_price: (await q(`SELECT COUNT(*) AS c FROM \`${p}specific_price\` WHERE id_product=?`, [idProduct]))[0]?.c || 0,
          attachments: (await q(`SELECT COUNT(*) AS c FROM \`${p}product_attachment\` WHERE id_product=?`, [idProduct]))[0]?.c || 0,
          features: (await q(`SELECT COUNT(*) AS c FROM \`${p}feature_product\` WHERE id_product=?`, [idProduct]))[0]?.c || 0,
          tags: (await q(`SELECT COUNT(*) AS c FROM \`${p}product_tag\` WHERE id_product=?`, [idProduct]))[0]?.c || 0
        };
        debugLog.data = { ...(debugLog.data||{}), summary };
      }
    } catch {}

    try { await conn.end(); } catch {}

    // Log transfer
    const rec = {
      when: new Date().toISOString(),
      id_product: idProduct,
      product_url: String(data?.page?.url || data?.meta?.url || ''),
      image: (Array.isArray(data?.product?.images) && data.product.images.length ? data.product.images[0] : (data?.meta?.image || '')),
      price,
      currency: String(data?.product?.currency || ''),
      declinaison: (reference ? `SKU: ${reference}` : '-'),
      file: source_file || '',
      name,
    };
    try { if (!JEROME_STORAGE_DISABLED) { const pool = await getPg(); if (pool) await pool.query('insert into grabbing_jerome_transfers(when_at,id_product,product_url,image,price,currency,declinaison,file,name) values($1,$2,$3,$4,$5,$6,$7,$8,$9)', [new Date(rec.when), rec.id_product, rec.product_url, rec.image, rec.price||null, rec.currency||null, rec.declinaison||null, rec.file||'', rec.name||'']); } } catch {}
    const items = loadPrestaTransfers(); items.unshift(rec); savePrestaTransfers(items);
    // Build debug summary for client when requested
    let out = { ok:true, id_product: idProduct, transfer: rec, images_created: (Array.isArray(createdImages)? createdImages.map(i=>({ id_image: i.id_image, position: i.position, cover: i.cover })) : []), debug_log: debugLog };
    try {
      const set = new Set();
      for (const q of debugLog.queries) {
        const m = String(q.sql||'').match(/`([a-z0-9_]+)`/ig) || [];
        for (const n of m) { const t = n.replace(/`/g,''); if (t) set.add(t); }
      }
      debugLog.tables = Array.from(set);
      debugLog.data = {
        ...(debugLog.data||{}),
        action: 'import',
        id_product: idProduct,
        name,
        reference,
        price,
        currency: String(data?.product?.currency||''),
        id_lang: idLang,
        id_shops: idShops,
        images_count: Array.isArray(data?.product?.images)? data.product.images.length: 0,
        variants_count: Array.isArray(data?.product?.variants)? data.product.variants.length: 0,
        images_created_ids: (Array.isArray(out.images_created)? out.images_created.map(x=>x.id_image): [])
      };
    } catch {}
    return res.json(out);
  } catch (e) {
    try { if (conn) await conn.rollback(); } catch {}
    try { if (conn) await conn.end(); } catch {}
    const code = (e && (e.code || e.errno)) || undefined;
    const sql = (e && (e.sql || e.sqlMessage)) || undefined;
    return res.status(500).json({ ok:false, error:'import_failed', message: e?.message || String(e), code, sql, debug_log: (typeof debugLog!== 'undefined'? debugLog: undefined) });
  }
});

// Re-send images only for an existing Presta product
// Body: { id_product?, images?: string[], domain?, url? }
// If id_product not provided, domain+url is used to resolve from ready-transfer notes
app.post('/api/presta/products/images/resend', async (req, res) => {
  let conn = null;
  try {
    const body = req.body || {};
    const wantDebug = true; // always-on
    const debugLog = { tables: [], data: {}, queries: [] };
    let idProduct = Number(body.id_product || 0) || 0;
    let images = Array.isArray(body.images) ? body.images : [];
    const rawDomain = String(body.domain || '').trim();
    const rawUrl = String(body.url || '').trim();
    const toAbsUrl = (u) => {
      try {
        const s = String(u||'').trim();
        if (!s) return '';
        if (/^https?:\/\//i.test(s)) return s;
        const base = publicBaseFromReq(req) || '';
        if (base) return new URL(s, base).toString();
        return s;
      } catch { return String(u||''); }
    };

    // Resolve from ready-transfer if needed
    let referenceFromMapped = '';
    if ((!idProduct || !images.length) && rawDomain && rawUrl) {
      try {
        const pool = await getPg();
        // Allow reads even if storage is disabled (flag targets writes)
        if (pool) {
          let domain = rawDomain.toLowerCase();
          try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
          domain = domain.replace(/^www\./,'');
          const r = await pool.query(
            `select notes, mapped, product_raw from public.grabbing_jerome_domains_url_ready_transfert where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2)) limit 1`,
            [domain, rawUrl]
          );
          if (r.rows.length) {
            const notes = String(r.rows[0].notes || '');
            const m = /id_product\s*=\s*(\d+)/i.exec(notes);
            if (m) idProduct = Number(m[1]) || idProduct;
            const mapped = r.rows[0].mapped || {};
            if (!images.length && mapped && Array.isArray(mapped.images)) images = mapped.images;
            try { if (mapped && mapped.sku) referenceFromMapped = String(mapped.sku); } catch {}
            var productRaw = r.rows[0].product_raw || null;
          }
        }
      } catch {}
    }

    
    if (!idProduct) return res.status(400).json({ ok:false, error:'bad_request', message:'id_product required (or provide domain+url linked to a transferred item)' });

    // Pre-delete counts for debug (only when requested)
    let preCounts = null;
    if (wantDebug) {
      let pre_pa=0, pre_pac=0, pre_pai=0, pre_pal=0, pre_pas=0, pre_stock_attr=0, pre_images=0, pre_image_lang=0, pre_image_shop=0;
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute\` WHERE id_product=?`, [idProduct]); pre_pa = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_combination\` pac JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pac.id_product_attribute WHERE pa.id_product=?`, [idProduct]); pre_pac = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_image\` pai JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pai.id_product_attribute WHERE pa.id_product=?`, [idProduct]); pre_pai = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_lang\` pal JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pal.id_product_attribute WHERE pa.id_product=?`, [idProduct]); pre_pal = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_shop\` pas JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pas.id_product_attribute WHERE pa.id_product=?`, [idProduct]); pre_pas = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}stock_available\` WHERE id_product=? AND id_product_attribute>0`, [idProduct]); pre_stock_attr = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}image\` WHERE id_product=?`, [idProduct]); pre_images = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}image_lang\` WHERE id_image IN (SELECT id_image FROM \`${p}image\` WHERE id_product=?)`, [idProduct]); pre_image_lang = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}image_shop\` WHERE id_image IN (SELECT id_image FROM \`${p}image\` WHERE id_product=?)`, [idProduct]); pre_image_shop = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      preCounts = { pa: pre_pa, pac: pre_pac, pai: pre_pai, pal: pre_pal, pas: pre_pas, stock_attr: pre_stock_attr, images: pre_images, image_lang: pre_image_lang, image_shop: pre_image_shop };
    }

    // Cleanup existing combinations and images for this product before re-inserting
    try {
      // Collect product_attribute ids, then delete related rows in chunks
      let paIds = [];
      try {
        const [rowsPa] = await conn.execute(`SELECT id_product_attribute FROM \`${p}product_attribute\` WHERE id_product=?`, [idProduct]);
        paIds = Array.isArray(rowsPa) ? rowsPa.map(r => Number(r.id_product_attribute||0)).filter(n=>n>0) : [];
      } catch {}
      const chunk = (arr, n) => { const out=[]; for (let i=0;i<arr.length;i+=n) out.push(arr.slice(i,i+n)); return out; };
      for (const ids of chunk(paIds, 500)) {
        const ph = ids.map(()=>'?').join(',');
        try { await conn.execute(`DELETE FROM \`${p}product_attribute_image\` WHERE id_product_attribute IN (${ph})`, ids); } catch {}
        try { await conn.execute(`DELETE FROM \`${p}product_attribute_combination\` WHERE id_product_attribute IN (${ph})`, ids); } catch {}
        try { await conn.execute(`DELETE FROM \`${p}product_attribute_lang\` WHERE id_product_attribute IN (${ph})`, ids); } catch {}
        try { await conn.execute(`DELETE FROM \`${p}product_attribute_shop\` WHERE id_product_attribute IN (${ph})`, ids); } catch {}
      }
      try { await conn.execute(`DELETE FROM \`${p}stock_available\` WHERE id_product=? AND id_product_attribute>0`, [idProduct]); } catch {}
      try { await conn.execute(`DELETE FROM \`${p}attribute_impact\` WHERE id_product=?`, [idProduct]); } catch {}
      try { await conn.execute(`DELETE FROM \`${p}product_attribute\` WHERE id_product=?`, [idProduct]); } catch {}

      // Collect image ids, then delete dependent rows in chunks
      let imgIds = [];
      try { const [rr] = await conn.execute(`SELECT id_image FROM \`${p}image\` WHERE id_product=?`, [idProduct]); imgIds = Array.isArray(rr)? rr.map(r=>Number(r.id_image||0)).filter(n=>n>0): []; } catch {}
      for (const ids of chunk(imgIds, 500)) {
        const ph = ids.map(()=>'?').join(',');
        try { await conn.execute(`DELETE FROM \`${p}product_attribute_image\` WHERE id_image IN (${ph})`, ids); } catch {}
        try { await conn.execute(`DELETE FROM \`${p}image_lang\` WHERE id_image IN (${ph})`, ids); } catch {}
        try { await conn.execute(`DELETE FROM \`${p}image_shop\` WHERE id_image IN (${ph})`, ids); } catch {}
      }
      // Remove physical files for old images
      try {
        const root = String(process.env.PRESTA_ROOT || '').trim();
        if (root && imgIds.length) {
          const makePath = (id) => { const parts = String(id).split(''); const dir = path.join(root, 'img', 'p', ...parts); const file = path.join(dir, `${id}.jpg`); return { dir, file }; };
          for (const idImg of imgIds) {
            try {
              const { dir, file } = makePath(idImg);
              try { if (fs.existsSync(file)) fs.unlinkSync(file); } catch {}
              try { if (fs.existsSync(dir)) { for (const f of fs.readdirSync(dir)) { if (new RegExp(`^${idImg}-.*\\.(jpg|webp)$`, 'i').test(f)) { try { fs.unlinkSync(path.join(dir, f)); } catch {} } } } } catch {}
            } catch {}
          }
        }
      } catch {}
      try { await conn.execute(`DELETE FROM \`${p}image\` WHERE id_product=?`, [idProduct]); } catch {}
    } catch {}
    // Build images list from mapped or local downloads if needed
    try {
      if ((!Array.isArray(images) || !images.length) && productRaw && Array.isArray(productRaw.images_local)) {
        const files = productRaw.images_local.map(it => {
          try {
            if (!it) return '';
            const local = it.file ? path.join(grabbingJeromeDir, it.file) : '';
            if (local && fs.existsSync(local)) return local;
            return toAbsUrl((it.url || it.href || it.download_url || '') || '');
          } catch { return ''; }
        }).filter(Boolean);
        images = files;
      }
      if ((!Array.isArray(images) || !images.length) && productRaw && Array.isArray(productRaw.images)) {
        images = productRaw.images.map(u => String(u||'')).filter(Boolean);
      }
      // Fallback: pull from latest stored snapshot if prepared row had none
      if ((!Array.isArray(images) || !images.length) && rawDomain && rawUrl) {
        try {
          const pool = await getPg();
          // Allow reads even if storage is disabled (flag targets writes)
          if (pool) {
            let domain = rawDomain.toLowerCase();
            try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
            domain = domain.replace(/^www\./,'');
            const hs = await pool.query(
              `select result_json from public.grabbing_jerome_domains_url_page_explore where domain=$1 and lower(trim(both from url))=lower(trim(both from $2)) order by explored_at desc nulls last limit 1`,
              [domain, rawUrl]
            );
            if (hs.rows && hs.rows.length && hs.rows[0].result_json) {
              const data = hs.rows[0].result_json || {};
              const locs = Array.isArray(data?.product?.images_local) ? data.product.images_local : [];
              const files = locs.map(it => {
                try {
                  if (!it) return '';
                  const local = it.file ? path.join(grabbingJeromeDir, it.file) : '';
                  if (local && fs.existsSync(local)) return local;
                  return toAbsUrl((it.url || it.href || it.download_url || '') || '');
                } catch { return ''; }
              }).filter(Boolean);
              if (files.length) images = files;
              // as a last resort, pick og_image
              if ((!images || !images.length) && data?.meta?.og_image) images = [String(data.meta.og_image)];
            }
          }
        } catch {}
      }
      // Normalize: absolute URLs, dedupe, prioritize product images over logos
      try {
        const abs = (u) => toAbsUrl(u);
        const seen = new Set();
        images = images
          .map(u => String(u||'').trim())
          .filter(Boolean)
          .map(abs)
          .filter(u => { const k=u.toLowerCase(); if (seen.has(k)) return false; seen.add(k); return true; });
        const score = (u) => {
          const s = String(u||'').toLowerCase();
          let sc = 0;
          if (/cdn\/shop\/products\//.test(s) || /\/products\//.test(s)) sc += 10;
          if (/\.(jpe?g|webp|avif|png)(?:\?|$)/.test(s)) sc += 5;
          if (/(?:^|[\/._-])(logo|favicon|sprite|icon|placeholder|badge|loading)(?:[\/._-]|$)/.test(s)) sc -= 10;
          return sc;
        };
        images.sort((a,b)=> score(b)-score(a));
      } catch {}

      // If everything is remote or a doc URL points to a missing local file, fall back to local uploads for this domain
      try {
        const isHttp = (s) => /^https?:\/\//i.test(String(s||''));
        const docLocalPath = (u) => { try { const m=/\/api\/grabbings\/jerome\/doc\/([^\/?#]+)$/i.exec(String(u||'')); if(m){ const name=decodeURIComponent(m[1]); if(/^[A-Za-z0-9._%\-]+$/.test(name)) return path.join(grabbingJeromeDir, name);} } catch{} return ''; };
        const domainForLocal = (()=>{ try{ if(rawDomain) return new URL(/^https?:\/\//i.test(rawDomain)? rawDomain: `https://${rawDomain}`).hostname.replace(/^www\./,''); if(rawUrl) return new URL(rawUrl).hostname.replace(/^www\./,''); }catch{} return ''; })();
        const needsLocal = (!images.length) || images.every(u=>isHttp(u)) || images.some(u=>{ const lp=docLocalPath(u); return lp && !fs.existsSync(lp); });
        if (domainForLocal && needsLocal) {
          const esc = domainForLocal.replace(/[-\/\\.^$*+?()[\]{}|]/g,'\\$');
          const names = fs.readdirSync(grabbingJeromeDir).filter(n => new RegExp(`^img-${esc}-.*\\.(?:jpe?g|png|webp|avif)$`, 'i').test(n));
          if (names.length) {
            const withStats = names.map(n=>{ const pth=path.join(grabbingJeromeDir,n); let t=0; try{ t=fs.statSync(pth).mtimeMs||0; }catch{} return { pth, t };}).sort((a,b)=> b.t-a.t);
            images = withStats.slice(0,12).map(it=>it.pth);
          }
        }
      } catch {}
    } catch {}
    if (!Array.isArray(images) || !images.length) return res.status(400).json({ ok:false, error:'no_images', message:'no images to resend' });

    const root = String(process.env.PRESTA_ROOT || '').trim();
    if (!root) return res.status(412).json({ ok:false, error:'presta_root_missing', message:'Set PRESTA_ROOT env to your PrestaShop root path' });

    // Resolve Presta DB config (active profile first, then base config)
    let cfg = null;
    try {
      const active = await getSetting('PRESTA_DB_ACTIVE');
      if (active) {
        const profilesRaw = await getSetting('PRESTA_DB_PROFILES');
        const profiles = profilesRaw ? JSON.parse(profilesRaw) : [];
        const prof = Array.isArray(profiles) ? profiles.find(x => x && x.name === active) : null;
        if (prof) cfg = { ...prof };
      }
    } catch {}
    if (!cfg) {
      try { const raw = await getSetting('PRESTA_DB_JSON'); cfg = raw ? JSON.parse(raw) : null; } catch {}
    }
    if (!cfg || !cfg.host || !cfg.user || !cfg.database) return res.status(412).json({ ok:false, error:'presta_db_not_configured' });

    const mysql2 = await import('mysql2/promise');
    conn = await mysql2.createConnection({ host: cfg.host, port: Number(cfg.port||3306), user: cfg.user, password: cfg.password, database: cfg.database, multipleStatements: true });
    // Always capture SQL with per-query status
    try {
      if (conn && typeof conn.execute === 'function' && !conn.__dbgWrap) {
        const orig = conn.execute.bind(conn);
        conn.__dbgWrap = true;
        conn.execute = async (sql, params=[]) => {
          const entry = { sql: String(sql||''), params: Array.isArray(params)? params: [] };
          try { (debugLog.queries||(debugLog.queries=[])).push(entry); } catch {}
          try { const r = await orig(sql, params); try { entry.ok = true; } catch {} return r; }
          catch (e) { try { (debugLog.error||(debugLog.error=[])).push(e?.message||String(e)); entry.err = e?.message||String(e); } catch {} throw e; }
        };
      }
    } catch {}
    const p = String(cfg.table_prefix||'ps_');
    const idLang = Number(cfg.default_lang_id||1) || 1;
    // Shops
    let idShops = [];
    if (Array.isArray(cfg.default_shop_ids)) idShops = cfg.default_shop_ids.map(n=>Number(n)).filter(n=>!isNaN(n)&&n>0);
    else idShops = String(cfg.default_shop_ids||'1').split(',').map(s=>Number(s.trim())).filter(n=>!isNaN(n)&&n>0);
    if (!idShops.length) idShops = [1];

    const http = await import('http');
    const https = await import('https');

    // Robust copy: follow redirects for remote URLs; report success boolean
    const copyToFile = async (src, dest) => {
      return await new Promise((resolve) => {
        try {
          const done = (ok=false) => resolve(!!ok);
          const write = () => {
            try {
              const ws = fs.createWriteStream(dest);
              ws.on('finish', () => {
                try { const st = fs.statSync(dest); if (st.size > 0) return done(true); } catch {}
                return done(false);
              });
              ws.on('error', () => done(false));
              return ws;
            } catch { return null; }
          };
          const maxRedirects = 5;
          const srcStr = String(src||'');
          // Handle Jerome doc URLs (relative or absolute) as local file sources
          try {
            const tryLocalCopy = (pathname) => {
              const name = decodeURIComponent((pathname||'').split('/').pop()||'');
              if (!/^[A-Za-z0-9._%\-]+$/.test(name)) return false;
              const pth = path.join(grabbingJeromeDir, name);
              if (!fs.existsSync(pth)) return false;
              try {
                const rs = fs.createReadStream(pth);
                rs.on('error', () => done(false));
                rs.on('open', () => { const ws = write(); if (!ws) return done(false); rs.pipe(ws); });
                return true;
              } catch { return false; }
            };
            if (/^\/?api\/grabbings\/jerome\/doc\//i.test(srcStr)) {
              if (tryLocalCopy(srcStr)) return; // handled
            }
          } catch {}

          if (/^https?:\/\//i.test(srcStr)) {
            // Special-case: local doc endpoint -> copy straight from disk if possible
            try {
              const uo = new URL(String(srcStr));
              if (/^\/api\/grabbings\/jerome\/doc\//i.test(uo.pathname)) {
                if (tryLocalCopy(uo.pathname)) return; // handled
              }
            } catch {}
            const doGet = (u, n) => {
              try {
                const h = String(u).startsWith('https') ? https : http;
                const req2 = h.get(u, { headers: { 'User-Agent': 'Mozilla/5.0 (compatible; Livechat/1.0)' } }, (resp) => {
                  const sc = Number(resp.statusCode||0);
                  if (sc >= 300 && sc < 400 && resp.headers && resp.headers.location && n < maxRedirects) {
                    try { resp.resume(); } catch {}
                    let nextUrl = '';
                    try { nextUrl = new URL(resp.headers.location, u).toString(); } catch { nextUrl = resp.headers.location; }
                    return doGet(nextUrl, n+1);
                  }
                  if (sc >= 400) { try { resp.resume(); } catch {} return done(false); }
                  const ws = write(); if (!ws) { try { resp.resume(); } catch {} return done(); }
                  resp.pipe(ws);
                });
                req2.on('error', () => done(false));
                req2.setTimeout(20000, () => { try { req2.destroy(); } catch {} done(false); });
              } catch { done(false); }
            };
            doGet(String(src), 0);
          } else {
            try {
              const p = srcStr;
              if (!p || !fs.existsSync(p)) return done(false);
              const rs = fs.createReadStream(p);
              rs.on('error', () => done(false));
              rs.on('open', () => { const ws = write(); if (!ws) return done(false); rs.pipe(ws); });
            } catch { done(false); }
          }
        } catch { resolve(false); }
      });
    };
    const makePath = (id) => {
      const parts = String(id).split('');
      const dir = path.join(root, 'img', 'p', ...parts);
      const file = path.join(dir, `${id}.jpg`);
      return { dir, file };
    };

    // Fetch Presta image types from DB (prefix-aware) and fall back to defaults
    const fetchPrestaImageTypes = async () => {
      try {
        const types = [];
        // Base select: product image types only
        let baseRows = [];
        try {
          const [r] = await conn.execute(
            `SELECT it.id_image_type, it.name, it.width, it.height, it.products
               FROM \`${p}image_type\` it`
          );
          baseRows = Array.isArray(r) ? r : [];
        } catch {}
        if (baseRows && baseRows.length) {
          // Optional multishop restriction using image_type_shop
          let allowedNames = null;
          try {
            // MariaDB can error on placeholders in SHOW TABLES; build literal safely
            const likeName = `${p}image_type_shop`;
            const [has] = await conn.execute(`SHOW TABLES LIKE '${likeName.replace(/'/g, "''")}'`);
            const tableExists = Array.isArray(has) && has.length > 0;
            if (tableExists && idShops && idShops.length) {
              const placeholders = idShops.map(() => '?').join(',');
              const [rs] = await conn.execute(
                `SELECT DISTINCT it.name
                   FROM \`${p}image_type\` it
                   JOIN \`${p}image_type_shop\` its ON its.id_image_type = it.id_image_type
                  WHERE its.id_shop IN (${placeholders})`,
                idShops
              );
              allowedNames = new Set((Array.isArray(rs)?rs:[]).map(x => String(x.name||'').trim()));
            }
          } catch {}
          for (const r of baseRows) {
            const name = String(r.name||'').trim();
            const width = Number(r.width||0); const height = Number(r.height||0);
            const isProduct = (r.products == null) ? true : (Number(r.products)||0) === 1;
            if (!name || !width || !height || !isProduct) continue;
            if (allowedNames && !allowedNames.has(name)) continue;
            types.push({ name, width, height });
          }
        }
        if (types.length) return types;
      } catch {}
      // Fallback defaults
      return [
        { name: 'cart_default', width: 80, height: 80 },
        { name: 'small_default', width: 80, height: 80 },
        { name: 'medium_default', width: 211, height: 211 },
        { name: 'home_default', width: 199, height: 199 },
        { name: 'large_default', width: 1000, height: 1000 },
        { name: 'category_default', width: 300, height: 300 },
        { name: 'stores_default', width: 210, height: 210 },
        { name: 'inner_default', width: 196, height: 196 },
      ];
    };
    // Resolve desired thumbnail formats from request body or env
    const parseThumbFormats = () => {
      try {
        const fromBodyList = Array.isArray(req.body?.thumb_formats) ? req.body.thumb_formats : null;
        const fromBodySingle = req.body?.fileType || req.body?.format || req.body?.thumb_format;
        let list = null;
        if (fromBodyList && fromBodyList.length) list = fromBodyList;
        else if (typeof fromBodySingle === 'string' && fromBodySingle.trim()) list = [fromBodySingle];
        else {
          // Try a plain text file named 'fileType' under the Jerome uploads dir
          // The file may contain a single value (e.g., 'webp') or comma-separated values (e.g., 'jpg,webp')
          let fromFile = '';
          try {
            const pth = path.join(grabbingJeromeDir, 'fileType');
            if (fs.existsSync(pth)) fromFile = fs.readFileSync(pth, 'utf8');
          } catch {}
          if (fromFile && String(fromFile).trim()) list = String(fromFile).trim();
          // Fallback to env
          if (!list) {
            const envVal = String(process.env.PRESTA_THUMB_FORMATS || 'jpg,webp');
            list = envVal.split(',');
          }
        }
        const set = new Set();
        for (const it of list) { const s = String(it||'').trim().toLowerCase(); if (s) set.add(s); }
        // Normalize common aliases
        if (set.has('jpeg')) { set.delete('jpeg'); set.add('jpg'); }
        if (!set.size) { set.add('jpg'); set.add('webp'); }
        return Array.from(set);
      } catch { return ['jpg','webp']; }
    };

    const generatePrestaThumbnails = async (srcPath, outDir, idImage, formats) => {
      try {
        let sharpMod = null;
        try {
          const m = await import('sharp');
          sharpMod = m?.default || m;
        } catch {}
        if (!sharpMod) return;
        const fmts = Array.isArray(formats) && formats.length ? formats : parseThumbFormats();
        const wantJpg = fmts.includes('jpg');
        const wantWebp = fmts.includes('webp');
        const tasks = [];
        const types = await fetchPrestaImageTypes();
        for (const t of types) {
          const w = Number(t.width||0), h = Number(t.height||0);
          if (wantJpg) {
            const jpgOut = path.join(outDir, `${idImage}-${t.name}.jpg`);
            try {
              tasks.push(
                sharpMod(srcPath)
                  .resize(w, h, { fit: 'contain', position: 'centre', background: { r:255, g:255, b:255, alpha:1 } })
                  .flatten({ background: '#ffffff' })
                  .jpeg({ quality: 85, mozjpeg: true })
                  .toFile(jpgOut)
                  .then(()=>{ try{ fs.chmodSync(jpgOut,0o775);}catch{} try{ fs.chownSync(jpgOut,33,33);}catch{} })
                  .catch(()=>{})
              );
            } catch {}
          }
          if (wantWebp) {
            const webpOut = path.join(outDir, `${idImage}-${t.name}.webp`);
            try {
              tasks.push(
                sharpMod(srcPath)
                  .resize(w, h, { fit: 'contain', position: 'centre', background: { r:255, g:255, b:255, alpha:1 } })
                  .flatten({ background: '#ffffff' })
                  .webp({ quality: 80 })
                  .toFile(webpOut)
                  .then(()=>{ try{ fs.chmodSync(webpOut,0o775);}catch{} try{ fs.chownSync(webpOut,33,33);}catch{} })
                  .catch(()=>{})
              );
            } catch {}
          }
        }
        await Promise.all(tasks);
        // Ensure permissions/ownership on generated thumbs
        try {
          const re = new RegExp(`^${idImage}-.*\\.(?:jpg|webp)$`, 'i');
          for (const f of fs.readdirSync(outDir)) {
            if (!re.test(f)) continue;
            const pth = path.join(outDir, f);
            try { fs.chmodSync(pth, 0o775); } catch {}
            try { fs.chownSync(pth, 33, 33); } catch {}
          }
        } catch {}
      } catch {}
    };

    // If id_product still missing, try to resolve by reference (mapped.sku)
    if (!idProduct && referenceFromMapped) {
      try {
        const [rr] = await conn.execute(`SELECT id_product FROM \`${p}product\` WHERE reference=? LIMIT 1`, [referenceFromMapped]);
        if (Array.isArray(rr) && rr.length) idProduct = Number(rr[0].id_product)||0;
      } catch {}
    }
    if (!idProduct) return res.status(400).json({ ok:false, error:'bad_request', message:'id_product required (or provide domain+url linked to a transferred item, or a mapped sku resolvable in Presta)' });

    // Load existing images for product
    const [rows] = await conn.execute(`SELECT id_image, position, cover FROM \`${p}image\` WHERE id_product=? ORDER BY position ASC, id_image ASC`, [idProduct]);
    // Load active languages and product name for legends (prefer default shop if column exists)
    let activeLangIdsImg = [idLang];
    try { const [lng] = await conn.execute(`SELECT id_lang FROM \`${p}lang\` WHERE active=1`); if (Array.isArray(lng)&&lng.length) activeLangIdsImg = lng.map(r=>Number(r.id_lang||0)).filter(n=>n>0); } catch {}
    let prodName = '';
    try {
      let hasIdShop = false;
      try { const [cols] = await conn.execute(`SHOW COLUMNS FROM \`${p}product_lang\``); hasIdShop = Array.isArray(cols) && cols.some(c => (c.Field||c.COLUMN_NAME) === 'id_shop'); } catch {}
      const idShopDefault = Array.isArray(idShops) && idShops.length ? idShops[0] : 1;
      if (hasIdShop) {
        const [nm] = await conn.execute(`SELECT name FROM \`${p}product_lang\` WHERE id_product=? AND id_lang=? AND id_shop=? LIMIT 1`, [idProduct, idLang, idShopDefault]);
        if (Array.isArray(nm)&&nm.length) prodName = String(nm[0].name||'');
      } else {
        const [nm] = await conn.execute(`SELECT name FROM \`${p}product_lang\` WHERE id_product=? AND id_lang=? LIMIT 1`, [idProduct, idLang]);
        if (Array.isArray(nm)&&nm.length) prodName = String(nm[0].name||'');
      }
    } catch {}
    let coverSet = false;
    const existing = Array.isArray(rows) ? rows : [];
    let idx = 0;

    const results = [];
    // Update existing rows' files
    for (; idx < existing.length && idx < images.length; idx++) {
      const r = existing[idx];
      const primary = String(images[idx]||'');
      const idImage = r.id_image;
      const cover = (idx === 0) ? 1 : null;
      const shopCover = (cover === 1) ? 1 : null;
      try { await conn.execute(`UPDATE \`${p}image\` SET position=?, cover=? WHERE id_image=?`, [idx+1, cover, idImage]); } catch {}
      for (const s of idShops) {
        try {
          await conn.execute(`INSERT INTO \`${p}image_shop\` (id_product,id_image,id_shop,cover) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE cover=VALUES(cover)`, [idProduct, idImage, s, shopCover]);
        } catch {}
      }
      try { for (const lid of activeLangIdsImg) { await conn.execute(`INSERT INTO \`${p}image_lang\` (id_image,id_lang,legend) VALUES (?,?,?) ON DUPLICATE KEY UPDATE legend=VALUES(legend)`, [idImage, lid, prodName]); } } catch {}
      const { dir, file } = makePath(idImage);
      try { fs.mkdirSync(dir, { recursive: true }); } catch {}
      try { fs.chmodSync(dir, 0o775); fs.chownSync(dir, 33, 33); } catch {}
      // Build fallback candidates if primary is a Jerome doc and local file missing
      const candidates = [primary];
      try {
        const tryAddByName = (src) => {
          try {
            const name = decodeURIComponent(String(src||'').split('/').pop()||'');
            if (productRaw && Array.isArray(productRaw.images_local)) {
              const it = productRaw.images_local.find(x => String(x?.file||'') === name);
              if (it && it.url) candidates.push(String(it.url));
            }
          } catch {}
        };
        if (/\/api\/grabbings\/jerome\/doc\//i.test(primary) || /^\/?api\/grabbings\/jerome\/doc\//i.test(primary)) tryAddByName(primary);
        if (productRaw && Array.isArray(productRaw.images) && productRaw.images[idx]) candidates.push(String(productRaw.images[idx]));
      } catch {}
      let ok = false;
      for (const src of candidates) { ok = await copyToFile(src, file); let st=0; try { st = fs.statSync(file).size||0; } catch {}; if (ok || st>0) { ok = true; break; } }
      try { fs.chmodSync(file, 0o775); fs.chownSync(file, 33, 33); } catch {}
      let size = 0; try { const st = fs.statSync(file); size = Number(st.size||0); } catch {}
      const okFinal = !!ok || size > 0;
      results.push({ id_image: idImage, src: primary, dest: file, ok: okFinal, size });
      // Generate thumbnails when copy succeeded
      if (okFinal) { try { await generatePrestaThumbnails(file, dir, idImage, parseThumbFormats()); } catch {} }
      if (cover && !coverSet) coverSet = true;
    }

    // Add extra images if provided
    for (; idx < images.length; idx++) {
      const primary = String(images[idx]||'');
      const cover = (idx === 0 && !coverSet) ? 1 : null;
      const shopCover = (cover === 1) ? 1 : 0;
      const [insI] = await conn.execute(`INSERT INTO \`${p}image\` (id_product, position, cover) VALUES (?,?,?)`, [idProduct, idx+1, cover]);
      const idImage = insI.insertId;
      for (const s of idShops) {
        try { await conn.execute(`INSERT INTO \`${p}image_shop\` (id_product,id_image,id_shop,cover) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE cover=VALUES(cover)`, [idProduct, idImage, s, shopCover]); } catch {}
      }
      try { for (const lid of activeLangIdsImg) { await conn.execute(`INSERT INTO \`${p}image_lang\` (id_image,id_lang,legend) VALUES (?,?,?) ON DUPLICATE KEY UPDATE legend=VALUES(legend)`, [idImage, lid, prodName]); } } catch {}
      const { dir, file } = makePath(idImage);
      try { fs.mkdirSync(dir, { recursive: true }); } catch {}
      try { fs.chmodSync(dir, 0o775); fs.chownSync(dir, 33, 33); } catch {}
      const candidates = [primary];
      try {
        const tryAddByName = (src) => {
          try {
            const name = decodeURIComponent(String(src||'').split('/').pop()||'');
            if (productRaw && Array.isArray(productRaw.images_local)) {
              const it = productRaw.images_local.find(x => String(x?.file||'') === name);
              if (it && it.url) candidates.push(String(it.url));
            }
          } catch {}
        };
        if (/\/api\/grabbings\/jerome\/doc\//i.test(primary) || /^\/?api\/grabbings\/jerome\/doc\//i.test(primary)) tryAddByName(primary);
        if (productRaw && Array.isArray(productRaw.images) && productRaw.images[idx]) candidates.push(String(productRaw.images[idx]));
      } catch {}
      let ok = false;
      for (const src of candidates) { ok = await copyToFile(src, file); let st=0; try { st = fs.statSync(file).size||0; } catch {}; if (ok || st>0) { ok = true; break; } }
      let size = 0; try { const st = fs.statSync(file); size = Number(st.size||0); } catch {}
      const okFinal = !!ok || size > 0;
      results.push({ id_image: idImage, src: primary, dest: file, ok: okFinal, size });
      // Generate thumbnails when copy succeeded
      if (okFinal) { try { await generatePrestaThumbnails(file, dir, idImage, parseThumbFormats()); } catch {} }
    }

    try { await conn.end(); } catch {}
    let out = { ok:true, id_product: idProduct, images: images.length, updated: Math.min(existing.length, images.length), inserted: Math.max(0, images.length - existing.length), results, debug_log: debugLog };
    try {
      const set = new Set();
      for (const q of debugLog.queries) {
        const m = String(q.sql||'').match(/`([a-z0-9_]+)`/ig) || [];
        for (const n of m) { const t = n.replace(/`/g,''); if (t) set.add(t); }
      }
      debugLog.tables = Array.from(set);
      debugLog.data = { action: 'images_resend', id_product: idProduct, id_lang: idLang, id_shops: idShops, images_in: Array.isArray(images)? images.length: 0, updated: out.updated, inserted: out.inserted };
    } catch {}
    return res.json(out);
  } catch (e) {
    try { if (conn) await conn.end(); } catch {}
    return res.status(500).json({ ok:false, error:'resend_images_failed', message: e?.message || String(e) });
  }
});

  // Re-send (upsert) product to Presta: update if id_product exists, else create
// Body:
// - Preferred: { domain, url } to use ready-transfer mapped payload and stored id_product (notes)
// - Or explicit: { id_product?, mapped?: { name, description, sku, price, currency }, page_url? }
  app.post('/api/presta/products/resend', async (req, res) => {
  let conn = null;
  try {
    const body = req.body || {};
    const wantDebug = !!(req.query?.debug || body.debug);
    const debugLog = { tables: [], data: {}, queries: [] };
    // Normalize incoming money-like numbers (cents -> euros)
    const normalizeMoney = (n) => {
      const x = Number(n);
      if (!Number.isFinite(x)) return 0;
      if ((Number.isInteger(x) && x >= 100) || x >= 1000) return Math.round((x / 100) * 100) / 100;
      return x;
    };
    const rawDomain = String(body.domain||'').trim();
    const rawUrl = String(body.url||body.page_url||'').trim();
    let idProduct = Number(body.id_product||0) || 0;
    let mapped = (body.mapped && typeof body.mapped === 'object') ? body.mapped : null;

    // Resolve mapped + id_product from ready-transfer if needed
    if ((!mapped || !idProduct) && rawUrl) {
      try {
        const pool = await getPg();
        // Allow reads even if storage writes are disabled
        if (pool) {
          let domain = rawDomain;
          if (!domain && rawUrl) { try { const u = new URL(rawUrl); domain = (u.hostname||'').toLowerCase(); } catch {} }
          domain = (domain||'').toLowerCase().replace(/^www\./,'');
          const q = await pool.query(
            `select id_product, notes, mapped, meta, product_raw, coalesce(page_type,'product') as page_type
               from public.grabbing_jerome_domains_url_ready_transfert
              where domain=$1 and lower(trim(both from url))=lower(trim(both from $2))
              limit 1`,
            [domain, rawUrl]
          );
          if (q.rows.length) {
            if (!mapped) mapped = q.rows[0].mapped || null;
            // Prefer explicit id_product column from ready-transfer
            const idpCol = Number(q.rows[0].id_product || 0);
            if (idpCol && !idProduct) idProduct = idpCol;
            const notes = String(q.rows[0].notes||'');
            const m = /id_product\s*=\s*(\d+)/i.exec(notes);
            if (m && !idProduct) idProduct = Number(m[1])||0;
            // Fallback: if mapped missing, rebuild from stored meta/product using current transfer config
            if (!mapped) {
              try {
                const meta = q.rows[0].meta || {};
                const product = q.rows[0].product_raw || {};
                const t = String(q.rows[0].page_type||'product').toLowerCase();
                let cfgTransfert = null;
                try {
                  const rCfg = await pool.query('select config_transfert from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
                  const all = rCfg.rows?.[0]?.config_transfert || {};
                  if (all && typeof all === 'object') cfgTransfert = all[t] || all['product'] || null;
                } catch {}
                mapped = applyTransferConfig(mapProductForPresta(meta, product), meta, product, cfgTransfert || {});
              } catch {}
            }
            // Merge variant attributes from stored product_raw if mapped variants lack them
            try {
              const product = q.rows[0].product_raw || {};
              const mv = Array.isArray(mapped?.variants) ? mapped.variants : null;
              const rv = Array.isArray(product?.variants) ? product.variants : null;
              if (mv && rv) {
                const byKey = (v) => {
                  const id = (v && (v.id != null)) ? String(v.id) : '';
                  const sku = (v && v.sku) ? String(v.sku) : '';
                  return `${id}#${sku}`;
                };
                const rawMap = new Map(rv.map(x => [byKey(x), x]));
                mapped.variants = mv.map(x => {
                  const key = byKey(x);
                  const src = rawMap.get(key);
                  if (src && !x.attributes && src.attributes) x = { ...x, attributes: src.attributes };
                  return x;
                });
              }
            } catch {}
          }
        }
      } catch {}
    }

    // Ensure mapped exists
    if (!mapped) return res.status(400).json({ ok:false, error:'bad_request', message:'mapped payload required (or provide domain+url of a prepared item)' });

    // Presta DB config
    let cfg = null;
    try {
      const active = await getSetting('PRESTA_DB_ACTIVE');
      if (active) {
        const profilesRaw = await getSetting('PRESTA_DB_PROFILES');
        const profiles = profilesRaw ? JSON.parse(profilesRaw) : [];
        const prof = Array.isArray(profiles) ? profiles.find(x => x && x.name === active) : null;
        if (prof) cfg = { ...prof };
      }
    } catch {}
    if (!cfg) { try { const raw = await getSetting('PRESTA_DB_JSON'); cfg = raw ? JSON.parse(raw) : null; } catch {} }
    if (!cfg || !cfg.host || !cfg.user || !cfg.database) return res.status(412).json({ ok:false, error:'presta_db_not_configured' });

    // Normalize fields
    const mysql2 = await import('mysql2/promise');
    conn = await mysql2.createConnection({ host: cfg.host, port: Number(cfg.port||3306), user: cfg.user, password: cfg.password, database: cfg.database, multipleStatements: true });
    try {
      if (wantDebug && conn && !conn.__dbgWrap) {
        const wrap = (method) => {
          const orig = conn[method] && conn[method].bind(conn);
          if (!orig) return;
          conn[method] = async (sql, params=[]) => {
            const entry = { sql: String(sql||''), params: Array.isArray(params)? params: [] };
            try { (debugLog.queries||(debugLog.queries=[])).push(entry); } catch {}
            try { const r = await orig(sql, params); try { entry.ok = true; } catch {} return r; }
            catch (e) { try { (debugLog.error||(debugLog.error=[])).push(e?.message||String(e)); entry.err = e?.message||String(e); } catch {} throw e; }
          };
        };
        conn.__dbgWrap = true;
        wrap('execute');
        wrap('query');
      }
    } catch {}
    const p = String(cfg.table_prefix||'ps_');
    let idShops = [];
    if (Array.isArray(cfg.default_shop_ids)) idShops = cfg.default_shop_ids.map(n=>Number(n)).filter(n=>!isNaN(n)&&n>0); else idShops = String(cfg.default_shop_ids||'1').split(',').map(s=>Number(s.trim())).filter(n=>!isNaN(n)&&n>0);
    if (!idShops.length) idShops = [1];
    let idShopDefault = idShops[0];
    const idLang = Number(cfg.default_lang_id||1) || 1;
    const taxGroupId = Number(cfg.default_tax_rules_group_id||0) || 0;
    const activeFlag = (cfg.default_active ? 1 : 0);
    const visibility = String(cfg.default_visibility||'both');

    const name = String(mapped.name||'Imported Product').slice(0,255);
    const description = String(mapped.description||'');
    const reference = String(mapped.sku||'').slice(0,64);
    const price = normalizeMoney(mapped.price||0);
    const idCategory = Number(cfg.default_category_id||2) || 2;

    // Filter configured shops to those existing in ps_shop; fall back to default if none
    try {
      if (Array.isArray(idShops) && idShops.length) {
        const lit = idShops.map(n=>Number(n)||0).filter(n=>n>0).join(',');
        const sql = `SELECT id_shop FROM \`${p}shop\` WHERE id_shop IN (${lit || '0'})`;
        const [rowsShop] = await conn.execute(sql);
        const found = new Set((Array.isArray(rowsShop)? rowsShop: []).map(r=>Number(r.id_shop||0)).filter(n=>n>0));
        idShops = idShops.filter(s => found.has(Number(s)));
        if (!idShops.length) { idShops = [idShopDefault || 1]; }
        idShopDefault = idShops[0] || 1;
      }
    } catch {}

    // Ensure category is mapped to each shop so product_shop upserts don't trip FK/consistency constraints
    try { for (const s of idShops) { await conn.execute(`INSERT IGNORE INTO \`${p}category_shop\` (id_category,id_shop,position) VALUES (?,?,0)`, [idCategory, s]); } } catch {}

    await conn.beginTransaction();
    // If idProduct not provided, try find by reference first
    if (!idProduct && reference) {
      try {
        // Prefer the most recently created product when multiple share the same reference
        const [rows] = await conn.execute(`SELECT id_product FROM \`${p}product\` WHERE reference=? ORDER BY id_product DESC LIMIT 1`, [reference]);
        if (Array.isArray(rows) && rows.length) idProduct = Number(rows[0].id_product)||0;
      } catch {}
    }

    if (!idProduct) {
      // Create new product
      const [insProd] = await conn.execute(`INSERT INTO \`${p}product\` (id_manufacturer,id_category_default,id_shop_default,reference,price,id_tax_rules_group,active,date_add,date_upd,isbn,upc,ean13,mpn) VALUES (?,?,?,?,?,?,?,NOW(),NOW(),?,?,?,?)`, [0, idCategory, idShopDefault, reference, price, taxGroupId, activeFlag, '', '', '', '']);
      idProduct = insProd.insertId;
      for (const s of idShops) { await conn.execute(`INSERT INTO \`${p}product_shop\` (id_product,id_shop,id_category_default,price,active,visibility,id_tax_rules_group,date_upd,date_add) VALUES (?,?,?,?,?,?,?,NOW(),NOW())`, [idProduct, s, idCategory, price, activeFlag, visibility, taxGroupId]); }
      // product_lang
      let hasIdShop = false; try { const [cols] = await conn.execute(`SHOW COLUMNS FROM \`${p}product_lang\``); hasIdShop = Array.isArray(cols) && cols.some(c => (c.Field||c.COLUMN_NAME) === 'id_shop'); } catch {}
      if (hasIdShop) { for (const s of idShops) await conn.execute(`INSERT INTO \`${p}product_lang\` (id_product,id_shop,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?,?)`, [idProduct, s, idLang, name, description, '', name.toLowerCase().replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'').slice(0,128)||'imported-product']); }
      else await conn.execute(`INSERT INTO \`${p}product_lang\` (id_product,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?)`, [idProduct, idLang, name, description, '', name.toLowerCase().replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'').slice(0,128)||'imported-product']);
      // stock + category
      for (const s of idShops) await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, 0, s, 0]);
      await conn.execute(`INSERT INTO \`${p}category_product\` (id_category,id_product,position) VALUES (?,?,0)`, [idCategory, idProduct]);
      await conn.commit();
      // Optional: run shell permission fixer after successful resend
      try {
        if (String(process.env.PRESTA_PERMS_SH||'') === '1') {
          const root = String(process.env.PRESTA_ROOT||'').trim();
          const shPath = path.join(__dirname, 'scripts', 'presta-fix-perms.sh');
          if (root && fs.existsSync(shPath)) {
          const { exec } = await import('child_process');
          const cmd2 = `bash -lc 'PRESTA_ROOT="${root.replace(/'/g, "'\\''")}" "${shPath}"'`;
          exec(cmd2, { env: { ...process.env, PRESTA_ROOT: root } }, (err, stdout, stderr) => {
            try { logToFile(`[presta:perms:resend] exit=${err? (err.code||1):0} stdout=${String(stdout||'').trim()} stderr=${String(stderr||'').trim()}`); } catch {}
          });
          }
        }
      } catch {}
    } else {
      // Update existing product
      await conn.execute(`UPDATE \`${p}product\` SET id_category_default=?, reference=?, price=?, id_tax_rules_group=?, active=?, date_upd=NOW() WHERE id_product=?`, [idCategory, reference, price, taxGroupId, activeFlag, idProduct]);
      // Ensure product_shop rows exist and upsert values per shop
      for (const s of idShops) {
        await conn.execute(
          `INSERT INTO \`${p}product_shop\` (id_product,id_shop,id_category_default,price,active,visibility,id_tax_rules_group,date_upd,date_add)
           VALUES (?,?,?,?,?,?,?,NOW(),NOW())
           ON DUPLICATE KEY UPDATE id_category_default=VALUES(id_category_default), price=VALUES(price), active=VALUES(active), visibility=VALUES(visibility), id_tax_rules_group=VALUES(id_tax_rules_group), date_upd=NOW()`,
          [idProduct, s, idCategory, price, activeFlag, visibility, taxGroupId]
        );
      }
      // product_lang update (shop-aware)
      let hasIdShop = false; try { const [cols] = await conn.execute(`SHOW COLUMNS FROM \`${p}product_lang\``); hasIdShop = Array.isArray(cols) && cols.some(c => (c.Field||c.COLUMN_NAME) === 'id_shop'); } catch {}
      if (hasIdShop) { for (const s of idShops) await conn.execute(`INSERT INTO \`${p}product_lang\` (id_product,id_shop,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name), description=VALUES(description), description_short=VALUES(description_short), link_rewrite=VALUES(link_rewrite)`, [idProduct, s, idLang, name, description, '', name.toLowerCase().replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'').slice(0,128)||'imported-product']); }
      else await conn.execute(`INSERT INTO \`${p}product_lang\` (id_product,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name), description=VALUES(description), description_short=VALUES(description_short), link_rewrite=VALUES(link_rewrite)`, [idProduct, idLang, name, description, '', name.toLowerCase().replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'').slice(0,128)||'imported-product']);
      // category mapping (ensure at least default)
      await conn.execute(`INSERT IGNORE INTO \`${p}category_product\` (id_category,id_product,position) VALUES (?,?,0)`, [idCategory, idProduct]);
      // Guard: if an error occurred so far (e.g., FK issues), abort early
      try {
        if (debugLog && Array.isArray(debugLog.error) && debugLog.error.length) {
          const first = debugLog.error[0];
          try { await conn.rollback(); } catch {}
          try { await conn.end(); } catch {}
          return res.status(500).json({ ok:false, error:'resend_failed', message: String(first||'SQL error'), debug_log: debugLog });
        }
      } catch {}
      await conn.commit();
    }

    // Upsert images from mapped/product_raw and write files + thumbnails
    try {
      const toAbsUrl = (u) => { try { const s=String(u||'').trim(); if (!s) return ''; if (/^https?:\/\//i.test(s)) return s; const base = publicBaseFromReq(req) || ''; return base ? new URL(s, base).toString() : s; } catch { return String(u||''); } };
      const root = String(process.env.PRESTA_ROOT || '').trim();
      if (!root) throw new Error('presta_root_missing');
      const makePath = (id) => { const parts = String(id).split(''); const dir = path.join(root, 'img', 'p', ...parts); const file = path.join(dir, `${id}.jpg`); return { dir, file }; };
      const http = await import('http');
      const https = await import('https');
      const copyToFile = async (src, dest) => new Promise((resolve) => {
        try {
          const done = (ok=false) => resolve(!!ok);
          const write = () => { try { const ws = fs.createWriteStream(dest); ws.on('finish', ()=>{ try{ const st=fs.statSync(dest); if (st.size>0) return done(true);}catch{} done(false); }); ws.on('error', ()=>done(false)); return ws; } catch { return null; } };
          const maxRedirects = 5; const srcStr = String(src||'');
          const tryLocalCopy = (pathname) => { try { const name = decodeURIComponent((pathname||'').split('/').pop()||''); if (!/^[A-Za-z0-9._%\-]+$/.test(name)) return false; const pth = path.join(grabbingJeromeDir, name); if (!fs.existsSync(pth)) return false; const rs = fs.createReadStream(pth); rs.on('error', ()=>done(false)); rs.on('open', ()=>{ const ws = write(); if (!ws) return done(false); rs.pipe(ws); }); return true; } catch { return false; } };
          if (/^\/?api\/grabbings\/jerome\/doc\//i.test(srcStr)) { if (tryLocalCopy(srcStr)) return; }
          if (/^https?:\/\//i.test(srcStr)) { try { const uo = new URL(String(srcStr)); if (/^\/api\/grabbings\/jerome\/doc\//i.test(uo.pathname)) { if (tryLocalCopy(uo.pathname)) return; } } catch {}
            const doGet = (u, n) => { try { const h = String(u).startsWith('https') ? https : http; const req2 = h.get(u, { headers:{'User-Agent':'Mozilla/5.0 (compatible; Livechat/1.0)'} }, (resp)=>{ const sc=Number(resp.statusCode||0); if (sc>=300 && sc<400 && resp.headers?.location && n<maxRedirects) { try{ resp.resume(); }catch{} let next=''; try{ next=new URL(resp.headers.location, u).toString(); } catch { next=resp.headers.location; } return doGet(next, n+1); } if (sc>=400) { try{ resp.resume(); }catch{} return done(false); } const ws = write(); if (!ws) { try{ resp.resume(); }catch{} return done(); } resp.pipe(ws); }); req2.on('error', ()=>done(false)); req2.setTimeout(20000, ()=>{ try{ req2.destroy(); }catch{} done(false); }); } catch { done(false); } };
            return doGet(srcStr, 0);
          }
          return done(false);
        } catch { resolve(false); }
      });
    const parseThumbFormats = () => { try { const envVal = String(process.env.PRESTA_THUMB_FORMATS || 'jpg,webp'); const list = envVal.split(',').map(s=>String(s||'').trim().toLowerCase()).filter(Boolean); const set=new Set(list); if (set.has('jpeg')) { set.delete('jpeg'); set.add('jpg'); } return Array.from(set.size?set:new Set(['jpg','webp'])); } catch { return ['jpg','webp']; } };
    const generatePrestaThumbnails = async (srcPath, outDir, idImage, formats, conn2, pfx2) => {
      try {
        let sharpMod=null; try { const m=await import('sharp'); sharpMod = m?.default || m; } catch {}
        if (!sharpMod) return;
        const fmts = Array.isArray(formats)&&formats.length? formats: parseThumbFormats();
        const wantJpg=fmts.includes('jpg'); const wantWebp=fmts.includes('webp');
        const [types] = await conn2.execute(`SELECT name,width,height FROM \`${pfx2}image_type\` WHERE products=1 ORDER BY name`);
        const tasks=[];
        for (const t of (Array.isArray(types)?types:[])) {
          const w=Number(t.width||0), h=Number(t.height||0);
          if (wantJpg) { const out=path.join(outDir, `${idImage}-${t.name}.jpg`); try { tasks.push(sharpMod(srcPath).resize(w, h, { fit:'contain', position:'centre', background:{ r:255, g:255, b:255, alpha:1 } }).flatten({ background:'#ffffff' }).jpeg({quality:85, mozjpeg:true}).toFile(out).then(()=>{ try{ fs.chmodSync(out,0o775);}catch{} try{ fs.chownSync(out,33,33);}catch{} }).catch(()=>{})); } catch {} }
          if (wantWebp) { const out=path.join(outDir, `${idImage}-${t.name}.webp`); try { tasks.push(sharpMod(srcPath).resize(w, h, { fit:'contain', position:'centre', background:{ r:255, g:255, b:255, alpha:1 } }).flatten({ background:'#ffffff' }).webp({quality:80}).toFile(out).then(()=>{ try{ fs.chmodSync(out,0o775);}catch{} try{ fs.chownSync(out,33,33);}catch{} }).catch(()=>{})); } catch {} }
        }
        await Promise.all(tasks);
        // Final sweep to ensure perms/owner
        try { const re=new RegExp(`^${idImage}-.*\\.(?:jpg|webp)$`,'i'); for(const f of fs.readdirSync(outDir)){ if(!re.test(f)) continue; const pth=path.join(outDir,f); try{ fs.chmodSync(pth,0o775);}catch{} try{ fs.chownSync(pth,33,33);}catch{} } } catch {}
      } catch {}
    };

      // Build image list (prefer mapped.images, fallback to product_raw.images_local, then product_raw.images)
      let imgs = [];
      try { if (Array.isArray(mapped?.images) && mapped.images.length) imgs = mapped.images.map(it => (typeof it==='string'? it : (it&&it.url)||'')).filter(Boolean); } catch {}
      try { if ((!imgs.length) && typeof productRaw === 'object' && Array.isArray(productRaw?.images_local)) { const files = productRaw.images_local.map(it=>{ try{ if (!it) return ''; const local = it.file ? path.join(grabbingJeromeDir, it.file):''; if (local && fs.existsSync(local)) return local; return toAbsUrl((it.url||it.href||it.download_url||'')||''); } catch { return ''; } }).filter(Boolean); imgs = files; } } catch {}
      try { if ((!imgs.length) && typeof productRaw === 'object' && Array.isArray(productRaw?.images)) imgs = productRaw.images.map(u=>String(u||'')).filter(Boolean); } catch {}
      imgs = imgs.map(toAbsUrl).filter(Boolean).slice(0, 12);

      // Load existing images
      const [existingImgRows] = await conn.execute(`SELECT id_image, position FROM \`${p}image\` WHERE id_product=? ORDER BY position ASC, id_image ASC`, [idProduct]);
      const existing = Array.isArray(existingImgRows) ? existingImgRows : [];
      let coverSet = existing.some((_,i)=> i===0);
      // Update existing
      for (let i=0;i<existing.length && i<imgs.length;i++) {
        const r = existing[i]; const url = String(imgs[i]||''); const idImage = r.id_image; const cover = (i===0)?1:null;
        try { await conn.execute(`UPDATE \`${p}image\` SET position=?, cover=? WHERE id_image=?`, [i+1, cover, idImage]); } catch {}
        for (const s of idShops) { try { await conn.execute(`INSERT INTO \`${p}image_shop\` (id_product,id_image,id_shop,cover) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE cover=VALUES(cover)`, [idProduct, idImage, s, cover]); } catch {} }
        try { await conn.execute(`INSERT IGNORE INTO \`${p}image_lang\` (id_image,id_lang,legend) VALUES (?,?,?)`, [idImage, idLang, '']); } catch {}
        const { dir, file } = makePath(idImage); try { fs.mkdirSync(dir, { recursive:true }); } catch {}
        try { fs.chmodSync(dir, 0o775); fs.chownSync(dir, 33, 33); } catch {}
        let ok = await copyToFile(url, file); let size=0; try{ size=fs.statSync(file).size||0;}catch{};
        try { fs.chmodSync(file, 0o775); fs.chownSync(file, 33, 33); } catch {}
        if (ok||size>0) { try { await generatePrestaThumbnails(file, dir, idImage, parseThumbFormats(), conn, p); } catch {} }
        if (cover && !coverSet) coverSet = true;
      }
      // Insert extra
      for (let i=existing.length;i<imgs.length;i++) {
        const url = String(imgs[i]||''); const cover = (i===0 && !coverSet)?1:null; const [insI] = await conn.execute(`INSERT INTO \`${p}image\` (id_product, position, cover) VALUES (?,?,?)`, [idProduct, i+1, cover]); const idImage = insI.insertId; for (const s of idShops) { try { await conn.execute(`INSERT INTO \`${p}image_shop\` (id_product,id_image,id_shop,cover) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE cover=VALUES(cover)`, [idProduct, idImage, s, cover]); } catch {} } try { await conn.execute(`INSERT INTO \`${p}image_lang\` (id_image,id_lang,legend) VALUES (?,?,?)`, [idImage, idLang, '']); } catch {}
        const { dir, file } = makePath(idImage); try { fs.mkdirSync(dir, { recursive:true }); } catch {}
        try { fs.chmodSync(dir, 0o775); fs.chownSync(dir, 33, 33); } catch {}
        let ok = await copyToFile(url, file); let size=0; try{ size=fs.statSync(file).size||0;}catch{};
        try { fs.chmodSync(file, 0o775); fs.chownSync(file, 33, 33); } catch {}
        if (ok||size>0) { try { await generatePrestaThumbnails(file, dir, idImage, parseThumbFormats(), conn, p); } catch {} }
      }
    } catch {}

    // Create or upsert combinations from mapped variants when provided
    try {
      const variants = Array.isArray(mapped?.variants) ? mapped.variants : [];
      if (variants.length) {
        // Fetch active languages for translating groups/values
        let activeLangIds = [idLang];
        try {
          const [langs] = await conn.execute(`SELECT id_lang FROM \`${p}lang\` WHERE active=1`);
          const ids = Array.isArray(langs) ? langs.map(r => Number(r.id_lang||0)).filter(n=>n>0) : [];
          if (ids.length) activeLangIds = ids;
        } catch {}
        // Ensure attribute group 'Variant'
        let idAttrGroup = 0;
        const [ag] = await conn.execute(`SELECT ag.id_attribute_group FROM \`${p}attribute_group_lang\` ag WHERE ag.name=? AND ag.id_lang=? LIMIT 1`, ['Variant', idLang]);
        if (ag && ag.length) { idAttrGroup = ag[0].id_attribute_group; }
        else {
          const [insG] = await conn.execute(`INSERT INTO \`${p}attribute_group\` (is_color_group, group_type, position) VALUES (0,'select',0)`);
          idAttrGroup = insG.insertId;
          for (const lid of activeLangIds) { try { await conn.execute(`INSERT INTO \`${p}attribute_group_lang\` (id_attribute_group,id_lang,name,public_name) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name), public_name=VALUES(public_name)`, [idAttrGroup, lid, 'Variant', 'Variant']); } catch {} }
          for (const s of idShops) { await conn.execute(`INSERT INTO \`${p}attribute_group_shop\` (id_attribute_group,id_shop) VALUES (?,?)`, [idAttrGroup, s]); }
        }
        // Ensure product marked as combinations
        try { await conn.execute(`UPDATE \`${pfx}product\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
        try { await conn.execute(`UPDATE \`${pfx}product_shop\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
        // Track default combination id to update cache_default_attribute
        let defaultPA0 = 0;
        // Load existing images to be able to associate variant images
        let imgRows = [];
        try { const [rowsImg] = await conn.execute(`SELECT id_image, position FROM \`${p}image\` WHERE id_product=? ORDER BY position ASC, id_image ASC`, [idProduct]); imgRows = Array.isArray(rowsImg)? rowsImg: []; } catch {}
        const mappedImages = (Array.isArray(mapped?.images) ? mapped.images.map(it => (typeof it === 'string' ? it : (it && it.url) || '')) : []).filter(Boolean);
        const norm = (u='') => { try { const x=new URL(String(u)); return (x.origin + x.pathname).toLowerCase(); } catch { return String(u||'').replace(/\?.*$/, '').toLowerCase(); } };
        const keyFrom = (u='') => { try { const s=String(u).split('?')[0]; const b=s.split('/').pop()||''; const noSize=b.replace(/([_-])\d+x\d+(?=\.[A-Za-z0-9]+$)/,''); return noSize.replace(/\.[A-Za-z0-9]+$/,'').toLowerCase(); } catch { return String(u||'').toLowerCase(); } };
        // Check if a default combination already exists (global flag on product_attribute)
        let hasDefault = false;
        try { const [r] = await conn.execute(`SELECT 1 FROM \`${p}product_attribute\` WHERE id_product=? AND default_on=1 LIMIT 1`, [idProduct]); hasDefault = Array.isArray(r) && r.length > 0; } catch {}
        // Also check per-shop default flags to avoid UNIQUE(id_product,id_shop,default_on) conflicts
        let defaultShops = new Set();
        try {
          const [rs] = await conn.execute(
            `SELECT DISTINCT pas.id_shop
               FROM \`${p}product_attribute_shop\` pas
               JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute = pas.id_product_attribute
              WHERE pa.id_product = ? AND pas.default_on = 1`,
            [idProduct]
          );
          if (Array.isArray(rs)) defaultShops = new Set(rs.map(r => Number(r.id_shop||0)).filter(n=>n>0));
        } catch {}
        // If no default yet, honor default_variant hints to pick default index
        let defaultIndex = 0;
        if (!hasDefault) {
          try {
            const wantSku = String(mapped?.default_variant_sku || mapped?.sku || '').trim();
            const wantIdRaw = mapped?.default_variant_id;
            const wantId = (wantIdRaw != null) ? Number(wantIdRaw) : NaN;
            const bySku = wantSku ? variants.findIndex(v => String(v?.sku||'').trim() === wantSku) : -1;
            const byId = Number.isFinite(wantId) ? variants.findIndex(v => Number(v?.id||NaN) === wantId) : -1;
            if (bySku >= 0) defaultIndex = bySku; else if (byId >= 0) defaultIndex = byId;
          } catch {}
        }
        for (let idx=0; idx<variants.length; idx++) {
          const v = variants[idx] || {};
          const title = String(v?.title || v?.sku || '').trim() || 'Default';
          const vSku = String(v?.sku || '').trim();
          let vPrice = 0;
          try { vPrice = (v && typeof v.price === 'object' && v.price && ('value' in v.price)) ? Number(v.price.value||0)||0 : Number(v?.price||0)||0; vPrice = normalizeMoney(vPrice); } catch { vPrice = 0; }
          const delta = Math.max(0, vPrice - price);
          // Build attribute pairs from explicit map when present, else fallback to single 'Variant' group
          const attrPairs = [];
          if (v && typeof v.attributes === 'object' && v.attributes) {
            for (const k of Object.keys(v.attributes)) {
              const gName = String(k||'').trim();
              const val = String(v.attributes[k]||'').trim();
              if (gName && val) attrPairs.push({ group: gName, value: val });
            }
          }
          if (!attrPairs.length) attrPairs.push({ group: 'Variant', value: title });
          // Ensure groups/values and collect attribute ids (re-use existing values when possible)
          const idAttrs = [];
          for (const pair of attrPairs) {
            let grpId = 0;
            const [gq] = await conn.execute(`SELECT ag.id_attribute_group FROM \`${p}attribute_group_lang\` ag WHERE ag.name=? AND ag.id_lang=? LIMIT 1`, [pair.group, idLang]);
            if (Array.isArray(gq) && gq.length) { grpId = gq[0].id_attribute_group; for (const lid of activeLangIds) { try { await conn.execute(`INSERT INTO \`${p}attribute_group_lang\` (id_attribute_group,id_lang,name,public_name) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name), public_name=VALUES(public_name)`, [grpId, lid, pair.group, pair.group]); } catch {} } }
            else {
              const [ig] = await conn.execute(`INSERT INTO \`${p}attribute_group\` (is_color_group, group_type, position) VALUES (0,'select',0)`);
              grpId = ig.insertId;
              for (const lid of activeLangIds) { try { await conn.execute(`INSERT INTO \`${p}attribute_group_lang\` (id_attribute_group,id_lang,name,public_name) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name), public_name=VALUES(public_name)`, [grpId, lid, pair.group, pair.group]); } catch {} }
              for (const s of idShops) { await conn.execute(`INSERT INTO \`${p}attribute_group_shop\` (id_attribute_group,id_shop) VALUES (?,?)`, [grpId, s]); }
            }
            // Reuse existing attribute value for this group when available; else create it
            let idAttr = 0;
            try {
              const [vr] = await conn.execute(`SELECT al.id_attribute FROM \`${p}attribute_lang\` al JOIN \`${p}attribute\` a ON a.id_attribute=al.id_attribute WHERE a.id_attribute_group=? AND al.id_lang=? AND al.name=? LIMIT 1`, [grpId, idLang, pair.value]);
              if (Array.isArray(vr) && vr.length) idAttr = Number(vr[0].id_attribute)||0;
            } catch {}
            if (!idAttr) {
              const [insA] = await conn.execute(`INSERT INTO \`${p}attribute\` (id_attribute_group, color, position) VALUES (?,?,0)`, [grpId, '']);
              idAttr = insA.insertId;
            }
            for (const lid of activeLangIds) { try { await conn.execute(`INSERT INTO \`${p}attribute_lang\` (id_attribute,id_lang,name) VALUES (?,?,?) ON DUPLICATE KEY UPDATE name=VALUES(name)`, [idAttr, lid, pair.value]); } catch {} }
            for (const s of idShops) { try { await conn.execute(`INSERT IGNORE INTO \`${p}attribute_shop\` (id_attribute,id_shop) VALUES (?,?)`, [idAttr, s]); } catch {} }
            idAttrs.push(idAttr);
          }
          // Upsert product_attribute row for this variant by (id_product, reference)
          const defOn = (!hasDefault && idx === defaultIndex) ? 1 : null;
          let idPA = 0;
          if (vSku) {
            try {
              const [rowsPA] = await conn.execute(`SELECT id_product_attribute FROM \`${p}product_attribute\` WHERE id_product=? AND reference=? LIMIT 1`, [idProduct, vSku]);
              if (Array.isArray(rowsPA) && rowsPA.length) idPA = Number(rowsPA[0].id_product_attribute)||0;
            } catch {}
          }
          if (idPA) {
            // Update price delta and default flag
            try { await conn.execute(`UPDATE \`${p}product_attribute\` SET price=?, default_on=? WHERE id_product_attribute=?`, [delta, defOn, idPA]); } catch {}
          } else {
            const [insPA] = await conn.execute(`INSERT INTO \`${p}product_attribute\` (id_product, reference, price, weight, default_on, ean13, upc, isbn) VALUES (?,?,?,?,?,?,?,?)`, [idProduct, vSku||'', delta, 0, defOn, '', '', '']);
            idPA = insPA.insertId;
          }
          for (const s of idShops) {
            const shopDef = (defOn === 1 && !defaultShops.has(Number(s))) ? 1 : null;
            await conn.execute(
              `INSERT INTO \`${p}product_attribute_shop\` (id_product,id_product_attribute,id_shop,price,default_on) VALUES (?,?,?,?,?)
               ON DUPLICATE KEY UPDATE price=VALUES(price), default_on=VALUES(default_on)` ,
              [idProduct, idPA, s, delta, shopDef]
            );
            if (shopDef === 1) defaultShops.add(Number(s));
          }
          if (defOn === 1 && !defaultPA0) defaultPA0 = idPA;
          for (const idAttr of idAttrs) {
            await conn.execute(`INSERT INTO \`${p}product_attribute_combination\` (id_attribute,id_product_attribute) VALUES (?,?) ON DUPLICATE KEY UPDATE id_attribute=VALUES(id_attribute)`, [idAttr, idPA]);
            // Attribute impact upsert
            try { await conn.execute(`INSERT INTO \`${p}attribute_impact\` (id_product,id_attribute,weight,price) VALUES (?,?,0,?) ON DUPLICATE KEY UPDATE price=VALUES(price), weight=VALUES(weight)`, [idProduct, idAttr, delta]); } catch {}
          }
          // stock_available rows
          await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1) ON DUPLICATE KEY UPDATE id_product=id_product`, [idProduct, idPA, 0, 0]);
          for (const s of idShops) { await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1) ON DUPLICATE KEY UPDATE id_product=id_product`, [idProduct, idPA, s, 0]); }
          // Minimal attribute language row
          try {
            for (const lid of (Array.isArray(activeLangIds)? activeLangIds : [idLang])) {
              try { await conn.execute(`INSERT IGNORE INTO \`${p}product_attribute_lang\` (id_product_attribute,id_lang,available_now,available_later) VALUES (?,?,NULL,NULL)`, [idPA, lid]); } catch {}
            }
          } catch {}
          // Associate variant image to combination if possible
          try {
            const vimg = String(v?.image||'');
            if (vimg && imgRows.length) {
              let j = mappedImages.findIndex(u => norm(u) === norm(vimg));
              if (j < 0) { const vk = keyFrom(vimg); j = mappedImages.findIndex(u => { const uk = keyFrom(u); return uk === vk || uk.includes(vk) || vk.includes(uk); }); }
              if (j >= 0 && imgRows[j] && imgRows[j].id_image) {
                const imgId = imgRows[j].id_image;
                await conn.execute(`INSERT IGNORE INTO \`${p}product_attribute_image\` (id_product_attribute,id_image) VALUES (?,?)`, [idPA, imgId]);
                try {
                  const legendVar = String(v?.title || v?.sku || mapped?.name || '').slice(0,128);
                  for (const lid of activeLangIds) { await conn.execute(`INSERT INTO \`${p}image_lang\` (id_image,id_lang,legend) VALUES (?,?,?) ON DUPLICATE KEY UPDATE legend=VALUES(legend)`, [imgId, lid, legendVar]); }
                } catch {}
              }
            }
          } catch {}
        }
        // Update product cache_default_attribute for BO visibility
        try { if (defaultPA0) await conn.execute(`UPDATE \`${p}product\` SET cache_default_attribute=? WHERE id_product=?`, [defaultPA0, idProduct]); } catch {}
        try { if (defaultPA0) await conn.execute(`UPDATE \`${p}product_shop\` SET cache_default_attribute=? WHERE id_product=?`, [defaultPA0, idProduct]); } catch {}
      }
    } catch {}

    // Update ready-transfer status+id_product if we have domain+url
    if (rawUrl) {
      try {
        const pool = await getPg();
        if (pool && !JEROME_STORAGE_DISABLED) {
          let domain = rawDomain;
          if (!domain && rawUrl) { try { const u = new URL(rawUrl); domain = (u.hostname||'').toLowerCase(); } catch {} }
          domain = (domain||'').toLowerCase().replace(/^www\./,'');
          await pool.query(
            `update public.grabbing_jerome_domains_url_ready_transfert set status='transferred', id_product=$3, notes=$4 where domain=$1 and lower(trim(both from url))=lower(trim(both from $2))`,
            [domain, rawUrl, idProduct, `id_product=${idProduct}`]
          );
        }
      } catch {}
    }

    // Post counts for debug
    let postCounts = null;
    if (wantDebug) {
      let post_pa=0, post_pac=0, post_pai=0, post_pal=0, post_pas=0, post_stock_attr=0, post_images=0, post_image_lang=0, post_image_shop=0;
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute\` WHERE id_product=?`, [idProduct]); post_pa = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_combination\` pac JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pac.id_product_attribute WHERE pa.id_product=?`, [idProduct]); post_pac = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_image\` pai JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pai.id_product_attribute WHERE pa.id_product=?`, [idProduct]); post_pai = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_lang\` pal JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pal.id_product_attribute WHERE pa.id_product=?`, [idProduct]); post_pal = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}product_attribute_shop\` pas JOIN \`${p}product_attribute\` pa ON pa.id_product_attribute=pas.id_product_attribute WHERE pa.id_product=?`, [idProduct]); post_pas = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}stock_available\` WHERE id_product=? AND id_product_attribute>0`, [idProduct]); post_stock_attr = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}image\` WHERE id_product=?`, [idProduct]); post_images = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}image_lang\` WHERE id_image IN (SELECT id_image FROM \`${p}image\` WHERE id_product=?)`, [idProduct]); post_image_lang = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      try { const [r]=await conn.execute(`SELECT COUNT(*) AS c FROM \`${p}image_shop\` WHERE id_image IN (SELECT id_image FROM \`${p}image\` WHERE id_product=?)`, [idProduct]); post_image_shop = Number((Array.isArray(r)&&r[0]?.c)||0); } catch {}
      postCounts = { pa: post_pa, pac: post_pac, pai: post_pai, pal: post_pal, pas: post_pas, stock_attr: post_stock_attr, images: post_images, image_lang: post_image_lang, image_shop: post_image_shop };
    }

    const baseOut = { ok:true, id_product: idProduct, action: (body.id_product? 'updated' : (idProduct? 'created_or_updated':'created')) };
    try {
      const set = new Set();
      for (const q of (debugLog.queries||[])) {
        const m = String(q.sql||'').match(/`([a-z0-9_]+)`/ig) || [];
        for (const n of m) { const t = n.replace(/`/g,''); if (t) set.add(t); }
      }
      debugLog.tables = Array.from(set);
      debugLog.data = {
        action: baseOut.action,
        id_product: idProduct,
        mapped_summary: {
          name: String(mapped?.name||''),
          sku: String(mapped?.sku||''),
          price: Number(mapped?.price||0)||0,
          currency: String(mapped?.currency||'')
        },
        id_lang: idLang,
        id_shops: idShops,
        cleanup_pre: preCounts,
        cleanup_post: postCounts
      };
    } catch {}
    try { await conn.end(); } catch {}
    return res.json({ ...baseOut, debug_log: debugLog });
  } catch (e) {
    try { if (conn) await conn.rollback(); } catch {}
    try { if (conn) await conn.end(); } catch {}
    return res.status(500).json({ ok:false, error:'resend_product_failed', message: e?.message || String(e) });
  }
});

// Serve saved discovery/extract JSON files
app.get('/api/grabbings/jerome/file/:name', async (req, res) => {
  const name = String(req.params?.name||'');
  if (!/^[A-Za-z0-9._%\-]+$/.test(name)) return res.status(400).end('bad_name');
  // Try DB first (new: grabbing_jerome_extracts.json_data)
  try {
    const pool = await getPg();
    if (pool && !JEROME_STORAGE_DISABLED) {
      const r = await pool.query('select json_data from grabbing_jerome_extracts where file_name=$1 limit 1', [name]);
      if (r.rows.length && r.rows[0].json_data) {
        const buf = Buffer.from(JSON.stringify(r.rows[0].json_data, null, 2));
        res.setHeader('Content-Type', 'application/json; charset=utf-8');
        res.setHeader('Content-Length', String(buf.length));
        return res.end(buf);
      }
    }
  } catch {}
  // Fallback to filesystem for older entries
  const p = path.join(grabbingJeromeDir, name);
  try {
    const st = fs.statSync(p);
    res.setHeader('Content-Type', 'application/json; charset=utf-8');
    res.setHeader('Content-Length', String(st.size));
    fs.createReadStream(p).pipe(res);
  } catch { res.status(404).end('not_found'); }
});

// Delete a discovery/extract JSON file
app.delete('/api/grabbings/jerome/file/:name', (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  const name = String(req.params?.name||'');
  // DB-backed delete for discovery export names: grabbing-jerome-db-<id>.json
  const m = /^grabbing-jerome-db-(\d+)\.json$/i.exec(name);
  if (m) {
    (async () => {
      try {
        const pool = await getPg();
        if (!pool) return res.status(404).json({ ok:false, error:'not_found' });
        const id = Number(m[1]);
        await pool.query('delete from grabbing_jerome_discover where id=$1', [id]);
        return res.json({ ok:true, deleted: name });
      } catch (e) { return res.status(500).json({ ok:false, error:'delete_failed', message: e?.message || String(e) }); }
    })();
    return;
  }
  if (!/^[A-Za-z0-9._%\-]+$/.test(name) || !/\.json$/i.test(name)) return res.status(400).json({ ok:false, error:'bad_name' });
  const p = path.join(grabbingJeromeDir, name);
  try { fs.unlinkSync(p); return res.json({ ok:true, deleted: name }); }
  catch (e) { return res.status(404).json({ ok:false, error:'not_found', message: e?.message || 'not_found' }); }
});

// Simple Jerome product extractor (baseline implementation)
// POST /api/grabbings/jerome/extract { url, debug?, snapshot_html?, download_images?, download_documents? }
// Returns: { ok, file, download_url, data, steps? }
app.post('/api/grabbings/jerome/extract', async (req, res) => {
  try {
    const body = req.body || {};
    const url = String(body.url || '').trim();
    if (!/^https?:\/\//i.test(url)) return res.status(400).json({ ok:false, error:'bad_url' });

    const steps = [];
    const step = (m) => { steps.push(m); try { logToFile(`[jerome:extract] ${m}`); } catch {} };
    step(`fetch_start ${url}`);

    let html = '';
    try {
      const r = await fetch(url, { redirect:'follow' });
      html = await r.text();
      step(`fetch_ok status=${r.status} length=${html?.length||0}`);
    } catch (e) {
      step(`fetch_failed ${e?.message||e}`);
      return res.status(500).json({ ok:false, error:'fetch_failed', message:String(e?.message||e), steps });
    }

    const absUrl = (u) => { try { return new URL(u, url).toString(); } catch { return u; } };
    const findMeta = (nameOrProp) => {
      const re = new RegExp(`<meta[^>]+(?:name|property)=[\"\']${nameOrProp}[\"\'][^>]*content=[\"\']([^\"\']+)[\"\'][^>]*>`, 'i');
      const m = re.exec(html); return m && m[1] ? m[1].trim() : '';
    };

    // Title and OG fallbacks
    let title = '';
    try { const m = /<title[^>]*>([\s\S]*?)<\/title>/i.exec(html); title = (m && m[1]) ? m[1].trim() : ''; } catch {}
    const ogTitle = findMeta('og:title'); if (!title && ogTitle) title = ogTitle;

    // Parse JSON-LD blocks to find Product info
    const product = {};
    const docs = [];
    try {
      const ldMatches = [...html.matchAll(/<script[^>]+type=[\"\']application\/ld\+json[\"\'][^>]*>([\s\S]*?)<\/script>/gi)];
      for (const m of ldMatches) {
        let jsonText = (m[1]||'').trim();
        // Remove HTML comments inside script if any
        jsonText = jsonText.replace(/<!--|-->/g,'');
        try {
          const obj = JSON.parse(jsonText);
          const items = Array.isArray(obj) ? obj : (obj && obj['@graph'] ? obj['@graph'] : [obj]);
          for (const it of items) {
            const type = (Array.isArray(it?.['@type']) ? it['@type'][0] : it?.['@type'] || '').toString().toLowerCase();
            if (type === 'product') {
              if (it.name && !product.name) product.name = String(it.name);
              if (it.sku && !product.sku) product.sku = String(it.sku);
              if (it.image) {
                const imgs = Array.isArray(it.image) ? it.image : [it.image];
                product.images = (product.images||[]).concat(imgs.map(absUrl)).filter(Boolean);
              }
              const offers = Array.isArray(it.offers) ? it.offers[0] : it.offers;
              if (offers) {
                const price = Number(offers.price || offers.priceSpecification?.price || 0);
                if (price) product.price = price;
                const cur = offers.priceCurrency || offers.priceSpecification?.priceCurrency;
                if (cur) product.currency = String(cur);
              }
            }
          }
        } catch (e) { step(`jsonld_parse_warn ${e?.message||e}`); }
      }
    } catch {}

    // OG image fallback
    if (!product.images || !product.images.length) {
      const ogImg = findMeta('og:image'); if (ogImg) product.images = [absUrl(ogImg)];
    }

    // Basic document detection (.pdf, .docx, .xlsx, .zip)
    try {
      const docMatches = [...html.matchAll(/<a[^>]+href=[\"\']([^\"\']+\.(?:pdf|doc|docx|xls|xlsx|zip))(?:\?[^\"\']*)?[\"\'][^>]*>([\s\S]*?)<\/a>/gi)];
      for (const m of docMatches) {
        const u = absUrl(m[1]);
        let text = m[2] ? String(m[2]).replace(/<[^>]+>/g,'').trim() : '';
        if (!text) { try { text = new URL(u).pathname.split('/').pop(); } catch { text = u; } }
        if (u) docs.push({ url: u, text });
      }
    } catch {}

    // Price meta fallbacks
    if (!product.price) {
      const pMeta = findMeta('product:price:amount');
      const v = Number(pMeta); if (v) product.price = v;
    }
    if (!product.currency) {
      const cMeta = findMeta('product:price:currency'); if (cMeta) product.currency = cMeta;
    }

    const now = new Date();
    const safeHost = (()=>{ try { return new URL(url).hostname.replace(/[^a-z0-9.-]/gi,'_'); } catch { return 'page'; } })();
    const fname = `jerome-extract-${safeHost}-${now.toISOString().replace(/[:.]/g,'-')}.json`;
    const fpath = path.join(grabbingJeromeDir, fname);
    const data = {
      page: { url },
      meta: { title },
      product,
      documents: docs,
    };
    try { fs.writeFileSync(fpath, JSON.stringify(data, null, 2), 'utf8'); step(`saved_json ${fname}`); }
    catch (e) { step(`save_failed ${e?.message||e}`); return res.status(500).json({ ok:false, error:'save_failed', message:String(e?.message||e), steps }); }
    // Insert metadata row into PostgreSQL if enabled
    try {
      const pool = await getPg();
      if (pool) {
        const stats = fs.statSync(fpath);
        await pool.query('insert into grabbing_jerome_extracts(file_name,mtime,size,download_url,product_url,price,currency,image,declinaison) values($1,$2,$3,$4,$5,$6,$7,$8,$9)', [fname, new Date(), Number(stats.size||0), `/api/grabbings/jerome/file/${encodeURIComponent(fname)}`, (data?.page?.url||data?.meta?.url||''), (product?.price||null), (product?.currency||null), (Array.isArray(product?.images)&&product.images[0])||null, (product?.sku?`SKU: ${product.sku}`:null)]);
      }
    } catch (e) { try { step(`pg_meta_warn ${e?.message||e}`); } catch {} }

    const download_url = `/api/grabbings/jerome/file/${encodeURIComponent(fname)}`;
    return res.json({ ok:true, file: fname, download_url, data, steps });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'extract_failed', message: String(e?.message||e) });
  }
});

// === Jerome Queue API ===
function loadJeromeQueue() {
  try {
    const txt = fs.readFileSync(grabbingJeromeQueueFile, 'utf8');
    const arr = JSON.parse(txt||'[]');
    return Array.isArray(arr) ? arr : [];
  } catch { return []; }
}
function saveJeromeQueue(items) {
  try { fs.writeFileSync(grabbingJeromeQueueFile, JSON.stringify(Array.isArray(items)? items: [], null, 2)); } catch {}
}
const newId = () => 'jq_' + Math.random().toString(36).slice(2) + Date.now().toString(36);

// GET current queue
app.get('/api/grabbings/jerome/queue', async (_req, res) => {
  try {
    const pool = await getPg();
    if (pool) {
      const { rows } = await pool.query('select id,url,status,added_at from grabbing_jerome_queue order by added_at desc limit 500');
      return res.json({ ok:true, items: rows });
    }
    const items = loadJeromeQueue();
    return res.json({ ok:true, items });
  } catch (e) { return res.status(500).json({ ok:false, error:'queue_list_failed', message:String(e?.message||e) }); }
});

// POST add to queue (accepts { urls: string[] } or { urls: [{url, added_at}] })
app.post('/api/grabbings/jerome/queue', async (req, res) => {
  try {
    const body = req.body || {};
    let urls = body.urls || [];
    if (!Array.isArray(urls)) urls = [];
    const nowIso = new Date().toISOString();
    const pool = await getPg();
    if (pool) {
      let added = 0;
      for (const u of urls) {
        const url = typeof u === 'string' ? u : (u && u.url);
        if (!url) continue;
        try {
          await pool.query('insert into grabbing_jerome_queue(id,url,status,added_at) values($1,$2,$3,$4) on conflict (id) do nothing', [newId(), url, 'pending', (u && u.added_at) || nowIso]);
          added++;
        } catch {}
      }
      const { rows } = await pool.query('select id,url,status,added_at from grabbing_jerome_queue order by added_at desc limit 500');
      return res.json({ ok:true, added_count: added, items: rows });
    }
    const queue = loadJeromeQueue();
    const existing = new Set(queue.map(x => (x && x.url ? String(x.url) : '')));
    let added = 0;
    for (const u of urls) {
      const url = typeof u === 'string' ? u : (u && u.url);
      if (!url || existing.has(url)) continue;
      queue.push({ id: newId(), url, status: 'pending', added_at: (u && u.added_at) || nowIso });
      existing.add(url); added++;
    }
    saveJeromeQueue(queue);
    return res.json({ ok:true, added_count: added, items: queue });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'queue_add_failed', message: e?.message || String(e) });
  }
});

// Alias POST /queue/add -> same as /queue
app.post('/api/grabbings/jerome/queue/add', (req, res) => {
  // Delegate by calling the handler above
  req.url = '/api/grabbings/jerome/queue';
  return app._router.handle(req, res, () => {});
});

// DELETE remove from queue by id
app.delete('/api/grabbings/jerome/queue/:id', async (req, res) => {
  try {
    const id = String(req.params?.id || '');
    const pool = await getPg();
    if (pool) {
      const r = await pool.query('delete from grabbing_jerome_queue where id=$1', [id]);
      const { rows } = await pool.query('select id,url,status,added_at from grabbing_jerome_queue order by added_at desc limit 500');
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, removed_id: id, items: rows });
    }
    let queue = loadJeromeQueue();
    const before = queue.length;
    queue = queue.filter(x => String(x?.id||'') !== id);
    if (queue.length === before) return res.status(404).json({ ok:false, error:'not_found' });
    saveJeromeQueue(queue);
    return res.json({ ok:true, removed_id: id, items: queue });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'queue_delete_failed', message: e?.message || String(e) });
  }
});

// ===== PrestaShop MariaDB connection: base config (single) =====
app.get('/api/admin/presta-db', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    const raw = await getSetting('PRESTA_DB_JSON');
    let conf = null; try { conf = raw ? JSON.parse(raw) : null; } catch {}
    const reveal = String(req.query?.reveal||'') === '1';
    if (conf) {
      if (reveal) {
        // return password as-is for admin explicit reveal
        conf = { ...conf, has_password: !!conf.password };
      } else {
        conf = { ...conf, has_password: !!conf.password, password: undefined };
      }
    }
    return res.json({ ok:true, config: conf });
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

app.post('/api/admin/presta-db', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    const b = req.body || {};
    // Preserve existing password if none provided (or empty string)
    let prev = null;
    try { const rawPrev = await getSetting('PRESTA_DB_JSON'); prev = rawPrev ? JSON.parse(rawPrev) : null; } catch {}
    const incomingPwd = b.password;
    const keepPrevPassword = (incomingPwd === undefined || String(incomingPwd).trim() === '');
    const finalPassword = keepPrevPassword ? (prev?.password || '') : String(incomingPwd).trim();
    const cfg = {
      host: String(b.host||'').trim(),
      port: Number(b.port||3306),
      user: String(b.user||'').trim(),
      password: finalPassword,
      database: String(b.database||'').trim(),
      table_prefix: String(b.table_prefix||'').trim(),
      default_category_id: Number(b.default_category_id||0),
      default_lang_id: Number(b.default_lang_id||1),
      default_shop_ids: Array.isArray(b.default_shop_ids) ? b.default_shop_ids.map(n=>Number(n)).filter(n=>!isNaN(n)&&n>0) : String(b.default_shop_ids||'1').split(',').map(s=>Number(s.trim())).filter(n=>!isNaN(n)&&n>0),
      default_shop_id: Number(b.default_shop_id||0),
      default_tax_rules_group_id: Number(b.default_tax_rules_group_id||0),
      default_manufacturer_id: Number(b.default_manufacturer_id||0),
      default_supplier_id: Number(b.default_supplier_id||0),
      default_active: b.default_active ? 1 : 0,
      default_visibility: String(b.default_visibility||'both'),
    };
    if (!cfg.host || !cfg.user || !cfg.database) return res.status(400).json({ ok:false, error:'bad_request', message:'host, user, database required' });
    await setSetting('PRESTA_DB_JSON', JSON.stringify(cfg));
    const safe = { ...cfg, has_password: !!cfg.password, password: undefined };
    return res.json({ ok:true, config: safe });
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Test MariaDB connection (optional — does not save anything)
app.post('/api/admin/presta-db/test', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    let cfg = req.body && typeof req.body === 'object' ? req.body : {};
    // If not all fields are present, try active profile first, then base config
    const needs = !cfg || !cfg.host || !cfg.user || !cfg.database;
    if (needs) {
      try {
        const active = await getSetting('PRESTA_DB_ACTIVE');
        if (active) {
          const profilesRaw = await getSetting('PRESTA_DB_PROFILES');
          const profiles = profilesRaw ? JSON.parse(profilesRaw) : [];
          const p = Array.isArray(profiles) ? profiles.find(x => x && x.name === active) : null;
          if (p) cfg = { ...p, ...(cfg||{}) };
        }
      } catch {}
      if (!cfg || !cfg.host) {
        try {
          const baseRaw = await getSetting('PRESTA_DB_JSON');
          const base = baseRaw ? JSON.parse(baseRaw) : null;
          if (base) cfg = { ...base, ...(cfg||{}) };
        } catch {}
      }
    }
    // If password is still missing/empty, backfill it from active profile or base config
    if (!cfg || !cfg.host || !cfg.user || !cfg.database) {
      return res.status(400).json({ ok:false, error:'bad_request', message:'host, user, database required' });
    }
    if (!cfg.password) {
      try {
        const active = await getSetting('PRESTA_DB_ACTIVE');
        if (active) {
          const profilesRaw = await getSetting('PRESTA_DB_PROFILES');
          const profiles = profilesRaw ? JSON.parse(profilesRaw) : [];
          const p = Array.isArray(profiles) ? profiles.find(x => x && x.name === active) : null;
          if (p && p.password) cfg.password = p.password;
        }
      } catch {}
      if (!cfg.password) {
        try {
          const baseRaw = await getSetting('PRESTA_DB_JSON');
          const base = baseRaw ? JSON.parse(baseRaw) : null;
          if (base && base.password) cfg.password = base.password;
        } catch {}
      }
    }
    const mysql2 = await import('mysql2/promise');
    const conn = await mysql2.createConnection({ host: cfg.host, port: Number(cfg.port||3306), user: cfg.user, password: cfg.password, database: cfg.database });
    const [rows] = await conn.query('SELECT 1 AS ok');
    await conn.end();
    return res.json({ ok:true, result: rows && rows[0] ? rows[0].ok : 1 });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'connect_failed', message: e?.message || String(e) });
  }
});

// ===== Presta DB connection profiles (multi-connection) =====
async function getPrestaProfiles() {
  try {
    const raw = await getSetting('PRESTA_DB_PROFILES');
    const arr = raw ? JSON.parse(raw) : [];
    return Array.isArray(arr) ? arr : [];
  } catch { return []; }
}
async function setPrestaProfiles(items) {
  await setSetting('PRESTA_DB_PROFILES', JSON.stringify(Array.isArray(items)? items: []));
}

app.get('/api/admin/presta-db/profiles', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const items = await getPrestaProfiles();
    const active = await getSetting('PRESTA_DB_ACTIVE');
    const reveal = String(req.query?.reveal||'') === '1';
    const list = items.map(p => (reveal ? ({ ...p, has_password: !!p.password }) : ({ ...p, password: undefined, has_password: !!p.password })));
    res.json({ ok:true, items: list, active: active || null });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

app.post('/api/admin/presta-db/profile', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const b = req.body || {};
    const name = String(b.name||'').trim();
    if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });
    const items = await getPrestaProfiles();
    const idx = items.findIndex(x => x && x.name === name);
    const prev = idx>=0 ? items[idx] : null;
    const incomingPwd = b.password;
    const keepPrevPassword = (incomingPwd === undefined || String(incomingPwd).trim() === '');
    const finalPassword = keepPrevPassword ? (prev?.password || '') : String(incomingPwd).trim();
    const next = {
      name,
      host: String(b.host||'').trim(),
      port: Number(b.port||3306),
      user: String(b.user||'').trim(),
      // Preserve previous password if omitted or empty
      password: finalPassword,
      database: String(b.database||'').trim(),
      table_prefix: String(b.table_prefix||'').trim(),
      default_category_id: Number(b.default_category_id||0),
      default_lang_id: Number(b.default_lang_id||1),
      default_shop_ids: Array.isArray(b.default_shop_ids) ? b.default_shop_ids.map(n=>Number(n)).filter(n=>!isNaN(n)&&n>0) : String(b.default_shop_ids||'1').split(',').map(s=>Number(s.trim())).filter(n=>!isNaN(n)&&n>0),
      default_shop_id: Number(b.default_shop_id||0),
      default_tax_rules_group_id: Number(b.default_tax_rules_group_id||0),
      default_manufacturer_id: Number(b.default_manufacturer_id||0),
      default_supplier_id: Number(b.default_supplier_id||0),
      default_active: b.default_active ? 1 : 0,
      default_visibility: String(b.default_visibility||'both'),
    };
    if (idx>=0) items[idx] = next; else items.push(next);
    await setPrestaProfiles(items);
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

app.post('/api/admin/presta-db/profile/select', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const name = String(req.body?.name||'').trim();
    const items = await getPrestaProfiles();
    if (!items.find(x=>x && x.name===name)) return res.status(404).json({ ok:false, error:'not_found' });
    await setSetting('PRESTA_DB_ACTIVE', name);
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

app.delete('/api/admin/presta-db/profile/:name', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const name = String(req.params.name||'').trim();
    const items = await getPrestaProfiles();
    const next = items.filter(x => x && x.name !== name);
    await setPrestaProfiles(next);
    const active = await getSetting('PRESTA_DB_ACTIVE');
    if (active === name) await setSetting('PRESTA_DB_ACTIVE','');
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// ===== PrestaShop MariaDB connection settings (saved in settings table) =====
app.get('/api/admin/presta-db', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    undefined
    const mysql2 = await import('mysql2/promise');
    conn = await mysql2.createConnection({ host: conf.host, port: Number(conf.port||3306), user: conf.user, password: conf.password, database: conf.database, multipleStatements: true });
    const p = String(conf.table_prefix || 'ps_');
    // Shops and options
    let idShops = [];
    if (Array.isArray(input?.options?.id_shops)) idShops = input.options.id_shops.map(n=>Number(n)).filter(n=>!isNaN(n)&&n>0);
    if (!idShops.length) {
      try { const saved = JSON.parse(raw); if (Array.isArray(saved?.default_shop_ids)) idShops = saved.default_shop_ids.map(n=>Number(n)).filter(n=>!isNaN(n)&&n>0); } catch {}
    }
    if (!idShops.length) idShops = [Number(input?.options?.id_shop||1)];
    const idShopDefault = idShops[0] || 1;
    const idLang = Number(input?.options?.id_lang || 1);
    const taxGroupId = Number(input?.options?.tax_rules_group_id ?? (conf.default_tax_rules_group_id ?? 0)) || 0;
    const activeFlag = (input?.options?.active ?? conf.default_active ?? 1) ? 1 : 0;
    const visibility = String(input?.options?.visibility || conf.default_visibility || 'both');
    const name = String(data?.product?.name || data?.meta?.title || '').trim().slice(0, 255) || 'Imported Product';
    const description = String(data?.product?.description || '').trim();
    const reference = String(data?.product?.sku || '').trim().slice(0, 64) || '';
    const price = Number(data?.product?.price || 0) || 0;
    const brandName = String(data?.product?.brand || '').trim().slice(0, 64);
    const slugify = (s) => (s||'').toLowerCase().normalize('NFD').replace(/[\u0300-\u036f]/g,'').replace(/[^a-z0-9]+/g,'-').replace(/(^-|-$)/g,'').slice(0,128) || 'imported-product';
    const linkRewrite = slugify(name);
    const breadcrumbs = Array.isArray(data?.product?.breadcrumbs) ? data.product.breadcrumbs : [];
    const catName = String(breadcrumbs[breadcrumbs.length-1]?.name || '').trim();
    const defaultCatName = catName || 'Imported';

    await conn.beginTransaction();

    // Ensure manufacturer
    let idManufacturer = 0;
    if (brandName) {
      const [rowsM] = await conn.execute(`SELECT id_manufacturer FROM \`${p}manufacturer\` WHERE name = ? LIMIT 1`, [brandName]);
      if (rowsM && rowsM.length) idManufacturer = rowsM[0].id_manufacturer;
      else {
        const [r] = await conn.execute(`INSERT INTO \`${p}manufacturer\` (name, active, date_add, date_upd) VALUES (?,?,NOW(),NOW())`, [brandName, 1]);
        idManufacturer = r.insertId || 0;
      }
    }

    // Resolve category: prefer explicit option, then saved default, then Home (2) or create by name
    let idCategory = Number(input?.options?.category_id || 0);
    if (!idCategory) {
      try {
        const savedRaw = await getSetting('PRESTA_DB_JSON');
        const saved = savedRaw ? JSON.parse(savedRaw) : {};
        if (saved && saved.default_category_id) idCategory = Number(saved.default_category_id)||0;
      } catch {}
    }
    if (!idCategory) {
      idCategory = 2; // Home
      try {
        const [chk] = await conn.execute(`SELECT id_category FROM \`${p}category\` WHERE id_category = 2 LIMIT 1`);
        if (!chk || !chk.length) idCategory = 0;
      } catch {}
    }
    if (!idCategory) {
      let existing = null;
      try { const [r] = await conn.execute(`SELECT c.id_category FROM \`${p}category\` c JOIN \`${p}category_lang\` l ON l.id_category=c.id_category AND l.id_lang=? WHERE l.name=? LIMIT 1`, [idLang, defaultCatName]); existing = r && r[0]; } catch {}
      if (existing) idCategory = existing.id_category;
      else {
        const [insCat] = await conn.execute(`INSERT INTO \`${p}category\` (id_parent, level_depth, active, date_add, date_upd) VALUES (1, 2, 1, NOW(), NOW())`);
        idCategory = insCat.insertId;
        try { await conn.execute(`INSERT INTO \`${p}category_shop\` (id_category,id_shop,position) VALUES (?,?,0)`, [idCategory, idShop]); } catch {}
        try { await conn.execute(`INSERT INTO \`${p}category_lang\` (id_category,id_lang,name,link_rewrite) VALUES (?,?,?,?)`, [idCategory, idLang, defaultCatName, slugify(defaultCatName)]); } catch {}
      }
    }

    // Insert product core rows
    const [insProd] = await conn.execute(`INSERT INTO \`${p}product\` (id_manufacturer, id_category_default, id_shop_default, reference, price, id_tax_rules_group, active, date_add, date_upd, isbn, upc, ean13, mpn) VALUES (?,?,?,?,?,?,?,NOW(),NOW(),?,?,?,?)`, [idManufacturer||0, idCategory||2, idShopDefault, reference, price, taxGroupId, activeFlag, '', '', '', '']);
    const idProduct = insProd.insertId;

    // product_shop for each shop
    for (const s of idShops) {
      await conn.execute(`INSERT INTO \`${p}product_shop\` (id_product,id_shop,id_category_default,price,active,visibility,id_tax_rules_group,date_upd,date_add) VALUES (?,?,?,?,?,?,?,NOW(),NOW())`, [idProduct, s, idCategory||2, price, activeFlag, visibility, taxGroupId]);
    }

    // Insert product_lang per shop if table has id_shop column; else without id_shop
    let productLangHasIdShop = false;
    try {
      const [cols] = await conn.execute(`SHOW COLUMNS FROM \`${p}product_lang\``);
      productLangHasIdShop = Array.isArray(cols) && cols.some(c => (c.Field||c.COLUMN_NAME) === 'id_shop');
    } catch {}
    const insertLangRow = async (prodId, langId, shopId) => {
      const vals = [prodId, langId, name, description, '', linkRewrite];
      if (productLangHasIdShop) {
        await conn.execute(`INSERT INTO \`${p}product_lang\` (id_product,id_shop,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?,?)`, [prodId, shopId, langId, name, description, '', linkRewrite]);
      } else {
        await conn.execute(`INSERT INTO \`${p}product_lang\` (id_product,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?)`, vals);
      }
    };
    // Requested language rows
    if (productLangHasIdShop) {
      for (const s of idShops) { await insertLangRow(idProduct, idLang, s); }
    } else {
      await insertLangRow(idProduct, idLang, 0);
    }
    // Ensure product_lang rows exist for all active languages across selected shops
    try {
      const [langs] = await conn.execute(`SELECT id_lang FROM \`${p}lang\` WHERE active = 1`);
      for (const row of (langs||[])) {
        const lid = Number(row.id_lang);
        if (!lid) continue;
        if (productLangHasIdShop) {
          for (const s of idShops) {
            const [exists] = await conn.execute(`SELECT 1 FROM \`${p}product_lang\` WHERE id_product=? AND id_lang=? AND id_shop=? LIMIT 1`, [idProduct, lid, s]);
            if (!exists || !exists.length) {
              await conn.execute(`INSERT INTO \`${p}product_lang\` (id_product,id_shop,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?,?)`, [idProduct, s, lid, name || 'Imported Product', description || '', '', linkRewrite || 'imported-product']);
            }
          }
        } else {
          const [exists] = await conn.execute(`SELECT 1 FROM \`${p}product_lang\` WHERE id_product=? AND id_lang=? LIMIT 1`, [idProduct, lid]);
          if (!exists || !exists.length) {
            await conn.execute(`INSERT INTO \`${p}product_lang\` (id_product,id_lang,name,description,description_short,link_rewrite) VALUES (?,?,?,?,?,?)`, [idProduct, lid, name || 'Imported Product', description || '', '', linkRewrite || 'imported-product']);
          }
        }
      }
    } catch {}

    // Resolve id_shop_group per shop for stock_available
    const shopGroups = new Map();
    try {
      if (idShops.length) {
        const placeholders = idShops.map(()=>'?').join(',');
        const [sgRows] = await conn.execute(`SELECT id_shop, id_shop_group FROM \`${p}shop\` WHERE id_shop IN (${placeholders})`, idShops);
        for (const r of (sgRows||[])) shopGroups.set(Number(r.id_shop), Number(r.id_shop_group||0));
      }
    } catch {}
    // stock_available: global (id_shop=0,id_shop_group=0) and per shop entries with id_shop_group
    await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, 0, 0, 0]);
    for (const s of idShops) {
      const sg = shopGroups.get(s) || 0;
      await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, 0, s, sg]);
    }

    await conn.execute(`INSERT IGNORE INTO \`${p}category_product\` (id_category,id_product,position) VALUES (?,?,0)`, [idCategory||2, idProduct]);
    for (const s of idShops) {
      try { await conn.execute(`INSERT IGNORE INTO \`${p}category_shop\` (id_category,id_shop,position) VALUES (?,?,0)`, [idCategory||2, s]); } catch {}
    }

    // Create variants/combinations in Presta from mapped input variants (preferred)
    let createdFromMapped = false;
    try {
      const vIn = Array.isArray(data?.product?.variants) ? data.product.variants : [];
      if (vIn.length) {
        // Money normalizer
        const normalizeMoney = (n) => { const x = Number(n); if (!Number.isFinite(x)) return 0; return ((Number.isInteger(x) && x >= 100) || x >= 1000) ? Math.round((x/100)*100)/100 : x; };
        // Ensure product_type is combinations before creating combinations (best-effort)
        try { await conn.execute(`UPDATE \`${pfx}product\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
        try { await conn.execute(`UPDATE \`${pfx}product_shop\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
        let isFirstVar = true;
        let defaultPA = 0;
        for (const v of vIn) {
          const title = String(v?.title || v?.sku || '').trim() || 'Default';
          const vSku = String(v?.sku || '').trim();
          let vPrice = 0; try { vPrice = (v && typeof v.price === 'object' && v.price && ('value' in v.price)) ? Number(v.price.value||0)||0 : Number(v?.price||0)||0; vPrice = normalizeMoney(vPrice); } catch { vPrice = 0; }
          // Build attribute pairs from explicit map when available, else fallback to single "Variant"
          const attrPairs = [];
          if (v && typeof v.attributes === 'object' && v.attributes) {
            for (const k of Object.keys(v.attributes)) {
              const gName = String(k||'').trim();
              const val = String(v.attributes[k]||'').trim();
              if (gName && val) attrPairs.push({ group: gName, value: val });
            }
          }
          if (!attrPairs.length) attrPairs.push({ group: 'Variant', value: title });
          // Ensure groups/values and collect attribute ids
          const idAttrs = [];
          for (const pair of attrPairs) {
            let grpId = 0;
            const [gq] = await conn.execute(`SELECT ag.id_attribute_group FROM \`${p}attribute_group_lang\` ag WHERE ag.name=? AND ag.id_lang=? LIMIT 1`, [pair.group, idLang]);
            if (Array.isArray(gq) && gq.length) grpId = gq[0].id_attribute_group; else {
              const [ig] = await conn.execute(`INSERT INTO \`${p}attribute_group\` (is_color_group, group_type, position) VALUES (0,'select',0)`);
              grpId = ig.insertId;
              await conn.execute(`INSERT INTO \`${p}attribute_group_lang\` (id_attribute_group,id_lang,name,public_name) VALUES (?,?,?,?)`, [grpId, idLang, pair.group, pair.group]);
              for (const s of idShops) { await conn.execute(`INSERT INTO \`${p}attribute_group_shop\` (id_attribute_group,id_shop) VALUES (?,?)`, [grpId, s]); }
            }
            let idAttr = 0;
            const [av] = await conn.execute(`SELECT a.id_attribute FROM \`${p}attribute_lang\` al JOIN \`${p}attribute\` a ON a.id_attribute=al.id_attribute WHERE al.name=? AND al.id_lang=? LIMIT 1`, [pair.value, idLang]);
            if (Array.isArray(av) && av.length) idAttr = av[0].id_attribute; else {
              const [insA] = await conn.execute(`INSERT INTO \`${p}attribute\` (id_attribute_group, color, position) VALUES (?,?,0)`, [grpId, '']);
              idAttr = insA.insertId;
              await conn.execute(`INSERT INTO \`${p}attribute_lang\` (id_attribute,id_lang,name) VALUES (?,?,?)`, [idAttr, idLang, pair.value]);
              for (const s of idShops) { await conn.execute(`INSERT IGNORE INTO \`${p}attribute_shop\` (id_attribute,id_shop) VALUES (?,?)`, [idAttr, s]); }
            }
            idAttrs.push(idAttr);
          }
          // Create product_attribute (combination) with delta price
          const delta = Math.max(0, (Number.isFinite(vPrice) ? vPrice : 0) - price);
          const defOn = isFirstVar ? 1 : null;
          const [insPA] = await conn.execute(`INSERT INTO \`${p}product_attribute\` (id_product, reference, price, weight, default_on, ean13, upc, isbn) VALUES (?,?,?,?,?,?,?,?)`, [idProduct, vSku||'', delta, 0, defOn, '', '', '']);
          const idPA = insPA.insertId;
          for (const s of idShops) {
            await conn.execute(`INSERT INTO \`${p}product_attribute_shop\` (id_product,id_product_attribute,id_shop,price,default_on) VALUES (?,?,?,?,?)`, [idProduct, idPA, s, delta, defOn]);
          }
          for (const idAttr of idAttrs) {
            await conn.execute(`INSERT INTO \`${p}product_attribute_combination\` (id_attribute,id_product_attribute) VALUES (?,?)`, [idAttr, idPA]);
            try { await conn.execute(`INSERT INTO \`${p}attribute_impact\` (id_product,id_attribute,weight,price) VALUES (?,?,0,?) ON DUPLICATE KEY UPDATE price=VALUES(price), weight=VALUES(weight)`, [idProduct, idAttr, delta]); } catch {}
          }
          await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, idPA, 0, 0]);
          for (const s of idShops) { const sg = shopGroups.get(s) || 0; await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, idPA, s, sg]); }
          // Minimal attribute language rows for all active languages
          try {
            let langs = [idLang];
            try { const [r] = await conn.execute(`SELECT id_lang FROM \`${p}lang\` WHERE active=1`); const ids = Array.isArray(r)? r.map(x=>Number(x.id_lang||0)).filter(n=>n>0):[]; if (ids.length) langs = ids; } catch {}
            for (const lid of langs) { try { await conn.execute(`INSERT IGNORE INTO \`${p}product_attribute_lang\` (id_product_attribute,id_lang,available_now,available_later) VALUES (?,?,NULL,NULL)`, [idPA, lid]); } catch {} }
          } catch {}
          isFirstVar = false;
        }
        // Mark product/product_shop as combinations type (best-effort; ignore if column missing)
        try { await conn.execute(`UPDATE \`${p}product\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
        try { await conn.execute(`UPDATE \`${p}product_shop\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
        createdFromMapped = true;
      }
    } catch (e) { try { logToFile(`[presta] mapped_variant_import_warn ${e?.message||e}`); } catch {} }

    // Optional: create simple variants based on Shopify analytics variants (fallback)
    try {
      if (!createdFromMapped) {
        const variants = data?.shopify?.analytics?.variants || [];
        if (Array.isArray(variants) && variants.length) {
          // Ensure attribute group 'Variant'
          let idAttrGroup = 0;
          const [ag] = await conn.execute(`SELECT ag.id_attribute_group FROM \`${p}attribute_group_lang\` ag WHERE ag.name=? AND ag.id_lang=? LIMIT 1`, ['Variant', idLang]);
          if (ag && ag.length) idAttrGroup = ag[0].id_attribute_group; else {
            const [insG] = await conn.execute(`INSERT INTO \`${p}attribute_group\` (is_color_group, group_type, position) VALUES (0,'select',0)`);
            idAttrGroup = insG.insertId;
            await conn.execute(`INSERT INTO \`${p}attribute_group_lang\` (id_attribute_group,id_lang,name,public_name) VALUES (?,?,?,?)`, [idAttrGroup, idLang, 'Variant', 'Variant']);
            for (const s of idShops) {
              await conn.execute(`INSERT INTO \`${p}attribute_group_shop\` (id_attribute_group,id_shop) VALUES (?,?)`, [idAttrGroup, s]);
            }
          }
          // Ensure product_type is combinations before creating combinations (best-effort)
          try { await conn.execute(`UPDATE \`${pfx}product\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
          try { await conn.execute(`UPDATE \`${pfx}product_shop\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
          let isFirstVar = true;
          for (const v of variants) {
            const title = String(v.public_title || v.name || '').trim() || 'Default';
            const vSku = String(v.sku || '').trim();
            const vPriceCents = Number(v.price || 0);
            const vPrice = isNaN(vPriceCents) ? 0 : (vPriceCents >= 100 ? vPriceCents/100 : vPriceCents);
            // Ensure attribute value
            let idAttr = 0;
            const [av] = await conn.execute(`SELECT a.id_attribute FROM \`${p}attribute_lang\` al JOIN \`${p}attribute\` a ON a.id_attribute=al.id_attribute WHERE al.name=? AND al.id_lang=? LIMIT 1`, [title, idLang]);
            if (av && av.length) idAttr = av[0].id_attribute; else {
              const [insA] = await conn.execute(`INSERT INTO \`${p}attribute\` (id_attribute_group, color, position) VALUES (?,?,0)`, [idAttrGroup, '']);
              idAttr = insA.insertId;
              await conn.execute(`INSERT INTO \`${p}attribute_lang\` (id_attribute,id_lang,name) VALUES (?,?,?)`, [idAttr, idLang, title]);
              for (const s of idShops) {
                await conn.execute(`INSERT IGNORE INTO \`${p}attribute_shop\` (id_attribute,id_shop) VALUES (?,?)`, [idAttr, s]);
              }
            }
            // Create product_attribute
            const defOn = isFirstVar ? 1 : null;
            const delta = Math.max(0, vPrice - price);
            const [insPA] = await conn.execute(`INSERT INTO \`${p}product_attribute\` (id_product, reference, price, weight, default_on, ean13, upc, isbn) VALUES (?,?,?,?,?,?,?,?)`, [idProduct, vSku||'', delta, 0, defOn, '', '', '']);
            const idPA = insPA.insertId;
            if (isFirstVar && !defaultPA) defaultPA = idPA;
            for (const s of idShops) {
              await conn.execute(`INSERT INTO \`${p}product_attribute_shop\` (id_product,id_product_attribute,id_shop,price,default_on) VALUES (?,?,?,?,?)`, [idProduct, idPA, s, delta, defOn]);
            }
            await conn.execute(`INSERT INTO \`${p}product_attribute_combination\` (id_attribute,id_product_attribute) VALUES (?,?)`, [idAttr, idPA]);
            // Attribute-level impact upsert
            try {
              await conn.execute(`INSERT INTO \`${p}attribute_impact\` (id_product,id_attribute,weight,price) VALUES (?,?,0,?) ON DUPLICATE KEY UPDATE price=VALUES(price), weight=VALUES(weight)`, [idProduct, idAttr, delta]);
            } catch {}
            await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, idPA, 0, 0]);
            for (const s of idShops) {
              const sg = shopGroups.get(s) || 0;
              await conn.execute(`INSERT INTO \`${p}stock_available\` (id_product,id_product_attribute,id_shop,id_shop_group,quantity,out_of_stock) VALUES (?,?,?,?,0,1)`, [idProduct, idPA, s, sg]);
            }
            // Minimal attribute language row
            try {
              // Insert language rows for all active languages
              let langs = [idLang];
              try { const [r] = await conn.execute(`SELECT id_lang FROM \`${p}lang\` WHERE active=1`); const ids = Array.isArray(r)? r.map(x=>Number(x.id_lang||0)).filter(n=>n>0):[]; if (ids.length) langs = ids; } catch {}
              for (const lid of langs) { try { await conn.execute(`INSERT IGNORE INTO \`${p}product_attribute_lang\` (id_product_attribute,id_lang,available_now,available_later) VALUES (?,?,NULL,NULL)`, [idPA, lid]); } catch {} }
            } catch {}
            isFirstVar = false;
          }
          // Mark product type
          try { await conn.execute(`UPDATE \`${pfx}product\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
          try { await conn.execute(`UPDATE \`${pfx}product_shop\` SET product_type='combinations' WHERE id_product=?`, [idProduct]); } catch {}
          // Set cache_default_attribute so back office shows combinations immediately
          try { if (defaultPA) await conn.execute(`UPDATE \`${p}product\` SET cache_default_attribute=? WHERE id_product=?`, [defaultPA, idProduct]); } catch {}
          try { if (defaultPA) await conn.execute(`UPDATE \`${p}product_shop\` SET cache_default_attribute=? WHERE id_product=?`, [defaultPA, idProduct]); } catch {}
        }
      }
    } catch (e) { try { logToFile(`[presta] variant_import_warn ${e?.message||e}`); } catch {} }

    // Optional: download and register product images if PRESTA_ROOT is set
    try {
      const root = String(process.env.PRESTA_ROOT || '').trim();
      const imgs = Array.isArray(data?.product?.images) ? data.product.images : [];
      if (root && imgs && imgs.length) {
        const http = await import('http');
        const https = await import('https');
        const makePath = (id) => {
          const parts = String(id).split('');
          const dir = path.join(root, 'img', 'p', ...parts);
          const file = path.join(dir + '.jpg');
          return { dir, file };
        };
        let pos = 0;
        for (const u of imgs) {
          pos++;
          const cover = pos === 1 ? 1 : null;
          const [insI] = await conn.execute(`INSERT INTO \`${p}image\` (id_product, position, cover) VALUES (?,?,?)`, [idProduct, pos, cover]);
          const idImage = insI.insertId;
          for (const s of idShops) { try { await conn.execute(`INSERT INTO \`${p}image_shop\` (id_product,id_image,id_shop,cover) VALUES (?,?,?,?) ON DUPLICATE KEY UPDATE cover=VALUES(cover)`, [idProduct, idImage, s, cover ? 1 : null]); } catch {} }
          try {
            let lids = [idLang];
            try { const [lng] = await conn.execute(`SELECT id_lang FROM \`${p}lang\` WHERE active=1`); if (Array.isArray(lng)&&lng.length) lids = lng.map(r=>Number(r.id_lang||0)).filter(n=>n>0); } catch {}
            const legend = String(name||'').slice(0,128);
            for (const lid of lids) { await conn.execute(`INSERT INTO \`${p}image_lang\` (id_image,id_lang,legend) VALUES (?,?,?) ON DUPLICATE KEY UPDATE legend=VALUES(legend)`, [idImage, lid, legend]); }
          } catch {}
          const { dir, file } = makePath(idImage);
          try { fs.mkdirSync(dir, { recursive: true }); } catch {}
          await new Promise((resolve) => {
            try {
              const h = String(u).startsWith('https') ? https : http;
              const req = h.get(u, (resp) => {
                if ((resp.statusCode||0) >= 400) { try { resp.resume(); } catch {} return resolve(); }
                const ws = fs.createWriteStream(file);
                resp.pipe(ws);
                ws.on('finish', () => resolve());
                ws.on('error', () => resolve());
              });
              req.on('error', () => resolve());
              req.setTimeout(20000, () => { try { req.destroy(); } catch {} resolve(); });
            } catch { resolve(); }
          });
        }
      }
    } catch (e) { try { logToFile(`[presta] image_import_warn ${e?.message||e}`); } catch {} }

    await conn.commit();
    // Append to transfer history
    try {
      const productUrl = String(data?.page?.url || data?.meta?.url || '').trim();
      const img = Array.isArray(data?.product?.images) && data.product.images.length ? data.product.images[0] : (data?.meta?.image || '');
      const variants = Array.isArray(data?.shopify?.analytics?.variants) ? data.shopify.analytics.variants : [];
      const decl = variants && variants.length ? variants.map(v => (v.public_title||v.name||'').trim()).filter(Boolean).slice(0,3).join(', ') + (variants.length>3?` (+${variants.length-3} more)`: '') : (reference ? `SKU: ${reference}` : '-');
      const rec = {
        when: new Date().toISOString(),
        id_product: idProduct,
        product_url: productUrl,
        image: img,
        price,
        currency: (data?.product?.currency || '').trim(),
        declinaison: decl,
        file: String(input?.source_file || ''),
        name,
      };
      const list = readJeromeTransfers();
      list.unshift(rec);
      writeJeromeTransfers(list.slice(0,500));
    } catch {}
    try { await conn.end(); } catch {}
    return res.json({ ok:true, id_product: idProduct });
  } catch (e) {
    try { if (conn) await conn.rollback(); } catch {}
    try { if (conn) await conn.end(); } catch {}
    const code = (e && (e.code || e.errno)) || undefined;
    const sql = (e && (e.sql || e.sqlMessage)) || undefined;
    return res.status(500).json({ ok:false, error:'import_failed', message: e?.message || String(e), code, sql, debug_log: (typeof debugLog!== 'undefined'? debugLog: undefined) });
  }
});
// Serve saved documents
app.get('/api/grabbings/jerome/doc/:name', (req, res) => {
  const name = String(req.params?.name||'');
  if (!/^[A-Za-z0-9._%\-]+$/.test(name)) return res.status(400).end('bad_name');
  const p = path.join(grabbingJeromeDir, name);
  try {
    return res.sendFile(p);
  } catch { return res.status(404).end('not_found'); }
});

// Helpers
function publicBaseFromReq(req) {
  try {
    const proto = (req.headers['x-forwarded-proto'] || req.protocol || 'http').toString();
    const host = (req.headers['x-forwarded-host'] || req.headers['host'] || '').toString();
    if (!host) return '';
    return `${proto}://${host}`.replace(/\/$/, '');
  } catch { return ''; }
}
function extractToken(req) {
  const q = String(req.query?.token || '').trim();
  const b = checkBearer(req.headers?.authorization || '');
  const h = String(req.headers['x-gateway-token'] || req.headers['x_api_token'] || '').trim();
  return q || b || h || '';
}
async function loadGatewayTokenIfEmpty() {
  if (gatewayToken) return gatewayToken;
  try {
    const v = await getSetting('GATEWAY_TOKEN');
    if (typeof v === 'string' && v.trim()) gatewayToken = v.trim();
  } catch {}
  return gatewayToken;
}
async function isGatewayAuthorized(req) {
  const provided = extractToken(req);
  const expected = (await loadGatewayTokenIfEmpty()) || String(process.env.ADMIN_TOKEN || '').trim();
  return !!provided && !!expected && provided === expected;
}
function normalizePhone(raw = '') {
  // Keep leading + and digits; drop spaces, dashes, parentheses
  const s = String(raw || '').trim();
  const sign = s.startsWith('+') ? '+' : '';
  const digits = s.replace(/[^0-9]/g, '');
  return (sign + digits).replace(/^\+?0+$/, sign ? '+' : '');
}

// Admin: view/update gateway config (token + endpoints)
app.get('/api/admin/gateway/config', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const base = publicBaseFromReq(req);
    const tok = (await loadGatewayTokenIfEmpty()) || '';
    const reveal = String(req.query?.reveal || '').trim() === '1';
    res.json({
      ok: true,
      base_url: base || null,
      endpoints: base ? {
        sms_incoming: `${base}/api/sms/incoming`,
        sms_status: `${base}/api/sms/status`,
        calls: `${base}/api/calls`,
      } : null,
      has_token: !!tok,
      token: reveal ? (tok || null) : undefined,
    });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.post('/api/admin/gateway/token/regenerate', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const tok = crypto.randomBytes(24).toString('hex');
    await setSetting('GATEWAY_TOKEN', tok);
    gatewayToken = tok;
    res.json({ ok:true, token: tok });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.post('/api/admin/gateway/token', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const tok = String(req.body?.token || '').trim();
    if (!tok) return res.status(400).json({ ok:false, error:'bad_request' });
    await setSetting('GATEWAY_TOKEN', tok);
    gatewayToken = tok;
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Socket.IO Namespace for Android Gateway
// Connect with: io(BASE_URL + '/gateway', { path: '/socket', query: { token: GATEWAY_TOKEN } })
const gatewayNs = io.of('/gateway');
gatewayNs.use(async (socket, next) => {
  try {
    const qTok = String(socket?.handshake?.query?.token || '').trim();
    const aTok = String(socket?.handshake?.auth?.token || '').trim();
    const hTok = checkBearer(String(socket?.handshake?.headers?.authorization || '')) || '';
    const provided = qTok || aTok || hTok || '';
    const expected = (await loadGatewayTokenIfEmpty()) || '';
    if (expected && provided && provided === expected) return next();
  } catch {}
  next(new Error('unauthorized'));
});
gatewayNs.on('connection', (socket) => {
  try { logToFile(`gateway: connected socketId=${socket.id}`); } catch {}
  try {
    gatewaySocketIds.add(socket.id);
    if (gatewaySocketIds.size === 1) gatewayConnectedAt = Date.now();
    gatewayLastActivityAt = Date.now();
  } catch {}

  socket.on('disconnect', () => {
    try {
      logToFile(`gateway: disconnected socketId=${socket.id}`);
      gatewaySocketIds.delete(socket.id);
      gatewayLastActivityAt = Date.now();
    } catch {}
  });

  // --- Test URL history (per domain, per user) ---
  app.get('/api/grabbings/jerome/domains/test-history', async (req, res) => {
    try {
      const domain = String(req.query.domain || '').trim().toLowerCase();
      if (!domain) return res.status(400).json({ ok:false, error:'missing_domain' });
      const userId = (req.headers['x-admin-token'] ? String(req.headers['x-admin-token']) : null);
      const r = await pool.query(
        `SELECT url, use_count, last_used_at FROM public.grabbing_jerome_test_history WHERE domain=$1 AND (($2::text IS NULL AND user_id IS NULL) OR user_id=$2) ORDER BY last_used_at DESC LIMIT 20`,
        [domain, userId]
      );
      return res.json({ ok:true, items: r.rows || [] });
    } catch (e) { return res.status(500).json({ ok:false, error:String(e?.message||e) }); }
  });

  app.post('/api/grabbings/jerome/domains/test-history', async (req, res) => {
    try {
      const { domain, url } = req.body || {};
      const dom = String(domain||'').trim().toLowerCase();
      const u = String(url||'').trim();
      if (!dom || !u) return res.status(400).json({ ok:false, error:'missing_params' });
      const userId = (req.headers['x-admin-token'] ? String(req.headers['x-admin-token']) : null);
      await pool.query(
        `INSERT INTO public.grabbing_jerome_test_history(domain, url, user_id, use_count, created_at, last_used_at)
         VALUES($1,$2,$3,1, now(), now())
         ON CONFLICT (domain, user_id, url)
         DO UPDATE SET use_count = public.grabbing_jerome_test_history.use_count + 1, last_used_at = now()`,
        [dom, u, userId]
      );
      // enforce retention (keep latest 20)
      await pool.query(
        `DELETE FROM public.grabbing_jerome_test_history a WHERE a.domain=$1 AND (($2::text IS NULL AND a.user_id IS NULL) OR a.user_id=$2)
         AND a.id NOT IN (
           SELECT id FROM public.grabbing_jerome_test_history WHERE domain=$1 AND (($2::text IS NULL AND user_id IS NULL) OR user_id=$2) ORDER BY last_used_at DESC, id DESC LIMIT 20
         )`,
        [dom, userId]
      );
      return res.json({ ok:true });
    } catch (e) { return res.status(500).json({ ok:false, error:String(e?.message||e) }); }
  });

  app.delete('/api/grabbings/jerome/domains/test-history', async (req, res) => {
    try {
      const { domain } = req.body || {};
      const dom = String(domain||'').trim().toLowerCase();
      if (!dom) return res.status(400).json({ ok:false, error:'missing_domain' });
      const userId = (req.headers['x-admin-token'] ? String(req.headers['x-admin-token']) : null);
      await pool.query(`DELETE FROM public.grabbing_jerome_test_history WHERE domain=$1 AND (($2::text IS NULL AND user_id IS NULL) OR user_id=$2)`, [dom, userId]);
      return res.json({ ok:true, deleted:true });
    } catch (e) { return res.status(500).json({ ok:false, error:String(e?.message||e) }); }
  });

  // Accept SMS incoming via socket (same structure as HTTP)
  socket.on('gateway:lines', async (payload = {}, cb) => {
    try {
      const b = payload || {};
      const deviceId = (typeof b.device_id === 'string' && b.device_id.trim()) || null;
      const lines = Array.isArray(b.lines) ? b.lines : [];
      if (!lines.length) { if (cb) cb({ ok:true, updated:0 }); return; }
      await ensureTables();
      let updated = 0;
      for (const x of lines) {
        const sub = Number(x.subscription_id || x.sub_id || 0) || null;
        const slot = (x.sim_slot != null) ? Number(x.sim_slot) : (x.sim != null ? Number(x.sim) : null);
        const carrier = typeof x.carrier === 'string' ? x.carrier : null;
        const dn = typeof x.display_name === 'string' ? x.display_name : null;
        const msisdn = typeof x.msisdn === 'string' ? x.msisdn : null;
        if (!sub && !msisdn) continue;
        await pool.query(`
          INSERT INTO gateway_lines (device_id, subscription_id, sim_slot, carrier, display_name, msisdn, last_seen)
          VALUES ($1,$2,$3,$4,$5,$6,NOW())
          ON CONFLICT (subscription_id) DO UPDATE SET device_id=EXCLUDED.device_id, sim_slot=EXCLUDED.sim_slot, carrier=EXCLUDED.carrier, display_name=EXCLUDED.display_name, msisdn=EXCLUDED.msisdn, last_seen=NOW()
        `, [deviceId, sub, slot, carrier, dn, msisdn]);
        updated++;
      }
      try { gatewayLastActivityAt = Date.now(); } catch {}
      if (cb) cb({ ok:true, updated });
    } catch (e) { if (cb) cb({ ok:false, error: String(e?.message || e) }); }
  });
  socket.on('sms:incoming', async (payload = {}, cb) => {
    try {
      const b = payload || {};
      const fromRaw = b.from || b.sender || b.phone || b.number || b.msisdn || b.address || '';
      const toRaw = b.to || b.recipient || b.destination || '';
      const textRaw = b.text || b.body || b.message || b.content || '';
      const messageId = b.message_id || b.id || b.msg_id || b.guid || null;
      const ts = b.timestamp || b.date || b.received_at || Date.now();
      const from = normalizePhone(fromRaw);
      const to = normalizePhone(toRaw);
      const content = String(textRaw || '').trim().slice(0, 2000);
      if (!from || !content) throw new Error('bad_request');

      const visitorId = from;
      await ensureVisitorExists(visitorId);

      const looksHtml = /<\s*[a-z][\s\S]*>/i.test(content);
      const content_html = looksHtml ? sanitizeAgentHtmlServer(content) : textToSafeHTML(content);

      const cols = [];
      const params = [];
      const ph = [];
      if (dbSchema.messages.hasVisitorId) { cols.push('visitor_id'); params.push(visitorId); ph.push(`$${params.length}`); }
      cols.push('sender'); params.push('visitor'); ph.push(`$${params.length}`);
      const msgCol = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
      cols.push(msgCol); params.push(content); ph.push(`$${params.length}`);
      if (dbSchema.messages.hasContentHtml) { cols.push('content_html'); params.push(content_html); ph.push(`$${params.length}`); }
      if (dbSchema.messages.hasAgentId) { cols.push('agent_id'); params.push(null); ph.push(`$${params.length}`); }
      const sql = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')}) RETURNING id, created_at`;
      const ins = await pool.query(sql, params);

      const nowIso = new Date().toISOString();
      try { await upsertVisitorColumns(visitorId, { last_action: 'visitor_message', last_action_at: nowIso, conversation_status: 'waiting_agent' }); } catch {}

      const out = {
        id: ins?.rows?.[0]?.id || messageId || undefined,
        visitorId,
        from: 'visitor',
        message: content,
        html: content_html,
        timestamp: Date.parse(ins?.rows?.[0]?.created_at) || (typeof ts === 'number' ? ts : Date.now()),
        via: 'sms',
        to,
      };
      io.to('agents').emit('dashboard_message', out);
      try { logToFile(`sms(socket): incoming from=${from} to=${to||''} len=${content.length}`); } catch {}
      try { gatewayLastActivityAt = Date.now(); } catch {}
      if (cb) cb({ ok:true });
    } catch (e) { if (cb) cb({ ok:false, error: String(e?.message || e) }); }
  });

  socket.on('sms:status', async (payload = {}, cb) => {
    try {
      await ensureTables();
      const b = payload || {};
      const messageId = String(b.message_id || b.id || b.msg_id || '').trim() || null;
      const status = String(b.status || b.state || '').trim() || null;
      const error = typeof b.error === 'string' ? b.error : (b.error?.message || null);
      await pool.query(`INSERT INTO sms_status (message_id, status, error, raw) VALUES ($1,$2,$3,$4)`, [messageId, status, error, b]);
      try { logToFile(`sms(socket): status id=${messageId||''} status=${status||''}`); } catch {}
      try { gatewayLastActivityAt = Date.now(); } catch {}
      if (cb) cb({ ok:true });
    } catch (e) { if (cb) cb({ ok:false, error: String(e?.message || e) }); }
  });

  // Phone-originated outgoing SMS (user sent from the phone's native app)
  socket.on('sms:phone:sent', async (payload = {}, cb) => {
    try {
      await ensureTables();
      const b = payload || {};
      const to = normalizePhone(b.to || b.address || '');
      const text = String(b.message || b.text || b.body || '').trim().slice(0, 2000);
      const subId = Number(b.subscription_id || b.sub_id || 0) || null;
      if (!to || !text) { if (cb) cb({ ok:false, error:'bad_request' }); return; }

      // Resolve line msisdn (from_number)
      let fromNumber = null;
      try { if (subId) { const rr = await pool.query(`SELECT msisdn FROM gateway_lines WHERE subscription_id=$1 ORDER BY last_seen DESC LIMIT 1`, [subId]); if (rr.rowCount) fromNumber = rr.rows[0].msisdn || null; } } catch {}

      // Insert as agent message
      const cols = [];
      const params = [];
      const ph = [];
      if (dbSchema.messages.hasVisitorId) { cols.push('visitor_id'); params.push(to); ph.push(`$${params.length}`); }
      cols.push('sender'); params.push('agent'); ph.push(`$${params.length}`);
      const msgCol = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
      cols.push(msgCol); params.push(text); ph.push(`$${params.length}`);
      if (dbSchema.messages.hasContentHtml) { cols.push('content_html'); params.push(textToSafeHTML(text)); ph.push(`$${params.length}`); }
      cols.push('via'); params.push('sms'); ph.push(`$${params.length}`);
      cols.push('to_number'); params.push(to); ph.push(`$${params.length}`);
      cols.push('from_number'); params.push(fromNumber); ph.push(`$${params.length}`);
      cols.push('subscription_id'); params.push(subId); ph.push(`$${params.length}`);
      const sql = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')}) RETURNING id, created_at`;
      const ins = await pool.query(sql, params);

      const out = { id: ins?.rows?.[0]?.id || undefined, visitorId: to, from: 'agent', message: text, html: textToSafeHTML(text), timestamp: Date.parse(ins?.rows?.[0]?.created_at)||Date.now(), via:'sms' };
      io.to(to).emit('chat_message', out);
      io.to('agents').emit('dashboard_message', out);
      try { logToFile(`sms(phone): sent to=${to} sub=${subId||''}`); } catch {}
      if (cb) cb({ ok:true });
    } catch (e) { if (cb) cb({ ok:false, error: String(e?.message||e) }); }
  });
  socket.on('call:log', async (payload = {}, cb) => {
    try {
      await ensureTables();
      const b = payload || {};
      const from = normalizePhone(b.from || b.caller || b.number || b.msisdn || '');
      const to = normalizePhone(b.to || b.callee || b.destination || '');
      const direction = String(b.direction || b.type || '').trim() || null;
      const status = String(b.status || '').trim() || null;
      const dur = Number(b.duration_sec || b.duration || b.seconds || 0) || null;
      const startedAt = b.started_at || b.start_ts || b.started || null;
      const endedAt = b.ended_at || b.end_ts || b.ended || null;
      if (!from) throw new Error('bad_request');
      await pool.query(`INSERT INTO call_logs (from_number, to_number, direction, status, duration_sec, started_at, ended_at, raw) VALUES ($1,$2,$3,$4,$5,$6,$7,$8)`, [from || null, to || null, direction, status, dur, startedAt ? new Date(startedAt) : null, endedAt ? new Date(endedAt) : null, b]);
      try { logToFile(`call(socket): ${direction||''} from=${from} to=${to||''} status=${status||''} dur=${dur||0}`); } catch {}
      try { gatewayLastActivityAt = Date.now(); } catch {}
      if (cb) cb({ ok:true });
    } catch (e) { if (cb) cb({ ok:false, error: String(e?.message || e) }); }
  });
});

// Gateway: Incoming SMS
app.post('/api/sms/incoming', async (req, res) => {
  try {
    if (!(await isGatewayAuthorized(req))) return res.status(401).json({ ok:false, error:'unauthorized' });
  } catch { return res.status(401).json({ ok:false, error:'unauthorized' }); }
  try {
    const b = req.body || {};
    const fromRaw = b.from || b.sender || b.phone || b.number || b.msisdn || b.address || '';
    const toRaw = b.to || b.recipient || b.destination || '';
    const textRaw = b.text || b.body || b.message || b.content || '';
    const messageId = b.message_id || b.id || b.msg_id || b.guid || null;
    const ts = b.timestamp || b.date || b.received_at || Date.now();
    const simSlot = (b.sim != null ? Number(b.sim) : (b.sim_slot != null ? Number(b.sim_slot) : null));
    const subscriptionId = (b.subscription_id != null ? Number(b.subscription_id) : null);
    const carrier = typeof b.carrier === 'string' ? b.carrier : null;
    const displayName = typeof b.display_name === 'string' ? b.display_name : null;
    const from = normalizePhone(fromRaw);
    let to = normalizePhone(toRaw);
    const content = String(textRaw || '').trim().slice(0, 2000);
    if (!from || !content) return res.status(400).json({ ok:false, error:'bad_request' });

    // Compose visitor id from phone number
    const visitorId = from;
    await ensureVisitorExists(visitorId);

    // Insert into messages table, respecting schema
    const looksHtml = /<\s*[a-z][\s\S]*>/i.test(content);
    const content_html = looksHtml ? sanitizeAgentHtmlServer(content) : textToSafeHTML(content);

    // Try to derive destination (SIM line MSISDN) when not provided
    if (!to) {
      try {
        if (Number.isFinite(subscriptionId)) {
          const r = await pool.query(`SELECT msisdn FROM gateway_lines WHERE subscription_id=$1 ORDER BY last_seen DESC LIMIT 1`, [subscriptionId]);
          if (r.rowCount) to = normalizePhone(r.rows[0].msisdn || '');
        } else if (Number.isFinite(simSlot)) {
          const r = await pool.query(`SELECT msisdn FROM gateway_lines WHERE sim_slot=$1 ORDER BY last_seen DESC LIMIT 1`, [simSlot]);
          if (r.rowCount) to = normalizePhone(r.rows[0].msisdn || '');
        } else {
          const def = await getSetting('SMS_DEFAULT_SUBSCRIPTION_ID');
          if (def) {
            const r = await pool.query(`SELECT msisdn FROM gateway_lines WHERE subscription_id=$1 ORDER BY last_seen DESC LIMIT 1`, [Number(def)]);
            if (r.rowCount) to = normalizePhone(r.rows[0].msisdn || '');
          }
        }
      } catch {}
    }

    const cols = [];
    const params = [];
    const ph = [];
    if (dbSchema.messages.hasVisitorId) { cols.push('visitor_id'); params.push(visitorId); ph.push(`$${params.length}`); }
    cols.push('sender'); params.push('visitor'); ph.push(`$${params.length}`);
    const msgCol = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
    cols.push(msgCol); params.push(content); ph.push(`$${params.length}`);
    if (dbSchema.messages.hasContentHtml) { cols.push('content_html'); params.push(content_html); ph.push(`$${params.length}`); }
    if (dbSchema.messages.hasAgentId) { cols.push('agent_id'); params.push(null); ph.push(`$${params.length}`); }
    // SMS metadata columns (always present via migrations; insert best-effort)
    cols.push('via'); params.push('sms'); ph.push(`$${params.length}`);
    cols.push('to_number'); params.push(to || null); ph.push(`$${params.length}`);
    cols.push('from_number'); params.push(from || null); ph.push(`$${params.length}`);
    cols.push('external_message_id'); params.push(messageId || null); ph.push(`$${params.length}`);
    cols.push('sim_slot'); params.push(Number.isFinite(simSlot) ? simSlot : null); ph.push(`$${params.length}`);
    cols.push('subscription_id'); params.push(Number.isFinite(subscriptionId) ? subscriptionId : null); ph.push(`$${params.length}`);
    cols.push('carrier'); params.push(carrier); ph.push(`$${params.length}`);
    cols.push('display_name'); params.push(displayName); ph.push(`$${params.length}`);
    const sql = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')}) RETURNING id, created_at`;
    const ins = await pool.query(sql, params);

    // Update visitor conversation status
    const nowIso = new Date().toISOString();
    try { await upsertVisitorColumns(visitorId, { last_action: 'visitor_message', last_action_at: nowIso, conversation_status: 'waiting_agent' }); } catch {}

    // Broadcast to agents dashboard
    const out = {
      id: ins?.rows?.[0]?.id || messageId || undefined,
      visitorId,
      from: 'visitor',
      message: content,
      html: content_html,
      timestamp: Date.parse(ins?.rows?.[0]?.created_at) || (typeof ts === 'number' ? ts : Date.now()),
      via: 'sms',
      to,
    };
    io.to('agents').emit('dashboard_message', out);
    try { logToFile(`sms: incoming from=${from} to=${to||''} len=${content.length}`); } catch {}
    try { gatewayLastActivityAt = Date.now(); } catch {}
    res.json({ ok:true });
  } catch (e) {
    try { logToFile(`❌ /api/sms/incoming: ${e.message}`); } catch {}
    res.status(500).json({ ok:false, error:'server_error' });
  }
});

// Gateway: SMS delivery status/ack
app.post('/api/sms/status', async (req, res) => {
  try { if (!(await isGatewayAuthorized(req))) return res.status(401).json({ ok:false, error:'unauthorized' }); } catch { return res.status(401).json({ ok:false, error:'unauthorized' }); }
  try {
    await ensureTables();
    const b = req.body || {};
    const messageId = String(b.message_id || b.id || b.msg_id || '').trim() || null;
    const status = String(b.status || b.state || '').trim() || null;
    const error = typeof b.error === 'string' ? b.error : (b.error?.message || null);
    const raw = b;
    await pool.query(`INSERT INTO sms_status (message_id, status, error, raw) VALUES ($1,$2,$3,$4)`, [messageId, status, error, raw]);
    try { logToFile(`sms: status id=${messageId||''} status=${status||''}`); } catch {}
    try { gatewayLastActivityAt = Date.now(); } catch {}
    res.json({ ok:true });
  } catch (e) {
    try { logToFile(`❌ /api/sms/status: ${e.message}`); } catch {}
    res.status(500).json({ ok:false, error:'server_error' });
  }
});

// Phone-originated outgoing SMS via HTTP (authorized by gateway token)
app.post('/api/sms/phone/sent', async (req, res) => {
  try { if (!(await isGatewayAuthorized(req))) return res.status(401).json({ ok:false, error:'unauthorized' }); } catch { return res.status(401).json({ ok:false, error:'unauthorized' }); }
  try {
    await ensureTables();
    const b = req.body || {};
    const to = normalizePhone(b.to || b.address || '');
    const text = String(b.message || b.text || b.body || '').trim().slice(0, 2000);
    const subId = Number(b.subscription_id || b.sub_id || 0) || null;
    if (!to || !text) return res.status(400).json({ ok:false, error:'bad_request' });
    let fromNumber = null;
    try { if (subId) { const rr = await pool.query(`SELECT msisdn FROM gateway_lines WHERE subscription_id=$1 ORDER BY last_seen DESC LIMIT 1`, [subId]); if (rr.rowCount) fromNumber = rr.rows[0].msisdn || null; } } catch {}

    const cols = [];
    const params = [];
    const ph = [];
    if (dbSchema.messages.hasVisitorId) { cols.push('visitor_id'); params.push(to); ph.push(`$${params.length}`); }
    cols.push('sender'); params.push('agent'); ph.push(`$${params.length}`);
    const msgCol = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
    cols.push(msgCol); params.push(text); ph.push(`$${params.length}`);
    if (dbSchema.messages.hasContentHtml) { cols.push('content_html'); params.push(textToSafeHTML(text)); ph.push(`$${params.length}`); }
    cols.push('via'); params.push('sms'); ph.push(`$${params.length}`);
    cols.push('to_number'); params.push(to); ph.push(`$${params.length}`);
    cols.push('from_number'); params.push(fromNumber); ph.push(`$${params.length}`);
    cols.push('subscription_id'); params.push(subId); ph.push(`$${params.length}`);
    const sql = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')}) RETURNING id, created_at`;
    const ins = await pool.query(sql, params);

    const out = { id: ins?.rows?.[0]?.id || undefined, visitorId: to, from: 'agent', message: text, html: textToSafeHTML(text), timestamp: Date.parse(ins?.rows?.[0]?.created_at)||Date.now(), via:'sms' };
    io.to(to).emit('chat_message', out);
    io.to('agents').emit('dashboard_message', out);
    try { logToFile(`sms(phone-http): sent to=${to} sub=${subId||''}`); } catch {}
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
// Gateway: Call logs (POST from Android), plus GET for admin review
app.post('/api/calls', async (req, res) => {
  try { if (!(await isGatewayAuthorized(req))) return res.status(401).json({ ok:false, error:'unauthorized' }); } catch { return res.status(401).json({ ok:false, error:'unauthorized' }); }
  try {
    await ensureTables();
    const b = req.body || {};

    // Helper: normalize a single call record from various Android shapes
    const normalizeCall = (x={}) => {
      const num = normalizePhone(x.number || x.from || x.caller || x.msisdn || '');
      const to = normalizePhone(x.to || x.callee || x.destination || '');
      // direction/status mapping for Android call log 'type'
      let direction = (x.direction || '').toString().trim().toLowerCase();
      let status = (x.status || '').toString().trim().toLowerCase();
      const typeNum = Number(x.type || 0);
      if (!direction && typeNum) {
        if (typeNum === 1) direction = 'incoming';
        else if (typeNum === 2) direction = 'outgoing';
        else if (typeNum === 3) { direction = 'incoming'; status = status || 'missed'; }
      }
      if (!status) status = (typeNum === 3 ? 'missed' : 'ended');
      const durationSec = Number(x.duration_sec || x.duration || x.seconds || 0) || 0;
      const startMs = x.started_at || x.start_ts || x.started || x.date || undefined;
      const endMs = x.ended_at || x.end_ts || x.ended || (startMs ? (Number(startMs) + durationSec*1000) : undefined);
      return {
        from: num,
        to,
        direction: direction || null,
        status: status || null,
        duration_sec: Number.isFinite(durationSec) ? durationSec : null,
        started_at: startMs ? new Date(Number(startMs)) : null,
        ended_at: endMs ? new Date(Number(endMs)) : null,
        raw: x,
      };
    };

    const arr = Array.isArray(b.calls) ? b.calls : null;
    if (arr && arr.length) {
      let ok = 0, bad = 0;
      for (const item of arr) {
        const c = normalizeCall(item || {});
        if (!c.from) { bad++; continue; }
        await pool.query(
          `INSERT INTO call_logs (from_number, to_number, direction, status, duration_sec, started_at, ended_at, raw) VALUES ($1,$2,$3,$4,$5,$6,$7,$8)`,
          [c.from || null, c.to || null, c.direction, c.status, c.duration_sec, c.started_at, c.ended_at, c.raw]
        );
        ok++;
      }
      try { logToFile(`call(batch): inserted=${ok} skipped=${bad}`); } catch {}
      try { gatewayLastActivityAt = Date.now(); } catch {}
      return res.json({ ok:true, inserted: ok, skipped: bad });
    }

    // Single object form
    const c = normalizeCall(b);
    if (!c.from) return res.status(400).json({ ok:false, error:'bad_request' });
    await pool.query(
      `INSERT INTO call_logs (from_number, to_number, direction, status, duration_sec, started_at, ended_at, raw) VALUES ($1,$2,$3,$4,$5,$6,$7,$8)`,
      [c.from || null, c.to || null, c.direction, c.status, c.duration_sec, c.started_at, c.ended_at, c.raw]
    );
    try { logToFile(`call: ${c.direction||''} from=${c.from} to=${c.to||''} status=${c.status||''} dur=${c.duration_sec||0}`); } catch {}
    try { gatewayLastActivityAt = Date.now(); } catch {}
    res.json({ ok:true, inserted: 1 });
  } catch (e) {
    try { logToFile(`❌ /api/calls (POST): ${e.message}`); } catch {}
    res.status(500).json({ ok:false, error:'server_error' });
  }
});
app.get('/api/calls', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const limit = Math.min(500, Math.max(1, parseInt(String(req.query?.limit||'50'), 10) || 50));
    const r = await pool.query(`SELECT id, from_number, to_number, direction, status, duration_sec, started_at, ended_at, created_at FROM call_logs ORDER BY created_at DESC LIMIT $1`, [limit]);
    res.json({ ok:true, items: r.rows });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Optional: Admin-triggered SMS send via Socket.IO gateway
// Body: { to: "+336...", message: "...", conversation_id?: "..." }
app.post('/api/sms/send', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const b = req.body || {};
    const to = normalizePhone(b.to || '');
    const message = String(b.message || '').trim();
    const conversation_id = b.conversation_id || undefined;
    const simSlot = (b.sim != null ? Number(b.sim) : (b.sim_slot != null ? Number(b.sim_slot) : null));
    const subscriptionId = (b.subscription_id != null ? Number(b.subscription_id) : null);
    const carrier = typeof b.carrier === 'string' ? b.carrier : null;
    const displayName = typeof b.display_name === 'string' ? b.display_name : null;
    // Default line if no hints provided
    let subId = subscriptionId;
    if (!Number.isFinite(subId)) {
      try { const defSub = await getSetting('SMS_DEFAULT_SUBSCRIPTION_ID'); if (defSub) subId = Number(defSub); } catch {}
    }
    if (!to || !message) return res.status(400).json({ ok:false, error:'bad_request' });
    const payload = { to, message, conversation_id };
    if (Number.isFinite(simSlot)) payload.sim = simSlot;
    if (Number.isFinite(subId)) payload.subscription_id = subId;
    if (carrier) payload.carrier = carrier;
    if (displayName) payload.display_name = displayName;
    gatewayNs.emit('sms:send', payload);
    try { logToFile(`sms:send emit to=${to} len=${message.length}`); } catch {}
    // Insert an agent message into messages table for traceability
    try {
      const looksHtml = /<\s*[a-z][\s\S]*>/i.test(message);
      const content_html = looksHtml ? sanitizeAgentHtmlServer(message) : textToSafeHTML(message);
      const cols = [];
      const params = [];
      const ph = [];
      if (dbSchema.messages.hasVisitorId) { cols.push('visitor_id'); params.push(to); ph.push(`$${params.length}`); }
      cols.push('sender'); params.push('agent'); ph.push(`$${params.length}`);
      const msgCol = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
      cols.push(msgCol); params.push(message); ph.push(`$${params.length}`);
      if (dbSchema.messages.hasContentHtml) { cols.push('content_html'); params.push(content_html); ph.push(`$${params.length}`); }
      cols.push('via'); params.push('sms'); ph.push(`$${params.length}`);
      cols.push('to_number'); params.push(to); ph.push(`$${params.length}`);
      // Attempt to resolve from_number (msisdn) from reported gateway lines when we know the subscription
      let fromNumber = null;
      try {
        if (Number.isFinite(subId)) {
          const rr = await pool.query(`SELECT msisdn FROM gateway_lines WHERE subscription_id = $1 LIMIT 1`, [subId]);
          if (rr.rowCount) fromNumber = rr.rows[0].msisdn || null;
        }
      } catch {}
      cols.push('from_number'); params.push(fromNumber); ph.push(`$${params.length}`);
      cols.push('sim_slot'); params.push(Number.isFinite(simSlot) ? simSlot : null); ph.push(`$${params.length}`);
      cols.push('subscription_id'); params.push(Number.isFinite(subId) ? subId : null); ph.push(`$${params.length}`);
      cols.push('carrier'); params.push(carrier); ph.push(`$${params.length}`);
      cols.push('display_name'); params.push(displayName); ph.push(`$${params.length}`);
      const sql = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')}) RETURNING id, created_at`;
      const ins = await pool.query(sql, params);
      const out = { id: ins?.rows?.[0]?.id || undefined, visitorId: to, from: 'agent', message, html: content_html, timestamp: Date.parse(ins?.rows?.[0]?.created_at)||Date.now(), via: 'sms', to };
      io.to('agents').emit('dashboard_message', out);
    } catch (e) { try { logToFile(`sms:send insert failed: ${e.message}`); } catch {} }
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin-only: request the phone to place a call
// Body: { to: "+336..." }
app.post('/api/call/place', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const to = normalizePhone(req.body?.to || '');
    if (!to) return res.status(400).json({ ok:false, error:'bad_request' });
    gatewayNs.emit('call:place', { to });
    try { logToFile(`call:place emit to=${to}`); } catch {}
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin-only: Gateway/phone connection status
app.get('/api/admin/gateway/status', (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const count = gatewaySocketIds.size;
    const connected = count > 0;
    res.json({
      ok: true,
      socket_connected: connected,
      socket_count: count,
      socket_since: gatewayConnectedAt ? new Date(gatewayConnectedAt).toISOString() : null,
      last_activity_at: gatewayLastActivityAt ? new Date(gatewayLastActivityAt).toISOString() : null,
    });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Gateway (phone) reports active lines via HTTP (authorized by GATEWAY_TOKEN)
// Body: { device_id?: string, lines: [ { subscription_id, sim_slot?, carrier?, display_name?, msisdn? }, ... ] }
app.post('/api/gateway/lines', async (req, res) => {
  try { if (!(await isGatewayAuthorized(req))) return res.status(401).json({ ok:false, error:'unauthorized' }); } catch { return res.status(401).json({ ok:false, error:'unauthorized' }); }
  try {
    const b = req.body || {};
    const deviceId = (typeof b.device_id === 'string' && b.device_id.trim()) || null;
    const lines = Array.isArray(b.lines) ? b.lines : [];
    if (!lines.length) return res.json({ ok:true, updated: 0 });
    await ensureTables();
    let updated = 0;
    for (const x of lines) {
      const sub = Number(x.subscription_id || x.sub_id || 0) || null;
      const slot = (x.sim_slot != null) ? Number(x.sim_slot) : (x.sim != null ? Number(x.sim) : null);
      const carrier = typeof x.carrier === 'string' ? x.carrier : null;
      const dn = typeof x.display_name === 'string' ? x.display_name : null;
      const msisdn = typeof x.msisdn === 'string' ? x.msisdn : null;
      if (!sub && !msisdn) continue;
      await pool.query(`
        INSERT INTO gateway_lines (device_id, subscription_id, sim_slot, carrier, display_name, msisdn, last_seen)
        VALUES ($1,$2,$3,$4,$5,$6,NOW())
        ON CONFLICT (subscription_id) DO UPDATE SET device_id=EXCLUDED.device_id, sim_slot=EXCLUDED.sim_slot, carrier=EXCLUDED.carrier, display_name=EXCLUDED.display_name, msisdn=EXCLUDED.msisdn, last_seen=NOW()
      `, [deviceId, sub, slot, carrier, dn, msisdn]);
      updated++;
    }
    try { gatewayLastActivityAt = Date.now(); } catch {}
    res.json({ ok:true, updated });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin: list active lines and default
app.get('/api/admin/gateway/lines', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    await ensureTables();
    const r = await pool.query(`SELECT id, device_id, subscription_id, sim_slot, carrier, display_name, msisdn, last_seen FROM gateway_lines ORDER BY last_seen DESC, subscription_id`);
    const defSub = await getSetting('SMS_DEFAULT_SUBSCRIPTION_ID').catch(()=>null);
    res.json({ ok:true, items: r.rows, default_subscription_id: defSub ? Number(defSub) : null });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin: set default subscription id used for /api/sms/send when hints missing
app.post('/api/admin/gateway/lines/default', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const sub = Number(req.body?.subscription_id || req.body?.sub_id || 0) || null;
    if (!sub) return res.status(400).json({ ok:false, error:'bad_request' });
    await setSetting('SMS_DEFAULT_SUBSCRIPTION_ID', String(sub));
    res.json({ ok:true, subscription_id: sub });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin: set or edit MSISDN for a subscription id (in case device cannot read it)
app.post('/api/admin/gateway/lines/set_msisdn', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const sub = Number(req.body?.subscription_id || req.body?.sub_id || 0) || null;
    const msisdn = String(req.body?.msisdn || '').trim();
    if (!sub) return res.status(400).json({ ok:false, error:'bad_request' });
    await ensureTables();
    // Upsert even if line wasn't reported yet
    await pool.query(`
      INSERT INTO gateway_lines (subscription_id, msisdn, last_seen)
      VALUES ($1, $2, NOW())
      ON CONFLICT (subscription_id) DO UPDATE SET msisdn=EXCLUDED.msisdn, last_seen=NOW()
    `, [sub, msisdn || null]);
    res.json({ ok:true, subscription_id: sub, msisdn: msisdn || null });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin-only: list SMS messages (recent first). Optional filter by phone via ?phone=+33...
app.get('/api/sms/messages', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const limit = Math.min(500, Math.max(1, parseInt(String(req.query?.limit||'100'), 10) || 100));
    const phone = (req.query?.phone && String(req.query.phone).trim()) || '';
    const where = [];
    const params = [];
    // SMS heuristic: via='sms' or has to_number
    where.push(`(COALESCE(via,'') = 'sms' OR COALESCE(to_number,'') <> '')`);
    if (phone) { params.push(phone); where.push(`(visitor_id = $${params.length} OR to_number = $${params.length})`); }
    const sql = `SELECT m.id, m.visitor_id, m.sender, COALESCE(m.content,m.message) AS text, m.content_html,
                        m.to_number,
                        COALESCE(m.to_number, (SELECT gl.msisdn FROM gateway_lines gl WHERE gl.subscription_id = m.subscription_id ORDER BY gl.last_seen DESC LIMIT 1)) AS line_msisdn,
                        m.from_number,
                        m.via, m.sim_slot, m.subscription_id, m.carrier, m.display_name, m.created_at
                 FROM messages m
                 ${where.length? 'WHERE ' + where.join(' AND ') : ''}
                 ORDER BY created_at DESC
                 LIMIT ${limit}`;
    const r = await pool.query(sql, params);
    res.json({ ok:true, items: r.rows });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin-only: list recent SMS conversations (one row per phone), newest first
// Query params: limit (default 100), search (optional phone/text substring)
app.get('/api/sms/conversations', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const limit = Math.min(500, Math.max(1, parseInt(String(req.query?.limit||'100'), 10) || 100));
    const search = String(req.query?.search || '').trim();
    const params = [];
    const whereRanked = `(COALESCE(m.via,'') = 'sms' OR COALESCE(m.to_number,'') <> '')`;
    const searchFilter = search ? `WHERE (COALESCE(co.phone, t.visitor_id) ILIKE $1 OR COALESCE(t.text,'') ILIKE $1)` : '';
    if (search) params.push(`%${search}%`);
    const sql = `
      WITH ranked AS (
        SELECT m.id, m.visitor_id, m.sender, COALESCE(m.content,m.message) AS text, m.content_html,
               m.created_at, m.to_number, m.subscription_id, m.sim_slot, m.carrier, m.display_name,
               row_number() OVER (PARTITION BY m.visitor_id ORDER BY m.created_at DESC) AS rn
        FROM messages m
        WHERE ${whereRanked}
      ), t AS (
        SELECT r.visitor_id, r.sender, r.text, r.created_at, r.to_number,
               r.subscription_id, r.sim_slot, r.carrier, r.display_name,
               COALESCE(r.to_number, (
                 SELECT gl.msisdn FROM gateway_lines gl
                 WHERE gl.subscription_id = r.subscription_id
                 ORDER BY gl.last_seen DESC LIMIT 1
               )) AS line_msisdn
        FROM ranked r
        WHERE r.rn = 1
      ), merged AS (
        SELECT COALESCE(t.visitor_id, co.phone) AS visitor_id,
               t.sender, t.text, t.created_at, t.to_number,
               t.subscription_id, t.sim_slot, t.carrier, t.display_name,
               COALESCE(t.line_msisdn, (
                 SELECT gl.msisdn FROM gateway_lines gl
                 WHERE gl.subscription_id = co.default_subscription_id
                 ORDER BY gl.last_seen DESC LIMIT 1
               )) AS line_msisdn,
               co.label, co.pinned, co.archived,
               GREATEST(COALESCE(t.created_at, 'epoch'), COALESCE(co.updated_at, 'epoch'), COALESCE(co.created_at, 'epoch')) AS sort_at
        FROM sms_conversation co
        FULL OUTER JOIN t ON co.phone = t.visitor_id
      )
      SELECT * FROM merged
      ${searchFilter}
      ORDER BY sort_at DESC
      LIMIT ${limit}
    `;
    const r = await pool.query(sql, params);
    res.json({ ok:true, items: r.rows.map(row => ({ ...row, sort_at: undefined })) });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Create/Upsert a conversation explicitly (before any message exists)
app.post('/api/sms/conversations', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const phone = normalizePhone(req.body?.phone || '');
    if (!phone) return res.status(400).json({ ok:false, error:'bad_request' });
    const label = typeof req.body?.label === 'string' ? req.body.label.trim() : null;
    const defSub = req.body?.default_subscription_id != null ? Number(req.body.default_subscription_id) : null;
    await ensureTables();
    await pool.query(`
      INSERT INTO sms_conversation (phone, label, default_subscription_id, created_at, updated_at)
      VALUES ($1, $2, $3, NOW(), NOW())
      ON CONFLICT (phone) DO UPDATE SET label=EXCLUDED.label, default_subscription_id=EXCLUDED.default_subscription_id, updated_at=NOW()
    `, [phone, label, Number.isFinite(defSub) ? defSub : null]);
    res.status(201).json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Delete a conversation: server messages and/or phone thread
// Query: server=1, phone=1 (both default to true if not provided)
app.delete('/api/sms/conversations/:phone', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const raw = String(req.params.phone || '').trim();
    const phone = normalizePhone(raw);
    if (!phone) return res.status(400).json({ ok:false, error:'bad_request' });
    const doServer = String(req.query?.server||'1') !== '0';
    const doPhone = String(req.query?.phone||'1') !== '0';
    let deleted = 0;
    if (doServer) {
      try {
        const r = await pool.query(`DELETE FROM messages WHERE visitor_id=$1 OR to_number=$1`, [phone]);
        deleted = r.rowCount || 0;
      } catch {}
      try { await pool.query(`DELETE FROM sms_conversation WHERE phone=$1`, [phone]); } catch {}
    }
    if (doPhone) {
      try { gatewayNs.emit('sms:phone:delete_thread', { phone }); } catch {}
    }
    res.json({ ok:true, deleted, phoneDeleted: !!doPhone });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin/agents: full conversation by phone (merged in/out)
app.get('/api/sms/conversation', async (req, res) => {
  const u = requireAdmin(req, res) || null; // keep simple for now: admin only
  if (!u) return;
  try {
    const phone = String(req.query?.phone || '').trim();
    if (!phone) return res.status(400).json({ ok:false, error:'bad_request' });
    const limit = Math.min(2000, Math.max(1, parseInt(String(req.query?.limit||'1000'), 10) || 1000));
    const r = await pool.query(`
      SELECT m.id, m.visitor_id, m.sender, COALESCE(m.content,m.message) AS text, m.content_html,
             m.to_number,
             COALESCE(m.to_number, (SELECT gl.msisdn FROM gateway_lines gl WHERE gl.subscription_id = m.subscription_id ORDER BY gl.last_seen DESC LIMIT 1)) AS line_msisdn,
             m.from_number,
             m.via, m.sim_slot, m.subscription_id, m.carrier, m.display_name, m.created_at
      FROM messages m
      WHERE (m.visitor_id = $1 OR m.to_number = $1)
        AND (COALESCE(m.via,'') = 'sms' OR COALESCE(m.to_number,'') <> '')
      ORDER BY m.created_at ASC
      LIMIT $2
    `, [phone, limit]);
    res.json({ ok:true, items: r.rows });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin-only: delete a message by id (id can be int/uuid/text)
app.delete('/api/sms/messages/:id', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
    const r = await pool.query(`DELETE FROM messages WHERE id::text = $1`, [id]);
    res.json({ ok:true, deleted: r.rowCount||0 });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// SPA fallback (exclude socket/api/mcp/mcp2/mcp-dev/oauth2)
app.get(/^\/(?!socket\/|api\/|mcp\/|mcp2\/|mcp-dev\/|oauth2\/).*/, (req, res) => {
  const exists = (() => { try { return fs.existsSync(indexHtml); } catch { return false; } })();
  if (exists) {
    return res.sendFile(indexHtml);
  }
  // Minimal placeholder to avoid ENOENT loop when dist is missing
  res.status(503).set('Content-Type','text/html; charset=utf-8').send(`<!doctype html>
  <html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Livechat App</title>
  <style>body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Helvetica,Arial,sans-serif;padding:24px;line-height:1.5;color:#111}code{background:#f3f4f6;padding:.15em .35em;border-radius:4px}</style>
  </head><body>
  <h1>Frontend build not found</h1>
  <p>The server could not find <code>frontend/dist/index.html</code>.</p>
  <ol>
    <li>Build the frontend: <code>cd frontend && npm ci && npm run build</code></li>
    <li>Ensure the files exist at: <code>${distDir.replace(/\\/g,'/')}</code></li>
    <li>Reload the server.</li>
  </ol>
  </body></html>`);
});

// Debug: inject a message (admin only) to verify DB writes
app.post('/api/debug/message', async (req, res) => {
  if (!requireAdminToken(req, res)) return;
  try {
    const b = req.body || {};
    const visitorId = String(b.visitorId || b.visitor_id || '').trim();
    const from = String(b.from || 'visitor').trim() === 'agent' ? 'agent' : 'visitor';
    const msg = String(b.message || b.content || b.text || '').trim();
    if (!visitorId || !msg) return res.status(400).json({ ok: false, error: 'bad_request' });
    io.emit('chat_message', { visitorId, from, message: msg, timestamp: Date.now() });
    res.json({ ok: true });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

function isLocalhost(req) {
  const ip = (req.ip || req.connection?.remoteAddress || "").replace(
    "::ffff:",
    ""
  );
  return ip === "127.0.0.1" || ip === "::1";
}
function requireAdminToken(req, res) {
  const expected = process.env.ADMIN_TOKEN || "";
  if (expected) {
    const got = req.headers["x-admin-token"] || req.query.admin_token;
    if (String(got) !== expected) {
      res.status(401).json({ error: "unauthorized" });
      return false;
    }
    return true;
  }
  // If no token configured, allow only localhost
  if (!isLocalhost(req)) {
    res.status(401).json({ error: "unauthorized" });
    return false;
  }
  return true;
}

async function adminBackfillActions(req, res) {
  if (!requireAdminToken(req, res)) return;
  try {
    const out1 = await pool.query(
      `UPDATE visitors
         SET last_action = 'page_view'
       WHERE last_action IS NULL AND page_url_last IS NOT NULL`
    );
    const out2 = await pool.query(
      `UPDATE visitors
         SET last_action_at = COALESCE(last_action_at, last_seen, created_at, NOW())
       WHERE last_action_at IS NULL AND (last_action IS NOT NULL OR page_url_last IS NOT NULL)`
    );
    res.json({
      ok: true,
      updated_last_action: out1.rowCount || 0,
      updated_last_action_at: out2.rowCount || 0,
    });
  } catch (e) {
    logToFile(`❌ backfill_actions failed: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
}
app.post("/api/admin/backfill_actions", adminBackfillActions);
app.get("/api/admin/backfill_actions", adminBackfillActions);

async function adminBackfillGeo(req, res) {
  if (!requireAdminToken(req, res)) return;
  try {
    const limit = Math.max(
      1,
      Math.min(5000, Number(req.body?.limit || req.query?.limit || 1000))
    );
    const idCol =
      dbSchema.visitors.idCol ||
      (dbSchema.visitors.hasVisitorIdCol ? "visitor_id" : "id") ||
      "visitor_id";
    const rows = await pool.query(
      `SELECT ${idCol} AS vid, ip
         FROM visitors
        WHERE ip IS NOT NULL
          AND (city IS NULL OR postcode IS NULL OR country_code IS NULL)
        LIMIT $1`,
      [limit]
    );
    let updated = 0;
    for (const r of rows.rows) {
      const vid = r.vid;
      const ip = r.ip;
      if (!vid || !ip) continue;
      const g = geoLookup(ip);
      const cc = g.country_code;
      const city = g.city;
      const pc = g.postcode;
      if (cc || city || pc) {
        await upsertVisitorColumns(vid, {
          country_code: cc,
          city,
          postcode: pc,
        });
        updated++;
      }
    }
    res.json({ ok: true, scanned: rows.rowCount || 0, updated });
  } catch (e) {
    logToFile(`❌ backfill_geo failed: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
}
app.post("/api/admin/backfill_geo", adminBackfillGeo);
app.get("/api/admin/backfill_geo", adminBackfillGeo);

// Simple debug endpoint to test geolocation for a given IP
app.get('/api/debug/geo', (req, res) => {
  if (!requireAdminToken(req, res)) return;
  const ip = String(req.query.ip || '').trim();
  if (!ip) return res.status(400).json({ error: 'bad_request', message: 'ip required' });
  const g = geoLookup(ip);
  // Also include raw provider outputs for transparency
  let lite = null; let mm = null;
  try { const r = geoip.lookup(ip); if (r) lite = { country: r.country||null, city: r.city||null, zip: r.zip || r.postalCode || null }; } catch {}
  try { if (mmReader) { const r = mmReader.city(ip); mm = { country: r?.country?.isoCode || null, city: r?.city?.names?.fr || r?.city?.names?.en || r?.city?.name || null, postal: r?.postal?.code || null }; } } catch {}
  res.json({ ip, result: g, lite, maxmind: mm });
});

// Agents management (admin only)
app.get('/api/agents', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const r = await pool.query(`
      SELECT a.id, a.name, a.email, a.is_active, a.role, a.last_login,
             a.preferred_lang, a.notifications, a.theme_color,
             a.org_id, o.name AS org_name
      FROM agents a
      LEFT JOIN organizations o ON o.id = a.org_id
      ORDER BY a.id ASC`);
    res.json(r.rows || []);
  } catch (e) {
    logToFile(`❌ GET /api/agents: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

app.post('/api/agents', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const b = req.body || {};
    const email = String(b.email || '').trim();
    const name = String(b.name || email || 'Agent').trim();
    const pwd = String(b.password || '').trim();
    if (!email || !pwd) return res.status(400).json({ error: 'bad_request', message: 'email and password required' });
    if (!/^[^@\s]+@[^@\s]+\.[^@\s]+$/.test(email)) return res.status(400).json({ error: 'invalid_email' });
    if (pwd.length < 8) return res.status(400).json({ error: 'weak_password' });
    const hash = await bcrypt.hash(pwd, 10);
    const roleRaw = String(b.role || 'agent').toLowerCase();
    const role = roleRaw === 'admin' ? 'admin' : (roleRaw === 'user' ? 'user' : 'agent');
    const isActive = b.is_active == null ? true : Boolean(b.is_active);
    try {
      const r = await pool.query(
        `INSERT INTO agents (name, email, password, role, is_active, preferred_lang, notifications, theme_color, theme_color2)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
         RETURNING id, name, email, is_active, role, last_login, preferred_lang, notifications, theme_color, theme_color2`,
        [name, email, hash, role, isActive, b.preferred_lang || null, b.notifications || null, b.theme_color || null, b.theme_color2 || null]
      );
      return res.status(201).json(r.rows[0]);
    } catch (e) {
      if (String(e.code) === '23505') {
        // unique violation
        return res.status(409).json({ error: 'email_exists' });
      }
      throw e;
    }
  } catch (e) {
    logToFile(`❌ POST /api/agents: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

app.get('/api/agents/:id', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const id = Number(req.params.id);
    if (!Number.isFinite(id)) return res.status(400).json({ error: 'bad_request' });
  const r = await pool.query(`
      SELECT a.id, a.name, a.email, a.is_active, a.role, a.last_login,
             a.preferred_lang, a.notifications, a.theme_color, a.theme_color2,
             a.org_id, o.name AS org_name
      FROM agents a
      LEFT JOIN organizations o ON o.id = a.org_id
      WHERE a.id=$1`, [id]);
    if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
    res.json(r.rows[0]);
  } catch (e) {
    logToFile(`❌ GET /api/agents/:id: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

  app.patch('/api/agents/:id', async (req, res) => {
    if (!requireAdminAuth(req, res)) return;
    try {
      const id = Number(req.params.id);
      if (!Number.isFinite(id)) return res.status(400).json({ error: 'bad_request' });
      const b = req.body || {};

    const sets = [];
    const vals = [];
    function push(col, val) {
      sets.push(`${col} = $${sets.length + 1}`);
      vals.push(val);
    }

    if (b.name != null) push('name', String(b.name));
    if (b.email != null) push('email', String(b.email));
    if (b.is_active != null) push('is_active', Boolean(b.is_active));
    if (b.role != null) push('role', String(b.role));
    if (b.preferred_lang != null) push('preferred_lang', String(b.preferred_lang || ''));
    if (b.notifications != null) push('notifications', b.notifications);
    if (b.theme_color != null) push('theme_color', String(b.theme_color || ''));
    if (b.theme_color2 != null) push('theme_color2', String(b.theme_color2 || ''));
    // ip_allowlist removed from product scope

    // Password change
    if (b.password) {
      const pwd = String(b.password || '').trim();
      if (pwd.length < 8) return res.status(400).json({ error: 'weak_password' });
      const hash = await bcrypt.hash(pwd, 10);
      push('password', hash);
    }

    // Allow superadmin to reassign organization
    try {
      const u = authFromRequest(req);
      if (u && u.is_superadmin && Object.prototype.hasOwnProperty.call(b, 'org_id')) {
        push('org_id', (b.org_id == null || String(b.org_id).trim()==='') ? null : String(b.org_id));
      }
    } catch {}

    if (sets.length === 0) return res.status(400).json({ error: 'bad_request', message: 'no valid fields' });
    const sql = `UPDATE agents SET ${sets.join(', ') } WHERE id = $${sets.length + 1}
                 RETURNING id, name, email, is_active, role, last_login, preferred_lang, notifications, theme_color, theme_color2, org_id`;
    const r = await pool.query(sql, [...vals, id]);
    if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
    res.json(r.rows[0]);
  } catch (e) {
    logToFile(`❌ PATCH /api/agents/:id: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

app.delete('/api/agents/:id', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const id = Number(req.params.id);
    if (!Number.isFinite(id)) return res.status(400).json({ error: 'bad_request' });
    const r = await pool.query(`DELETE FROM agents WHERE id = $1`, [id]);
    res.json({ ok: true, rows: r.rowCount || 0 });
  } catch (e) {
    logToFile(`❌ DELETE /api/agents/:id: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Auth: login/logout/me routes handled in src/modules/auth/index.js

// MCP Server Integration
app.get("/api/automations/mcp", async (_req, res) => {
  try {
    // Example: Fetch data from MCP server
    const mcpData = await fetchMCPData();
    res.json({ success: true, data: mcpData });
  } catch (e) {
    logToFile(`❌ MCP server error: ${e.message}`);
    res.status(500).json({ error: "mcp_server_error" });
  }
});

// List automatic messages
app.get("/api/automations/messages", async (_req, res) => {
  try {
    const r = await pool.query(
      `SELECT id, title, url_match, locale, trigger_type, enabled, triggered_count, conversations_count, created_at, updated_at
       FROM auto_messages ORDER BY id DESC`
    );
    res.json(r.rows || []);
  } catch (e) {
    logToFile(`❌ /api/automations/messages: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Create a new automatic message
app.post("/api/automations/messages", async (req, res) => {
  try {
    const { title, url_match = null, locale = null, trigger_type = null, enabled = false } = req.body || {};
    if (!title || !`${title}`.trim()) return res.status(400).json({ error: "bad_request", message: "title required" });
    const r = await pool.query(
      `INSERT INTO auto_messages (title, url_match, locale, trigger_type, enabled)
       VALUES ($1, $2, $3, $4, $5)
       RETURNING id, title, url_match, locale, trigger_type, enabled, triggered_count, conversations_count, created_at, updated_at`,
      [String(title).trim(), url_match, locale, trigger_type, Boolean(enabled)]
    );
    res.status(201).json(r.rows[0]);
  } catch (e) {
    logToFile(`❌ POST /api/automations/messages: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Update fields (partial)
app.patch("/api/automations/messages/:id", async (req, res) => {
  try {
    const id = Number(req.params.id);
    if (!Number.isFinite(id)) return res.status(400).json({ error: "bad_request" });
    const allowed = ["title", "url_match", "locale", "trigger_type", "enabled", "triggered_count", "conversations_count"];
    const entries = Object.entries(req.body || {}).filter(([k, _]) => allowed.includes(k));
    if (!entries.length) return res.status(400).json({ error: "bad_request", message: "no valid fields" });
    const sets = entries.map(([k], i) => `${k} = $${i + 1}`);
    const values = entries.map(([, v]) => v);
    sets.push(`updated_at = NOW()`);
    const sql = `UPDATE auto_messages SET ${sets.join(", ")} WHERE id = $${values.length + 1} RETURNING *`;
    const r = await pool.query(sql, [...values, id]);
    if (r.rowCount === 0) return res.status(404).json({ error: "not_found" });
    res.json(r.rows[0]);
  } catch (e) {
    logToFile(`❌ PATCH /api/automations/messages/:id: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Delete
app.delete("/api/automations/messages/:id", async (req, res) => {
  try {
    const id = Number(req.params.id);
    if (!Number.isFinite(id)) return res.status(400).json({ error: "bad_request" });
    const r = await pool.query(`DELETE FROM auto_messages WHERE id = $1`, [id]);
    res.json({ ok: true, rows: r.rowCount });
  } catch (e) {
    logToFile(`❌ DELETE /api/automations/messages/:id: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// -------- Welcome messages (per shop_name + lang_iso) --------
function makeWelcomeId(shop, lang) {
  const s = String(shop || '').toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_+|_+$/g, '').replace(/_+/g, '_');
  const l = String(lang || '').toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_+|_+$/g, '').replace(/_+/g, '_');
  return `${s}_${l}`;
}

function makeBotId(shop, lang) {
  return `bot_${makeWelcomeId(shop, lang)}`;
}

// List (union of visitor-derived combos + any existing welcome_message rows)
app.get("/api/automations/welcome", async (_req, res) => {
  try {
    // Distinct shop/lang seen among visitors
    const v = await pool.query(
      `SELECT DISTINCT shop_name, lang_iso
       FROM visitors
       WHERE shop_name IS NOT NULL AND shop_name <> ''
         AND lang_iso IS NOT NULL AND lang_iso <> ''`
    );
    // Existing welcome messages (may include entries without a corresponding visitor combo)
    const wm = await pool.query(`SELECT * FROM welcome_message`);

    const outMap = new Map();

    // Seed with visitor-derived combos, joined with any existing welcome row
    const byId = new Map((wm.rows || []).map((r) => [String(r.id_message), r]));
    for (const row of v.rows || []) {
      const shop = row.shop_name;
      const lang = row.lang_iso;
      const id = makeWelcomeId(shop, lang);
      const name = (rec?.name && String(rec.name).trim().length) ? rec.name : `${shop} / ${lang}`;
      const rec = byId.get(id) || null;
      outMap.set(id, {
        id_message: id,
        name,
        shop_name: shop,
        lang_iso: lang,
        enabled: rec ? !!rec.enabled : false,
        title: rec?.title || null,
        content: rec?.content || null,
        exists: !!rec,
      });
    }

    // Ensure all explicit welcome_message rows are included (even if no visitors combo)
    for (const r of wm.rows || []) {
      const id = String(r.id_message);
      if (outMap.has(id)) continue; // already included
      const shop = r.shop_name || null;
      const lang = r.lang_iso || null;
      const name = (rec?.name && String(rec.name).trim().length)
        ? rec.name
        : (shop && lang ? `${shop} / ${lang}` : id);
      outMap.set(id, {
        id_message: id,
        name,
        shop_name: shop,
        lang_iso: lang,
        enabled: !!r.enabled,
        title: r.title || null,
        content: r.content || null,
        exists: true,
      });
    }

    // Sort by shop then lang, fallback by id for stable UI
    const out = Array.from(outMap.values()).sort((a, b) => {
      const sa = (a.shop_name || '').toString();
      const sb = (b.shop_name || '').toString();
      const la = (a.lang_iso || '').toString();
      const lb = (b.lang_iso || '').toString();
      return sa.localeCompare(sb) || la.localeCompare(lb) || String(a.id_message).localeCompare(String(b.id_message));
    });
    res.json(out);
  } catch (e) {
    logToFile(`❌ GET /api/automations/welcome: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Ensure records exist for all current distinct (shop_name, lang_iso)
app.post("/api/automations/welcome/sync", async (_req, res) => {
  try {
    const v = await pool.query(
      `SELECT DISTINCT shop_name, lang_iso
       FROM visitors
       WHERE shop_name IS NOT NULL AND shop_name <> ''
         AND lang_iso IS NOT NULL AND lang_iso <> ''`
    );
    let created = 0;
    for (const row of v.rows || []) {
      const id = makeWelcomeId(row.shop_name, row.lang_iso);
      const r = await pool.query(
        `INSERT INTO welcome_message (id_message, shop_name, lang_iso, title, content, enabled)
         VALUES ($1, $2, $3, $4, $5, $6)
         ON CONFLICT (id_message) DO NOTHING`,
        [id, row.shop_name, row.lang_iso, 'Bienvenue', null, false]
      );
      created += r.rowCount || 0;
    }
    res.json({ ok: true, created });
  } catch (e) {
    logToFile(`❌ POST /api/automations/welcome/sync: ${e.message}`);
    res.status(500).json({ error: "server_error" });
  }
});

// Update a welcome message by id_message
app.patch("/api/automations/welcome/:id", async (req, res) => {
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    const allowed = ["title", "content", "enabled"];
    const entries = Object.entries(req.body || {}).filter(([k]) => allowed.includes(k));
    if (!entries.length) return res.status(400).json({ error: 'bad_request', message: 'no valid fields' });
    const sets = entries.map(([k], i) => `${k} = $${i + 1}`);
    const values = entries.map(([, v]) => v);
    sets.push(`updated_at = NOW()`);
    const sql = `UPDATE welcome_message SET ${sets.join(', ')} WHERE id_message = $${values.length + 1} RETURNING *`;
    const r = await pool.query(sql, [...values, id]);
    if (r.rowCount === 0) return res.status(404).json({ error: 'not_found' });
    res.json(r.rows[0]);
  } catch (e) {
    logToFile(`❌ PATCH /api/automations/welcome/:id: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Create or upsert a welcome message row
app.post("/api/automations/welcome", async (req, res) => {
  try {
    const b = req.body || {};
    const rawId = String(b.id_message || '').trim();
    const title = b.title ?? null;
    const content = b.content ?? null;

    // Template-only mode: accept id_message/title/content without shop/lang
    if (rawId) {
      // Try to derive shop/lang from the id pattern: <shop>_<lang>
      let shop = null, lang = null;
      try {
        const m = /^(.+)_([a-z]{2})$/i.exec(rawId);
        if (m) { shop = m[1].replace(/_/g, ' ').trim(); lang = m[2].toLowerCase(); }
      } catch {}
      // Fallback values to satisfy NOT NULL schema
      if (!shop) shop = rawId; // store id as shop name if unknown
      if (!lang) lang = 'xx';  // unknown language placeholder
      try {
        const r = await pool.query(
          `INSERT INTO welcome_message (id_message, shop_name, lang_iso, title, content, enabled)
           VALUES ($1, $2, $3, $4, $5, $6)
           ON CONFLICT (id_message)
           DO UPDATE SET title = EXCLUDED.title, content = EXCLUDED.content, updated_at = NOW()
           RETURNING *`,
          [rawId, shop, lang, title, content, false]
        );
        return res.status(201).json(r.rows[0]);
      } catch (e) {
        if (String(e?.code) === '23505') {
          // Likely violation of unique (shop_name, lang_iso)
          return res.status(409).json({ error: 'conflict', message: 'shop_lang_already_exists' });
        }
        throw e;
      }
    }

    // Back-compat: support legacy payloads that include shop/lang
    const shop = String(b.shop_name || '').trim();
    const lang = String(b.lang_iso || '').trim();
    if (!shop || !lang) return res.status(400).json({ error: 'bad_request' });
    const id = makeWelcomeId(shop, lang);
    const enabled = Boolean(b.enabled);
    const r2 = await pool.query(
      `INSERT INTO welcome_message (id_message, shop_name, lang_iso, title, content, enabled)
       VALUES ($1, $2, $3, $4, $5, $6)
       ON CONFLICT (shop_name, lang_iso)
       DO UPDATE SET id_message = EXCLUDED.id_message, title = EXCLUDED.title, content = EXCLUDED.content, enabled = EXCLUDED.enabled, updated_at = NOW()
       RETURNING *`,
      [id, shop, lang, title, content, enabled]
    );
    res.status(201).json(r2.rows[0]);
  } catch (e) {
    logToFile(`❌ POST /api/automations/welcome: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Rename a welcome message id_message
app.post('/api/automations/welcome/:id/rename', async (req, res) => {
  try {
    const oldId = String(req.params.id || '').trim();
    const newId = String(req.body?.new_id || req.body?.newId || '').trim();
    if (!oldId || !newId) return res.status(400).json({ error: 'bad_request', message: 'new_id required' });
    if (oldId === newId) return res.status(400).json({ error: 'bad_request', message: 'ids are identical' });
    const exists = await pool.query(`SELECT 1 FROM welcome_message WHERE id_message=$1 LIMIT 1`, [newId]);
    if (exists.rowCount) return res.status(409).json({ error: 'conflict', message: 'new_id already exists' });
    const r = await pool.query(`UPDATE welcome_message SET id_message=$1, updated_at=NOW() WHERE id_message=$2 RETURNING *`, [newId, oldId]);
    if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
    res.json({ ok: true, row: r.rows[0] });
  } catch (e) {
    logToFile(`❌ POST /api/automations/welcome/:id/rename: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Duplicate a welcome message to a new id_message
app.post('/api/automations/welcome/:id/duplicate', async (req, res) => {
  try {
    const srcId = String(req.params.id || '').trim();
    if (!srcId) return res.status(400).json({ error: 'bad_request' });
    const r0 = await pool.query(`SELECT * FROM welcome_message WHERE id_message=$1 LIMIT 1`, [srcId]);
    if (!r0.rowCount) return res.status(404).json({ error: 'not_found' });
    const src = r0.rows[0];
    let newId = String(req.body?.new_id || req.body?.newId || '').trim();
    const title = req.body?.title ?? src.title;
    const enabled = (req.body?.enabled == null) ? !!src.enabled : !!req.body.enabled;
    if (!newId) {
      // derive unique id: src_copy, src_copyN
      let base = `${srcId}_copy`;
      newId = base;
      for (let i = 2; i < 1000; i++) {
        const chk = await pool.query(`SELECT 1 FROM welcome_message WHERE id_message=$1 LIMIT 1`, [newId]);
        if (!chk.rowCount) break;
        newId = `${base}${i}`;
      }
      const chk2 = await pool.query(`SELECT 1 FROM welcome_message WHERE id_message=$1 LIMIT 1`, [newId]);
      if (chk2.rowCount) return res.status(409).json({ error: 'conflict', message: 'could_not_generate_unique_id' });
    } else {
      const chk = await pool.query(`SELECT 1 FROM welcome_message WHERE id_message=$1 LIMIT 1`, [newId]);
      if (chk.rowCount) return res.status(409).json({ error: 'conflict', message: 'new_id already exists' });
    }
    const ins = await pool.query(
      `INSERT INTO welcome_message (id_message, shop_name, lang_iso, title, content, enabled)
       VALUES ($1,$2,$3,$4,$5,$6)
       RETURNING *`,
      [newId, src.shop_name, src.lang_iso, title, src.content, enabled]
    );
    res.status(201).json({ ok: true, row: ins.rows[0] });
  } catch (e) {
    logToFile(`❌ POST /api/automations/welcome/:id/duplicate: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Delete a welcome message by id_message
app.delete('/api/automations/welcome/:id', async (req, res) => {
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    try { await ensureChatbotWelcomeLinkTable(); } catch {}
    // Best-effort: remove links to allow deletion (FK is RESTRICT)
    try { await pool.query(`DELETE FROM chatbot_welcome_link WHERE welcome_message_id=$1`, [id]); } catch {}
    const r = await pool.query(`DELETE FROM welcome_message WHERE id_message=$1`, [id]);
    if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
    res.json({ ok: true, deleted: r.rowCount });
  } catch (e) {
    logToFile(`❌ DELETE /api/automations/welcome/:id: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

function openaiForConfig(cfgRow) {
  // Enforce per-bot key from DB only (no env fallback)
  const key = cfgRow?.openai_api_key;
  if (!key) return null;
  try {
    return new OpenAI({
      apiKey: key,
      organization: cfgRow?.openai_org || undefined,
      project: cfgRow?.openai_project || undefined,
      baseURL: cfgRow?.openai_base_url || undefined,
    });
  } catch {
    return null;
  }
}

  // List (computed from visitors, with join to chatbot_config)
  app.get("/api/automations/chatbots", async (_req, res) => {
    try {
      try { await ensureChatbotMcpServerName(); } catch {}
      const existing = await pool.query(`SELECT * FROM chatbot_config`);
      // Load welcome links to include welcome_message_id without widening chatbot_config
      let linkById = new Map();
      try {
        await ensureChatbotWelcomeLinkTable();
        const lr = await pool.query(`SELECT id_bot, welcome_message_id FROM chatbot_welcome_link`);
        linkById = new Map((lr.rows || []).map((r) => [String(r.id_bot), r.welcome_message_id]));
      } catch {}
      const out = [];
      for (const rec of existing.rows || []) {
        const id = String(rec.id_bot);
        if (!id) continue;
        const shop = rec.shop_name || '';
        const lang = rec.lang_iso || '';
        const name = (rec?.name && String(rec.name).trim().length)
          ? rec.name
          : (shop && lang ? `${shop} / ${lang}` : id);
        out.push({
          id_bot: id,
          name,
          shop_name: shop || null,
          lang_iso: lang || null,
          enabled: !!rec.enabled,
          has_api_key: !!rec.openai_api_key,
          openai_api_key: rec.openai_api_key || null,
          prompt_id: rec.prompt_id || null,
          prompt_version: rec.prompt_version || null,
          bot_behavior: rec.bot_behavior || 'manual',
          mcp_enabled: rec.mcp_enabled ?? null,
          mcp_tools: rec.mcp_tools || null,
          mcp_server_name: rec.mcp_server_name || null,
          web_search_enabled: rec.web_search_enabled ?? null,
          prompt_config_id: rec.prompt_config_id || null,
          local_prompt_id: rec.local_prompt_id || null,
          welcome_message_id: linkById.get(id) || null,
          exists: true,
        });
      }
      // sort by shop/lang
      out.sort((a, b) => (a.shop_name || '').localeCompare(b.shop_name || '') || (a.lang_iso || '').localeCompare(b.lang_iso || ''));
      res.json(out);
    } catch (e) {
      logToFile(`❌ GET /api/automations/chatbots: ${e.message}`);
      res.status(500).json({ error: 'server_error' });
    }
  });

// Ensure records exist for all current distinct (shop_name, lang_iso)
app.post("/api/automations/chatbots/sync", async (_req, res) => {
  try {
    const v = await pool.query(
      `SELECT DISTINCT shop_name, lang_iso
       FROM visitors
       WHERE shop_name IS NOT NULL AND shop_name <> ''
         AND lang_iso IS NOT NULL AND lang_iso <> ''`
    );
    let created = 0;
    for (const row of v.rows || []) {
      const id = makeBotId(row.shop_name, row.lang_iso);
      const r = await pool.query(
        `INSERT INTO chatbot_config (id_bot, shop_name, lang_iso, assistant_id, enabled)
         VALUES ($1, $2, $3, $4, $5)
         ON CONFLICT (id_bot) DO NOTHING`,
        [id, row.shop_name, row.lang_iso, null, false]
      );
      created += r.rowCount || 0;
    }
    res.json({ ok: true, created });
  } catch (e) {
    logToFile(`❌ POST /api/automations/chatbots/sync: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

  // Create or upsert a chatbot config
  app.post("/api/automations/chatbots", async (req, res) => {
    try {
      const b = req.body || {};
    const shop = String(b.shop_name || '').trim();
    const lang = String(b.lang_iso || '').trim();
    const id = String(b.id_bot || '').trim() || makeBotId(shop, lang);
    if (!shop || !lang || !id) return res.status(400).json({ error: 'bad_request' });
    const assistant_id = b.assistant_id ?? null;
    const enabled = Boolean(b.enabled);
    const name = b.name ?? null;
    const instructions = b.instructions ?? null;
    const model = b.model ?? null;
    const temperature = b.temperature ?? null;
    const top_p = b.top_p ?? null;
    const response_format = b.response_format ?? null;
    const tools_code_interpreter = b.tools_code_interpreter ?? null;
    const tools_file_search = b.tools_file_search ?? null;
    const openai_api_key = b.openai_api_key ?? null;
    const openai_org = b.openai_org ?? null;
    const openai_project = b.openai_project ?? null;
    const openai_base_url = b.openai_base_url ?? null;
    const prompt_id = b.prompt_id ?? null;
    const prompt_version = b.prompt_version ?? null;
    const prompt_config_id = b.prompt_config_id ?? null;
    let local_prompt_id = b.local_prompt_id ?? null; // legacy field; no auto-mirroring
    const mcp_enabled = b.mcp_enabled === true;
    const welcome_message_id = b.welcome_message_id ? String(b.welcome_message_id).trim() : null;
    const mcp_tools = Array.isArray(b.mcp_tools) && b.mcp_tools.length ? b.mcp_tools : null;
    let r;
    const sql = `INSERT INTO chatbot_config (id_bot, shop_name, lang_iso, enabled, name, instructions, openai_api_key, prompt_id, prompt_version, bot_behavior, mcp_enabled, mcp_tools, local_prompt_id, prompt_config_id)
                 VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
                 ON CONFLICT (id_bot) DO UPDATE SET enabled = EXCLUDED.enabled, name = EXCLUDED.name, instructions = COALESCE(EXCLUDED.instructions, chatbot_config.instructions), openai_api_key = COALESCE(EXCLUDED.openai_api_key, chatbot_config.openai_api_key), prompt_id = EXCLUDED.prompt_id, prompt_version = EXCLUDED.prompt_version, bot_behavior = COALESCE(EXCLUDED.bot_behavior, chatbot_config.bot_behavior), mcp_enabled = COALESCE(EXCLUDED.mcp_enabled, chatbot_config.mcp_enabled), mcp_tools = EXCLUDED.mcp_tools, local_prompt_id = COALESCE(EXCLUDED.local_prompt_id, chatbot_config.local_prompt_id), prompt_config_id = COALESCE(EXCLUDED.prompt_config_id, chatbot_config.prompt_config_id), updated_at = NOW()
                 RETURNING *`;
    try {
      r = await pool.query(sql, [id, shop, lang, enabled, name, instructions, openai_api_key, prompt_id, prompt_version, b.bot_behavior || null, mcp_enabled, mcp_tools, local_prompt_id, prompt_config_id]);
    } catch (e) {
      if (String(e?.code) === '42703') { // undefined_column
        try { await ensureChatbotInstructions(); } catch {}
        try { await ensureTables(); } catch {}
        r = await pool.query(sql, [id, shop, lang, enabled, name, instructions, openai_api_key, prompt_id, prompt_version, b.bot_behavior || null, mcp_enabled, mcp_tools, local_prompt_id, prompt_config_id]);
      } else {
        throw e;
      }
    }
    if (welcome_message_id) {
      try { await ensureChatbotWelcomeLinkTable(); } catch {}
      try {
        await pool.query(
          `INSERT INTO chatbot_welcome_link (id_bot, welcome_message_id, updated_at)
           VALUES ($1, $2, NOW())
           ON CONFLICT (id_bot) DO UPDATE SET welcome_message_id = EXCLUDED.welcome_message_id, updated_at = NOW()`,
          [id, welcome_message_id]
        );
      } catch {}
    }
    // Upsert welcome link if provided
    const linkId = String(req.body?.welcome_message_id || '').trim();
    if (linkId) {
      try { await ensureChatbotWelcomeLinkTable(); } catch {}
      try {
        await pool.query(
          `INSERT INTO chatbot_welcome_link (id_bot, welcome_message_id, updated_at)
           VALUES ($1, $2, NOW())
           ON CONFLICT (id_bot) DO UPDATE SET welcome_message_id = EXCLUDED.welcome_message_id, updated_at = NOW()`,
          [id, linkId]
        );
      } catch {}
    }
    // Link welcome message by id in separate table
    if (welcome_message_id) {
      try { await ensureChatbotWelcomeLinkTable(); } catch {}
      try {
        await pool.query(
          `INSERT INTO chatbot_welcome_link (id_bot, welcome_message_id, updated_at)
           VALUES ($1, $2, NOW())
           ON CONFLICT (id_bot) DO UPDATE SET welcome_message_id = EXCLUDED.welcome_message_id, updated_at = NOW()`,
          [id, welcome_message_id]
        );
      } catch {}
    }
    const row = r.rows[0];
    res.status(201).json(row);
  } catch (e) {
    logToFile(`❌ POST /api/automations/chatbots: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Update fields (assistant_id, enabled)
  app.patch("/api/automations/chatbots/:id", async (req, res) => {
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    const allowed = ["enabled", "name", "instructions", "openai_api_key", "prompt_id", "prompt_version", "bot_behavior", "mcp_enabled", "mcp_tools", "web_search_enabled", "local_prompt_id", "prompt_config_id", "mcp_server_name"];
    const entries = Object.entries(req.body || {}).filter(([k]) => allowed.includes(k));
    if (!entries.length) return res.status(400).json({ error: 'bad_request', message: 'no valid fields' });
    const sets = entries.map(([k], i) => `${k} = $${i + 1}`);
    const values = entries.map(([, v]) => v);
    sets.push(`updated_at = NOW()`);
    const sql = `UPDATE chatbot_config SET ${sets.join(', ')} WHERE id_bot = $${values.length + 1} RETURNING *`;
    let r;
    try {
      r = await pool.query(sql, [...values, id]);
    } catch (e) {
      // If a column is missing (e.g., instructions/web_search_enabled/welcome_message_id), attempt to auto-migrate and retry once
      if (String(e?.code) === '42703' /* undefined_column */) {
        try {
          await ensureChatbotInstructions();
          try { await ensureChatbotWelcomeMessage(); } catch {}
          try { await ensureChatbotWelcomeMessageId(); } catch {}
          await ensureTables();
          r = await pool.query(sql, [...values, id]);
        } catch (e2) {
          throw e2;
        }
      } else {
        throw e;
      }
    }
    if (r.rowCount === 0) {
      // Fallback upsert: create minimal row when missing
      let shop = null, lang = null;
      try {
        const m = /^bot_(.+)_([a-z]{2})$/i.exec(id);
        if (m) { shop = m[1].replace(/_/g, ' '); lang = m[2].toLowerCase(); }
      } catch {}
      if (!shop || !lang) {
        // Try to discover from visitors (best-effort)
        try {
          const vr = await pool.query(`SELECT DISTINCT shop_name, lang_iso FROM visitors WHERE shop_name IS NOT NULL AND shop_name<>'' AND lang_iso IS NOT NULL AND lang_iso<>'' LIMIT 1`);
          if (vr.rowCount) { shop = shop || vr.rows[0].shop_name; lang = lang || vr.rows[0].lang_iso; }
        } catch {}
      }
      if (shop && lang) {
        const enabled = req.body?.enabled === true;
        const name = req.body?.name || null;
        const openai_api_key = req.body?.openai_api_key || null;
        const prompt_id = req.body?.prompt_id || null;
        const prompt_version = req.body?.prompt_version || null;
        const bot_behavior = req.body?.bot_behavior || null;
        const mcp_enabled = req.body?.mcp_enabled === true;
        const mcp_tools = Array.isArray(req.body?.mcp_tools) && req.body.mcp_tools.length ? req.body.mcp_tools : null;
        const ins = await pool.query(
          `INSERT INTO chatbot_config (id_bot, shop_name, lang_iso, enabled, name, openai_api_key, prompt_id, prompt_version, bot_behavior, mcp_enabled, mcp_tools, updated_at)
           VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,NOW())
           ON CONFLICT (id_bot) DO NOTHING
           RETURNING *`,
          [id, shop, lang, enabled, name, openai_api_key, prompt_id, prompt_version, bot_behavior, mcp_enabled, mcp_tools]
        );
        if (ins.rowCount) {
          r = ins; // Treat as the new row
        }
      }
      if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
    }
    // Upsert welcome link if provided
    const linkId = String(req.body?.welcome_message_id || '').trim();
    if (linkId) {
      try { await ensureChatbotWelcomeLinkTable(); } catch {}
      try {
        await pool.query(
          `INSERT INTO chatbot_welcome_link (id_bot, welcome_message_id, updated_at)
           VALUES ($1, $2, NOW())
           ON CONFLICT (id_bot) DO UPDATE SET welcome_message_id = EXCLUDED.welcome_message_id, updated_at = NOW()`,
          [id, linkId]
        );
      } catch {}
    }
    const row = r.rows[0];
    // Try to apply config to OpenAI assistant if available
    try {
      const openai = openaiForConfig(row);
      if (openai && row.assistant_id) {
        const tools = [];
        if (row.tools_code_interpreter) tools.push({ type: 'code_interpreter' });
        if (row.tools_file_search) tools.push({ type: 'file_search' });
        const respFormat = row.response_format === 'json_object' ? { type: 'json_object' } : 'text';
        await openai.beta.assistants.update(row.assistant_id, {
          model: row.model || process.env.OPENAI_MODEL || 'gpt-4o-mini',
          instructions: row.instructions || undefined,
          tools: tools.length ? tools : undefined,
          response_format: respFormat,
        });
      }
    } catch (e) {
      logToFile(`⚠️ OpenAI assistant update failed: ${e.message}`);
    }
    res.json(row);
  } catch (e) {
    logToFile(`❌ PATCH /api/automations/chatbots/:id: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// POST alias for environments that block PATCH at the proxy layer.
// Semantics: same as the PATCH route above (update fields; create minimal row if missing).
  app.post("/api/automations/chatbots/:id/save", async (req, res) => {
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    const allowed = ["enabled", "name", "instructions", "openai_api_key", "prompt_id", "prompt_version", "bot_behavior", "mcp_enabled", "mcp_tools", "web_search_enabled", "local_prompt_id", "prompt_config_id"];
    const entries = Object.entries(req.body || {}).filter(([k]) => allowed.includes(k));
    if (!entries.length) return res.status(400).json({ error: 'bad_request', message: 'no valid fields' });
    const sets = entries.map(([k], i) => `${k} = $${i + 1}`);
    const values = entries.map(([, v]) => v);
    sets.push(`updated_at = NOW()`);
    const sql = `UPDATE chatbot_config SET ${sets.join(', ')} WHERE id_bot = $${values.length + 1} RETURNING *`;
    let r;
    try {
      r = await pool.query(sql, [...values, id]);
    } catch (e) {
      // If a column is missing (e.g., web_search_enabled), attempt to auto-migrate and retry once
      if (String(e?.code) === '42703' /* undefined_column */) {
        try {
          await ensureChatbotWelcomeMessage();
          await ensureTables();
          r = await pool.query(sql, [...values, id]);
        } catch (e2) {
          throw e2;
        }
      } else {
        throw e;
      }
    }
    if (r.rowCount === 0) {
      // Fallback upsert (same as in PATCH)
      let shop = null, lang = null;
      try { const m = /^bot_(.+)_([a-z]{2})$/i.exec(id); if (m) { shop = m[1].replace(/_/g, ' '); lang = m[2].toLowerCase(); } } catch {}
      if (!shop || !lang) {
        try { const vr = await pool.query(`SELECT DISTINCT shop_name, lang_iso FROM visitors WHERE shop_name IS NOT NULL AND shop_name<>'' AND lang_iso IS NOT NULL AND lang_iso<>'' LIMIT 1`); if (vr.rowCount) { shop = shop || vr.rows[0].shop_name; lang = lang || vr.rows[0].lang_iso; } } catch {}
      }
      if (shop && lang) {
        const enabled = req.body?.enabled === true;
        const name = req.body?.name || null;
        const instructions = req.body?.instructions || null;
        const openai_api_key = req.body?.openai_api_key || null;
        const prompt_id = req.body?.prompt_id || null;
        const prompt_version = req.body?.prompt_version || null;
        const bot_behavior = req.body?.bot_behavior || null;
        const ins = await pool.query(
          `INSERT INTO chatbot_config (id_bot, shop_name, lang_iso, enabled, name, instructions, openai_api_key, prompt_id, prompt_version, bot_behavior, local_prompt_id, prompt_config_id, welcome_message, updated_at)
           VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,NOW())
           ON CONFLICT (id_bot) DO NOTHING
           RETURNING *`,
          [
            id,
            shop,
            lang,
            enabled,
            name,
            instructions,
            openai_api_key,
            prompt_id,
            prompt_version,
            bot_behavior,
            req.body?.local_prompt_id || null,
            req.body?.prompt_config_id || null,
            req.body?.welcome_message || null,
          ]
        );
        if (ins.rowCount) r = ins;
      }
      if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
    }
    const row = r.rows[0];
    res.json(row);
  } catch (e) {
    logToFile(`❌ POST /api/automations/chatbots/:id/save: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Minimal list API for frontend selectors
app.get('/api/welcome-messages', async (_req, res) => {
  try {
    const r = await pool.query(`SELECT id_message AS id, title, content, enabled, shop_name, lang_iso, created_at, updated_at FROM welcome_message ORDER BY shop_name, lang_iso`);
    res.json({ ok: true, items: r.rows || [] });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Rename a chatbot id (primary key). Optionally cascade to files.
app.post("/api/automations/chatbots/:id/rename", async (req, res) => {
  const client = await pool.connect();
  try {
    const oldId = String(req.params.id || '').trim();
    const newId = String(req.body?.new_id_bot || req.body?.newId || '').trim();
    const cascadeFiles = req.body?.cascade_files === true;
    if (!oldId || !newId) return res.status(400).json({ error: 'bad_request', message: 'new_id_bot required' });
    if (oldId === newId) return res.status(400).json({ error: 'bad_request', message: 'ids are identical' });
    const existsNew = await client.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [newId]);
    if (existsNew.rowCount) return res.status(409).json({ error: 'conflict', message: 'new_id_bot already exists' });
    const existsOld = await client.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [oldId]);
    if (!existsOld.rowCount) return res.status(404).json({ error: 'not_found' });

    await client.query('BEGIN');
    try { await ensureChatbotWelcomeLinkTable(); } catch {}
    // Preserve any welcome links, then remove them to avoid FK conflict
    let links = [];
    try {
      const lr = await client.query(`SELECT welcome_message_id FROM chatbot_welcome_link WHERE id_bot=$1`, [oldId]);
      links = lr.rows || [];
    } catch {}
    try { await client.query(`DELETE FROM chatbot_welcome_link WHERE id_bot=$1`, [oldId]); } catch {}

    // Update primary key on parent row now that children are detached
    const r = await client.query(`UPDATE chatbot_config SET id_bot=$1, updated_at=NOW() WHERE id_bot=$2 RETURNING *`, [newId, oldId]);
    if (!r.rowCount) {
      await client.query('ROLLBACK');
      return res.status(404).json({ error: 'not_found' });
    }

    // Recreate welcome links with the new id
    try {
      for (const row of links) {
        await client.query(
          `INSERT INTO chatbot_welcome_link (id_bot, welcome_message_id, updated_at, enabled)
           VALUES ($1, $2, NOW(), COALESCE($3,false))
           ON CONFLICT (id_bot) DO UPDATE SET welcome_message_id = EXCLUDED.welcome_message_id, updated_at = NOW(), enabled = COALESCE(EXCLUDED.enabled, chatbot_welcome_link.enabled)`,
          [newId, row.welcome_message_id, row.enabled]
        );
      }
    } catch {}

    // Optional cascade to mcp_files.bot_id
    if (cascadeFiles) {
      try { await client.query(`UPDATE mcp_files SET bot_id=$1 WHERE bot_id=$2`, [newId, oldId]); } catch {}
    }

    await client.query('COMMIT');
    res.json({ ok: true, row: r.rows[0] });
  } catch (e) {
    try { await pool.query('ROLLBACK'); } catch {}
    logToFile(`❌ POST /api/automations/chatbots/:id/rename: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  } finally {
    try { client.release(); } catch {}
  }
});

// Alias: some proxies block certain paths; provide "/update" as a stable alternative
  app.post("/api/automations/chatbots/:id/update", async (req, res) => {
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    const allowed = ["enabled", "name", "instructions", "openai_api_key", "prompt_id", "prompt_version", "bot_behavior", "mcp_enabled", "mcp_tools", "web_search_enabled", "local_prompt_id", "prompt_config_id", "mcp_server_name"];
    const entries = Object.entries(req.body || {}).filter(([k]) => allowed.includes(k));
    if (!entries.length) return res.status(400).json({ error: 'bad_request', message: 'no valid fields' });
    const sets = entries.map(([k], i) => `${k} = $${i + 1}`);
    const values = entries.map(([, v]) => v);
    sets.push(`updated_at = NOW()`);
    const sql = `UPDATE chatbot_config SET ${sets.join(', ')} WHERE id_bot = $${values.length + 1} RETURNING *`;
    let r = await pool.query(sql, [...values, id]);
    if (r.rowCount === 0) {
      // Create minimal row if missing (same logic as /save)
      let shop = null, lang = null;
      try { const m = /^bot_(.+)_([a-z]{2})$/i.exec(id); if (m) { shop = m[1].replace(/_/g, ' '); lang = m[2].toLowerCase(); } } catch {}
      if (!shop || !lang) {
        try { const vr = await pool.query(`SELECT DISTINCT shop_name, lang_iso FROM visitors WHERE shop_name IS NOT NULL AND shop_name<>'' AND lang_iso IS NOT NULL AND lang_iso<>'' LIMIT 1`); if (vr.rowCount) { shop = shop || vr.rows[0].shop_name; lang = lang || vr.rows[0].lang_iso; } } catch {}
      }
      if (shop && lang) {
        const enabled = req.body?.enabled === true;
        const name = req.body?.name || null;
        const instructions = req.body?.instructions || null;
        const openai_api_key = req.body?.openai_api_key || null;
        const prompt_id = req.body?.prompt_id || null;
        const prompt_version = req.body?.prompt_version || null;
        const bot_behavior = req.body?.bot_behavior || null;
        const mcp_enabled = req.body?.mcp_enabled === true;
        const mcp_tools = Array.isArray(req.body?.mcp_tools) && req.body.mcp_tools.length ? req.body.mcp_tools : null;
        const ins = await pool.query(
          `INSERT INTO chatbot_config (id_bot, shop_name, lang_iso, enabled, name, instructions, openai_api_key, prompt_id, prompt_version, bot_behavior, mcp_enabled, mcp_tools, local_prompt_id, prompt_config_id, updated_at)
           VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,NOW())
           ON CONFLICT (id_bot) DO NOTHING
           RETURNING *`,
          [
            id,
            shop,
            lang,
            enabled,
            name,
            instructions,
            openai_api_key,
            prompt_id,
            prompt_version,
            bot_behavior,
            mcp_enabled,
            mcp_tools,
            req.body?.local_prompt_id || null,
            req.body?.prompt_config_id || null,
          ]
        );
        if (ins.rowCount) r = ins;
      }
      if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
    }
    // Upsert welcome link if provided
    const linkId2 = String(req.body?.welcome_message_id || '').trim();
    if (linkId2) {
      try { await ensureChatbotWelcomeLinkTable(); } catch {}
      try {
        await pool.query(
          `INSERT INTO chatbot_welcome_link (id_bot, welcome_message_id, updated_at)
           VALUES ($1, $2, NOW())
           ON CONFLICT (id_bot) DO UPDATE SET welcome_message_id = EXCLUDED.welcome_message_id, updated_at = NOW()`,
          [id, linkId2]
        );
      } catch {}
    }
    res.json(r.rows[0]);
  } catch (e) {
    logToFile(`❌ POST /api/automations/chatbots/:id/update: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Upload and attach a file to the assistant (by URL or base64 content)
app.post("/api/automations/chatbots/:id/files", async (req, res) => {
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    const r0 = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1`, [id]);
    if (!r0.rowCount) return res.status(404).json({ error: 'not_found' });
    const cfgRow = r0.rows[0];
    const openai = openaiForConfig(cfgRow);
    if (!openai) return res.status(400).json({ error: 'openai_disabled' });

    // Prefer Responses API + Vector Store flow.
    // Ensure a vector store exists for this bot.
    let vectorStoreId = cfgRow.vector_store_id || null;
    try {
      if (!vectorStoreId) {
        const vs = await openai.vectorStores.create({ name: `kb_${id}` });
        vectorStoreId = vs?.id || null;
        if (vectorStoreId) {
          await pool.query(
            `UPDATE chatbot_config SET vector_store_id = $1, updated_at = NOW() WHERE id_bot = $2`,
            [vectorStoreId, id]
          );
        }
      }
    } catch (e) {
      logToFile(`⚠️ vector store create failed: ${e.message}`);
    }
    if (!vectorStoreId) return res.status(500).json({ error: 'no_vector_store' });

    const { file_url, filename, content_b64, items } = req.body || {};
    const uploads = [];

    const ensureDir = () => { try { fs.mkdirSync(path.join(__dirname, 'tmp_uploads'), { recursive: true }); } catch {} };
    ensureDir();

    const uploadOne = async (payload) => {
      let name = String(payload.filename || '').trim() || 'attachment.txt';
      let dataBuf = null;
      if (payload.content_b64) {
        try { dataBuf = Buffer.from(String(payload.content_b64), 'base64'); } catch {}
      } else if (payload.file_url) {
        const resp = await fetch(String(payload.file_url));
        if (!resp.ok) throw new Error(`download_failed_${resp.status}`);
        const ab = await resp.arrayBuffer();
        dataBuf = Buffer.from(ab);
        if (!payload.filename) {
          try { const u = new URL(String(payload.file_url)); const base = u.pathname.split('/').pop(); if (base) name = base; } catch {}
        }
      }
      if (!dataBuf || !dataBuf.length) throw new Error('no_content');
      const tmpPath = path.join(__dirname, 'tmp_uploads', `${Date.now()}-${Math.random().toString(16).slice(2)}-${name}`);
      await fs.promises.writeFile(tmpPath, dataBuf);
      const stream = fs.createReadStream(tmpPath);
      // Upload file then attach to vector store
      const up = await openai.files.create({ file: stream, purpose: 'assistants' });
      const fileId = up?.id;
      if (!fileId) throw new Error('upload_failed');
      await openai.vectorStores.files.create(vectorStoreId, { file_id: fileId });
      await pool.query(
        `UPDATE chatbot_config SET file_ids = COALESCE(file_ids, '{}'::text[]) || $1::text, updated_at = NOW() WHERE id_bot = $2`,
        [fileId, id]
      );
      uploads.push({ filename: name, file_id: fileId, vector_store_id: vectorStoreId });
    };

    if (Array.isArray(items) && items.length) {
      for (const it of items) {
        try { await uploadOne(it || {}); } catch (e) { uploads.push({ error: String(e?.message || e) }); }
      }
    } else {
      try { await uploadOne({ file_url, filename, content_b64 }); } catch (e) { return res.status(400).json({ error: 'upload_failed', message: String(e?.message || e) }); }
    }

    res.status(201).json({ ok: true, uploads, vector_store_id: vectorStoreId });
  } catch (e) {
    logToFile(`❌ POST /api/automations/chatbots/:id/files: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Inspect remote OpenAI assistant vs local config (debug helper)
app.get("/api/automations/chatbots/:id/inspect", async (req, res) => {
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    const r0 = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1`, [id]);
    if (!r0.rowCount) return res.status(404).json({ error: 'not_found' });
    const row = r0.rows[0];
    const openai = openaiForConfig(row);
    if (!openai || !row.assistant_id) {
      return res.json({
        has_openai: !!openai,
        assistant_id: row.assistant_id || null,
        local: {
          name: row.name || null,
          model: row.model || null,
          instructions_len: (row.instructions || '').length,
          tools: {
            code_interpreter: !!row.tools_code_interpreter,
            file_search: !!row.tools_file_search,
          },
        },
        remote: null,
      });
    }
    // Assistant (legacy) details if present
    let asst = null; let remoteTools = [];
    try {
      asst = await openai.beta.assistants.retrieve(row.assistant_id);
      remoteTools = Array.isArray(asst.tools) ? asst.tools.map((t) => t?.type) : [];
    } catch {}
    // Vector store info (Responses API)
    let vsFiles = [];
    if (row.vector_store_id) {
      try {
        const list = await openai.vectorStores.files.list(row.vector_store_id, { limit: 100 });
        vsFiles = (list?.data || []).map((f) => ({ id: f.id, status: f.status }));
      } catch {}
    }
    return res.json({
      has_openai: true,
      assistant_id: row.assistant_id,
      local: {
        name: row.name || null,
        model: row.model || null,
        instructions_len: (row.instructions || '').length,
        instructions_preview: (row.instructions || '').slice(0, 200),
        tools: {
          code_interpreter: !!row.tools_code_interpreter,
          file_search: !!row.tools_file_search,
        },
      },
      remote: {
        name: asst?.name || null,
        model: asst?.model || null,
        instructions_len: ((asst && asst.instructions) || '').length,
        instructions_preview: ((asst && asst.instructions) || '').slice(0, 200),
        tools: remoteTools,
        vector_store_id: row.vector_store_id || null,
        vector_store_files: vsFiles,
      },
      match: {
        model: (row.model || '') === ((asst && asst.model) || ''),
        has_code_interpreter: remoteTools.includes('code_interpreter') === !!row.tools_code_interpreter,
        has_file_search: remoteTools.includes('file_search') === !!row.tools_file_search,
        instructions_same_len: ((row.instructions || '').length) === ((((asst && asst.instructions) || '').length)),
      }
    });
  } catch (e) {
    logToFile(`❌ GET /api/automations/chatbots/:id/inspect: ${e.message}`);
    res.status(500).json({ error: 'server_error' });
  }
});

// Force-push local config (name, instructions, tools, model) to the OpenAI assistant
app.post("/api/automations/chatbots/:id/push", async (req, res) => {
  try {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    const r0 = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1`, [id]);
    if (!r0.rowCount) return res.status(404).json({ error: 'not_found' });
    const row = r0.rows[0];
    const openai = openaiForConfig(row);
    if (!openai || !row.assistant_id) return res.status(400).json({ error: 'openai_disabled_or_no_assistant' });
    const tools = [];
    if (row.tools_code_interpreter) tools.push({ type: 'code_interpreter' });
    if (row.tools_file_search) tools.push({ type: 'file_search' });
    const respFormat = row.response_format === 'json_object' ? { type: 'json_object' } : 'text';
    const asst = await openai.beta.assistants.update(row.assistant_id, {
      model: row.model || process.env.OPENAI_MODEL || 'gpt-4o-mini',
      name: row.name || undefined,
      instructions: row.instructions || undefined,
      tools: tools.length ? tools : undefined,
      response_format: respFormat,
    });
    res.json({ ok: true, assistant_id: asst.id, model: asst.model, tools: asst.tools });
  } catch (e) {
    logToFile(`❌ POST /api/automations/chatbots/:id/push: ${e.message}`);
    res.status(500).json({ error: 'server_error', message: e.message });
  }
});

// Generate a reply using the Responses API (no Assistants object required)
  app.post("/api/automations/chatbots/:id/respond", async (req, res) => {
    try {
      const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    const r0 = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1`, [id]);
    if (!r0.rowCount) return res.status(404).json({ error: 'not_found' });
    const row = r0.rows[0];
    const b = req.body || {};
    const userInput = b.input ?? b.message ?? '';
    if (!`${userInput}`.trim()) return res.status(400).json({ error: 'bad_request', message: 'input required' });
    const fnTools = MCP.toFunctionTools(Array.isArray(row.mcp_tools) ? row.mcp_tools : null);
    // Optional multi-turn history provided by the UI for this test endpoint
    const seedFromReq = (() => {
      try {
        const arr = Array.isArray(b.history) ? b.history : [];
        const out = [];
        for (const m of arr) {
          if (!m || typeof m !== 'object') continue;
          const role = String(m.role || '').toLowerCase();
          const content = String(m.content || '').trim();
          if (!content) continue;
          if (role === 'user' || role === 'assistant') out.push({ role, content });
        }
        return out;
      } catch { return []; }
    })();
    async function botNeedsAuth(botId) {
      if (getMcpToken()) return true;
      try {
        const r = await pool.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 AND COALESCE(mcp_token,'') <> '' LIMIT 1`, [botId]);
        return !!r.rowCount;
      } catch { return false; }
    }
    const needAuth = await botNeedsAuth(id);
    const session = { authed: !needAuth };
    let result;
    const t0 = Date.now();
    let apiKeyUse = String(row.openai_api_key || '').trim();
    // If a prompt is assigned (prompt_config only), fetch it and apply its settings
    let localPrompt = null;
    try {
      const pid = row.prompt_config_id || null;
      if (pid) {
        const pr = await pool.query(`SELECT * FROM prompt_config WHERE id=$1 LIMIT 1`, [pid]);
        if (pr.rowCount) localPrompt = pr.rows[0];
      }
    } catch {}
    // Fallback API key: Prompt Config -> server/global (.env or admin setting)
    if (!apiKeyUse) {
      const k = (localPrompt && localPrompt.openai_api_key) ? String(localPrompt.openai_api_key).trim() : '';
      apiKeyUse = k || getOpenaiApiKey();
    }
    if (!apiKeyUse) {
      return res.status(400).json({ error: 'bad_request', message: 'openai_api_key missing (bot, prompt, or server)' });
    }
    // Build MCP tools from servers linked to the assigned prompt (if any)
    let extraTools = [];
    try {
      const pid = (row.prompt_config_id || '').toString();
      if (pid) {
        const rs = await pool.query(
          `SELECT m.id, m.name, m.kind, m.http_base, m.ws_url, m.stream_url, m.sse_url, m.token, m.enabled, m.options
             FROM prompt_config_mcp x
             JOIN mcp_server_config m ON m.id = x.mcp_server_id
            WHERE x.prompt_config_id = $1
            ORDER BY m.updated_at DESC`,
          [pid]
        );
        const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
        const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
        const proto = (fproto || req.protocol || 'http').toLowerCase();
        const host = (fhost || req.headers.host || 'localhost').trim();
        const base = `${proto}://${host}`;
        extraTools = (rs.rows || []).map((row) => {
          let options = row.options; try { if (typeof options === 'string') options = JSON.parse(options); } catch { options = {}; }
          const allowed = Array.isArray(options?.allowed_tools) ? options.allowed_tools : undefined;
          const label = row.name || (row.kind || 'mcp');
          const pref = (options && options.server_url_pref === 'sse') ? 'sse' : 'stream';
          let serverUrl = pref === 'stream'
            ? (row.stream_url || row.sse_url || `${base}/mcp/${encodeURIComponent(label)}/stream`)
            : (row.sse_url || row.stream_url || `${base}/mcp/${encodeURIComponent(label)}/events`);
          // Append token as query for compatibility with clients that don't set Authorization
          if (row.token) {
            try { const u = new URL(serverUrl, base); if (!u.searchParams.get('token')) u.searchParams.set('token', row.token); serverUrl = u.toString(); } catch {}
          }
          const tool = { type: 'mcp', server_label: label, server_url: serverUrl, require_approval: 'never' };
          if (row.token) tool.authorization = row.token;
          if (allowed && allowed.length) tool.allowed_tools = allowed;
          return tool;
        }).filter((t) => t.server_url);

        // Also include MCP2 servers linked to this prompt
        try {
          const rs2 = await pool.query(
            `SELECT s.id, s.name, s.http_base, s.ws_url, s.stream_url, s.sse_url, s.token, s.enabled, s.options
               FROM prompt_config_mcp2 x
               JOIN mcp2_server s ON s.id = x.mcp2_server_id
              WHERE x.prompt_config_id = $1
              ORDER BY s.updated_at DESC`,
            [pid]
          );
          const fproto2 = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
          const fhost2 = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
          const proto2 = (fproto2 || req.protocol || 'http').toLowerCase();
          const host2 = (fhost2 || req.headers.host || 'localhost').trim();
          const base2 = `${proto2}://${host2}`;
          const more = (rs2.rows || []).map((srow) => {
            let options = srow.options; try { if (typeof options === 'string') options = JSON.parse(options); } catch { options = {}; }
            const allowed = Array.isArray(options?.allowed_tools) ? options.allowed_tools : undefined;
            const pref = (options && options.server_url_pref === 'sse') ? 'sse' : 'stream';
            // Prefer explicit stream/sse URLs; otherwise derive from http_base/name; fallback to current host
            let serverUrl = '';
            if (pref === 'stream') {
              serverUrl = srow.stream_url || deriveMcp2Endpoints(srow.http_base, srow.name).stream_url || `${base2}/mcp2/${encodeURIComponent(srow.name)}/stream`;
            } else {
              serverUrl = srow.sse_url || deriveMcp2Endpoints(srow.http_base, srow.name).sse_url || `${base2}/mcp2/${encodeURIComponent(srow.name)}/events`;
            }
            if (srow.token) {
              try { const u = new URL(serverUrl, base2); if (!u.searchParams.get('token')) u.searchParams.set('token', srow.token); serverUrl = u.toString(); } catch {}
            }
            const tool = { type: 'mcp', server_label: srow.name, server_url: serverUrl, require_approval: 'never' };
            if (srow.token) tool.authorization = srow.token;
            if (allowed && allowed.length) tool.allowed_tools = allowed;
            return tool;
          }).filter((t) => t.server_url);
          extraTools = [...extraTools, ...more];
        } catch {}
      }
    } catch {}

    // Effective model precedence: request override > prompt_config.model > chatbot row.model > env default
    const effectiveModel = String((b.model || (localPrompt && localPrompt.model) || row.model || process.env.OPENAI_MODEL || 'gpt-4o-mini'));

    if (Array.isArray(extraTools) && extraTools.length) {
      // Prefer MCP transport when prompt-linked servers exist
      result = await respondWithPrompt({
        apiKey: apiKeyUse,
        model: effectiveModel,
        promptId: row.prompt_id,
        promptVersion: row.prompt_version,
        input: `${userInput}`,
        seedMessages: [
          ...((Array.isArray(localPrompt?.messages) ? localPrompt.messages : []) || []),
          ...seedFromReq,
        ],
        instructions: localPrompt?.dev_message ?? row.instructions,
        toolsFileSearch: localPrompt ? !!localPrompt?.tools?.file_search : !!row.tools_file_search,
        toolsCodeInterpreter: localPrompt ? !!localPrompt?.tools?.code_interpreter : !!row.tools_code_interpreter,
        webSearchEnabled: localPrompt ? !!localPrompt?.tools?.web_search : !!row.web_search_enabled,
        webSearchAllowedDomains: (localPrompt && Array.isArray(localPrompt?.tools?.web_search_allowed_domains)) ? localPrompt.tools.web_search_allowed_domains : undefined,
        vectorStoreId: localPrompt?.vector_store_id || undefined,
        vectorStoreIds: Array.isArray(localPrompt?.vector_store_ids) ? localPrompt.vector_store_ids : (Array.isArray(row.vector_store_ids) ? row.vector_store_ids : undefined),
        responseFormat: row.response_format,
        temperature: row.temperature,
        topP: row.top_p,
        organization: row.openai_org || undefined,
        project: row.openai_project || undefined,
        extraTools,
      });
    } else if (fnTools && fnTools.length) {
      result = await respondWithPromptAndTools({
        apiKey: apiKeyUse,
        model: effectiveModel,
        promptId: row.prompt_id,
        promptVersion: row.prompt_version,
        input: `${userInput}`,
        seedMessages: [
          ...((Array.isArray(localPrompt?.messages) ? localPrompt.messages : []) || []),
          ...seedFromReq,
        ],
        instructions: row.instructions,
        responseFormat: row.response_format,
        temperature: row.temperature,
        topP: row.top_p,
        organization: row.openai_org || undefined,
        project: row.openai_project || undefined,
        functionTools: fnTools,
        onToolCall: async ({ name, arguments: args }) => {
          const ctx = { shop_name: row.shop_name, lang_iso: row.lang_iso, id_bot: id, session };
          return await MCP.run(name, args, ctx);
        },
      });
    } else {
      result = await respondWithPrompt({
        apiKey: apiKeyUse,
        model: effectiveModel,
        promptId: row.prompt_id,
        promptVersion: row.prompt_version,
        input: `${userInput}`,
        seedMessages: Array.isArray(localPrompt?.messages) ? localPrompt.messages : undefined,
        instructions: localPrompt?.dev_message ?? row.instructions,
        toolsFileSearch: localPrompt ? !!localPrompt?.tools?.file_search : !!row.tools_file_search,
        toolsCodeInterpreter: localPrompt ? !!localPrompt?.tools?.code_interpreter : !!row.tools_code_interpreter,
        webSearchEnabled: localPrompt ? !!localPrompt?.tools?.web_search : !!row.web_search_enabled,
        webSearchAllowedDomains: (localPrompt && Array.isArray(localPrompt?.tools?.web_search_allowed_domains)) ? localPrompt.tools.web_search_allowed_domains : undefined,
        vectorStoreId: localPrompt?.vector_store_id || undefined,
        vectorStoreIds: Array.isArray(localPrompt?.vector_store_ids) ? localPrompt.vector_store_ids : (Array.isArray(row.vector_store_ids) ? row.vector_store_ids : undefined),
        responseFormat: row.response_format,
        temperature: row.temperature,
        topP: row.top_p,
        organization: row.openai_org || undefined,
        project: row.openai_project || undefined,
      });
    }
    const ms = Date.now() - t0;
    res.json({ ok: true, text: result.text, raw: result.raw, request: result.request || null, request_body: result.request_body || null, conversation: result.conversation || null, response_id: result.response_id || null, openai_request_id: result.openai_request_id || null, ms, seconds: ms/1000 });
  } catch (e) {
    logToFile(`❌ POST /api/automations/chatbots/:id/respond: ${e.message}`);
    try {
      const dbg = getOpenaiDebug() || {};
      return res.status(500).json({
        error: 'server_error',
        message: e?.message || String(e),
        request: dbg.lastRequestBody || null,
        request_body: dbg.lastRequestBody || null,
        retry: dbg.lastRetryBody || null,
        continue: dbg.lastContinue || null,
      });
    } catch {
      return res.status(500).json({ error: 'server_error', message: e?.message || String(e) });
    }
  }
});

// Generic test endpoint allowing per-call overrides (for admin/testing only)
app.post("/api/responses/test", async (req, res) => {
  try {
    const b = req.body || {};
    const apiKey = b.apiKey || b.openai_api_key;
    const promptId = b.promptId || b.prompt_id;
    const promptVersion = b.promptVersion || b.prompt_version;
    const msg = (b.message || b.content || b.input || "").trim();
    if (!apiKey) return res.status(400).json({ error: 'bad_request', message: 'apiKey required' });
    if (!promptId) return res.status(400).json({ error: 'bad_request', message: 'promptId required' });
    if (!msg) return res.status(400).json({ error: 'bad_request', message: 'message/content required' });

    const t0 = Date.now();
    const { text, raw } = await respondWithPrompt({
      apiKey,
      promptId,
      promptVersion,
      input: msg,
    });
    const ms = Date.now() - t0;
    res.json({ ok: true, text, raw, ms, seconds: ms/1000 });
  } catch (e) {
    res.status(500).json({ error: 'server_error', message: e.message });
  }
});

// Simple API health endpoint for frontend checks
app.get('/api/health', (_req, res) => {
  res.json({ ok: true, openai_ready: true });
});

// Minimal MCP status/info endpoint to expose server availability and URLs.
// This is not a full MCP implementation, but provides the information panel
// requested by the admin UI and a stable place to expand later.
app.get('/mcp/status', async (req, res) => {
  try {
    // Prefer DB config (mcp_server_config) when present
    let httpBase = '';
    let wsUrl = '';
    try {
      const row = await getMcpServerConfigByKind('main');
      if (row && row.http_base) {
        httpBase = row.http_base;
        wsUrl = row.ws_url || inferWsUrlFromBase(httpBase, '/mcp/ws');
      }
    } catch {}
    // Legacy inference when DB not loaded in this sync context
    if (!httpBase) {
      httpBase = (getMcpPublicBase() || '').trim();
      if (httpBase) {
        try { const u = new URL(httpBase); const wsScheme = u.protocol === 'https:' ? 'wss:' : 'ws:'; wsUrl = `${wsScheme}//${u.host}/mcp/ws`; httpBase = `${u.protocol}//${u.host}`; } catch { httpBase = ''; }
      }
    }
    if (!httpBase) {
      const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
      const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
      const proto = (fproto || req.protocol || 'http').toLowerCase();
      const host = (fhost || req.headers.host || 'localhost').trim();
      httpBase = `${proto}://${host}`;
      const wsScheme = proto === 'https' ? 'wss' : 'ws';
      wsUrl = `${wsScheme}://${host}/mcp/ws`;
    }
    const now = new Date().toISOString();
    res.json({
      ok: true,
      version: '0.1',
      time: now,
      httpBase,
      wsUrl,
      notes: 'MCP status online. This server exposes /mcp/status and can be extended to full MCP JSON-RPC over WebSocket.',
    });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'mcp_status_failed', message: e?.message || String(e) });
  }
});

// --- MCP WebSocket endpoint implementing a minimal JSON-RPC interface ---
// Accept common subprotocols used by MCP clients (e.g., 'mcp', 'jsonrpc')
const wssMcp = new WebSocketServer({
  noServer: true,
  handleProtocols: (protocols /* Set<string> */, _req) => {
    try {
      if (protocols && protocols.size) {
        const offered = Array.from(protocols);
        // Prefer any variant of vnd.mcp+json (optionally with parameters)
        for (const p of offered) { if (/^vnd\.mcp\+json\b/i.test(p)) return p; }
        // Common alternates seen in some clients
        for (const p of offered) { if (/^model[-]context[-]?protocol\b/i.test(p)) return p; }
        if (protocols.has('mcp')) return 'mcp';
        if (protocols.has('jsonrpc')) return 'jsonrpc';
        // Fallback to the first offered protocol to keep the connection
        return offered[0];
      }
    } catch {}
    return false; // no subprotocol
  },
});

// Auth helper for HTTP endpoints under /mcp (except /mcp/status)
function checkBearer(h = "") {
  const m = /^Bearer\s+(.+)$/i.exec(String(h || ""));
  return m ? m[1] : null;
}
async function isMcpAuthorized(req) {
  const q = req.query?.mcp_token || req.query?.token;
  const b = checkBearer(req.headers?.authorization);
  const t = String(q || b || "").trim();

  // 1) Name-scoped server token: /mcp/:name/(stream|events|sse)
  const nameScoped = String(req.params?.name || '').trim();
  if (nameScoped) {
    try {
      const r = await pool.query(`SELECT token FROM mcp_server_config WHERE name=$1 LIMIT 1`, [nameScoped]);
      if (r.rowCount) {
        const stok = String(r.rows[0].token || '');
        if (!stok) return true; // no token set for this server
        return !!t && t === stok;
      }
      // Fallback to MCP2 server token when name matches
      try {
        const r2 = await pool.query(`SELECT token FROM mcp2_server WHERE name=$1 LIMIT 1`, [nameScoped]);
        if (r2.rowCount) {
          const tok2 = String(r2.rows[0].token || '');
          if (!tok2) return true;
          return !!t && t === tok2;
        }
      } catch {}
    } catch {}
  }

  // 2) Global token (legacy): applies to all /mcp/* endpoints (non-exclusive)
  const g = getMcpToken();
  if (g && t === g) return true;

  // 2b) Any per-server token (when using generic /mcp/* endpoints like files)
  if (t) {
    try {
      const rs = await pool.query(`SELECT 1 FROM mcp_server_config WHERE token = $1 LIMIT 1`, [t]);
      if (rs.rowCount) return true;
    } catch {}
    try {
      const rs2 = await pool.query(`SELECT 1 FROM mcp2_server WHERE token = $1 LIMIT 1`, [t]);
      if (rs2.rowCount) return true;
    } catch {}
  }

  // 3) Per-bot behavior: if bot_id is present, require token only when that bot has one
  const botId = String(req.query?.bot_id || req.body?.bot_id || '').trim();
  if (botId) {
    try {
      const r = await pool.query(`SELECT mcp_token FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [botId]);
      const btok = r.rowCount ? String(r.rows[0].mcp_token || '') : '';
      if (!btok) return true; // open for this bot
      return !!t && t === btok;
    } catch { return false; }
  }

  // 4) If any bot has a token, require a token that matches any bot; else open
  try {
    const any = await pool.query(`SELECT 1 FROM chatbot_config WHERE COALESCE(mcp_token,'') <> '' LIMIT 1`);
    if (!any.rowCount) return true;
    if (!t) return false;
    const r = await pool.query(`SELECT 1 FROM chatbot_config WHERE COALESCE(mcp_token,'') <> '' AND mcp_token=$1 LIMIT 1`, [t]);
    return !!r.rowCount;
  } catch { return false; }
}

// --- Helpers for per-server file storage isolation ---
function slugifyName(name) {
  return String(name || '')
    .toLowerCase()
    .replace(/[^a-z0-9._-]+/g, '_')
    .replace(/^_+|_+$/g, '') || 'default';
}

async function resolveServerNameFromReq(req) {
  // Prefer explicit :name param on name-scoped routes
  try {
    const p = req?.params?.name ? String(req.params.name).trim() : '';
    if (p) return p;
  } catch {}
  // Else try token to server mapping
  try {
    const q = String(req.query?.mcp_token || req.query?.token || '').trim();
    const b = checkBearer(req.headers?.authorization);
    const tok = String(q || b || '').trim();
    if (tok) {
      const r = await pool.query(`SELECT name FROM mcp_server_config WHERE token=$1 LIMIT 1`, [tok]);
      if (r.rowCount) return r.rows[0].name || '';
      try { const r2 = await pool.query(`SELECT name FROM mcp2_server WHERE token=$1 LIMIT 1`, [tok]); if (r2.rowCount) return r2.rows[0].name || ''; } catch {}
    }
  } catch {}
  return '';
}
async function requireMcpAuth(req, res) {
  const ok = await isMcpAuthorized(req);
  if (!ok) { res.status(401).json({ ok: false, error: 'unauthorized' }); return false; }
  return true;
}

// File storage dir for MCP uploads (declared earlier)

function wsSend(ws, obj) {
  try { ws.send(JSON.stringify(obj)); } catch {}
}
const jsonrpcOk = (id, result) => ({ jsonrpc: '2.0', id, result });
const jsonrpcErr = (id, code, message, data) => ({ jsonrpc: '2.0', id, error: { code, message, data } });

async function mcp_getVisitor(args = {}) {
  const vid = String(args.visitorId || '').trim();
  if (!vid) throw new Error('visitorId required');
  const idCol = dbSchema.visitors.idCol || (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id' : 'id');
  const r = await pool.query(`SELECT * FROM visitors WHERE ${idCol} = $1 LIMIT 1`, [vid]);
  return r.rowCount ? r.rows[0] : null;
}
async function mcp_listRecentVisitors(args = {}) {
  const limit = Math.max(1, Math.min(100, Number(args.limit || 20)));
  const idCol = dbSchema.visitors.idCol || (dbSchema.visitors.hasVisitorIdCol ? 'visitor_id' : 'id');
  const r = await pool.query(
    `SELECT ${idCol} AS visitor_id, shop_name, lang_iso, last_seen, last_action, conversation_status
       FROM visitors
      ORDER BY COALESCE(last_seen, NOW()) DESC
      LIMIT $1`,
    [limit]
  );
  return r.rows || [];
}
async function mcp_sendAgentMessage(args = {}) {
  const visitorId = String(args.visitorId || '').trim();
  const raw = String(args.message || '').trim();
  if (!visitorId) throw new Error('visitorId required');
  if (!raw) throw new Error('message required');

  await ensureVisitorExists(visitorId);
  const looksHtml = /<\s*[a-z][\s\S]*>/i.test(raw);
  const content_html = looksHtml ? sanitizeAgentHtmlServer(raw) : textToSafeHTML(raw);
  const msgCol = dbSchema.messages.hasContent ? 'content' : (dbSchema.messages.hasMessage ? 'message' : 'content');
  const cols = [];
  const params = [];
  const ph = [];
  let onConflict = '';
  const msgId = globalThis.crypto?.randomUUID?.() || `${Date.now()}-${Math.random().toString(16).slice(2)}`;
  if (dbSchema.useDbDedup) { cols.push('id'); params.push(msgId); ph.push(`$${params.length}`); onConflict = ' ON CONFLICT (id) DO NOTHING'; }
  if (dbSchema.messages.hasVisitorId) { cols.push('visitor_id'); params.push(visitorId); ph.push(`$${params.length}`); }
  cols.push('sender'); params.push('agent'); ph.push(`$${params.length}`);
  cols.push(msgCol); params.push(raw); ph.push(`$${params.length}`);
  if (dbSchema.messages.hasContentHtml) { cols.push('content_html'); params.push(content_html); ph.push(`$${params.length}`); }
  if (dbSchema.messages.hasAgentId) { cols.push('agent_id'); params.push(null); ph.push(`$${params.length}`); }
  const sql = `INSERT INTO messages (${cols.join(', ')}) VALUES (${ph.join(', ')})${onConflict} RETURNING id, created_at`;
  await pool.query(sql, params);

  const out = { id: msgId, visitorId, from: 'agent', message: raw, html: content_html, agentId: null, timestamp: Date.now() };
  io.to(visitorId).emit('chat_message', out);
  io.to('agents').emit('dashboard_message', out);

  try { await upsertVisitorColumns(visitorId, { last_action: 'agent_message', last_action_at: new Date().toISOString(), conversation_status: 'waiting_visitor' }); } catch {}
  return { ok: true, message: out };
}

const MCP_TOOLS = [
  { name: 'get_visitor', description: 'Fetch a visitor by visitorId', inputSchema: { type: 'object', properties: { visitorId: { type: 'string' } }, required: ['visitorId'] }, run: mcp_getVisitor },
  { name: 'list_recent_visitors', description: 'List recent visitors', inputSchema: { type: 'object', properties: { limit: { type: 'integer', minimum: 1, maximum: 100 } } }, run: mcp_listRecentVisitors },
  { name: 'send_agent_message', description: 'Send an agent message to a visitor', inputSchema: { type: 'object', properties: { visitorId: { type: 'string' }, message: { type: 'string' } }, required: ['visitorId','message'] }, run: mcp_sendAgentMessage },
];
async function loadCustomToolsForServer(serverName) {
  try {
    if (!serverName) return [];
    const r = await pool.query(`SELECT id FROM mcp_server_config WHERE name=$1 LIMIT 1`, [serverName]);
    if (!r.rowCount) return [];
    const serverId = r.rows[0].id;
    const t = await pool.query(`SELECT name, description, grp, kind, input_schema, code, enabled FROM mcp_tool_def WHERE server_id=$1 AND enabled = TRUE ORDER BY updated_at DESC`, [serverId]);
    return t.rows || [];
  } catch { return []; }
}

function normalizeToolSchema(s) {
  try {
    if (!s) return { type: 'object' };
    if (typeof s === 'string') return JSON.parse(s);
    if (typeof s === 'object') return s;
  } catch {}
  return { type: 'object' };
}

async function listToolsForClientFiltered(allowNames = null, serverName = '') {
  try {
    const ts = MCP.tools();
    let allowSet = null;
    if (Array.isArray(allowNames)) {
      // Treat empty array as "no tools allowed"
      allowSet = new Set(allowNames);
    }
    const base = (ts || []).filter((t) => (allowSet ? allowSet.has(t.name) : true));

    // Overlay with custom tools for this server (Designer)
    const customs = await loadCustomToolsForServer(serverName);
    const byName = new Map();
    for (const t of base) byName.set(t.name, { ...t });
    for (const c of customs) {
      const name = String(c.name || '').trim();
      if (!name) continue;
      const desc = c.description || '';
      const schema = normalizeToolSchema(c.input_schema);
      if (byName.has(name)) {
        const orig = byName.get(name);
        byName.set(name, { ...orig, description: desc || orig.description, inputSchema: schema, input_schema: schema });
      } else {
        const t = { name, description: desc, inputSchema: schema, input_schema: schema };
        if (!allowSet || allowSet.has(name)) byName.set(name, t);
      }
    }

    const list = Array.from(byName.values());
    return list.map((t) => {
      const schema = t.inputSchema || t.input_schema || { type: 'object' };
      return { name: t.name, description: t.description, inputSchema: schema, input_schema: schema };
    });
  } catch {
    return [];
  }
}

// Backward-compatible helper
async function listToolsForClient() { return await listToolsForClientFiltered(null, ''); }

// Resolve allowed tool names for an HTTP MCP request
// Priority: per-server type (when name is provided) > per-bot restrict list > heuristic
async function getAllowedMcpToolNamesForReq(req) {
  try {
    // 1) Name-scoped server filtering by server_type and options
    const serverName = String(req.params?.name || '').trim();
    if (serverName) {
      try {
        const r = await pool.query(
          `SELECT server_type, options FROM mcp_server_config WHERE name=$1 LIMIT 1`,
          [serverName],
        );
        if (r.rowCount) {
          const t = String(r.rows[0].server_type || '').toLowerCase();
          let opts = r.rows[0].options;
          try { if (typeof opts === 'string') opts = JSON.parse(opts); } catch { opts = {}; }
          if (Array.isArray(opts?.allowed_tools)) {
            // Respect explicit allowlist as-is (no forced local_* tools)
            return opts.allowed_tools.filter(Boolean);
          }

          if (t === 'files' || t === 'file' || t === 'filetools') {
            // Default expose only these tools per request
            return ['search_documents', 'fetch_document', 'list_files', 'upload_file'];
          }

          if (t === 'database' || t === 'db') {
            // Determine DB kind from connection_url or explicit db_kind
            let dbKind = '';
            try {
              const raw = String(opts?.connection_url || '').trim();
              if (raw) {
                const u = new URL(raw);
                dbKind = (u.protocol || '').replace(':', '').toLowerCase();
              }
            } catch {}
            if (!dbKind) dbKind = String(opts?.db_kind || '').toLowerCase();

            // Only expose livechat-specific DB tools when pointing at the app DB
            const appUrl = String(process.env.DATABASE_URL || '').trim();
            const sameAsApp = appUrl && String(opts?.connection_url || '').trim() === appUrl;

            if (dbKind === 'mariadb' || dbKind === 'mysql') {
              // Not compatible with app-specific tools
              return []; // no tools
            }
            if (dbKind === 'postgres' || dbKind === 'postgresql') {
              return sameAsApp
                ? [
                    'postgresql.get_visitor',
                    'postgresql.list_recent_visitors',
                    'postgresql.send_agent_message',
                    // Postgres helpers for Zásilkovna table
                    'postgresql.get_packetid_by_email',
                    'postgresql.get_packetid_by_name',
                    'postgresql.get_packetid_by_id_order',
                    'postgresql.get_packetid_by_surname',
                    'postgresql.get_status_by_packetid',
                    'postgresql.get_date_of_delivery_by_packetid',
                  ]
                : []; // external Postgres with unknown schema: hide app-specific tools
            }
            // Unknown DB kind: safest is to hide tools
            return [];
          }

          if (t === 'ai') {
            return ['openai_upload_file'];
          }
          if (t === 'apis') {
            return ['authenticate','http_get_json','http_post_json','presta_livechat_custom','list_of_instructions'];
          }
          if (t === 'prestashop' || t === 'presta' || t === 'prestashop_api') {
            try {
              const all = (MCP.tools() || []).map(t => t && t.name).filter(Boolean);
              const ps = all.filter(n => /^psapi\./i.test(n));
              return ps.length ? [...ps, 'presta_livechat_custom'] : null;
            } catch { return null; }
          }
          if (t === 'custom') {
            return null; // no restriction for generic/custom
          }
        }
      } catch {}
    }

    // 2) Bot-scoped restriction via query param
    const botId = String(req.query?.bot_id || '').trim();
    let allow = null;
    if (botId) {
      try {
        const r = await pool.query(`SELECT mcp_tools FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [botId]);
        const arr = r.rowCount ? r.rows[0].mcp_tools : null;
        if (Array.isArray(arr) && arr.length) allow = arr.filter(Boolean);
      } catch {}
    }

    // 3) Heuristic fallback based on naming
    if (!allow) {
      const hint = (
        String(serverName || '').toLowerCase() + ' ' + String(botId || '').toLowerCase()
      );
      if (hint.includes('files')) {
        allow = ['list_files', 'search_documents', 'fetch_document', 'upload_file'];
      }
    }
    return allow;
  } catch { return null; }
}

async function runCustomToolIfAny(serverName, name, args, ctx) {
  try {
    if (!serverName || !name) return undefined;
    const r = await pool.query(`SELECT id, server_type, options FROM mcp_server_config WHERE name=$1 LIMIT 1`, [serverName]);
    if (!r.rowCount) return undefined;
    const serverId = r.rows[0].id;
    const row = await pool.query(`SELECT name, kind, code FROM mcp_tool_def WHERE server_id=$1 AND name=$2 AND enabled = TRUE LIMIT 1`, [serverId, name]);
    if (!row.rowCount) return undefined;
    let kind = String(row.rows[0].kind || 'function').toLowerCase();
    let code = row.rows[0].code || {};
    try { if (typeof code === 'string') code = JSON.parse(code); } catch { code = {}; }

    // Proxy to another tool (default target = same name)
    if (kind === 'proxy' || (kind === 'function' && code && code.target)) {
      const target = String(code.target || name).trim();
      return await MCP.run(target, args, ctx);
    }

    // Simple SQL executor for database servers
    if (kind === 'sql') {
      const st = String(r.rows[0].server_type || '').toLowerCase();
      let opt = r.rows[0].options || {};
      try { if (typeof opt === 'string') opt = JSON.parse(opt); } catch { opt = {}; }
      if (st !== 'database') throw new Error('server_not_database');
      let connUrl = String(opt.connection_url || opt.url || '').trim();
      if (!connUrl) {
        const host = opt.host || 'localhost';
        const port = Number(opt.port || 3306);
        const user = opt.user || opt.username || '';
        const password = opt.password || '';
        const database = opt.database || '';
        connUrl = `mysql://${encodeURIComponent(user)}:${encodeURIComponent(password)}@${host}:${port}/${database}`;
      }
      const sql = String(code.sql || '').trim();
      if (!sql) throw new Error('sql_missing');
      // params: prefer args.params (array) else empty
      let params = [];
      try { if (Array.isArray(args.params)) params = args.params; } catch {}

      // Choose driver based on URL scheme
      let scheme = '';
      try { const u = new URL(connUrl); scheme = (u.protocol || '').replace(':','').toLowerCase(); } catch {}
      if (scheme === 'postgres' || scheme === 'postgresql') {
        const pg = await import('pg');
        const client = new pg.Client({ connectionString: connUrl });
        await client.connect();
        try {
          const res = await client.query(sql, params);
          return { ok: true, rows: res?.rows || [] };
        } finally { try { await client.end(); } catch {} }
      } else if (scheme === 'mysql' || scheme === 'mariadb' || !scheme) {
        const mysql = await import('mysql2/promise');
        const conn = await mysql.createConnection(connUrl);
        try {
          const [rows] = await conn.execute(sql, params);
          return { ok: true, rows };
        } finally { try { await conn.end(); } catch {} }
      } else {
        // Unknown DB kind: let core/built-ins handle the tool
        return undefined;
      }
    }
    // Unsupported kinds: do not block built-ins. Fallback to core tool.
    return undefined;
  } catch (e) {
    return { ok: false, error: String(e?.message || e) };
  }
}

wssMcp.on('connection', async (ws, req) => {
  // Authorize connection and maintain a per-WS session context
  try {
    const url = new URL(req?.url || '', 'http://local');
    const q = url.searchParams.get('token') || url.searchParams.get('mcp_token');
    // Accept token from Authorization: Bearer <token> or from query
    const auth = String(req.headers?.authorization || '').trim();
    const m = /^Bearer\s+(.+)$/i.exec(auth);
    const presented = String(q || (m ? m[1] : '') || '').trim();
    const botId = String(url.searchParams.get('bot_id') || '').trim();
    if (DEBUG_MCP) {
      logToFile(`🔌 MCP WS connect: path=${url.pathname} bot_id=${botId || '-'} proto_req=${String(req.headers['sec-websocket-protocol']||'').trim()}`);
    }

    let authorized = true;
    const g = getMcpToken();
    if (g) {
      authorized = presented === g;
    } else if (botId) {
      try {
        const r = await pool.query(`SELECT mcp_token FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [botId]);
        const btok = r.rowCount ? String(r.rows[0].mcp_token || '') : '';
        authorized = btok ? (presented === btok) : true; // open when no bot token
      } catch {
        authorized = false;
      }
    } else {
      try {
        const any = await pool.query(`SELECT 1 FROM chatbot_config WHERE COALESCE(mcp_token,'') <> '' LIMIT 1`);
        if (any.rowCount) {
          if (!presented) authorized = false;
          else {
            const r = await pool.query(`SELECT 1 FROM chatbot_config WHERE COALESCE(mcp_token,'') <> '' AND mcp_token=$1 LIMIT 1`, [presented]);
            authorized = !!r.rowCount;
          }
        }
      } catch {
        authorized = false;
      }
    }

    if (!authorized) { if (DEBUG_MCP) logToFile(`⛔ MCP WS unauthorized bot=${botId || '-'} token=${presented ? 'yes' : 'no'}`); try { ws.close(1008, 'unauthorized'); } catch {} ; return; }
    if (DEBUG_MCP) logToFile(`✅ MCP WS authorized bot=${botId || '-'} subprotocol=${ws.protocol || '-'} session open`);

    // Per-connection session state for tools that need auth
    const session = { authed: !!presented }; // auto-auth when a valid token was presented
    const baseCtx = { id_bot: botId, session };
    // Determine allowed tool names for this connection (per bot or by path hint)
    let allowedToolNames = null;
    try {
      if (botId) {
        const r = await pool.query(`SELECT mcp_tools FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [botId]);
        const arr = r.rowCount ? r.rows[0].mcp_tools : null;
        if (Array.isArray(arr) && arr.length) allowedToolNames = arr.filter(Boolean);
      }
    } catch {}
    if (!allowedToolNames) {
      const p = String(url.pathname || '').toLowerCase();
      if (p.includes('files')) {
        allowedToolNames = ['upload_file','list_files','search_documents','fetch_document'];
      }
    }

    ws.on('message', async (buf) => {
      let msg; try { msg = JSON.parse(buf.toString('utf8')); } catch { return; }
      const id = msg.id; const method = msg.method; const params = msg.params || {};
      if (DEBUG_MCP) logToFile(`📩 MCP WS msg method=${method}`);
      try {
        if (method === 'initialize') {
          wsSend(ws, jsonrpcOk(id, {
            protocolVersion: '2024-11-05',
            serverInfo: { name: 'livechat-mcp', version: '0.1' },
            capabilities: {
              logging: {},
              tools: { listChanged: true },
              resources: { subscribe: true, listChanged: true },
              prompts: { listChanged: true },
            }
          }));
          wsSend(ws, { jsonrpc: '2.0', method: 'initialized', params: {} });
          return;
        }
        if (method === 'tools/list') return wsSend(ws, jsonrpcOk(id, { tools: listToolsForClientFiltered(allowedToolNames) }));
        if (method === 'resources/list') return wsSend(ws, jsonrpcOk(id, { resources: [] }));
        if (method === 'prompts/list') return wsSend(ws, jsonrpcOk(id, { prompts: [] }));
        if (method === 'resources/subscribe') return wsSend(ws, jsonrpcOk(id, { ok: true }));
        if (method === 'resources/unsubscribe') return wsSend(ws, jsonrpcOk(id, { ok: true }));
        if (method === 'resources/templates/list') return wsSend(ws, jsonrpcOk(id, { templates: [] }));
        if (method === 'tools/call') {
          const name = params.name || params.tool || '';
          const args = params.arguments || params.args || {};
          // Allow per-call bot override, but default to connection bot
          const me = authFromRequest(req) || null;
          const ctx = { ...baseCtx, id_bot: String(args.bot_id || baseCtx.id_bot || ''), user_id: me?.id || null, user_email: me?.email || null };
          if (Array.isArray(allowedToolNames) && !allowedToolNames.includes(name)) {
            return wsSend(ws, jsonrpcErr(id, -32601, `Tool not allowed: ${name}`));
          }
          const result = await MCP.run(name, args, ctx);
          // If tool was 'authenticate', update session from ctx
          if (name === 'authenticate' && ctx?.session) session.authed = !!ctx.session.authed;
          return wsSend(ws, jsonrpcOk(id, { content: [{ type: 'text', text: JSON.stringify(result) }] }));
        }
        if (method === 'ping') return wsSend(ws, jsonrpcOk(id, { pong: true, time: new Date().toISOString() }));
        return wsSend(ws, jsonrpcErr(id, -32601, `Unknown method: ${method}`));
      } catch (e) {
        return wsSend(ws, jsonrpcErr(id, -32000, e?.message || 'server_error'));
      }
    });
  } catch {
    try { ws.close(1011, 'internal_error'); } catch {}
  }
});

// Helper to attach MCP upgrade handling to any HTTP server
function attachMcpUpgrade(srv) {
  srv.on('upgrade', (req, socket, head) => {
    try {
      let url = req.url || '';
      // Support MCP2 alias: /mcp2/:name/ws[/bot/:id] -> /mcp/:name/ws[/bot/:id]
      if (/^\/mcp2\/[A-Za-z0-9._%\-]+\/ws(\/bot\/.+)?/i.test(url)) {
        try {
          const u = new URL(url, 'http://local');
          const parts = u.pathname.split('/');
          // ['', 'mcp2', ':name', 'ws', ...] -> ['', 'mcp', ':name', 'ws', ...]
          parts[1] = 'mcp';
          const pathname = parts.join('/');
          url = pathname + (u.search || '');
          req.url = url;
        } catch {}
      }
      // Support path alias: /mcp/:name/ws[/bot/:id][?token=...] -> /mcp/ws[?bot_id=:id]
      if (/^\/mcp\/[A-Za-z0-9._%\-]+\/ws(\/bot\/.+)?/i.test(url)) {
        try {
          const u = new URL(url, 'http://local');
          const parts = u.pathname.split('/');
          // parts: ['', 'mcp', ':name', 'ws', ...]
          const pos = parts.indexOf('ws');
          if (pos >= 0) {
            const after = parts.slice(pos + 1);
            let newUrl = '/mcp/ws' + (u.search || '');
            if (after[0] === 'bot' && after.length >= 2) {
              const botId = decodeURIComponent(after.slice(1).join('/'));
              const qs = u.search ? u.search + '&' : '?';
              newUrl = `/mcp/ws${qs}bot_id=${encodeURIComponent(botId)}`;
            }
            url = newUrl;
            req.url = url;
          }
        } catch {}
      }
      // Support path alias: /mcp/ws/bot/:id[?token=...] -> /mcp/ws?bot_id=:id
      if (url.startsWith('/mcp/ws/bot/')) {
        try {
          const u = new URL(url, 'http://local');
          const parts = u.pathname.split('/');
          const botId = decodeURIComponent(parts.slice(4).join('/'));
          const qs = u.search ? u.search + '&' : '?';
          url = `/mcp/ws${qs}bot_id=${encodeURIComponent(botId)}`;
          req.url = url;
        } catch {}
      }
      if (url.startsWith('/mcp/ws')) {
        wssMcp.handleUpgrade(req, socket, head, (ws) => {
          wssMcp.emit('connection', ws, req);
        });
      }
    } catch {
      try { socket.destroy(); } catch {}
    }
  });
}

// Attach to main Express server (port PORT)
attachMcpUpgrade(server);

// Optional: dedicated MCP WebSocket port via MCP_PORT or MCP_WS_PORT
const MCP_PORT = Number(process.env.MCP_PORT || process.env.MCP_WS_PORT || 0);
let mcpServer = null;
if (Number.isFinite(MCP_PORT) && MCP_PORT > 0) {
  mcpServer = http.createServer((_req, res) => {
    res.statusCode = 200;
    res.setHeader('Content-Type', 'text/plain; charset=utf-8');
    res.end('MCP WebSocket endpoint is at /mcp/ws');
  });
  attachMcpUpgrade(mcpServer);
  // Avoid crashing the whole app if this port is taken
  mcpServer.on('error', (e) => {
    logToFile(`❌ MCP WS server error on ${MCP_PORT}: ${e?.code || ''} ${e?.message || e}`);
    try { mcpServer.close(); } catch {}
  });
  try {
    mcpServer.listen(MCP_PORT, '0.0.0.0', () => {
      logToFile(`🚀 MCP WS listening on 0.0.0.0:${MCP_PORT}`);
    });
  } catch (e) {
    logToFile(`❌ Failed to bind MCP_PORT ${MCP_PORT}: ${e?.message || e}`);
  }
}

// Separate, OpenAI-compatible MCP server under /mcp-dev with its own token
app.get('/mcp-dev/status', async (req, res) => {
  try {
    let httpBase = (getMcpDevPublicBase() || '').trim();
    let wsUrl = '';
    const row = await getMcpServerConfigByKind('dev');
    if (row && row.http_base) {
      httpBase = row.http_base;
      wsUrl = row.ws_url || inferWsUrlFromBase(httpBase, '/mcp-dev/ws');
    } else if (httpBase) {
      try {
        const u = new URL(httpBase);
        const wsScheme = u.protocol === 'https:' ? 'wss:' : 'ws:';
        wsUrl = `${wsScheme}//${u.host}/mcp-dev/ws`;
        httpBase = `${u.protocol}//${u.host}`;
      } catch { httpBase = ''; }
    }
    if (!httpBase) {
      const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
      const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
      const proto = (fproto || req.protocol || 'http').toLowerCase();
      const host = (fhost || req.headers.host || 'localhost').trim();
      httpBase = `${proto}://${host}`;
      const wsScheme = proto === 'https' ? 'wss' : 'ws';
      wsUrl = `${wsScheme}://${host}/mcp-dev/ws`;
    }
    // Optionally include token when caller presents ADMIN token or is localhost
    function isAdminLike(rq) {
      try {
        const expected = process.env.ADMIN_TOKEN || '';
        if (expected) {
          const got = rq.headers['x-admin-token'] || rq.query.admin_token;
          return String(got) === expected;
        }
        // No ADMIN_TOKEN set → allow localhost to view
        return isLocalhost(rq);
      } catch { return false; }
    }
    const maybeToken = isAdminLike(req) ? ((row?.token || getMcpDevToken()) || null) : undefined;
    res.json({ ok: true, version: '0.1', httpBase, wsUrl, enabled: getMcpDevEnabled(), notes: 'MCP‑DEV ready', token: maybeToken });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'mcp_dev_status_failed', message: e?.message || String(e) });
  }
});

// Dev MCP WS server with explicit subprotocol negotiation (helps some clients)
const wssMcpDev = new WebSocketServer({
  noServer: true,
  handleProtocols: (protocols /* Set<string> */, _req) => {
    try {
      if (protocols && protocols.size) {
        const offered = Array.from(protocols);
        // Prefer any variant of vnd.mcp+json (optionally with parameters)
        for (const p of offered) { if (/^vnd\.mcp\+json\b/i.test(p)) return p; }
        // Common alternates seen in some clients
        for (const p of offered) { if (/^mcp\.version\./i.test(p)) return p; }
        for (const p of offered) { if (/^model[-]context[-]?protocol\b/i.test(p)) return p; }
        if (protocols.has('mcp')) return 'mcp';
        if (protocols.has('jsonrpc')) return 'jsonrpc';
        // Fallback to the first offered protocol to keep the connection
        return offered[0];
      }
    } catch {}
    return false; // no subprotocol
  },
});
async function isMcpDevAuthorized(req) {
  if (!getMcpDevEnabled()) return false;
  const q = req.query?.mcp_token || req.query?.token;
  const b = checkBearer(req.headers?.authorization);
  const t = String(q || b || "").trim();
  const g = getMcpDevToken();
  // If dev token is set, require exact match; if empty, open
  if (!g) return true;
  return t === g;
}

async function getServerTypeByName(name) {
  try {
    const n = String(name || '').trim();
    if (!n) return null;
    const r = await pool.query(`SELECT server_type FROM mcp_server_config WHERE name=$1 LIMIT 1`, [n]);
    return r.rowCount ? (r.rows[0].server_type || null) : null;
  } catch { return null; }
}

function normalizeToolDescriptors(tools) {
  return (tools || []).map(t => {
    const schema = t.inputSchema || t.input_schema || { type: 'object' };
    return { name: t.name, description: t.description, inputSchema: schema, input_schema: schema };
  });
}

async function listToolsForClientForServer(serverName) {
  try {
    const ts = MCP.tools() || [];
    const type = await getServerTypeByName(serverName);
    if (!type) return normalizeToolDescriptors(ts);
    const t = String(type).toLowerCase();
    let allow = null;
    if (t === 'files') {
      allow = new Set(['list_files', 'search_documents', 'fetch_document', 'upload_file']);
    } else if (t === 'database') {
      allow = new Set(['postgresql.get_visitor', 'postgresql.list_recent_visitors', 'postgresql.send_agent_message']);
    } else if (t === 'prestashop' || t === 'presta' || t === 'prestashop_api') {
      try {
        const names = (MCP.tools() || []).map((tool) => tool && tool.name).filter(Boolean);
        const ps = names.filter((n) => /^psapi\./i.test(n));
        if (ps.length) allow = new Set([...ps, 'presta_livechat_custom']);
      } catch {}
    }
    if (!allow) return normalizeToolDescriptors(ts);
    const filtered = ts.filter(tool => allow.has(tool.name));
    return normalizeToolDescriptors(filtered);
  } catch { return []; }
}
async function requireMcpDevAuth(req, res) {
  if (!getMcpDevEnabled()) { res.status(503).json({ ok:false, error:'disabled' }); return false; }
  const ok = await isMcpDevAuthorized(req);
  if (!ok) { res.status(401).json({ ok: false, error: 'unauthorized' }); }
  return ok;
}

// Minimal JSON-RPC over WS mirroring the main MCP server
wssMcpDev.on('connection', (ws, req) => {
  try {
    const url = new URL(req.url || '', 'http://local');
    const headerTok = checkBearer(req.headers?.authorization || '');
    const presented = (headerTok || url.searchParams.get('token') || url.searchParams.get('mcp_token') || '').trim();
    const session = { authed: !getMcpDevToken() || presented === getMcpDevToken() };
    const baseCtx = { id_bot: 'mcp_dev', session };

    ws.on('message', async (buf) => {
      let msg; try { msg = JSON.parse(buf.toString('utf8')); } catch { return; }
      const id = msg.id; const method = msg.method; const params = msg.params || {};
      try {
        if (method === 'initialize') {
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: {
            protocolVersion: '2024-11-05',
            serverInfo: { name: 'livechat-mcp-dev', version: '0.1' },
            capabilities: {
              logging: {},
              tools: { listChanged: true },
              resources: { subscribe: true, listChanged: true },
              prompts: { listChanged: true },
            }
          } }));
          ws.send(JSON.stringify({ jsonrpc: '2.0', method: 'initialized', params: {} }));
          return;
        }
        if (method === 'tools/list') {
          const tools = listToolsForClient();
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { tools } }));
          return;
        }
        if (method === 'ping') {
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { pong: true, time: new Date().toISOString() } }));
          return;
        }
        if (method === 'resources/list') {
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { resources: [] } }));
          return;
        }
        if (method === 'prompts/list') {
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { prompts: [] } }));
          return;
        }
        if (method === 'resources/subscribe') { ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { ok: true } })); return; }
        if (method === 'resources/unsubscribe') { ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { ok: true } })); return; }
        if (method === 'resources/templates/list') { ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { templates: [] } })); return; }
        if (method === 'tools/call') {
          const name = params.name || params.tool || '';
          const args = params.arguments || params.args || {};
          const ctx = { ...baseCtx };
          const result = await MCP.run(name, args, ctx);
          // Return text content for maximum Inspector compatibility
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { content: [{ type: 'text', text: JSON.stringify(result) }] } }));
          return;
        }
        if (method === 'resources/list') {
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { resources: [] } }));
          return;
        }
        if (method === 'prompts/list') {
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: { prompts: [] } }));
          return;
        }
        ws.send(JSON.stringify({ jsonrpc: '2.0', id, error: { code: -32601, message: `Unknown method: ${method}` } }));
      } catch (e) {
        ws.send(JSON.stringify({ jsonrpc: '2.0', id, error: { code: -32000, message: e?.message || 'server_error' } }));
      }
    });
  } catch { try { ws.close(1011, 'internal_error'); } catch {} }
});

function attachMcpDevUpgrade(srv) {
  srv.on('upgrade', (req, socket, head) => {
    try {
      const url = req.url || '';
      if (url.startsWith('/mcp-dev/ws')) {
        wssMcpDev.handleUpgrade(req, socket, head, (ws) => {
          wssMcpDev.emit('connection', ws, req);
        });
      }
    } catch { try { socket.destroy(); } catch {} }
  });
}
attachMcpDevUpgrade(server);

// Dev MCP file upload/list/download (stored with bot_id='mcp_dev')
app.post('/mcp-dev/files/base64', async (req, res) => {
  if (!await requireMcpDevAuth(req, res)) return;
  try {
    const b = req.body || {};
    const filename = String(b.filename || '').trim();
    const base64 = String(b.content_base64 || '').trim();
    if (!filename || !base64) return res.status(400).json({ ok: false, error: 'bad_request' });
    const buf = Buffer.from(base64, 'base64');
    if (buf.length > MAX_UPLOAD_BYTES) {
      return res.status(413).json({ ok: false, error: 'too_large', message: `file exceeds limit ${MAX_UPLOAD_BYTES} bytes` });
    }
    const id = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
    const rel = id + '-' + filename.replace(/[^a-zA-Z0-9._-]+/g, '_');
    const full = path.join(mcpDevUploadDir, rel);
    fs.writeFileSync(full, buf);
    const ct = String(b.content_type || 'application/octet-stream');
    await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, bot_id) VALUES ($1,$2,$3,$4,$5,$6)`, [id, filename, rel, ct, buf.length, 'mcp_dev']);
    res.json({ ok: true, id, file_name: filename, size_bytes: buf.length, content_type: ct });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e.message });
  }
});

// Binary streaming upload (multipart-free); send file body as application/octet-stream
app.post('/mcp-dev/files/upload', async (req, res) => {
  if (!await requireMcpDevAuth(req, res)) return;
  try {
    const filename = String(req.query.filename || '').trim();
    if (!filename) return res.status(400).json({ ok: false, error: 'bad_request', message: 'filename required' });
    const id = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
    const rel = id + '-' + filename.replace(/[^a-zA-Z0-9._-]+/g, '_');
    const full = path.join(mcpDevUploadDir, rel);
    const ct = String(req.query.content_type || req.headers['content-type'] || 'application/octet-stream');
    let size = 0;
    let aborted = false;
    const ws = fs.createWriteStream(full);
    req.on('data', (chunk) => {
      if (aborted) return;
      try { size += chunk.length; if (size > MAX_UPLOAD_BYTES) { aborted = true; try { ws.destroy(); } catch {}; try { req.destroy(); } catch {}; try { fs.unlinkSync(full); } catch {}; res.status(413).json({ ok:false, error:'too_large', message:`file exceeds limit ${MAX_UPLOAD_BYTES} bytes` }); } } catch {}
    });
    req.on('error', () => { if (aborted) return; try { ws.destroy(); } catch {}; try { fs.unlinkSync(full); } catch {}; });
    ws.on('error', () => { try { fs.unlinkSync(full); } catch {}; });
    ws.on('finish', async () => {
      try {
        if (aborted) return;
        await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, bot_id) VALUES ($1,$2,$3,$4,$5,$6)`, [id, filename, rel, ct, size, 'mcp_dev']);
        res.json({ ok: true, id, file_name: filename, size_bytes: size, content_type: ct });
      } catch (e) {
        res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
      }
    });
    req.pipe(ws);
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.get('/mcp-dev/files', async (req, res) => {
  if (!await requireMcpDevAuth(req, res)) return;
  try {
    const limit = Math.max(1, Math.min(200, Number(req.query.limit || 50)));
    const r = await pool.query(`SELECT id, file_name, content_type, size_bytes, bot_id, created_at FROM mcp_files WHERE bot_id = 'mcp_dev' ORDER BY created_at DESC LIMIT $1`, [limit]);
    res.json({ ok: true, files: r.rows || [] });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e.message });
  }
});

app.get('/mcp-dev/file/:id/download', async (req, res) => {
  try {
    // Allow signed URLs (exp/sig) to bypass token
    const id = String(req.params.id || '').trim();
    const exp = Number(req.query.exp || 0);
    const sig = String(req.query.sig || '').trim();
    let signedOk = false;
    if (sig && exp > Math.floor(Date.now()/1000)) {
      const sec = await ensureFileSignSecret();
      const expected = hmacSha256Hex(sec, `mcp-dev|${id}|${exp}`);
      signedOk = constEq(sig, expected);
    }
    if (!signedOk) { if (!await requireMcpDevAuth(req, res)) return; }
    const r = await pool.query(`SELECT * FROM mcp_files WHERE id=$1 AND bot_id='mcp_dev' LIMIT 1`, [id]);
    if (!r.rowCount) return res.status(404).end();
    const row = r.rows[0];
    const full = path.join(mcpDevUploadDir, row.file_path);
    if (!fs.existsSync(full)) return res.status(404).end();
    res.setHeader('Content-Type', row.content_type || 'application/octet-stream');
    res.setHeader('Content-Disposition', `inline; filename="${row.file_name}"`);
    fs.createReadStream(full).pipe(res);
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e.message });
  }
});

// Delete a DEV file
app.delete('/mcp-dev/file/:id', async (req, res) => {
  if (!await requireMcpDevAuth(req, res)) return;
  try {
    const id = String(req.params.id || '').trim();
    const r = await pool.query(`SELECT * FROM mcp_files WHERE id=$1 AND bot_id='mcp_dev' LIMIT 1`, [id]);
    if (!r.rowCount) return res.status(404).json({ ok: false, error: 'not_found' });
    const row = r.rows[0];
    const full = path.join(mcpDevUploadDir, row.file_path);
    try { if (fs.existsSync(full)) fs.unlinkSync(full); } catch {}
    await pool.query(`DELETE FROM mcp_files WHERE id=$1 AND bot_id='mcp_dev'`, [id]);
    res.json({ ok: true, id });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// OpenAI Actions-friendly bridge for DEV
app.get('/mcp-dev/actions/tools', async (req, res) => {
  if (!await requireMcpDevAuth(req, res)) return;
  try {
    res.json({ ok: true, tools: listToolsForClient() });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.post('/mcp-dev/actions/tools/call', async (req, res) => {
  if (!await requireMcpDevAuth(req, res)) return;
  try {
    const b = req.body || {};
    const name = String(b.name || b.tool || '').trim();
    if (!name) return res.status(400).json({ ok: false, error: 'bad_request', message: 'name required' });
    let args = b.arguments ?? b.args ?? {};
    if (typeof args === 'string') { try { args = JSON.parse(args); } catch { args = {}; } }
    const result = await MCP.run(name, args, { id_bot: 'mcp_dev', session: { authed: true } });
    res.json({ ok: true, tool: name, bot_id: 'mcp_dev', output: result });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.get('/mcp-dev/actions/openapi.json', (req, res) => {
  try {
    const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
    const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
    const proto = (fproto || req.protocol || 'http').toLowerCase();
    const host = (fhost || req.headers.host || 'localhost').trim();
    const base = `${proto}://${host}`;
    const spec = {
      openapi: '3.0.3',
      info: { title: 'MCP DEV Tools', version: '0.1.0' },
      servers: [{ url: base }],
      components: { securitySchemes: { bearerAuth: { type: 'http', scheme: 'bearer', bearerFormat: 'JWT' }, tokenQuery: { type: 'apiKey', in: 'query', name: 'token' } } },
      security: [{ tokenQuery: [] }],
      paths: {
        '/mcp-dev/actions/tools': { get: { summary: 'List tools', responses: { '200': { description: 'ok' } } } },
        '/mcp-dev/actions/tools/call': { post: { summary: 'Call tool', requestBody: { required: true }, responses: { '200': { description: 'ok' } } } }
      }
    };
    res.json(spec);
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Minimal SSE transport compatible with @modelcontextprotocol/inspector "SSE".
// Pattern:
//  - Client opens GET /mcp/events (or /mcp-dev/events) as EventSource
//  - Server immediately emits an `endpoint` event whose data is the POST URL
//    to send JSON-RPC messages to (we use /mcp/message?sessionId=...)
//  - Client POSTs JSON-RPC messages to that endpoint; responses are emitted
//    back on the SSE stream as `data: {json}` frames.

// Shared helpers
function sseWriteEvent(res, eventName, data) {
  try {
    res.write(`event: ${eventName}\n`);
    res.write(`data: ${data}\n\n`);
  } catch {}
}
function sseWriteJson(res, obj) {
  try { res.write(`data: ${JSON.stringify(obj)}\n\n`); } catch {}
}
function sseWriteComment(res, text = '') {
  try { res.write(`:${text}\n\n`); } catch {}
}

// In-memory session stores (simple; ok for dev/inspector usage)
const sseSessions = new Map(); // sessionId -> { res, ctx, keepalive }
const sseDevSessions = new Map();

function createSseSession(store, res, ctx, messagePath, allowNames = null) {
  const sessionId = (globalThis.crypto?.randomUUID?.() || `${Date.now()}-${Math.random().toString(16).slice(2)}`);
  store.set(sessionId, { res, ctx, keepalive: null, allow: Array.isArray(allowNames) ? allowNames : null });
  // Send endpoint for this session (relative/absolute path accepted by client)
  const sep = messagePath.includes('?') ? '&' : '?';
  const endpoint = `${messagePath}${sep}sessionId=${encodeURIComponent(sessionId)}`;
  sseWriteEvent(res, 'endpoint', endpoint);
  // Kick a keepalive every 20s
  const t = setInterval(() => sseWriteComment(res, 'ka'), 20000);
  store.get(sessionId).keepalive = t;
  // Cleanup on close
  res.on('close', () => {
    try { clearInterval(store.get(sessionId)?.keepalive); } catch {}
    store.delete(sessionId);
  });
  return sessionId;
}

// --- DEV SSE endpoints (/mcp-dev)
app.get(['/mcp-dev/events', '/mcp-dev/sse'], async (req, res) => {
  try {
    if (!await requireMcpDevAuth(req, res)) return;
    // Prepare headers for SSE
    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');
    res.setHeader('Cache-Control', 'no-cache, no-transform');
    res.setHeader('Connection', 'keep-alive');
    // Establish a simple authed context (mirrors WS dev behavior)
    const headerTok = checkBearer(req.headers?.authorization || '');
    const qTok = String(req.query?.token || req.query?.mcp_token || '').trim();
    const presented = (headerTok || qTok || '').trim();
    const session = { authed: !getMcpDevToken() || presented === getMcpDevToken() };
    const baseCtx = { id_bot: 'mcp_dev', session };
    // Create session and announce absolute POST endpoint for broad client support
    const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
    const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
    const proto = (fproto || req.protocol || 'http').toLowerCase();
    const host = (fhost || req.headers.host || 'localhost').trim();
    const absoluteMessage = `${proto}://${host}/mcp-dev/message`;
    createSseSession(sseDevSessions, res, baseCtx, absoluteMessage);
  } catch (e) {
    try { res.status(500).end(); } catch {}
  }
});

app.post('/mcp-dev/message', async (req, res) => {
  try {
    if (!await requireMcpDevAuth(req, res)) return;
    const sessionId = String(req.query?.sessionId || '').trim();
    const sess = sseDevSessions.get(sessionId);
    if (!sess) { return res.status(404).end('session_not_found'); }
    const msg = req.body || {};
    const outRes = sess.res;
    const id = msg.id; const method = msg.method; const params = msg.params || {};
    try {
      if (method === 'initialize') {
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: {
          protocolVersion: '2024-11-05',
          serverInfo: { name: 'livechat-mcp-dev', version: '0.1' },
          capabilities: {
            logging: {},
            tools: { listChanged: true },
            resources: { subscribe: true, listChanged: true },
            prompts: { listChanged: true },
          }
        } });
        sseWriteJson(outRes, { jsonrpc: '2.0', method: 'initialized', params: {} });
        return res.status(204).end();
      }
      if (method === 'tools/list') {
        const tools = listToolsForClient();
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { tools } });
        return res.status(204).end();
      }
      if (method === 'resources/list') {
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { resources: [] } });
        return res.status(204).end();
      }
      if (method === 'prompts/list') {
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { prompts: [] } });
        return res.status(204).end();
      }
      if (method === 'ping') {
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { pong: true, time: new Date().toISOString() } });
        return res.status(204).end();
      }
      if (method === 'resources/subscribe') { sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { ok: true } }); return res.status(204).end(); }
      if (method === 'resources/unsubscribe') { sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { ok: true } }); return res.status(204).end(); }
      if (method === 'resources/templates/list') { sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { templates: [] } }); return res.status(204).end(); }
      if (method === 'tools/call') {
        const name = params.name || params.tool || '';
        const args = params.arguments || params.args || {};
        const ctx = { ...sess.ctx };
        const result = await MCP.run(name, args, ctx);
        // Return text content for maximum Inspector compatibility
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { content: [{ type: 'text', text: JSON.stringify(result) }] } });
        return res.status(204).end();
      }
      sseWriteJson(outRes, { jsonrpc: '2.0', id, error: { code: -32601, message: `Unknown method: ${method}` } });
      return res.status(204).end();
    } catch (e) {
      sseWriteJson(outRes, { jsonrpc: '2.0', id, error: { code: -32000, message: e?.message || 'server_error' } });
      return res.status(204).end();
    }
  } catch (e) {
    res.status(500).json({ error: 'server_error', message: e?.message || String(e) });
  }
});

// --- MAIN SSE endpoints (/mcp)
app.get(['/mcp/events', '/mcp/sse', '/mcp/:name/events', '/mcp/:name/sse', '/mcp2/events', '/mcp2/sse', '/mcp2/:name/events', '/mcp2/:name/sse'], async (req, res) => {
  try {
    if (!await requireMcpAuth(req, res)) return;
    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');
    res.setHeader('Cache-Control', 'no-cache, no-transform');
    res.setHeader('Connection', 'keep-alive');
    const headerTok = checkBearer(req.headers?.authorization || '');
    const qTok = String(req.query?.token || req.query?.mcp_token || '').trim();
    const presented = (headerTok || qTok || '').trim();
    const botId = String(req.query?.bot_id || '').trim();
    // Session is considered authed when a valid token was presented per isMcpAuthorized
    const ok = await isMcpAuthorized(req).catch(() => false);
    const session = { authed: !!ok };
    let serverNameCtx = '';
    try { serverNameCtx = String(req.params?.name || '').trim(); } catch {}
    if (!serverNameCtx) { try { serverNameCtx = await resolveServerNameFromReq(req); } catch {} }
    const baseCtx = { id_bot: botId || null, server_name: serverNameCtx || undefined, session };
    const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
    const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
    const proto = (fproto || req.protocol || 'http').toLowerCase();
    const host = (fhost || req.headers.host || 'localhost').trim();
    // Include token/bot_id in message endpoint so SSE clients keep auth when posting
    const tokParam = presented ? `token=${encodeURIComponent(presented)}` : '';
    const botParam = botId ? `bot_id=${encodeURIComponent(botId)}` : '';
    const qs = [tokParam, botParam].filter(Boolean).join('&');
    const absoluteMessage = `${proto}://${host}/mcp/message${qs ? ('?' + qs) : ''}`;
    // Compute per-server allowed tool names and store in session
    let allow = null; try { allow = await getAllowedMcpToolNamesForReq(req); } catch {}
    createSseSession(sseSessions, res, baseCtx, absoluteMessage, allow);
  } catch (e) { try { res.status(500).end(); } catch {} }
});

app.post('/mcp/message', async (req, res) => {
  try {
    if (!await requireMcpAuth(req, res)) return;
    const sessionId = String(req.query?.sessionId || '').trim();
    const sess = sseSessions.get(sessionId);
    if (!sess) return res.status(404).end('session_not_found');
    const msg = req.body || {};
    const outRes = sess.res;
    const id = msg.id; const method = msg.method; const params = msg.params || {};
    try {
      if (method === 'initialize') {
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: {
          protocolVersion: '2024-11-05',
          serverInfo: { name: 'livechat-mcp', version: '0.1' },
          capabilities: {
            logging: {},
            tools: { listChanged: true },
            resources: { subscribe: true, listChanged: true },
            prompts: { listChanged: true },
          }
        } });
        sseWriteJson(outRes, { jsonrpc: '2.0', method: 'initialized', params: {} });
        return res.status(204).end();
      }
      if (method === 'tools/list') {
        const tools = listToolsForClientFiltered(sess.allow || null);
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { tools } });
        return res.status(204).end();
      }
      if (method === 'resources/list') {
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { resources: [] } });
        return res.status(204).end();
      }
      if (method === 'prompts/list') {
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { prompts: [] } });
        return res.status(204).end();
      }
      if (method === 'ping') {
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { pong: true, time: new Date().toISOString() } });
        return res.status(204).end();
      }
      if (method === 'resources/subscribe') { sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { ok: true } }); return res.status(204).end(); }
      if (method === 'resources/unsubscribe') { sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { ok: true } }); return res.status(204).end(); }
      if (method === 'resources/templates/list') { sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { templates: [] } }); return res.status(204).end(); }
      if (method === 'tools/call') {
        const name = params.name || params.tool || '';
        const args = params.arguments || params.args || {};
        const ctx = { ...sess.ctx, id_bot: String(args?.bot_id || sess.ctx?.id_bot || '') };
        if (Array.isArray(sess.allow) && !sess.allow.includes(name)) {
          sseWriteJson(outRes, { jsonrpc: '2.0', id, error: { code: -32601, message: `Tool not allowed: ${name}` } });
          return res.status(204).end();
        }
        const result = await MCP.run(name, args, ctx);
        sseWriteJson(outRes, { jsonrpc: '2.0', id, result: { content: [{ type: 'text', text: JSON.stringify(result) }] } });
        return res.status(204).end();
      }
      sseWriteJson(outRes, { jsonrpc: '2.0', id, error: { code: -32601, message: `Unknown method: ${method}` } });
      return res.status(204).end();
    } catch (e) {
      sseWriteJson(outRes, { jsonrpc: '2.0', id, error: { code: -32000, message: e?.message || 'server_error' } });
      return res.status(204).end();
    }
  } catch (e) {
    res.status(500).json({ error: 'server_error', message: e?.message || String(e) });
  }
});

// JSON upload endpoint: { filename, content_base64, content_type?, bot_id? }
app.post('/mcp/files/base64', async (req, res) => {
  if (!await requireMcpAuth(req, res)) return;
  try {
    const b = req.body || {};
    const filename = String(b.filename || '').trim();
    const base64 = String(b.content_base64 || '').trim();
    if (!filename || !base64) return res.status(400).json({ ok: false, error: 'bad_request' });
    const buf = Buffer.from(base64, 'base64');
    if (buf.length > MAX_UPLOAD_BYTES) {
      return res.status(413).json({ ok: false, error: 'too_large', message: `file exceeds limit ${MAX_UPLOAD_BYTES} bytes` });
    }
    const serverName = await resolveServerNameFromReq(req);
    const subdir = serverName ? slugifyName(serverName) : '';
    const id = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
    const relName = id + '-' + filename.replace(/[^a-zA-Z0-9._-]+/g, '_');
    const rel = subdir ? path.join(subdir, relName) : relName;
    const destDir = subdir ? path.join(mcpUploadDir, subdir) : mcpUploadDir;
    try { fs.mkdirSync(destDir, { recursive: true }); } catch {}
    const full = path.join(destDir, relName);
    fs.writeFileSync(full, buf);
    const ct = String(b.content_type || 'application/octet-stream');
    const botId = (b.bot_id && String(b.bot_id).trim()) || null;
    await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, server_name, bot_id) VALUES ($1,$2,$3,$4,$5,$6,$7)`, [id, filename, rel, ct, buf.length, serverName || null, botId]);
    res.json({ ok: true, id, file_name: filename, size_bytes: buf.length, content_type: ct });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e.message });
  }
});

app.get('/mcp/files', async (req, res) => {
  if (!await requireMcpAuth(req, res)) return;
  try {
    const botId = String(req.query.bot_id || '').trim();
    const serverName = String(req.query.server_name || '').trim();
    const limit = Math.max(1, Math.min(200, Number(req.query.limit || 50)));
    const where = [];
    const params = [];
    if (botId) { where.push('bot_id = $' + (params.push(botId))); }
    if (serverName) { where.push('server_name = $' + (params.push(serverName))); }
    params.push(limit);
    const r = await pool.query(`SELECT id, file_name, content_type, size_bytes, server_name, bot_id, created_at FROM mcp_files ${where.length?'WHERE '+where.join(' AND '):''} ORDER BY created_at DESC LIMIT $${params.length}`, params);
    res.json({ ok: true, files: r.rows || [] });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e.message });
  }
});

app.get('/mcp/file/:id/download', async (req, res) => {
  try {
    // Allow signed URLs (exp/sig) to bypass token
    const id = String(req.params.id || '').trim();
    const exp = Number(req.query.exp || 0);
    const sig = String(req.query.sig || '').trim();
    let signedOk = false;
    if (sig && exp > Math.floor(Date.now()/1000)) {
      const sec = await ensureFileSignSecret();
      const expected = hmacSha256Hex(sec, `mcp|${id}|${exp}`);
      signedOk = constEq(sig, expected);
    }
    if (!signedOk) { if (!await requireMcpAuth(req, res)) return; }
    const r = await pool.query(`SELECT * FROM mcp_files WHERE id=$1 LIMIT 1`, [id]);
    if (!r.rowCount) return res.status(404).end();
    const row = r.rows[0];
    const full = path.join(mcpUploadDir, row.file_path);
    if (!fs.existsSync(full)) return res.status(404).end();
    res.setHeader('Content-Type', row.content_type || 'application/octet-stream');
    res.setHeader('Content-Disposition', `inline; filename="${row.file_name}"`);
    fs.createReadStream(full).pipe(res);
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e.message });
  }
});

// Streaming upload (multipart-free) for main MCP: send file body as application/octet-stream
app.post('/mcp/files/upload', async (req, res) => {
  if (!await requireMcpAuth(req, res)) return;
  try {
    const filename = String(req.query.filename || '').trim();
    if (!filename) return res.status(400).json({ ok: false, error: 'bad_request', message: 'filename required' });
    const id = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
    const rel = id + '-' + filename.replace(/[^a-zA-Z0-9._-]+/g, '_');
    const full = path.join(mcpUploadDir, rel);
    const ct = String(req.query.content_type || req.headers['content-type'] || 'application/octet-stream');
    let size = 0;
    let aborted = false;
    const ws = fs.createWriteStream(full);
    req.on('data', (chunk) => {
      if (aborted) return;
      try {
        size += chunk.length;
        if (size > MAX_UPLOAD_BYTES) {
          aborted = true;
          try { ws.destroy(); } catch {}
          try { req.destroy(); } catch {}
          try { fs.unlinkSync(full); } catch {}
          return res.status(413).json({ ok:false, error:'too_large', message:`file exceeds limit ${MAX_UPLOAD_BYTES} bytes` });
        }
      } catch {}
    });
    req.on('error', () => { if (aborted) return; try { ws.destroy(); } catch {}; try { fs.unlinkSync(full); } catch {}; });
    ws.on('error', () => { try { fs.unlinkSync(full); } catch {}; });
    ws.on('finish', async () => {
      try {
        if (aborted) return;
        await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, bot_id) VALUES ($1,$2,$3,$4,$5,$6)`, [id, filename, rel, ct, size, null]);
        res.json({ ok: true, id, file_name: filename, size_bytes: size, content_type: ct });
      } catch (e) {
        res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
      }
    });
    req.pipe(ws);
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// === OpenAI Actions-friendly HTTP interface for MCP tools ===
// List available tools (name, description, inputSchema)
app.get('/mcp/actions/tools', async (req, res) => {
  if (!await requireMcpAuth(req, res)) return;
  try {
    const tools = listToolsForClient();
    res.json({ ok: true, tools });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Call a specific tool over HTTP for use as an OpenAI Action endpoint
// Body: { name: string, arguments?: object|string, bot_id?: string }
app.post('/mcp/actions/tools/call', async (req, res) => {
  if (!await requireMcpAuth(req, res)) return;
  try {
    const b = req.body || {};
    const name = String(b.name || b.tool || '').trim();
    if (!name) return res.status(400).json({ ok: false, error: 'bad_request', message: 'name required' });
    let args = b.arguments ?? b.args ?? {};
    if (typeof args === 'string') {
      try { args = JSON.parse(args); } catch { args = {}; }
    }
    if (typeof args !== 'object' || Array.isArray(args) || args === null) args = {};
    const botId = String(b.bot_id || req.query.bot_id || args.bot_id || '').trim();

    const ctx = { id_bot: botId || undefined, session: { authed: true } };
    const allow = await getAllowedMcpToolNamesForReq(req);
    if (Array.isArray(allow) && !allow.includes(name)) {
      return res.status(403).json({ ok: false, error: 'not_allowed', message: `Tool not allowed: ${name}` });
    }
    const result = await MCP.run(name, args, ctx);
    res.json({ ok: true, tool: name, bot_id: botId || null, output: result });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Dynamic OpenAPI spec to register in OpenAI Actions UI
app.get(['/mcp/actions/openapi.json', '/.well-known/openapi.json'], (req, res) => {
  try {
    const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
    const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
    const proto = (fproto || req.protocol || 'http').toLowerCase();
    const host = (fhost || req.headers.host || 'localhost').trim();
    const base = `${proto}://${host}`;
    const spec = {
      openapi: '3.0.3',
      info: { title: 'MCP Tools HTTP Bridge', version: '0.1.0' },
      servers: [{ url: base }],
      components: {
        securitySchemes: {
          bearerAuth: { type: 'http', scheme: 'bearer', bearerFormat: 'JWT' },
          tokenQuery: { type: 'apiKey', in: 'query', name: 'token' },
        },
        schemas: {
          ToolCallRequest: {
            type: 'object',
            required: ['name'],
            properties: {
              name: { type: 'string', description: 'Tool name' },
              arguments: { type: 'object', additionalProperties: true },
              bot_id: { type: 'string' },
            },
          },
          ToolCallResponse: {
            type: 'object',
            properties: {
              ok: { type: 'boolean' },
              tool: { type: 'string' },
              bot_id: { type: 'string', nullable: true },
              output: { type: 'object', additionalProperties: true },
            },
          },
          ToolsListResponse: {
            type: 'object',
            properties: {
              ok: { type: 'boolean' },
              tools: {
                type: 'array',
                items: {
                  type: 'object',
                  properties: {
                    name: { type: 'string' },
                    description: { type: 'string' },
                    inputSchema: { type: 'object' },
                  },
                },
              },
            },
          },
        },
      },
      security: [{ bearerAuth: [] }, { tokenQuery: [] }],
      paths: {
        '/mcp/actions/tools': {
          get: {
            summary: 'List available MCP tools',
            security: [{ bearerAuth: [] }, { tokenQuery: [] }],
            responses: {
              '200': { description: 'OK', content: { 'application/json': { schema: { $ref: '#/components/schemas/ToolsListResponse' } } } },
              '401': { description: 'Unauthorized' },
            },
          },
        },
        '/mcp/actions/tools/call': {
          post: {
            summary: 'Call an MCP tool',
            security: [{ bearerAuth: [] }, { tokenQuery: [] }],
            requestBody: {
              required: true,
              content: {
                'application/json': { schema: { $ref: '#/components/schemas/ToolCallRequest' } },
              },
            },
            responses: {
              '200': { description: 'OK', content: { 'application/json': { schema: { $ref: '#/components/schemas/ToolCallResponse' } } } },
              '400': { description: 'Bad request' },
              '401': { description: 'Unauthorized' },
              '500': { description: 'Server error' },
            },
          },
        },
      },
    };
    res.json(spec);
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Issue MCP access token for authenticated agents. Returns the configured
// MCP token if set; otherwise indicates that no token is required.
app.get('/api/mcp/token', (req, res) => {
  const u = authFromRequest(req);
  if (!u) return res.status(401).json({ ok: false, error: 'unauthorized' });
  const t = getMcpToken();
  if (!t) return res.json({ ok: true, required: false, token: null });
  res.json({ ok: true, required: true, token: t });
});

// Per-bot MCP token management (stored in chatbot_config)
app.get('/api/automations/chatbots/:id/mcp/token', async (req, res) => {
  const u = authFromRequest(req);
  if (!u) return res.status(401).json({ ok: false, error: 'unauthorized' });
  try {
    const id = String(req.params.id || '').trim();
    let r = await pool.query(`SELECT mcp_token FROM chatbot_config WHERE id_bot=$1`, [id]);
    if (!r.rowCount) {
      // Auto-create minimal chatbot_config when missing (derive shop/lang from visitors)
      try {
        const v = await pool.query(`SELECT DISTINCT shop_name, lang_iso FROM visitors WHERE shop_name IS NOT NULL AND shop_name<>'' AND lang_iso IS NOT NULL AND lang_iso<>''`);
        let found = null;
        for (const row of v.rows || []) {
          const bid = makeBotId(row.shop_name, row.lang_iso);
          if (bid === id) { found = row; break; }
        }
        if (found) {
          await pool.query(
            `INSERT INTO chatbot_config (id_bot, shop_name, lang_iso, enabled)
             VALUES ($1,$2,$3,$4)
             ON CONFLICT (id_bot) DO NOTHING`,
            [id, found.shop_name, found.lang_iso, false]
          );
          r = await pool.query(`SELECT mcp_token FROM chatbot_config WHERE id_bot=$1`, [id]);
        }
      } catch {}
    }
    const token = r.rowCount ? (r.rows[0].mcp_token || null) : null;
    res.json({ ok: true, required: !!token, token });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/automations/chatbots/:id/mcp/token/regenerate', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const id = String(req.params.id || '').trim();
    const tok = (globalThis.crypto?.randomUUID?.() || '') + '-' + (crypto.randomBytes ? crypto.randomBytes(16).toString('hex') : Math.random().toString(16).slice(2));
    await pool.query(`UPDATE chatbot_config SET mcp_token=$1, updated_at=NOW() WHERE id_bot=$2`, [tok, id]);
    res.json({ ok: true, token: tok });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/automations/chatbots/:id/mcp/token/disable', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const id = String(req.params.id || '').trim();
    await pool.query(`UPDATE chatbot_config SET mcp_token=NULL, updated_at=NOW() WHERE id_bot=$1`, [id]);
    res.json({ ok: true, token: null, required: false });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/automations/chatbots/:id/mcp/token', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const id = String(req.params.id || '').trim();
    const t = String(req.body?.token || '').trim();
    await pool.query(`UPDATE chatbot_config SET mcp_token=$1, updated_at=NOW() WHERE id_bot=$2`, [t || null, id]);
    res.json({ ok: true, token: t || null, required: !!t });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Admin: regenerate or set/disable MCP token
app.post('/api/admin/mcp/token/regenerate', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const tok = (globalThis.crypto?.randomUUID?.() || '') + '-' + (crypto.randomBytes ? crypto.randomBytes(16).toString('hex') : Math.random().toString(16).slice(2));
    await setSetting('MCP_TOKEN', tok);
    mcpToken = tok;
    try { await pool.query(`INSERT INTO mcp_server_config (id, name, kind, token, created_at, updated_at) VALUES ($1,'MCP','main',$2,NOW(),NOW()) ON CONFLICT (name) DO UPDATE SET token=EXCLUDED.token, updated_at=NOW()`, [makeMcpServerId(), tok]); } catch {}
    res.json({ ok: true, token: tok });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/admin/mcp/token/disable', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    await setSetting('MCP_TOKEN', '');
    mcpToken = '';
    try { await pool.query(`UPDATE mcp_server_config SET token=NULL, updated_at=NOW() WHERE name='MCP'`); } catch {}
    res.json({ ok: true, token: null, required: false });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/admin/mcp/token', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const t = String(req.body?.token || '').trim();
    await setSetting('MCP_TOKEN', t);
    mcpToken = t;
    res.json({ ok: true, token: t || null, required: !!t });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Admin: get/set public base URL for MCP/OpenAI Actions
app.get('/api/admin/mcp/public-base', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    res.json({ ok: true, value: getMcpPublicBase() || null });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/admin/mcp/public-base', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const v = String(req.body?.value || '').trim();
    await setSetting('MCP_PUBLIC_BASE', v);
    mcpPublicBase = v;
    try {
      const seedDisabled = /^(1|true|yes)$/i.test(String(process.env.DISABLE_LEGACY_MCP_SEED || ''));
      if (!seedDisabled) {
        await pool.query(`INSERT INTO mcp_server_config (id, name, kind, http_base, created_at, updated_at)
                          VALUES ($1,'MCP','main',$2,NOW(),NOW())
                          ON CONFLICT (name) DO UPDATE SET http_base=EXCLUDED.http_base, updated_at=NOW()`, [makeMcpServerId(), v || null]);
      }
    } catch {}
    res.json({ ok: true, value: v || null });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// ---- Admin endpoints for MCP-DEV token/public base ----
app.post('/api/admin/mcp-dev/token/regenerate', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const tok = crypto.randomUUID();
    await setSetting('MCP_DEV_TOKEN', tok);
    mcpDevToken = tok;
    try { await pool.query(`INSERT INTO mcp_server_config (id, name, kind, token, created_at, updated_at) VALUES ($1,'MCP-DEV','dev',$2,NOW(),NOW()) ON CONFLICT (name) DO UPDATE SET token=EXCLUDED.token, updated_at=NOW()`, [makeMcpServerId(), tok]); } catch {}
    res.json({ ok: true, token: tok, required: true });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Fetch current MCP-DEV token (admin only)
app.get('/api/admin/mcp-dev/token', async (req, res) => {
  // Allow either cookie-authenticated admin OR ADMIN_TOKEN header/query
  try {
    const u = authFromRequest(req);
    let allowed = u && String(u.role || '') === 'admin';
    if (!allowed) {
      const expected = process.env.ADMIN_TOKEN || '';
      if (expected) {
        const got = req.headers['x-admin-token'] || req.query.admin_token;
        allowed = String(got) === expected;
      } else {
        // No ADMIN_TOKEN configured → allow only localhost
        allowed = isLocalhost(req);
      }
    }
    if (!allowed) return res.status(401).json({ ok: false, error: 'unauthorized' });
    const t = getMcpDevToken();
    res.json({ ok: true, token: t || null, required: !!t });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/admin/mcp-dev/token/disable', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    await setSetting('MCP_DEV_TOKEN', '');
    mcpDevToken = '';
    try { await pool.query(`UPDATE mcp_server_config SET token=NULL, updated_at=NOW() WHERE name='MCP-DEV'`); } catch {}
    res.json({ ok: true, token: null, required: false });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/admin/mcp-dev/token', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const t = String(req.body?.token || '').trim();
    await setSetting('MCP_DEV_TOKEN', t);
    mcpDevToken = t;
    res.json({ ok: true, token: t || null, required: !!t });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.get('/api/admin/mcp-dev/public-base', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    res.json({ ok: true, value: getMcpDevPublicBase() || null });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/admin/mcp-dev/public-base', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const v = String(req.body?.value || '').trim();
    await setSetting('MCP_DEV_PUBLIC_BASE', v);
    mcpDevPublicBase = v;
    try {
      const seedDisabled = /^(1|true|yes)$/i.test(String(process.env.DISABLE_LEGACY_MCP_SEED || ''));
      if (!seedDisabled) {
        await pool.query(`INSERT INTO mcp_server_config (id, name, kind, http_base, created_at, updated_at) VALUES ($1,'MCP-DEV','dev',$2,NOW(),NOW()) ON CONFLICT (name) DO UPDATE SET http_base=EXCLUDED.http_base, updated_at=NOW()`, [makeMcpServerId(), v || null]);
      }
    } catch {}
    res.json({ ok: true, value: v || null });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// ---- Admin endpoints for OpenAI API key ----
app.get('/api/admin/openai/key', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const dbVal = getOpenaiApiKey() || null;
    const envVal = process.env.OPENAI_API_KEY || '';
    res.json({ ok: true, value: dbVal || envVal || null });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Fetch current MCP token (admin or localhost via ADMIN_TOKEN)
app.get('/api/admin/mcp/token', async (req, res) => {
  try {
    const u = authFromRequest(req);
    let allowed = u && String(u.role || '') === 'admin';
    if (!allowed) {
      const expected = process.env.ADMIN_TOKEN || '';
      if (expected) {
        const got = req.headers['x-admin-token'] || req.query.admin_token;
        allowed = String(got) === expected;
      } else {
        allowed = isLocalhost(req);
      }
    }
    if (!allowed) return res.status(401).json({ ok: false, error: 'unauthorized' });
    const t = getMcpToken();
    // Do not auto-create legacy MCP rows when seeding is disabled
    const seedDisabled = /^(1|true|yes)$/i.test(String(process.env.DISABLE_LEGACY_MCP_SEED || ''));
    if (!seedDisabled) {
      try { await pool.query(`INSERT INTO mcp_server_config (id, name, kind, token, created_at, updated_at) VALUES ($1,'MCP','main',$2,NOW(),NOW()) ON CONFLICT (name) DO UPDATE SET token=EXCLUDED.token, updated_at=NOW()`, [makeMcpServerId(), t || null]); } catch {}
      try { await pool.query(`INSERT INTO mcp_server_config (id, name, kind, token, created_at, updated_at) VALUES ($1,'MCP-DEV','dev',$2,NOW(),NOW()) ON CONFLICT (name) DO UPDATE SET token=EXCLUDED.token, updated_at=NOW()`, [makeMcpServerId(), t || null]); } catch {}
    }
    res.json({ ok: true, token: t || null, required: !!t });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// Status helper to expose public base and ws URL
app.get('/mcp-dev-prestashop/status', (req, res) => {
  try {
    let httpBase = (getMcpDevPrestaPublicBase() || '').trim();
    let wsUrl = '';
    if (httpBase) {
      try {
        const u = new URL(httpBase);
        const wsScheme = u.protocol === 'https:' ? 'wss:' : 'ws:';
        wsUrl = `${wsScheme}//${u.host}/mcp-dev-prestashop/ws`;
        httpBase = `${u.protocol}//${u.host}`;
      } catch { httpBase = ''; }
    }
    if (!httpBase) {
      const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
      const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
      const proto = (fproto || req.protocol || 'http').toLowerCase();
      const host = (fhost || req.headers.host || 'localhost').trim();
      httpBase = `${proto}://${host}`;
      const wsScheme = proto === 'https' ? 'wss' : 'ws';
      wsUrl = `${wsScheme}://${host}/mcp-dev-prestashop/ws`;
    }
    function isAdminLike(rq) {
      try {
        const expected = process.env.ADMIN_TOKEN || '';
        if (expected) {
          const got = rq.headers['x-admin-token'] || rq.query.admin_token;
          return String(got) === expected;
        }
        return isLocalhost(rq);
      } catch { return false; }
    }
    const maybeToken = isAdminLike(req) ? (getMcpDevPrestaToken() || null) : undefined;
    res.json({ ok: true, version: '0.1', httpBase, wsUrl, enabled: getMcpDevPrestaEnabled(), notes: 'MCP-DEV-Prestashop ready', token: maybeToken });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'mcp_dev_presta_status_failed', message: e?.message || String(e) });
  }
});

// Unified alias under /mcp for Presta status
app.get('/mcp/mcp-dev-prestashop/status', async (req, res) => {
  try {
    let httpBase = (getMcpDevPrestaPublicBase() || '').trim();
    let wsUrl = '';
    const row = await getMcpServerConfigByKind('dev-prestashop');
    if (row && row.http_base) {
      httpBase = row.http_base;
      wsUrl = row.ws_url || inferWsUrlFromBase(httpBase, '/mcp-dev-prestashop/ws');
    } else if (httpBase) {
      try {
        const u = new URL(httpBase);
        const wsScheme = u.protocol === 'https:' ? 'wss:' : 'ws:';
        wsUrl = `${wsScheme}//${u.host}/mcp-dev-prestashop/ws`;
        httpBase = `${u.protocol}//${u.host}`;
      } catch { httpBase = ''; }
    }
    if (!httpBase) {
      const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
      const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
      const proto = (fproto || req.protocol || 'http').toLowerCase();
      const host = (fhost || req.headers.host || 'localhost').trim();
      httpBase = `${proto}://${host}`;
      const wsScheme = proto === 'https' ? 'wss' : 'ws';
      wsUrl = `${wsScheme}://${host}/mcp-dev-prestashop/ws`;
    }
    function isAdminLike(rq) {
      try {
        const expected = process.env.ADMIN_TOKEN || '';
        if (expected) {
          const got = rq.headers['x-admin-token'] || rq.query.admin_token;
          return String(got) === expected;
        }
        return isLocalhost(rq);
      } catch { return false; }
    }
    const maybeToken = isAdminLike(req) ? ((row?.token || getMcpDevPrestaToken()) || null) : undefined;
    res.json({ ok: true, version: '0.1', httpBase, wsUrl, enabled: getMcpDevPrestaEnabled(), notes: 'MCP-DEV-Prestashop ready', token: maybeToken });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'mcp_dev_presta_status_failed', message: e?.message || String(e) });
  }
});

const wssMcpDevPresta = new WebSocketServer({
  noServer: true,
  handleProtocols: (protocols, _req) => {
    try {
      if (protocols && protocols.size) {
        const offered = Array.from(protocols);
        for (const p of offered) { if (/^vnd\.mcp\+json\b/i.test(p)) return p; }
        for (const p of offered) { if (/^model[-]context[-]?protocol\b/i.test(p)) return p; }
        if (protocols.has('mcp')) return 'mcp';
        if (protocols.has('jsonrpc')) return 'jsonrpc';
        return offered[0];
      }
    } catch {}
    return false;
  },
});

async function isMcpDevPrestaAuthorized(req) {
  if (!getMcpDevPrestaEnabled()) return false;
  const q = req.query?.mcp_token || req.query?.token;
  const b = checkBearer(req.headers?.authorization);
  const t = String(q || b || "").trim();
  const g = getMcpDevPrestaToken();
  if (!g) return true; // open when no token set
  return t === g;
}
async function requireMcpDevPrestaAuth(req, res) {
  if (!getMcpDevPrestaEnabled()) { res.status(503).json({ ok:false, error:'disabled' }); return false; }
  const ok = await isMcpDevPrestaAuthorized(req);
  if (!ok) { res.status(401).json({ ok: false, error: 'unauthorized' }); }
  return ok;
}

function prestaToolsList() {
  // Minimal shape expected by MCP clients
  const as = (name, desc, schema) => ({
    name,
    description: desc,
    inputSchema: schema,
    input_schema: schema,
  });

  // Fetch a single chatbot config (includes instructions)
  app.get("/api/automations/chatbots/:id", async (req, res) => {
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ error: 'bad_request' });
      const r = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
      res.json(r.rows[0]);
    } catch (e) {
      logToFile(`❌ GET /api/automations/chatbots/:id: ${e.message}`);
      res.status(500).json({ error: 'server_error' });
    }
  });
  return [
    as('ps_search_customers', 'Search customers by name/email', { type:'object', properties:{ name:{type:'string'}, firstname:{type:'string'}, lastname:{type:'string'}, email:{type:'string'}, limit:{type:'integer', minimum:1, maximum:50, default:5} } }),
    as('ps_list_orders', 'List orders by customer/reference/date', { type:'object', properties:{ customer_id:{ anyOf:[{type:'integer'},{type:'string'}] }, reference:{type:'string'}, date_from:{type:'string'}, date_to:{type:'string'}, limit:{ type:'integer', minimum:1, maximum:50, default:10 } } }),
    as('ps_get_order', 'Get one order by id or reference', { type:'object', properties:{ id:{ anyOf:[{type:'integer'},{type:'string'}] }, reference:{type:'string'} } }),
    as('ps_find_product', 'Find products by name/reference', { type:'object', properties:{ name:{type:'string'}, reference:{type:'string'}, limit:{type:'integer', minimum:1, maximum:50, default:5} } }),
    as('ps_get_product', 'Get product by id/reference', { type:'object', properties:{ id:{ anyOf:[{type:'integer'},{type:'string'}] }, reference:{type:'string'} } }),
    as('ps_get_stock', 'Get stock by product id', { type:'object', properties:{ product_id:{ anyOf:[{type:'integer'},{type:'string'}] } }, required:['product_id'] }),
  ];
}

async function runPrestaTool(name, args = {}) {
  const [base, key] = await Promise.all([
    getSetting('COMPANY_CHAT_PRESTA_BASE'),
    getSetting('COMPANY_CHAT_PRESTA_KEY'),
  ]);
  const envBase = process.env.PRESTASHOP_BASE_URL || '';
  const envKey = process.env.PRESTASHOP_API_KEY || '';
  const prestaBase = String(base || envBase || '').trim();
  const prestaKey = String(key || envKey || '').trim();
  if (!prestaBase || !prestaKey) return { ok:false, error:'prestashop_not_configured' };
  const presta = createPrestaClient({ baseURL: prestaBase, apiKey: prestaKey });
  if (name === 'ps_search_customers') {
    const limit = Number(args?.limit || 5) || 5;
    const email = args?.email ? String(args.email).trim() : '';
    const firstname = args?.firstname ? String(args.firstname).trim() : '';
    const lastname = args?.lastname ? String(args.lastname).trim() : '';
    const full = args?.name ? String(args.name).trim() : '';
    const data = await presta.searchCustomers({ email, firstname, lastname, name: full, limit });
    const arr = normalizePrestaCollection(data, 'customers');
    return { ok:true, count: arr.length, customers: arr };
  }
  if (name === 'ps_list_orders') {
    const customer_id = args?.customer_id != null ? String(args.customer_id).trim() : '';
    const reference = args?.reference ? String(args.reference).trim() : '';
    const date_from = args?.date_from ? String(args.date_from).trim() : '';
    const date_to = args?.date_to ? String(args.date_to).trim() : '';
    const limit = Number(args?.limit || 10) || 10;
    try {
      const data = await presta.listOrders({ customerId: customer_id || undefined, reference: reference || undefined, dateFrom: date_from || undefined, dateTo: date_to || undefined, limit });
      const arr = normalizePrestaCollection(data, 'orders');
      return { ok:true, count: arr.length, orders: arr };
    } catch (e) {
      const msg = String(e?.message || '');
      const filterUnsupported = /Unable to filter by this field/i.test(msg) || /code\"?:\s*38/.test(msg);
      if (!filterUnsupported) throw e;
      // Fallback: retry without server-side filters, then filter client-side
      const wideLimit = Math.max(limit, 100);
      const retry = await presta.listOrders({ customerId: customer_id || undefined, limit: wideLimit });
      let arr = normalizePrestaCollection(retry, 'orders');
      if (reference) arr = arr.filter(o => String(o.reference || '') === reference);
      if (date_from || date_to) {
        const fromMs = date_from ? Date.parse(date_from) : null;
        const toMs = date_to ? Date.parse(date_to) : null;
        arr = arr.filter(o => {
          const t = Date.parse(String(o.date_add || ''));
          if (Number.isNaN(t)) return false;
          if (fromMs != null && t < fromMs) return false;
          if (toMs != null && t > toMs) return false;
          return true;
        });
      }
      arr = arr.slice(0, limit);
      return { ok:true, count: arr.length, orders: arr };
    }
  }
  if (name === 'ps_get_order') {
    const id = args?.id != null ? String(args.id).trim() : '';
    const ref = args?.reference ? String(args.reference).trim() : '';
    let data;
    if (id) data = await presta.getOrder(id);
    else if (ref) {
      try {
        data = await presta.getOrderByReference(ref);
      } catch (e) {
        const msg = String(e?.message || '');
        const filterUnsupported = /Unable to filter by this field/i.test(msg) || /code\"?:\s*38/.test(msg);
        if (!filterUnsupported) throw e;
        // Fallback: fetch recent orders and match by reference
        const retry = await presta.listOrders({ limit: 100 });
        const arr = normalizePrestaCollection(retry, 'orders');
        const found = arr.find(o => String(o.reference || '') === ref);
        data = found ? { orders: [found] } : { orders: [] };
      }
    } else return { ok:false, error:'bad_args' };
    const arr = normalizePrestaCollection(data, 'orders');
    return { ok:true, count: arr.length, orders: arr };
  }
  if (name === 'ps_find_product') {
    const reference = args?.reference ? String(args.reference).trim() : '';
    const nameQ = args?.name ? String(args.name).trim() : '';
    const limit = Number(args?.limit || 5) || 5;
    let data;
    if (reference) data = await presta.getProductByReference(reference);
    else if (nameQ) data = await presta.findProductsByName(nameQ, limit);
    else return { ok:false, error:'bad_args' };
    const arr = normalizePrestaCollection(data, 'products');
    const compact = arr.slice(0, limit).map(p => pick(p, ['id', 'reference', 'price', 'weight', 'active', 'id_manufacturer', 'id_category_default', 'name', 'description_short']));
    return { ok:true, count: arr.length, products: compact };
  }
  if (name === 'ps_get_product') {
    const id = args?.id != null ? String(args.id).trim() : '';
    const reference = args?.reference ? String(args.reference).trim() : '';
    let data;
    if (id) data = await presta.getProduct(id);
    else if (reference) data = await presta.getProductByReference(reference);
    else return { ok:false, error:'bad_args' };
    const arr = normalizePrestaCollection(data, 'products');
    return { ok:true, count: arr.length, products: arr };
  }
  if (name === 'ps_get_stock') {
    const productId = args?.product_id != null ? String(args.product_id).trim() : '';
    if (!productId) return { ok:false, error:'bad_args' };
    const data = await presta.getStockByProductId(productId);
    const arr = normalizePrestaCollection(data, 'stock_availables');
    return { ok:true, count: arr.length, stock: arr };
  }
  return { ok:false, error:'unknown_tool' };
}

function listPrestaToolsForClient() {
  return prestaToolsList();
}

wssMcpDevPresta.on('connection', (ws, req) => {
  try {
    const url = new URL(req.url || '', 'http://local');
    const headerTok = checkBearer(req.headers?.authorization || '');
    const presented = (headerTok || url.searchParams.get('token') || url.searchParams.get('mcp_token') || '').trim();
    const session = { authed: !getMcpDevPrestaToken() || presented === getMcpDevPrestaToken() };

    ws.on('message', async (buf) => {
      let msg; try { msg = JSON.parse(buf.toString('utf8')); } catch { return; }
      const id = msg.id; const method = msg.method; const params = msg.params || {};
      try {
        if (method === 'initialize') {
          ws.send(JSON.stringify({ jsonrpc: '2.0', id, result: {
            protocolVersion: '2024-11-05',
            serverInfo: { name: 'livechat-mcp-dev-prestashop', version: '0.1' },
            capabilities: { logging: {}, tools: { listChanged: true }, resources: { subscribe: true, listChanged: true }, prompts: { listChanged: true } }
          } }));
          return;
        }
        if (method === 'tools/list') {
          ws.send(JSON.stringify({ jsonrpc:'2.0', id, result:{ tools: listPrestaToolsForClient() } }));
          return;
        }
        if (method === 'prompts/list') {
          ws.send(JSON.stringify({ jsonrpc:'2.0', id, result:{ prompts: [] } }));
          return;
        }
        if (method === 'resources/list') {
          ws.send(JSON.stringify({ jsonrpc:'2.0', id, result:{ resources: [] } }));
          return;
        }
        if (method === 'tools/call') {
          const name = params.name || params.tool || '';
          const args = params.arguments || params.args || {};
          const result = await runPrestaTool(name, args);
          ws.send(JSON.stringify({ jsonrpc:'2.0', id, result:{ content: [{ type:'text', text: JSON.stringify(result) }] } }));
          return;
        }
        ws.send(JSON.stringify({ jsonrpc:'2.0', id, error:{ code:-32601, message:`Unknown method: ${method}` } }));
      } catch (e) {
        ws.send(JSON.stringify({ jsonrpc:'2.0', id: null, error:{ code:-32000, message: String(e?.message || 'server_error') } }));
      }
    });
  } catch {}
});

// Upgrade handler for both dev servers (existing code hooks in attachMcpUpgrade)
function attachPrestaUpgrade(serverInstance) {
  try {
    serverInstance.on('upgrade', async (req, socket, head) => {
      try {
        const url = req.url || '';
        if (url.startsWith('/mcp-dev-prestashop/ws')) {
          if (!(await isMcpDevPrestaAuthorized(req))) { socket.destroy(); return; }
          wssMcpDevPresta.handleUpgrade(req, socket, head, (ws) => {
            wssMcpDevPresta.emit('connection', ws, req);
          });
          return;
        }
      } catch { socket.destroy(); }
    });
  } catch {}
}
attachPrestaUpgrade(server);
if (mcpServer) attachPrestaUpgrade(mcpServer);

// Streamable HTTP for Presta MCP
app.post('/mcp-dev-prestashop/stream', async (req, res) => {
  if (!await requireMcpDevPrestaAuth(req, res)) return;
  try {
    const msg = req.body || {};
    const id = msg.id; const method = msg.method; const params = msg.params || {};
    res.setHeader('Content-Type', 'application/json; charset=utf-8');
    res.setHeader('mcp-session-id', 'mcp-dev-prestashop-' + (Date.now()));
    if (method === 'initialize') {
      return res.status(200).json(jsonrpcResponse(id, { protocolVersion:'2024-11-05', serverInfo:{ name:'livechat-mcp-dev-prestashop', version:'0.1' }, capabilities:{ logging:{}, tools:{ listChanged:true }, resources:{ subscribe:true, listChanged:true }, prompts:{ listChanged:true } } }));
    }
    if (method === 'tools/list') {
      return res.status(200).json(jsonrpcResponse(id, { tools: listPrestaToolsForClient() }));
    }
    if (method === 'resources/list') {
      return res.status(200).json(jsonrpcResponse(id, { resources: [] }));
    }
    if (method === 'prompts/list') {
      return res.status(200).json(jsonrpcResponse(id, { prompts: [] }));
    }
    if (method === 'tools/call') {
      const name = params.name || params.tool || '';
      const args = params.arguments || params.args || {};
      const result = await runPrestaTool(name, args);
      return res.status(200).json(jsonrpcResponse(id, { content: [{ type:'text', text: JSON.stringify(result) }] }));
    }
    return res.status(200).json(jsonrpcError(id, -32601, `Unknown method: ${method}`));
  } catch (e) {
    return res.status(500).json({ jsonrpc:'2.0', id: null, error:{ code:-32000, message: e?.message || 'server_error' } });
  }
});
app.post('/mcp/mcp-dev-prestashop/stream', async (req, res) => {
  if (!await requireMcpDevPrestaAuth(req, res)) return;
  try {
    const msg = req.body || {};
    const id = msg.id; const method = msg.method; const params = msg.params || {};
    res.setHeader('Content-Type', 'application/json; charset=utf-8');
    res.setHeader('mcp-session-id', 'mcp-dev-prestashop-' + (Date.now()));
    if (method === 'initialize') {
      return res.status(200).json(jsonrpcResponse(id, { protocolVersion:'2024-11-05', serverInfo:{ name:'livechat-mcp-dev-prestashop', version:'0.1' }, capabilities:{ logging:{}, tools:{ listChanged:true }, resources:{ subscribe:true, listChanged:true }, prompts:{ listChanged:true } } }));
    }
    if (method === 'tools/list') { return res.status(200).json(jsonrpcResponse(id, { tools: listPrestaToolsForClient() })); }
    if (method === 'resources/list') { return res.status(200).json(jsonrpcResponse(id, { resources: [] })); }
    if (method === 'prompts/list') { return res.status(200).json(jsonrpcResponse(id, { prompts: [] })); }
    if (method === 'tools/call') {
      const name = params.name || params.tool || '';
      const args = params.arguments || params.args || {};
      const result = await runPrestaTool(name, args);
      return res.status(200).json(jsonrpcResponse(id, { content: [{ type:'text', text: JSON.stringify(result) }] }));
    }
    return res.status(200).json(jsonrpcError(id, -32601, `Unknown method: ${method}`));
  } catch (e) {
    return res.status(500).json({ jsonrpc:'2.0', id: null, error:{ code:-32000, message: e?.message || 'server_error' } });
  }
});
app.get('/mcp/mcp-dev-prestashop/stream', (_req, res) => {
  res.status(405).type('text/plain; charset=utf-8').send('Use POST JSON (application/json) to /mcp/mcp-dev-prestashop/stream for Streamable HTTP (MCP).');
});

// Convenience HTTP endpoints for MCP-DEV-Prestashop tools (like MCP-DEV actions)
app.get('/mcp-dev-prestashop/actions/tools', async (req, res) => {
  try { return res.json({ ok:true, tools: listPrestaToolsForClient() }); }
  catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.post('/mcp-dev-prestashop/actions/tools/call', async (req, res) => {
  try {
    const b = req.body || {};
    const name = String(b.name || b.tool || '').trim();
    const args = (typeof b.arguments === 'object' && b.arguments) || (typeof b.args === 'object' && b.args) || {};
    if (!name) return res.status(400).json({ ok:false, error:'bad_request' });
    const result = await runPrestaTool(name, args);
    return res.json({ ok:true, result });
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Unified actions aliases under /mcp for Presta tools
app.get('/mcp/mcp-dev-prestashop/actions/tools', async (req, res) => {
  try { return res.json({ ok:true, tools: listPrestaToolsForClient() }); }
  catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.post('/mcp/mcp-dev-prestashop/actions/tools/call', async (req, res) => {
  try {
    const b = req.body || {};
    const name = String(b.name || b.tool || '').trim();
    const args = (typeof b.arguments === 'object' && b.arguments) || (typeof b.args === 'object' && b.args) || {};
    if (!name) return res.status(400).json({ ok:false, error:'bad_request' });
    const result = await runPrestaTool(name, args);
    return res.json({ ok:true, result });
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Admin: create a signed download URL for MCP-DEV file
app.post('/api/mcp-dev/file/signed-url', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const b = req.body || {};
    const id = String(b.id || b.file_id || '').trim();
    const ttl = Math.max(10, Math.min(86400, Number(b.expiresIn || b.ttl || 600)));
    if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
    const sec = await ensureFileSignSecret();
    const exp = Math.floor(Date.now()/1000) + ttl;
    const sig = hmacSha256Hex(sec, `mcp-dev|${id}|${exp}`);
    const proto = (req.headers['x-forwarded-proto']?.toString().split(',')[0] || req.protocol || 'http').toLowerCase();
    const host = (req.headers['x-forwarded-host']?.toString().split(',')[0] || req.headers.host || 'localhost').trim();
    const url = `${proto}://${host}/mcp-dev/file/${encodeURIComponent(id)}/download?exp=${exp}&sig=${sig}`;
    res.json({ ok:true, url, exp });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});
// Admin: create a signed download URL for MCP file
app.post('/api/mcp/file/signed-url', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const b = req.body || {};
    const id = String(b.id || b.file_id || '').trim();
    const ttl = Math.max(10, Math.min(86400, Number(b.expiresIn || b.ttl || 600)));
    if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
    const sec = await ensureFileSignSecret();
    const exp = Math.floor(Date.now()/1000) + ttl;
    const sig = hmacSha256Hex(sec, `mcp|${id}|${exp}`);
    const proto = (req.headers['x-forwarded-proto']?.toString().split(',')[0] || req.protocol || 'http').toLowerCase();
    const host = (req.headers['x-forwarded-host']?.toString().split(',')[0] || req.headers.host || 'localhost').trim();
    const url = `${proto}://${host}/mcp/file/${encodeURIComponent(id)}/download?exp=${exp}&sig=${sig}`;
    res.json({ ok:true, url, exp });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

  // ---- Admin: OpenAI debug (last request/continuation/error) ----
  app.get('/api/admin/openai/debug', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const dbg = getOpenaiDebug() || {};
      res.json({ ok: true, ...dbg });
    } catch (e) {
      res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
    }
  });

  // ---- Admin: Prompts debug (last prompt-related events) ----
  app.get('/api/admin/openai/prompts/debug', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const dbg = getPromptsDebug() || {};
      res.json({ ok: true, ...dbg });
    } catch (e) {
      res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
    }
  });

  // Conversation Hub: get selected chatbot ids
  app.get('/api/automations/conversation-hub', async (_req, res) => {
    try {
      const raw = await getSetting('conversation_hub_bots');
      let ids = [];
      try { const j = raw ? JSON.parse(raw) : null; if (j && Array.isArray(j.ids)) ids = j.ids.map(String); } catch {}
      res.json({ ok: true, ids });
    } catch (e) {
      logToFile(`❌ GET /api/automations/conversation-hub: ${e.message}`);
      res.status(500).json({ ok: false, error: 'server_error' });
    }
  });

  // Conversation Hub: set selected chatbot ids
  app.post('/api/automations/conversation-hub', async (req, res) => {
    try {
      const arr = Array.isArray(req.body?.ids) ? req.body.ids.map((x)=> String(x || '').trim()).filter(Boolean) : [];
      await setSetting('conversation_hub_bots', JSON.stringify({ ids: arr }));
      res.json({ ok: true, ids: arr });
    } catch (e) {
      logToFile(`❌ POST /api/automations/conversation-hub: ${e.message}`);
      res.status(500).json({ ok: false, error: 'server_error' });
    }
  });

  // Map external (Prestashop) assistant_id -> internal id_bot (dedicated table)
  app.get('/api/visitors/:id/chatbot-map', async (req, res) => {
    try {
      const vid = String(req.params.id || '').trim();
      if (!vid) return res.status(400).json({ ok: false, error: 'bad_request' });
      // Load visitor
      const vr = await pool.query(`SELECT visitor_id, shop_name, lang_iso, assistant_id FROM visitors WHERE (visitor_id=$1 OR id=$1) LIMIT 1`, [vid]);
      if (!vr.rowCount) return res.status(404).json({ ok: false, error: 'not_found' });
      const v = vr.rows[0];
      const assistantIdExt = v.assistant_id || null;
      let linkedId = null;
      if (assistantIdExt) {
        try { await ensureHubBotMapTable(); } catch {}
        try { const mr = await pool.query(`SELECT id_bot FROM hub_bot_map WHERE assistant_id_ext=$1 LIMIT 1`, [assistantIdExt]); if (mr.rowCount) linkedId = mr.rows[0].id_bot || null; } catch {}
      }
      // Suggest candidates from DB (same shop/lang)
      let candidates = [];
      try {
        const cr = await pool.query(`SELECT id_bot, name FROM chatbot_config WHERE ($1 IS NULL OR shop_name=$1) AND ($2 IS NULL OR lang_iso=$2) ORDER BY shop_name, lang_iso`, [v.shop_name || null, v.lang_iso || null]);
        candidates = (cr.rows || []).map(r => ({ id_bot: r.id_bot, name: r.name || null }));
      } catch {}
      res.json({ ok: true, visitor_id: v.visitor_id, assistant_id_ext: assistantIdExt, linked_id_bot: linkedId, candidates });
    } catch (e) {
      logToFile(`❌ GET /api/visitors/:id/chatbot-map: ${e.message}`);
      res.status(500).json({ ok: false, error: 'server_error' });
    }
  });

  app.post('/api/visitors/:id/chatbot-map', async (req, res) => {
    try {
      const vid = String(req.params.id || '').trim();
      if (!vid) return res.status(400).json({ ok: false, error: 'bad_request' });
      const target = String(req.body?.id_bot || '').trim();
      if (!target) return res.status(400).json({ ok: false, error: 'bad_request', message: 'id_bot required' });
      // Ensure target exists
      const ex = await pool.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [target]);
      if (!ex.rowCount) return res.status(404).json({ ok: false, error: 'not_found', message: 'id_bot not found' });
      // Load visitor to get external id
      const vr = await pool.query(`SELECT assistant_id FROM visitors WHERE (visitor_id=$1 OR id=$1) LIMIT 1`, [vid]);
      if (!vr.rowCount) return res.status(404).json({ ok: false, error: 'not_found' });
      const assistantIdExt = vr.rows[0]?.assistant_id || null;
      if (!assistantIdExt) return res.status(400).json({ ok: false, error: 'bad_request', message: 'visitor has no assistant_id' });
      // Update mapping in dedicated table
      try { await ensureHubBotMapTable(); } catch {}
      await pool.query(`INSERT INTO hub_bot_map (assistant_id_ext, id_bot, updated_at)
                        VALUES ($1,$2,NOW())
                        ON CONFLICT (assistant_id_ext)
                        DO UPDATE SET id_bot=EXCLUDED.id_bot, updated_at=NOW()`, [assistantIdExt, target]);
      res.json({ ok: true, assistant_id_ext: assistantIdExt, linked_id_bot: target });
    } catch (e) {
      logToFile(`❌ POST /api/visitors/:id/chatbot-map: ${e.message}`);
      res.status(500).json({ ok: false, error: 'server_error' });
    }
  });

  // Conversation Hub mapping stats: count of external IDs linked per chatbot
  app.get('/api/automations/conversation-hub/stats', async (_req, res) => {
    try {
      try { await ensureHubBotMapTable(); } catch {}
      const r = await pool.query(`SELECT id_bot, COUNT(*)::INT AS count FROM hub_bot_map GROUP BY id_bot`);
      const items = (r.rows || []).map(row => ({ id_bot: row.id_bot, count: Number(row.count) || 0 }));
      res.json({ ok: true, items });
    } catch (e) {
      logToFile(`❌ GET /api/automations/conversation-hub/stats: ${e.message}`);
      res.status(500).json({ ok: false, error: 'server_error' });
    }
  });

  // Delete a chatbot by id (cascades to chatbot_welcome_link; cleans mcp_files)
  app.delete("/api/automations/chatbots/:id", async (req, res) => {
    const id = String(req.params.id || '').trim();
    if (!id) return res.status(400).json({ error: 'bad_request' });
    try {
      try { await ensureChatbotWelcomeLinkTable(); } catch {}
      // Clean any associated files (best-effort; table may not exist)
      try { await pool.query(`DELETE FROM mcp_files WHERE bot_id=$1`, [id]); } catch {}
      const r = await pool.query(`DELETE FROM chatbot_config WHERE id_bot=$1`, [id]);
      if (!r.rowCount) return res.status(404).json({ error: 'not_found' });
      // ON DELETE CASCADE removes from chatbot_welcome_link
      res.json({ ok: true, deleted: r.rowCount });
    } catch (e) {
      logToFile(`❌ DELETE /api/automations/chatbots/:id: ${e.message}`);
      res.status(500).json({ error: 'server_error' });
    }
  });

  // ---- Admin: Google — simple Drive list test using Service Account ----
  app.post('/api/google/test', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      const previewOnly = (b.preview === true) || String(req.query?.preview || '').toLowerCase() === 'true';
      // 1) Resolve credentials
      let creds = b.service_account_json || process.env.GOOGLE_SERVICE_ACCOUNT_JSON || null;
      if (typeof creds === 'string' && creds.trim()) {
        try { creds = JSON.parse(creds); } catch {}
      }
      // Also allow pointing to a file via GOOGLE_APPLICATION_CREDENTIALS
      if (!creds && process.env.GOOGLE_APPLICATION_CREDENTIALS) {
        try { const p = process.env.GOOGLE_APPLICATION_CREDENTIALS; const txt = fs.readFileSync(p, 'utf8'); creds = JSON.parse(txt); } catch {}
      }
      if (!creds || typeof creds !== 'object') {
        return res.status(400).json({ ok:false, error:'missing_credentials', message:'Provide service_account_json (body) or set GOOGLE_SERVICE_ACCOUNT_JSON/GOOGLE_APPLICATION_CREDENTIALS.' });
      }
      // 2) Resolve scopes
      const scopesRaw = String(b.scopes || process.env.GOOGLE_OAUTH_SCOPES || 'https://www.googleapis.com/auth/drive.readonly');
      const scopes = scopesRaw.split(/\s+/).filter(Boolean);
      // 3) Optional user to impersonate (domain-wide delegation)
      const subject = (b.impersonate || process.env.GOOGLE_IMPERSONATE_USER || '').trim() || undefined;

      // 4) Create client
      const client = new google.auth.JWT({
        email: creds.client_email,
        key: creds.private_key,
        scopes,
        subject,
      });
      const drive = google.drive({ version: 'v3', auth: client });
      const r = await drive.files.list({ pageSize: 5, fields: 'files(id,name,modifiedTime,owners(emailAddress))' });
      const files = (r.data.files || []).map(f => ({ id: f.id, name: f.name, modifiedTime: f.modifiedTime, owner: (f.owners && f.owners[0] && f.owners[0].emailAddress) || null }));
      return res.json({ ok:true, count: files.length, files });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // ====================== GOOGLE OAUTH (user flow) ======================
  const OAUTH_DEFAULT_SCOPES = (
    process.env.GOOGLE_OAUTH_SCOPES || [
      'openid', 'email', 'profile',
      'https://www.googleapis.com/auth/gmail.readonly',
      'https://www.googleapis.com/auth/calendar.readonly',
      'https://www.googleapis.com/auth/contacts.readonly',
      'https://www.googleapis.com/auth/drive.readonly',
    ].join(' ')
  ).split(/\s+/).filter(Boolean);

  const GOOGLE_TOKENS_KEY = (userId) => `GOOGLE_OAUTH_TOKENS_USER_${userId}`;
  const GOOGLE_LAST_ERR_KEY = (userId) => `GOOGLE_OAUTH_LAST_ERROR_USER_${userId}`;
  const oauthStates = new Map(); // ephemeral CSRF state cache

  function makeOAuthClient() {
    const clientId = process.env.GOOGLE_OAUTH_CLIENT_ID || '';
    const clientSecret = process.env.GOOGLE_OAUTH_CLIENT_SECRET || '';
    const redirectUri = process.env.GOOGLE_OAUTH_REDIRECT_URI || '';
    if (!clientId || !clientSecret || !redirectUri) {
      throw new Error('missing_oauth_env');
    }
    return new google.auth.OAuth2(clientId, clientSecret, redirectUri);
  }

  // Start OAuth: redirects the browser to Google consent
  app.get('/api/oauth2/google/start', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const oauth2 = makeOAuthClient();
      // Capture where to return (best-effort): Referer or home
      let from = req.get('referer') || '';
      try { const u = new URL(from); if (!u.hostname) from = ''; } catch { from = ''; }
      const state = Buffer.from(JSON.stringify({ uid: u.id, ts: Date.now(), nonce: crypto.randomBytes(8).toString('hex'), from })).toString('base64url');
      oauthStates.set(state, { uid: u.id, at: Date.now() });
      const url = oauth2.generateAuthUrl({
        access_type: 'offline',
        include_granted_scopes: true,
        prompt: 'consent',
        scope: OAUTH_DEFAULT_SCOPES,
        state,
      });
      res.redirect(url);
    } catch (e) {
      res.status(500).type('text/plain').send(`OAuth start error: ${e?.message || e}`);
    }
  });

  // OAuth callback: exchange code for tokens and store them per-user
  app.get('/api/oauth2/google/callback', async (req, res) => {
    try {
      const { code = '', state = '' } = req.query || {};
      if (!code) return res.status(400).type('text/plain').send('Missing code');
      const s = String(state || '');
      // Try robust state decode (works on Node 12+)
      const decodeState = (val) => {
        try {
          if (!val) return null;
          // base64url -> base64
          let b = val.replace(/-/g, '+').replace(/_/g, '/');
          while (b.length % 4) b += '=';
          const txt = Buffer.from(b, 'base64').toString('utf8');
          const j = JSON.parse(txt);
          return j && typeof j === 'object' ? j : null;
        } catch { return null; }
      };
      let parsed = decodeState(s);
      const cached = oauthStates.get(s) || null;
      // Also try to resolve user from current session as fallback
      const uSess = authFromRequest(req);
      let uid = parsed?.uid || cached?.uid || (uSess && uSess.id);
      if (!uid) return res.status(400).type('text/plain').send('Bad state');
      oauthStates.delete(s);
      const oauth2 = makeOAuthClient();
      const { tokens } = await oauth2.getToken(String(code));
      if (!tokens || (!tokens.access_token && !tokens.refresh_token)) return res.status(400).type('text/plain').send('No tokens returned');
      try { await ensureTablesMigration({ pool, logToFile }); } catch {}
      await setSetting(GOOGLE_TOKENS_KEY(uid), JSON.stringify(tokens));
      try { await setSetting(GOOGLE_LAST_ERR_KEY(uid), ''); } catch {}
      try { logToFile(`oauth_google_success uid=${uid} scope=${tokens.scope||''}`); } catch {}
      const from = (parsed && parsed.from && typeof parsed.from === 'string') ? parsed.from : '/';
      const safeFrom = (()=>{ try { const u = new URL(from, `${req.protocol}://${req.get('host')}`); return u.pathname + (u.search||'') + (u.hash||''); } catch { return '/'; } })();
      const html = `<!doctype html><meta charset="utf-8" />
<title>Connected</title>
<script>
try{(window.opener||window.parent).postMessage({kind:'oauth_ok'},'*');}catch(e){}
try{ if(window.opener){ window.close(); } else { window.location = ${JSON.stringify(safeFrom||'/')}; } }catch(e){ window.location = ${JSON.stringify(safeFrom||'/')}; }
</script>
<p>Connected. <a href=${JSON.stringify(safeFrom||'/')}>Return to app</a></p>`;
      res.type('text/html').send(html);
    } catch (e) {
      try {
        // Try to persist last error for current user if possible
        const { state = '' } = req.query || {};
        const s = String(state||'');
        const decodeState = (val) => { try { if (!val) return null; let b = val.replace(/-/g,'+').replace(/_/g,'/'); while (b.length%4) b+='='; const txt = Buffer.from(b,'base64').toString('utf8'); return JSON.parse(txt); } catch { return null; } };
        const parsed = decodeState(s) || {};
        const uSess = authFromRequest(req);
        const uid = parsed?.uid || (uSess && uSess.id);
        if (uid) await setSetting(GOOGLE_LAST_ERR_KEY(uid), String(e?.message || e));
        try { logToFile(`oauth_google_error uid=${uid||''} err=${e?.message||e}`); } catch {}
      } catch {}
      res.status(500).type('text/plain').send(`OAuth callback error: ${e?.message || e}`);
    }
  });

  // Backward-compat paths (old routes without /api prefix)
  app.get('/oauth2/google/start', (req, res) => {
    try { return res.redirect(302, '/api/oauth2/google/start'); } catch { res.status(302).redirect('/api/oauth2/google/start'); }
  });
  app.get('/oauth2/google/callback', (req, res) => {
    try {
      const q = req.originalUrl && req.originalUrl.includes('?') ? req.originalUrl.split('?')[1] : '';
      return res.redirect(302, '/api/oauth2/google/callback' + (q ? `?${q}` : ''));
    } catch {
      return res.status(302).redirect('/api/oauth2/google/callback');
    }
  });

  async function loadUserOAuthClient(userId) {
    const row = await getSetting(GOOGLE_TOKENS_KEY(userId));
    if (!row) return null;
    let tokens = null; try { tokens = JSON.parse(row); } catch {}
    if (!tokens) return null;
    const oauth2 = makeOAuthClient();
    oauth2.setCredentials(tokens);
    // Auto-refresh handling: hook token event to persist refresh
    oauth2.on('tokens', async (t) => {
      try {
        const cur = { ...(tokens || {}), ...t };
        tokens = cur; // update local ref
        await setSetting(GOOGLE_TOKENS_KEY(userId), JSON.stringify(cur));
      } catch {}
    });
    return oauth2;
  }

  // Status
  app.get('/api/google/oauth/status', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const row = await getSetting(GOOGLE_TOKENS_KEY(u.id));
      if (!row) return res.json({ ok:true, connected:false });
      let t = null; try { t = JSON.parse(row); } catch {}
      const has = !!(t && (t.refresh_token || t.access_token));
      res.json({ ok:true, connected: has, token: has ? { expiry_date: t?.expiry_date || null, scope: t?.scope || '' } : null });
    } catch { res.json({ ok:true, connected:false }); }
  });

  // Debug: include last error
  app.get('/api/google/oauth/debug', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const status = await getSetting(GOOGLE_TOKENS_KEY(u.id));
      const err = await getSetting(GOOGLE_LAST_ERR_KEY(u.id));
      let t=null; try{ t=status?JSON.parse(status):null; }catch{}
      const has = !!(t && (t.refresh_token || t.access_token));
      res.json({ ok:true, connected:has, last_error: err||'' });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
  });

  // Revoke & clear
  app.post('/api/google/oauth/revoke', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const row = await getSetting(GOOGLE_TOKENS_KEY(u.id));
      if (row) {
        let t = null; try { t = JSON.parse(row); } catch {}
        try {
          const oauth2 = makeOAuthClient();
          if (t?.access_token) await oauth2.revokeToken(t.access_token);
          if (t?.refresh_token) await oauth2.revokeToken(t.refresh_token);
        } catch {}
        await setSetting(GOOGLE_TOKENS_KEY(u.id), '');
      }
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // OAuth tests (Drive/Gmail/Calendar/People)
  app.get('/api/google/oauth/drive', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const drive = google.drive({ version: 'v3', auth: oauth2 });
      const r = await drive.files.list({ pageSize: 5, fields: 'files(id,name,modifiedTime,owners(emailAddress))' });
      const files = (r.data.files || []).map(f => ({ id: f.id, name: f.name, modifiedTime: f.modifiedTime, owner: (f.owners && f.owners[0] && f.owners[0].emailAddress) || null }));
      res.json({ ok:true, count: files.length, files });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  app.get('/api/google/oauth/gmail', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });
      const r = await gmail.users.labels.list({ userId: 'me' });
      const labels = (r.data.labels || []).map(l => ({ id: l.id, name: l.name, type: l.type, messagesTotal: l.messagesTotal, messagesUnread: l.messagesUnread, threadsTotal: l.threadsTotal, threadsUnread: l.threadsUnread }));
      res.json({ ok:true, count: labels.length, labels });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // List recent messages (simple inbox view)
  app.get('/api/google/oauth/gmail/messages', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });
      // Accept multiple labels via labelIds/labels/labelId/label query params
      let labelIds = [];
      const raw = (req.query.labelIds ?? req.query.labels ?? req.query.labelId ?? req.query.label);
      if (Array.isArray(raw)) labelIds = raw.map(String).filter(Boolean);
      else if (typeof raw === 'string' && raw.trim()) labelIds = raw.split(',').map(s=>s.trim()).filter(Boolean);
      if (!labelIds.length) labelIds = ['INBOX'];
      const maxResults = Math.min(50, Math.max(1, Number(req.query.max || req.query.maxResults || 20)));
      const q = String(req.query.q || '').trim() || undefined;
      const list = await gmail.users.messages.list({ userId: 'me', labelIds, maxResults, q });
      const items = list.data.messages || [];
      const pickHeader = (headers, name) => {
        try { const h = (headers||[]).find(h => String(h.name||'').toLowerCase() === String(name).toLowerCase()); return h ? (h.value || '') : ''; } catch { return ''; }
      };
      const decodeB64 = (s='') => { try { const b=s.replace(/-/g,'+').replace(/_/g,'/'); return Buffer.from(b,'base64').toString('utf8'); } catch { return ''; } };
      const details = await Promise.all(items.map(async (m) => {
        try {
          const r = await gmail.users.messages.get({ userId:'me', id:m.id, format:'metadata', metadataHeaders:['From','Subject','Date'] });
          const md = r.data || {};
          const hdrs = (md.payload && md.payload.headers) || [];
          return {
            id: md.id,
            threadId: md.threadId,
            snippet: md.snippet || '',
            from: pickHeader(hdrs, 'From'),
            subject: pickHeader(hdrs, 'Subject'),
            date: pickHeader(hdrs, 'Date'),
            labelIds: md.labelIds || [],
          };
        } catch { return { id: m.id, threadId: m.threadId, snippet:'', from:'', subject:'', date:'', labelIds: [] }; }
      }));
      res.json({ ok:true, items: details });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Message details (basic text/html extraction)
  app.get('/api/google/oauth/gmail/messages/:id', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });
      const r = await gmail.users.messages.get({ userId:'me', id, format:'full' });
      const msg = r.data || {};
      const hdrs = (msg.payload && msg.payload.headers) || [];
      const pickHeader = (name) => { try { const h = hdrs.find(h=>String(h.name||'').toLowerCase()===String(name).toLowerCase()); return h? (h.value||''):''; } catch { return ''; } };
      const decodeB64 = (s='') => { try { const b=s.replace(/-/g,'+').replace(/_/g,'/'); return Buffer.from(b,'base64').toString('utf8'); } catch { return ''; } };
      const walkParts = (p, out) => {
        if (!p) return;
        if (p.mimeType === 'text/plain' && p.body && p.body.data) out.text += decodeB64(p.body.data);
        if (p.mimeType === 'text/html' && p.body && p.body.data) out.html += decodeB64(p.body.data);
        if (Array.isArray(p.parts)) for (const c of p.parts) walkParts(c, out);
      };
      const body = { text:'', html:'' };
      walkParts(msg.payload, body);
      res.json({ ok:true, id: msg.id, threadId: msg.threadId, snippet: msg.snippet||'',
        from: pickHeader('From'), to: pickHeader('To'), cc: pickHeader('Cc'), subject: pickHeader('Subject'), date: pickHeader('Date'),
        labelIds: msg.labelIds||[], body_text: body.text, body_html: body.html });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Mark as read (remove UNREAD)
  app.post('/api/google/oauth/gmail/messages/:id/mark-read', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });
      await gmail.users.messages.modify({ userId:'me', id, requestBody: { removeLabelIds: ['UNREAD'] } });
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Mark as unread (add UNREAD)
  app.post('/api/google/oauth/gmail/messages/:id/mark-unread', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });
      await gmail.users.messages.modify({ userId:'me', id, requestBody: { addLabelIds: ['UNREAD'] } });
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Star / Unstar
  app.post('/api/google/oauth/gmail/messages/:id/star', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });
      await gmail.users.messages.modify({ userId:'me', id, requestBody: { addLabelIds: ['STARRED'] } });
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/google/oauth/gmail/messages/:id/unstar', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });
      await gmail.users.messages.modify({ userId:'me', id, requestBody: { removeLabelIds: ['STARRED'] } });
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  function toBase64Url(str) {
    return Buffer.from(str, 'utf8').toString('base64').replace(/\+/g,'-').replace(/\//g,'_').replace(/=+$/,'');
  }

  // Reply to a message (simple)
  app.post('/api/google/oauth/gmail/messages/:id/reply', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const text = String(b.text || '').trim();
      const html = typeof b.html === 'string' ? b.html : '';
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });

      // Fetch original to get headers + thread
      const gr = await gmail.users.messages.get({ userId:'me', id, format:'metadata', metadataHeaders:['From','Subject','Message-ID','References'] });
      const msg = gr.data || {};
      const hdrs = (msg.payload && msg.payload.headers) || [];
      const pick = (name) => { try { const h = hdrs.find(h=>String(h.name||'').toLowerCase()===String(name).toLowerCase()); return h ? h.value || '' : ''; } catch { return ''; } };
      const origFrom = pick('From');
      const origSubject = pick('Subject') || '';
      const messageId = pick('Message-ID');
      const refs = pick('References');
      const to = String(b.to || origFrom || '').trim();
      let subject = String(b.subject || '').trim();
      if (!subject) subject = /^re:/i.test(origSubject) ? origSubject : `Re: ${origSubject}`;
      const headers = [
        `To: ${to}`,
        `Subject: ${subject}`,
        `In-Reply-To: ${messageId}`,
        `References: ${refs ? `${refs} ${messageId}` : messageId}`,
        `MIME-Version: 1.0`,
      ];
      let body = '';
      if (html && html.trim()) {
        headers.push(`Content-Type: text/html; charset=UTF-8`);
        body = html;
      } else {
        headers.push(`Content-Type: text/plain; charset=UTF-8`);
        body = text || '';
      }
      const raw = headers.join('\r\n') + `\r\n\r\n` + body;
      const sent = await gmail.users.messages.send({ userId:'me', requestBody: { raw: toBase64Url(raw), threadId: msg.threadId } });
      res.json({ ok:true, id: sent.data && sent.data.id, threadId: sent.data && sent.data.threadId });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Forward a message (simple)
  app.post('/api/google/oauth/gmail/messages/:id/forward', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      const b = req.body || {};
      const to = String(b.to || '').trim();
      if (!id || !to) return res.status(400).json({ ok:false, error:'bad_request' });
      const text = String(b.text || '').trim();
      const html = typeof b.html === 'string' ? b.html : '';
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const gmail = google.gmail({ version: 'v1', auth: oauth2 });
      const gr = await gmail.users.messages.get({ userId:'me', id, format:'metadata', metadataHeaders:['Subject'] });
      const subj = (((gr.data && gr.data.payload && gr.data.payload.headers) || []).find(h=>/subject/i.test(h.name||''))||{}).value || '';
      const subject = /^fwd:/i.test(subj) ? subj : `Fwd: ${subj}`;
      const headers = [
        `To: ${to}`,
        `Subject: ${subject}`,
        `MIME-Version: 1.0`,
      ];
      let body = '';
      if (html && html.trim()) { headers.push(`Content-Type: text/html; charset=UTF-8`); body = html; }
      else { headers.push(`Content-Type: text/plain; charset=UTF-8`); body = text || ''; }
      const raw = headers.join('\r\n') + `\r\n\r\n` + body;
      const sent = await gmail.users.messages.send({ userId:'me', requestBody: { raw: toBase64Url(raw) } });
      res.json({ ok:true, id: sent.data && sent.data.id, threadId: sent.data && sent.data.threadId });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  app.get('/api/google/oauth/calendar', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const calendar = google.calendar({ version: 'v3', auth: oauth2 });
      const now = new Date().toISOString();
      const r = await calendar.events.list({ calendarId: 'primary', timeMin: now, maxResults: 5, singleEvents: true, orderBy: 'startTime' });
      const items = (r.data.items || []).map(ev => ({ id: ev.id, summary: ev.summary || '', start: ev.start, end: ev.end }));
      res.json({ ok:true, count: items.length, events: items });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  app.get('/api/google/oauth/people', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      const oauth2 = await loadUserOAuthClient(u.id);
      if (!oauth2) return res.status(401).json({ ok:false, error:'not_connected' });
      const people = google.people({ version: 'v1', auth: oauth2 });

      // Pagination and fields
      const maxRaw = String(req.query.max || req.query.pageSize || '200');
      let pageSize = parseInt(maxRaw, 10);
      if (!Number.isFinite(pageSize) || pageSize <= 0) pageSize = 200;
      pageSize = Math.min(Math.max(pageSize, 1), 1000); // Google API max 1000
      const pageToken = (req.query.pageToken || req.query.page_token || '').toString() || undefined;
      const fields = (req.query.fields || 'names,emailAddresses,phoneNumbers,organizations,memberships,photos').toString();

      const r = await people.people.connections.list({
        resourceName: 'people/me',
        pageSize,
        pageToken,
        personFields: fields,
        sortOrder: 'LAST_MODIFIED_ASCENDING',
      });

      const list = (r.data.connections || []).map(p => ({
        name: (p.names && p.names[0] && p.names[0].displayName) || '',
        givenName: (p.names && p.names[0] && p.names[0].givenName) || '',
        familyName: (p.names && p.names[0] && p.names[0].familyName) || '',
        email: (p.emailAddresses && p.emailAddresses[0] && p.emailAddresses[0].value) || '',
        phone: (p.phoneNumbers && p.phoneNumbers[0] && (p.phoneNumbers[0].value || p.phoneNumbers[0].formattedValue)) || '',
        organization: (p.organizations && p.organizations[0] && p.organizations[0].name) || '',
        jobTitle: (p.organizations && p.organizations[0] && p.organizations[0].title) || '',
        labels: (p.memberships || []).map(m => (m.contactGroupMembership && m.contactGroupMembership.contactGroupId) || (m.contactGroupMembership && m.contactGroupMembership.contactGroupResourceName) || '').filter(Boolean),
        photoUrl: (p.photos && p.photos[0] && p.photos[0].url) || '',
      }));

      res.json({ ok:true, count: list.length, nextPageToken: r.data.nextPageToken || null, contacts: list });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // Gmail labels (requires domain-wide delegation + impersonation)
  app.post('/api/google/test/gmail', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      let creds = b.service_account_json || process.env.GOOGLE_SERVICE_ACCOUNT_JSON || null;
      if (typeof creds === 'string' && creds.trim()) { try { creds = JSON.parse(creds); } catch {} }
      if (!creds || typeof creds !== 'object') return res.status(400).json({ ok:false, error:'missing_credentials' });
      const subject = (b.impersonate || process.env.GOOGLE_IMPERSONATE_USER || '').trim();
      if (!subject) return res.status(400).json({ ok:false, error:'impersonate_required', message:'Provide impersonate email (Workspace) and enable domain-wide delegation.' });
      const scopesRaw = String(b.scopes || 'https://www.googleapis.com/auth/gmail.readonly');
      const scopes = scopesRaw.split(/\s+/).filter(Boolean);
      const client = new google.auth.JWT({ email: creds.client_email, key: creds.private_key, scopes, subject });
      const gmail = google.gmail({ version: 'v1', auth: client });
      const r = await gmail.users.labels.list({ userId: 'me' });
      const labels = (r.data.labels || []).map(l => ({ id: l.id, name: l.name, type: l.type }));
      res.json({ ok:true, count: labels.length, labels });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Calendar upcoming events (requires impersonation or a shared calendar)
  app.post('/api/google/test/calendar', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      let creds = b.service_account_json || process.env.GOOGLE_SERVICE_ACCOUNT_JSON || null;
      if (typeof creds === 'string' && creds.trim()) { try { creds = JSON.parse(creds); } catch {} }
      if (!creds || typeof creds !== 'object') return res.status(400).json({ ok:false, error:'missing_credentials' });
      const subject = (b.impersonate || process.env.GOOGLE_IMPERSONATE_USER || '').trim() || undefined;
      const scopesRaw = String(b.scopes || 'https://www.googleapis.com/auth/calendar.readonly');
      const scopes = scopesRaw.split(/\s+/).filter(Boolean);
      const client = new google.auth.JWT({ email: creds.client_email, key: creds.private_key, scopes, subject });
      const calendar = google.calendar({ version: 'v3', auth: client });
      const now = new Date().toISOString();
      const r = await calendar.events.list({ calendarId: 'primary', timeMin: now, maxResults: 5, singleEvents: true, orderBy: 'startTime' });
      const items = (r.data.items || []).map(ev => ({ id: ev.id, summary: ev.summary || '', start: ev.start, end: ev.end }));
      res.json({ ok:true, count: items.length, events: items });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // People API contacts list (requires impersonation)
  app.post('/api/google/test/people', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      let creds = b.service_account_json || process.env.GOOGLE_SERVICE_ACCOUNT_JSON || null;
      if (typeof creds === 'string' && creds.trim()) { try { creds = JSON.parse(creds); } catch {} }
      if (!creds || typeof creds !== 'object') return res.status(400).json({ ok:false, error:'missing_credentials' });
      const subject = (b.impersonate || process.env.GOOGLE_IMPERSONATE_USER || '').trim();
      if (!subject) return res.status(400).json({ ok:false, error:'impersonate_required', message:'Provide impersonate email (Workspace) and enable domain-wide delegation.' });
      const scopesRaw = String(b.scopes || 'https://www.googleapis.com/auth/contacts.readonly');
      const scopes = scopesRaw.split(/\s+/).filter(Boolean);
      const client = new google.auth.JWT({ email: creds.client_email, key: creds.private_key, scopes, subject });
      const people = google.people({ version: 'v1', auth: client });
      const r = await people.people.connections.list({ resourceName: 'people/me', pageSize: 5, personFields: 'names,emailAddresses' });
      const list = (r.data.connections || []).map(p => ({
        name: (p.names && p.names[0] && p.names[0].displayName) || '',
        email: (p.emailAddresses && p.emailAddresses[0] && p.emailAddresses[0].value) || '',
      }));
      res.json({ ok:true, count: list.length, contacts: list });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

    // ---- Local Prompts CRUD (deprecated; use prompt_config instead) ----
  app.get('/api/local-prompts', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    return res.status(410).json({ ok:false, error:'gone', message:'local_prompt is deprecated; use /api/prompt-configs' });
  });
  app.post('/api/local-prompts', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    return res.status(410).json({ ok:false, error:'gone', message:'local_prompt is deprecated; use /api/prompt-configs' });
  });
  app.get('/api/local-prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    return res.status(410).json({ ok:false, error:'gone', message:'local_prompt is deprecated; use /api/prompt-configs/:id' });
  });
  app.patch('/api/local-prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    return res.status(410).json({ ok:false, error:'gone', message:'local_prompt is deprecated; use /api/prompt-configs/:id' });
  });
 

  // MCP server status (dev-prestashop)
  app.get('/api/local-prompts/mcp/dev-prestashop', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      let httpBase = (getMcpDevPrestaPublicBase() || '').trim();
      let wsUrl = '';
      if (httpBase) {
        try { const u = new URL(httpBase); const wsScheme = u.protocol === 'https:' ? 'wss:' : 'ws:'; wsUrl = `${wsScheme}//${u.host}/mcp-dev-prestashop/ws`; httpBase = `${u.protocol}//${u.host}`; } catch { httpBase = ''; }
      }
      if (!httpBase) {
        const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
        const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
        const proto = (fproto || req.protocol || 'http').toLowerCase();
        const host = (fhost || req.headers.host || 'localhost').trim();
        httpBase = `${proto}://${host}`;
        const wsScheme = proto === 'https' ? 'wss' : 'ws';
        wsUrl = `${wsScheme}://${host}/mcp-dev-prestashop/ws`;
      }
      const enabled = getMcpDevPrestaEnabled();
      const token = getMcpDevPrestaToken() || null;
      res.json({ ok:true, kind:'mcp-dev-prestashop', httpBase, wsUrl, enabled, token });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // Delete
  app.delete('/api/local-prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    return res.status(410).json({ ok:false, error:'gone', message:'local_prompt is deprecated; delete prompt via /api/prompt-configs' });
  });

  // ---- Prompt Configs (canonical local prompts) CRUD + Assignments ----
  app.get('/api/prompt-configs', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      await ensurePromptModelColumn();
      const r = await pool.query(`SELECT id, name, dev_message, messages, tools, openai_api_key, prompt_id, prompt_version, model, vector_store_id, vector_store_ids, created_at, updated_at FROM prompt_config ORDER BY updated_at DESC`);
      return res.json({ ok:true, items: r.rows });
    } catch (e) { try { logToFile(`[PROMPT_CONFIGS_LIST_ERR] code=${e?.code||''} msg=${e?.message||e}`); } catch {} return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/prompt-configs', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      await ensurePromptModelColumn();
      const b = req.body || {};
      const id = makeLocalPromptId();
      const name = String(b.name || '').trim();
      if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });
      const dev_message = (typeof b.dev_message === 'string' && b.dev_message) ? b.dev_message : null;
      // Sanitize messages/tools to valid JSON values
      let messages = null;
      try {
        const mv = b.messages;
        if (Array.isArray(mv)) messages = mv;
        else if (typeof mv === 'string' && mv.trim()) {
          const parsed = JSON.parse(mv);
          messages = Array.isArray(parsed) ? parsed : null;
        }
      } catch {}
      let tools = null;
      try {
        const tv = b.tools;
        if (tv && typeof tv === 'object' && !Array.isArray(tv)) tools = tv;
        else if (typeof tv === 'string' && tv.trim()) {
          const parsed = JSON.parse(tv);
          tools = (parsed && typeof parsed === 'object' && !Array.isArray(parsed)) ? parsed : null;
        }
      } catch {}
      // Force JSON strings for ::json casts and log
      const messagesJson = messages != null ? JSON.stringify(messages) : null;
      const toolsJson = tools != null ? JSON.stringify(tools) : null;
      try { logToFile(`[PROMPT_CONFIG_CREATE] id=${id} name=${name} messagesType=${Array.isArray(messages)?'array':(messages===null?'null':typeof messages)} toolsKeys=${tools?Object.keys(tools).join(','):''}`); } catch {}
      const openai_api_key = (typeof b.openai_api_key === 'string' && b.openai_api_key) ? b.openai_api_key : null;
      const prompt_id = (typeof b.prompt_id === 'string' && b.prompt_id) ? b.prompt_id : null;
      const prompt_version = (typeof b.prompt_version === 'string' && b.prompt_version) ? b.prompt_version : null;
      const model = (typeof b.model === 'string' && b.model) ? b.model : null;
      // Ensure multi-vector column exists
      try { await pool.query(`ALTER TABLE prompt_config ADD COLUMN IF NOT EXISTS vector_store_ids JSON`); } catch {}
      const r = await pool.query(
        `INSERT INTO prompt_config (id, name, dev_message, messages, tools, openai_api_key, prompt_id, prompt_version, model, vector_store_id, vector_store_ids, created_at, updated_at)
         VALUES ($1,$2,$3,$4::json,$5::json,$6,$7,$8,$9,$10,$11::json,NOW(),NOW())
         RETURNING id, name, dev_message, messages, tools, openai_api_key, prompt_id, prompt_version, model, vector_store_id, vector_store_ids, created_at, updated_at`,
        [id, name, dev_message, messagesJson, toolsJson, openai_api_key, prompt_id, prompt_version, model, null, JSON.stringify([])]
      );
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { try { logToFile(`[PROMPT_CONFIG_UPDATE_ERR] id=${id} code=${e?.code||''} msg=${e?.message||e}`); } catch {} return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.get('/api/prompt-configs/:id', async (req, res) => {
    const u = requireAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      await ensurePromptVectorIdsColumn();
      await ensurePromptModelColumn();
      const id = String(req.params.id || '').trim();
      const r = await pool.query(`SELECT id, name, dev_message, messages, tools, openai_api_key, prompt_id, prompt_version, model, vector_store_id, vector_store_ids, created_at, updated_at FROM prompt_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Available MCP tools (unfiltered) for admin UIs
  app.get('/api/admin/mcp/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const list = MCP.tools?.() || [];
      const tools = list.map((t) => {
        const schema = t.inputSchema || t.input_schema || { type: 'object' };
        return { name: t.name, description: t.description, inputSchema: schema };
      });
      res.json({ ok: true, tools });
    } catch (e) {
      res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
    }
  });

  // ================= MCP Server Config (CRUD) ==================
  app.get('/api/mcp-servers', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const r = await pool.query(`SELECT id, name, kind, group_id, http_base, ws_url, stream_url, sse_url, token, enabled, notes, server_type, options, created_at, updated_at FROM mcp_server_config ORDER BY updated_at DESC`);
      return res.json({ ok:true, items: r.rows });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/mcp-servers', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const b = req.body || {};
      const id = makeMcpServerId();
      const name = String(b.name || '').trim();
      if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });
      const kind = (typeof b.kind === 'string' && b.kind.trim()) || null;
      let group_id = (typeof b.group_id === 'string' && b.group_id.trim()) || null;
      const group_name = (typeof b.group_name === 'string' && b.group_name.trim()) || '';
      const http_base = (typeof b.http_base === 'string' && b.http_base.trim()) || null;
      const ws_url = (typeof b.ws_url === 'string' && b.ws_url.trim()) || null;
      const stream_url = (typeof b.stream_url === 'string' && b.stream_url.trim()) || null;
      const sse_url = (typeof b.sse_url === 'string' && b.sse_url.trim()) || null;
      let token = (typeof b.token === 'string' && b.token.trim()) || null;
      const enabled = !!b.enabled;
      const notes = (typeof b.notes === 'string' && b.notes) || null;
      const server_type = (typeof b.server_type === 'string' && b.server_type.trim()) || null;
      let options = null;
      try {
        if (b.options && typeof b.options === 'object' && !Array.isArray(b.options)) options = b.options;
        else if (typeof b.options === 'string' && b.options.trim()) options = JSON.parse(b.options);
      } catch {}
      if (!group_id && group_name) {
        const gid = makeMcpGroupId();
        await pool.query(`INSERT INTO mcp_group (id, name, description, created_at, updated_at) VALUES ($1,$2,NULL,NOW(),NOW()) ON CONFLICT (name) DO NOTHING`, [gid, group_name]);
        const rG = await pool.query(`SELECT id FROM mcp_group WHERE name=$1 LIMIT 1`, [group_name]);
        group_id = rG.rowCount ? rG.rows[0].id : gid;
      }
      // Base name used for auto-label; persist in options.name_base (and group_name)
      const name_base = String(name);
      // Ensure group_name in options for labeling
      let groupNameLabel = '';
      if (group_id && !group_name) {
        try { const g = await pool.query(`SELECT name FROM mcp_group WHERE id=$1 LIMIT 1`, [group_id]); if (g.rowCount) groupNameLabel = g.rows[0].name || ''; } catch {}
      } else if (group_name) {
        groupNameLabel = group_name;
      }
      const optionsWithBase = { ...(options || {}), name_base, ...(groupNameLabel ? { group_name: groupNameLabel } : {}) };
      // Compute final display name; never include group name in the server name
      const finalName = server_type ? buildMcpServerDisplayName(name_base, server_type, optionsWithBase, groupNameLabel) : name_base;
      if (!token) { try { token = crypto.randomBytes(24).toString('hex'); } catch {} }
      const r = await pool.query(
        `INSERT INTO mcp_server_config (id, name, kind, group_id, http_base, ws_url, stream_url, sse_url, token, enabled, notes, server_type, options, created_at, updated_at)
         VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13::json,NOW(),NOW())
         RETURNING id, name, kind, group_id, http_base, ws_url, stream_url, sse_url, token, enabled, notes, server_type, options, created_at, updated_at`,
        [id, finalName, kind, group_id, http_base, ws_url, stream_url, sse_url, token, enabled, notes, server_type, JSON.stringify(optionsWithBase)]
      );
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.get('/api/mcp-servers/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      const r = await pool.query(`SELECT id, name, kind, group_id, http_base, ws_url, stream_url, sse_url, token, enabled, notes, server_type, options, created_at, updated_at FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.patch('/api/mcp-servers/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      const b = req.body || {};
      const allowed = ['name','kind','group_id','http_base','ws_url','stream_url','sse_url','token','enabled','notes','server_type','options','auto_label','group_name'];
      const entries0 = Object.entries(b).filter(([k]) => allowed.includes(k));
      // Normalize options to JSON string for ::json cast
      const entries = entries0.map(([k,v]) => {
        if (k === 'options') {
          try {
            if (v && typeof v === 'object' && !Array.isArray(v)) return [k, JSON.stringify(v)];
            if (typeof v === 'string' && v.trim()) { JSON.parse(v); return [k, v]; }
            return [k, null];
          } catch { return [k, null]; }
        }
        return [k, v];
      });
      if (!entries.length) return res.status(400).json({ ok:false, error:'bad_request' });

      // Load current row to compute auto label if needed
      const curQ = await pool.query(`SELECT name, server_type, group_id, options FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      const cur = curQ.rowCount ? curQ.rows[0] : null;
      let curOpts = {};
      try { curOpts = (cur && cur.options && typeof cur.options === 'object') ? cur.options : (cur?.options ? JSON.parse(cur.options) : {}); } catch { curOpts = {}; }
      const willChangeType = entries.some(([k]) => k === 'server_type');
      const willChangeOptions = entries.some(([k]) => k === 'options');
      const providedName = entries.find(([k]) => k === 'name')?.[1];
      const autoLabel = String(b.auto_label ?? '').toLowerCase() === 'true' || b.auto_label === true;

      // Merge options object when provided as JSON string for name_base updates
      let nextOptionsObj = { ...curOpts };
      const optionsEntry = entries.find(([k]) => k === 'options');
      if (optionsEntry) {
        try { nextOptionsObj = JSON.parse(optionsEntry[1] || '{}'); } catch { nextOptionsObj = {}; }
      }

      // Ensure group exists when group_name provided
      let groupIdEff = b.group_id || undefined;
      if (!groupIdEff && b.group_name && String(b.group_name).trim()) {
        const gn = String(b.group_name).trim();
        const gid = makeMcpGroupId();
        await pool.query(`INSERT INTO mcp_group (id, name, description, created_at, updated_at) VALUES ($1,$2,NULL,NOW(),NOW()) ON CONFLICT (name) DO NOTHING`, [gid, gn]);
        const rG = await pool.query(`SELECT id FROM mcp_group WHERE name=$1 LIMIT 1`, [gn]);
        groupIdEff = rG.rowCount ? rG.rows[0].id : gid;
      }

      // Decide new name (without group label)
      let nextName = providedName !== undefined ? String(providedName) : undefined;
      const baseName = (nextOptionsObj.name_base || curOpts.name_base || cur?.name || '').toString();
      const typeEffective = (willChangeType ? (b.server_type || cur?.server_type) : cur?.server_type) || '';
      let groupNameLabel = '';
      // Prefer newly provided group_name; else fetch by final group_id; else by current group_id
      const groupEntry = entries.find(([k]) => k === 'group_id');
      const groupIdCandidate = groupIdEff !== undefined ? groupIdEff : (groupEntry ? groupEntry[1] : cur?.group_id);
      if (b.group_name && String(b.group_name).trim()) {
        groupNameLabel = String(b.group_name).trim();
      } else if (groupIdCandidate) {
        try { const rG2 = await pool.query(`SELECT name FROM mcp_group WHERE id=$1 LIMIT 1`, [groupIdCandidate]); if (rG2.rowCount) groupNameLabel = rG2.rows[0].name || ''; } catch {}
      }
      // Keep server name stable unless explicitly requested via auto_label
      if (autoLabel && baseName) {
        const computed = buildMcpServerDisplayName(baseName, typeEffective, nextOptionsObj, groupNameLabel);
        nextName = computed;
      } else if (providedName) {
        // Update name_base when user explicitly sets a new base name
        nextOptionsObj.name_base = providedName;
      }

      // Rebuild entries/sets/vals including computed name/options
      const groupIdFinal = (groupIdEff !== undefined) ? groupIdEff : groupIdCandidate;
      const effEntries = entries.filter(([k]) => !['auto_label','name','options','group_name','group_id'].includes(k));
      if (nextName !== undefined) effEntries.push(['name', nextName]);
      if (groupIdFinal !== undefined) effEntries.push(['group_id', groupIdFinal || null]);
      effEntries.push(['options', JSON.stringify(nextOptionsObj)]);
      const sets = effEntries.map(([k], i) => (k === 'options' ? `${k} = $${i + 1}::json` : `${k} = $${i + 1}`));
      const vals = effEntries.map(([, v]) => v);
      sets.push('updated_at = NOW()');
      const r = await pool.query(`UPDATE mcp_server_config SET ${sets.join(', ')} WHERE id = $${vals.length + 1}
        RETURNING id, name, kind, group_id, http_base, ws_url, stream_url, sse_url, token, enabled, notes, server_type, options, created_at, updated_at`, [...vals, id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.delete('/api/mcp-servers/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      await pool.query(`DELETE FROM mcp_server_config WHERE id=$1`, [id]);
      return res.json({ ok:true });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Tokens per MCP server (regenerate/disable/get)
  app.get('/api/mcp-servers/:id/token', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { const id = String(req.params.id||'').trim(); const r = await pool.query(`SELECT token FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]); if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' }); return res.json({ ok:true, token: r.rows[0].token || '' }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/mcp-servers/:id/token/regenerate', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { const id = String(req.params.id||'').trim(); const tok = crypto.randomBytes(24).toString('hex'); await pool.query(`UPDATE mcp_server_config SET token=$1, updated_at=NOW() WHERE id=$2`, [tok, id]); return res.json({ ok:true, token: tok }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/mcp-servers/:id/token/disable', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { const id = String(req.params.id||'').trim(); await pool.query(`UPDATE mcp_server_config SET token=NULL, updated_at=NOW() WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // ================= MCP2 Server Config (CRUD) ==================
  // Kinds
  app.get('/api/mcp2/kinds', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const r = await pool.query(`SELECT id, code, name, description, org_id, created_at, updated_at FROM mcp2_kind ORDER BY lower(code)`); return res.json({ ok:true, items: r.rows }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/kinds', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const b = req.body || {};
      const id = makeMcp2KindId();
      const code = String(b.code||'').trim(); if (!code) return res.status(400).json({ ok:false, error:'bad_request', message:'code required' });
      const name = String(b.name||'').trim() || code;
      const description = (typeof b.description==='string' && b.description) ? b.description : null;
      const r = await pool.query(`INSERT INTO mcp2_kind (id, code, name, description, created_at, updated_at) VALUES ($1,$2,$3,$4,NOW(),NOW()) RETURNING id, code, name, description, created_at, updated_at`, [id, code, name, description]);
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.patch('/api/mcp2/kinds/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const allowed = new Set(['code','name','description','org_id']);
      const b = req.body || {};
      const ent = Object.entries(b).filter(([k]) => allowed.has(k));
      if (!ent.length) return res.status(400).json({ ok:false, error:'bad_request', message:'no valid fields' });
      const sets = ent.map(([k],i)=> `${k} = $${i+1}`);
      const vals = ent.map(([,v])=> v);
      sets.push('updated_at = NOW()');
      try {
        const r = await pool.query(`UPDATE mcp2_kind SET ${sets.join(', ')} WHERE id=$${vals.length+1} RETURNING id, code, name, description, created_at, updated_at`, [...vals, id]);
        if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
        return res.json({ ok:true, item: r.rows[0] });
      } catch (e) {
        if (e && e.code === '23505') return res.status(409).json({ ok:false, error:'conflict', message:'code already exists' });
        throw e;
      }
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.delete('/api/mcp2/kinds/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`DELETE FROM mcp2_kind WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Types
  app.get('/api/mcp2/types', async (req, res) => {
    if (!requireAdminEither(req, res)) return;
    try { await ensureTables(); const r = await pool.query(`SELECT id, code, name, description, org_id, created_at, updated_at FROM mcp2_type ORDER BY lower(code)`); return res.json({ ok:true, items: r.rows }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  // Known option schemas keyed by type code
  app.get('/api/mcp2/type-schemas', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { return res.json({ ok:true, items: MCP2_TYPE_SCHEMAS }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/types', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const b = req.body || {};
      const id = makeMcp2TypeId();
      const code = String(b.code||'').trim(); if (!code) return res.status(400).json({ ok:false, error:'bad_request', message:'code required' });
      const name = String(b.name||'').trim() || code;
      const description = (typeof b.description==='string' && b.description) ? b.description : null;
      const r = await pool.query(`INSERT INTO mcp2_type (id, code, name, description, created_at, updated_at) VALUES ($1,$2,$3,$4,NOW(),NOW()) RETURNING id, code, name, description, created_at, updated_at`, [id, code, name, description]);
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.patch('/api/mcp2/types/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const allowed = new Set(['code','name','description','tool_prefix','org_id']);
      const b = req.body || {};
      const ent = Object.entries(b).filter(([k]) => allowed.has(k));
      if (!ent.length) return res.status(400).json({ ok:false, error:'bad_request', message:'no valid fields' });
      const sets = ent.map(([k],i)=> `${k} = $${i+1}`);
      const vals = ent.map(([,v])=> v);
      sets.push('updated_at = NOW()');
      try {
        const r = await pool.query(`UPDATE mcp2_type SET ${sets.join(', ')} WHERE id=$${vals.length+1} RETURNING id, code, name, description, tool_prefix, created_at, updated_at`, [...vals, id]);
        if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
        return res.json({ ok:true, item: r.rows[0] });
      } catch (e) {
        if (e && e.code === '23505') return res.status(409).json({ ok:false, error:'conflict', message:'code already exists' });
        throw e;
      }
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.delete('/api/mcp2/types/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`DELETE FROM mcp2_type WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Servers
  app.get('/api/mcp2/servers', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const r = await pool.query(`SELECT id, name, kind_id, type_id, http_base, ws_url, stream_url, sse_url, token, enabled, options, notes, org_id, created_at, updated_at FROM mcp2_server ORDER BY updated_at DESC`);
      return res.json({ ok:true, items: r.rows });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/servers', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const b = req.body || {};
      const id = makeMcp2ServerId();
      const name = String(b.name||'').trim(); if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });
      const kind_id = (typeof b.kind_id==='string' && b.kind_id.trim()) || null;
      const type_id = (typeof b.type_id==='string' && b.type_id.trim()) || null;
      let http_base = (typeof b.http_base==='string' && b.http_base.trim()) || null;
      if (!http_base) {
        try { http_base = process.env.HA_BASE_URL || 'https://chat.piscinesondespro.fr'; } catch { http_base = 'https://chat.piscinesondespro.fr'; }
      }
      let ws_url = (typeof b.ws_url==='string' && b.ws_url.trim()) || null;
      let stream_url = (typeof b.stream_url==='string' && b.stream_url.trim()) || null;
      let sse_url = (typeof b.sse_url==='string' && b.sse_url.trim()) || null;
      // Auto-derive endpoints from base+name if missing
      try {
        if (!ws_url || !stream_url || !sse_url) {
          const d = deriveMcp2Endpoints(http_base, name);
          ws_url = ws_url || d.ws_url || null;
          stream_url = stream_url || d.stream_url || null;
          sse_url = sse_url || d.sse_url || null;
        }
      } catch {}
      const token = (typeof b.token==='string' && b.token.trim()) || null;
      const enabled = !!b.enabled;
      const notes = (typeof b.notes==='string' && b.notes) || null;
      let options = null; try { if (b.options && typeof b.options==='object' && !Array.isArray(b.options)) options = b.options; else if (typeof b.options==='string' && b.options.trim()) options = JSON.parse(b.options); } catch {}
      // Validate type-specific options
      try {
        if (type_id && options && options.type_config && options.type_config.values) {
          let typeCode = String(options.type_config.code||'').trim();
          if (!typeCode) typeCode = await getMcp2TypeCodeById(type_id);
          const check = validateTypeOptions(typeCode, options.type_config.values);
          if (!check.ok) return res.status(400).json({ ok:false, error: check.error || 'invalid_options', fields: check.fields || [] });
          options.type_config.code = typeCode;
        }
      } catch {}
      const r = await pool.query(
        `INSERT INTO mcp2_server (id, name, kind_id, type_id, http_base, ws_url, stream_url, sse_url, token, enabled, options, notes, created_at, updated_at)
         VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11::json,$12,NOW(),NOW())
         RETURNING id, name, kind_id, type_id, http_base, ws_url, stream_url, sse_url, token, enabled, options, notes, created_at, updated_at`,
        [id, name, kind_id, type_id, http_base, ws_url, stream_url, sse_url, token, enabled, options ? JSON.stringify(options) : null, notes]
      );
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.patch('/api/mcp2/servers/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const allowed = new Set(['name','kind_id','type_id','http_base','ws_url','stream_url','sse_url','token','enabled','options','notes','org_id']);
      const b = req.body || {};
      const entries = Object.entries(b).filter(([k]) => allowed.has(k));
      const eff = entries.map(([k,v]) => k === 'options' && v != null ? [k, JSON.stringify(typeof v==='string'?JSON.parse(v):v)] : [k, v]);
      if (!eff.length) return res.status(400).json({ ok:false, error:'bad_request', message:'no valid fields' });
      const sets = eff.map(([k],i)=> (k==='options'?`${k} = $${i+1}::json`:`${k} = $${i+1}`));
      const vals = eff.map(([,v])=> v);
      sets.push('updated_at = NOW()');
      // Validate type-specific options if present
      try {
        const typeId = (b.type_id && String(b.type_id).trim()) || null;
        let typeCode = '';
        if (typeId) typeCode = await getMcp2TypeCodeById(typeId);
        else {
          // If not provided, try to resolve from current row
          try { const cur = await pool.query(`SELECT type_id FROM mcp2_server WHERE id=$1 LIMIT 1`, [id]); if (cur.rowCount && cur.rows[0].type_id) typeCode = await getMcp2TypeCodeById(cur.rows[0].type_id); } catch {}
        }
        let optsRaw = null; try { optsRaw = b.options ? (typeof b.options==='string' ? JSON.parse(b.options) : b.options) : null; } catch {}
        if (typeCode && optsRaw && optsRaw.type_config && optsRaw.type_config.values) {
          const check = validateTypeOptions(typeCode, optsRaw.type_config.values);
          if (!check.ok) return res.status(400).json({ ok:false, error: check.error || 'invalid_options', fields: check.fields || [] });
          // Ensure code stored
          optsRaw.type_config.code = typeCode;
          // Replace options entry in the update arrays
          const idx = eff.findIndex(([k]) => k === 'options');
          if (idx >= 0) {
            eff[idx] = ['options', JSON.stringify(optsRaw)];
            const sidx = sets.findIndex((s) => s.startsWith('options = '));
            if (sidx >= 0) sets[sidx] = 'options = $' + (idx + 1) + '::json';
            vals[idx] = JSON.stringify(optsRaw);
          }
        }
      } catch {}

      const r = await pool.query(`UPDATE mcp2_server SET ${sets.join(', ')} WHERE id=$${vals.length+1} RETURNING id, name, kind_id, type_id, http_base, ws_url, stream_url, sse_url, token, enabled, options, notes, created_at, updated_at`, [...vals, id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.delete('/api/mcp2/servers/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`DELETE FROM mcp2_server WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // MCP2 tokens (get/regenerate/disable)
  app.get('/api/mcp2/servers/:id/token', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); const r = await pool.query(`SELECT token FROM mcp2_server WHERE id=$1 LIMIT 1`, [id]); if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' }); return res.json({ ok:true, token: r.rows[0].token || '' }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/servers/:id/token/regenerate', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); const tok = crypto.randomBytes(24).toString('hex'); await pool.query(`UPDATE mcp2_server SET token=$1, updated_at=NOW() WHERE id=$2`, [tok, id]); return res.json({ ok:true, token: tok }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/servers/:id/token/disable', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`UPDATE mcp2_server SET token=NULL, updated_at=NOW() WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Seed default tools for a server based on its type
  app.post('/api/mcp2/servers/:id/tools/seed-defaults', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const r = await pool.query(`SELECT type_id, name FROM mcp2_server WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const typeId = r.rows[0].type_id || '';
      let typeCode = await getMcp2TypeCodeById(typeId);
      typeCode = String(typeCode||'').toLowerCase();
      // Normalization for known codes
      if (typeCode === 'api_prestashop' || typeCode === 'prestashop_api') typeCode = 'api_prestashop';
      if (!typeCode) return res.status(400).json({ ok:false, error:'unknown_type' });
      // 1) Prefer DB-registered defaults via mcp2_type_tool
      const mt = await pool.query(`
        SELECT t.id, t.name, t.description, t.input_schema, t.code, t.version, x.default_enabled
          FROM mcp2_type_tool x
          JOIN mcp2_tool t ON t.id = x.tool_id
         WHERE x.type_id = $1
      `, [typeId]);
      let inserted = 0; const created = [];
      if (mt.rowCount) {
        for (const row of mt.rows) {
          try {
            const sid = makeMcp2ToolId();
            // Name with prefix if any
            let prefix = '';
            try { const qp = await pool.query(`SELECT t.tool_prefix FROM mcp2_server s LEFT JOIN mcp2_type t ON t.id = s.type_id WHERE s.id=$1 LIMIT 1`, [id]); if (qp.rowCount) prefix = qp.rows[0].tool_prefix || ''; } catch {}
            const attachName = (prefix ? String(prefix) : '') + String(row.name || '');
            const q = await pool.query(`
              INSERT INTO mcp2_server_tool (id, server_id, tool_id, name, enabled, version, created_at, updated_at)
              VALUES ($1,$2,$3,$4,$5,$6,NOW(),NOW())
              ON CONFLICT (server_id, name) DO NOTHING
              RETURNING id
            `, [sid, id, row.id, attachName || null, row.default_enabled!==false, Number(row.version)||1]);
            if (q.rowCount) { inserted++; created.push(q.rows[0]); }
          } catch {}
        }
        return res.json({ ok:true, inserted, items: created });
      }
      // 2) Fallback to built-in templates, register to catalog and map
      const defs = MCP2_TYPE_DEFAULT_TOOLS[typeCode] || [];
      for (const t of defs) {
        try {
          // Upsert into catalog
          const tid = makeMcp2ToolId();
          await pool.query(`INSERT INTO mcp2_tool (id, name, description, input_schema, code, version, created_at, updated_at)
                            VALUES ($1,$2,$3,$4::json,$5::json,$6,NOW(),NOW())
                            ON CONFLICT (name) DO NOTHING`,
            [tid, t.name, t.description||null, JSON.stringify(t.input_schema||{}), JSON.stringify(t.code||{}), Number(t.version)||1]);
          const rid = await pool.query(`SELECT id FROM mcp2_tool WHERE name=$1 LIMIT 1`, [t.name]);
          const toolId = rid.rowCount ? rid.rows[0].id : tid;
          // Map to type
          await pool.query(`INSERT INTO mcp2_type_tool (type_id, tool_id, default_enabled, created_at)
                            VALUES ($1,$2,$3,NOW()) ON CONFLICT (type_id, tool_id) DO NOTHING`,
            [typeId, toolId, t.enabled!==false]);
          // Attach to server
          const sid = makeMcp2ToolId();
          let prefix = '';
          try { const qp = await pool.query(`SELECT t.tool_prefix FROM mcp2_server s LEFT JOIN mcp2_type t ON t.id = s.type_id WHERE s.id=$1 LIMIT 1`, [id]); if (qp.rowCount) prefix = qp.rows[0].tool_prefix || ''; } catch {}
          const attachName = (prefix ? String(prefix) : '') + String(t.name || '');
          const q = await pool.query(`INSERT INTO mcp2_server_tool (id, server_id, tool_id, name, enabled, version, created_at, updated_at)
                                      VALUES ($1,$2,$3,$4,$5,$6,NOW(),NOW())
                                      ON CONFLICT (server_id, name) DO NOTHING
                                      RETURNING id`,
            [sid, id, toolId, attachName || null, t.enabled!==false, Number(t.version)||1]);
          if (q.rowCount) inserted++;
        } catch {}
      }
      return res.json({ ok:true, inserted });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // ================= MCP2 Catalog Tools (CRUD) ==================
  app.get('/api/mcp2/catalog/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const r = await pool.query(`SELECT id, name, description, input_schema, code, version, created_at, updated_at FROM mcp2_tool ORDER BY name`);
      return res.json({ ok:true, items: r.rows });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
  });
  app.post('/api/mcp2/catalog/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const b = req.body || {};
      const id = makeMcp2ToolId();
      const name = String(b.name||'').trim(); if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });
      const description = (typeof b.description==='string' && b.description) ? b.description : null;
      let input_schema = null; try { if (b.input_schema && typeof b.input_schema==='object' && !Array.isArray(b.input_schema)) input_schema=b.input_schema; else if (typeof b.input_schema==='string' && b.input_schema.trim()) input_schema=JSON.parse(b.input_schema); } catch {}
      let code = null; try { if (b.code && typeof b.code==='object' && !Array.isArray(b.code)) code=b.code; else if (typeof b.code==='string' && b.code.trim()) code=JSON.parse(b.code); } catch {}
      const version = Number.isFinite(Number(b.version)) ? Number(b.version) : 1;
      const r = await pool.query(
        `INSERT INTO mcp2_tool (id, name, description, input_schema, code, version, created_at, updated_at)
         VALUES ($1,$2,$3,$4::json,$5::json,$6,NOW(),NOW())
         RETURNING id, name, description, input_schema, code, version, created_at, updated_at`,
        [id, name, description, input_schema?JSON.stringify(input_schema):null, code?JSON.stringify(code):null, version]
      );
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
  });
  app.patch('/api/mcp2/catalog/tools/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const allowed = new Set(['name','description','input_schema','code','version']);
      const b = req.body || {};
      const ent = Object.entries(b).filter(([k]) => allowed.has(k)).map(([k,v]) => (k==='input_schema'||k==='code') && v!=null ? [k, JSON.stringify(typeof v==='string'?JSON.parse(v):v)] : [k,v]);
      if (!ent.length) return res.status(400).json({ ok:false, error:'bad_request' });
      const sets = ent.map(([k],i)=> ((k==='input_schema'||k==='code')?`${k} = $${i+1}::json`:`${k} = $${i+1}`));
      const vals = ent.map(([,v])=> v);
      sets.push('updated_at = NOW()');
      const r = await pool.query(`UPDATE mcp2_tool SET ${sets.join(', ')} WHERE id=$${vals.length+1} RETURNING id, name, description, input_schema, code, version, created_at, updated_at`, [...vals, id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.delete('/api/mcp2/catalog/tools/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`DELETE FROM mcp2_tool WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // ================= MCP2 Type Tool Mappings ==================
  app.get('/api/mcp2/types/:id/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const r = await pool.query(`
        SELECT x.type_id, x.tool_id, x.default_enabled,
               t.name, t.description, t.input_schema, t.code, t.version
          FROM mcp2_type_tool x
          JOIN mcp2_tool t ON t.id = x.tool_id
         WHERE x.type_id = $1
         ORDER BY t.name
      `, [id]);
      return res.json({ ok:true, items: r.rows });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/types/:id/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const typeId = String(req.params.id||'').trim();
      const toolId = String(req.body?.tool_id||'').trim();
      const def = !!req.body?.default_enabled;
      if (!typeId || !toolId) return res.status(400).json({ ok:false, error:'bad_request' });
      await pool.query(`INSERT INTO mcp2_type_tool (type_id, tool_id, default_enabled, created_at) VALUES ($1,$2,$3,NOW()) ON CONFLICT (type_id, tool_id) DO NOTHING`, [typeId, toolId, def]);
      return res.json({ ok:true });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.patch('/api/mcp2/types/:typeId/tools/:toolId', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const typeId=String(req.params.typeId||'').trim(); const toolId=String(req.params.toolId||'').trim(); const def = !!req.body?.default_enabled; await pool.query(`UPDATE mcp2_type_tool SET default_enabled=$1 WHERE type_id=$2 AND tool_id=$3`, [def, typeId, toolId]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.delete('/api/mcp2/types/:typeId/tools/:toolId', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const typeId=String(req.params.typeId||'').trim(); const toolId=String(req.params.toolId||'').trim(); await pool.query(`DELETE FROM mcp2_type_tool WHERE type_id=$1 AND tool_id=$2`, [typeId, toolId]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  // Alternate detach (POST) for environments blocking DELETE
  app.post('/api/mcp2/types/:typeId/tools/:toolId/detach', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const typeId=String(req.params.typeId||'').trim(); const toolId=String(req.params.toolId||'').trim(); await pool.query(`DELETE FROM mcp2_type_tool WHERE type_id=$1 AND tool_id=$2`, [typeId, toolId]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Bulk detach tools from a type
  app.post('/api/mcp2/types/:typeId/tools/detach', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const typeId = String(req.params.typeId||'').trim();
      const ids = Array.isArray(req.body?.tool_ids) ? req.body.tool_ids.map(String).filter(Boolean) : [];
      if (!typeId || ids.length === 0) return res.status(400).json({ ok:false, error:'bad_request' });
      let removed = 0;
      for (const tid of ids) {
        try { const r = await pool.query(`DELETE FROM mcp2_type_tool WHERE type_id=$1 AND tool_id=$2`, [typeId, tid]); removed += (r.rowCount||0); } catch {}
      }
      return res.json({ ok:true, removed });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Bulk attach catalog tools to a type by name prefix (family)
  app.post('/api/mcp2/types/:id/tools/attach-family', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const typeId = String(req.params.id||'').trim();
      const prefix = String(req.body?.prefix||'').trim();
      const def = req.body?.default_enabled === undefined ? true : !!req.body.default_enabled;
      if (!typeId || !prefix) return res.status(400).json({ ok:false, error:'bad_request', message:'prefix required' });
      const tools = await pool.query(`SELECT id FROM mcp2_tool WHERE name ILIKE $1`, [prefix.replace(/%/g,'') + '%']);
      let attached = 0;
      for (const row of (tools.rows||[])) {
        try {
          const r = await pool.query(`INSERT INTO mcp2_type_tool (type_id, tool_id, default_enabled, created_at) VALUES ($1,$2,$3,NOW()) ON CONFLICT (type_id, tool_id) DO NOTHING`, [typeId, row.id, def]);
          attached += (r.rowCount||0);
        } catch {}
      }
      return res.json({ ok:true, attached, total: tools.rowCount||0 });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Apply type tool_prefix to all server attachments of this type
  app.post('/api/mcp2/types/:id/attachments/apply-prefix', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const typeId = String(req.params.id||'').trim();
      const overwrite = !!req.body?.overwrite;
      const tr = await pool.query(`SELECT tool_prefix FROM mcp2_type WHERE id=$1 LIMIT 1`, [typeId]);
      if (!tr.rowCount) return res.status(404).json({ ok:false, error:'type_not_found' });
      const prefix = String(tr.rows[0].tool_prefix || '');
      if (!prefix) return res.status(400).json({ ok:false, error:'no_prefix' });
      // Find all server attachments for servers of this type with their catalog names
      const rows = await pool.query(`
        SELECT st.id, st.name AS current_name, ct.name AS catalog_name
          FROM mcp2_server_tool st
          JOIN mcp2_server s ON s.id = st.server_id
          LEFT JOIN mcp2_tool ct ON ct.id = st.tool_id
         WHERE s.type_id = $1
      `, [typeId]);
      let renamed = 0;
      for (const row of (rows.rows||[])) {
        const desired = prefix + String(row.catalog_name || '');
        const now = String(row.current_name || '');
        if (!overwrite) {
          if (now && now.startsWith(prefix)) continue; // keep existing prefixed names
        }
        try { const r = await pool.query(`UPDATE mcp2_server_tool SET name=$1, updated_at=NOW() WHERE id=$2`, [desired, row.id]); renamed += (r.rowCount||0); } catch {}
      }
      return res.json({ ok:true, renamed, count: rows.rowCount||0 });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Mark MCP2 server as tested/untested (stores flag in options JSON)
  app.post('/api/mcp2/servers/:id/mark-tested', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const r = await pool.query(`SELECT options FROM mcp2_server WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      let opt = r.rows[0].options; try { if (typeof opt === 'string') opt = JSON.parse(opt); } catch { opt = {}; }
      if (!opt || typeof opt !== 'object') opt = {};
      const nowIso = new Date().toISOString();
      opt.tested = true; opt.tested_at = nowIso;
      const up = await pool.query(`UPDATE mcp2_server SET options=$1::json, updated_at=NOW() WHERE id=$2 RETURNING id, name, kind_id, type_id, http_base, ws_url, stream_url, sse_url, token, enabled, options, notes, created_at, updated_at`, [JSON.stringify(opt), id]);
      return res.json({ ok:true, item: up.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/mcp2/servers/:id/mark-untested', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const r = await pool.query(`SELECT options FROM mcp2_server WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      let opt = r.rows[0].options; try { if (typeof opt === 'string') opt = JSON.parse(opt); } catch { opt = {}; }
      if (!opt || typeof opt !== 'object') opt = {};
      delete opt.tested; delete opt.tested_at;
      const up = await pool.query(`UPDATE mcp2_server SET options=$1::json, updated_at=NOW() WHERE id=$2 RETURNING id, name, kind_id, type_id, http_base, ws_url, stream_url, sse_url, token, enabled, options, notes, created_at, updated_at`, [JSON.stringify(opt), id]);
      return res.json({ ok:true, item: up.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Tools per MCP2 server
  app.get('/api/mcp2/servers/:id/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      // Join catalog when referenced
      const r = await pool.query(`
        SELECT st.id, st.server_id, st.tool_id, st.name, st.description, st.input_schema, st.code, st.enabled, st.version, st.created_at, st.updated_at,
               ct.name AS catalog_name, ct.description AS catalog_description, ct.input_schema AS catalog_input_schema, ct.code AS catalog_code, ct.version AS catalog_version
          FROM mcp2_server_tool st
          LEFT JOIN mcp2_tool ct ON ct.id = st.tool_id
         WHERE st.server_id=$1
         ORDER BY COALESCE(st.name, ct.name)
      `, [id]);
      const items = (r.rows||[]).map(row => {
        // Prefer explicit server overrides; else fall back to catalog for display
        const name = row.name || row.catalog_name || '';
        const description = row.description || row.catalog_description || null;
        const input_schema = row.input_schema || row.catalog_input_schema || null;
        const code = row.code || row.catalog_code || null;
        const version = row.version || row.catalog_version || 1;
        return { id: row.id, server_id: row.server_id, tool_id: row.tool_id || null, name, description, input_schema, code, enabled: row.enabled!==false, version, created_at: row.created_at, updated_at: row.updated_at };
      });
      return res.json({ ok:true, items });
    }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/servers/:id/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const serverId = String(req.params.id||'').trim();
      const b = req.body || {};
      const enabled = b.enabled !== false;
      const version = Number.isFinite(Number(b.version)) ? Number(b.version) : 1;
      const tool_id = (typeof b.tool_id==='string' && b.tool_id.trim()) || '';
      if (!tool_id) return res.status(400).json({ ok:false, error:'bad_request', message:'tool_id required (attach catalog tool)' });
      // Attach a catalog tool to this server
      const id = makeMcp2ToolId();
      // Apply optional type prefix to attachment name for uniqueness/readability
      let prefix = '';
      try { const q = await pool.query(`SELECT t.tool_prefix FROM mcp2_server s LEFT JOIN mcp2_type t ON t.id = s.type_id WHERE s.id=$1 LIMIT 1`, [serverId]); if (q.rowCount) prefix = q.rows[0].tool_prefix || ''; } catch {}
      let toolName = '';
      try { const q = await pool.query(`SELECT name FROM mcp2_tool WHERE id=$1 LIMIT 1`, [tool_id]); if (q.rowCount) toolName = q.rows[0].name || ''; } catch {}
      const attachName = (prefix ? String(prefix) : '') + String(toolName || '');
      const r = await pool.query(
        `INSERT INTO mcp2_server_tool (id, server_id, tool_id, name, enabled, version, created_at, updated_at)
         VALUES ($1,$2,$3,$4,$5,$6,NOW(),NOW())
         ON CONFLICT (server_id, name) DO NOTHING
         RETURNING id, server_id, tool_id, name, enabled, version, created_at, updated_at`,
        [id, serverId, tool_id, attachName || null, enabled, version]
      );
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.patch('/api/mcp2/tools/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      // Only toggle flags at server level; definitions live in catalog now
      const allowed = new Set(['enabled','version']);
      const b = req.body || {};
      const ent = Object.entries(b).filter(([k]) => allowed.has(k));
      if (!ent.length) return res.status(400).json({ ok:false, error:'bad_request', message:'no valid fields' });
      const sets = ent.map(([k],i)=> `${k} = $${i+1}`);
      const vals = ent.map(([,v])=> v);
      sets.push('updated_at = NOW()');
      const r = await pool.query(`UPDATE mcp2_server_tool SET ${sets.join(', ')} WHERE id=$${vals.length+1} RETURNING id, server_id, tool_id, enabled, version, created_at, updated_at`, [...vals, id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.delete('/api/mcp2/tools/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`DELETE FROM mcp2_server_tool WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  // Alternate server detach via POST
  app.post('/api/mcp2/tools/:id/delete', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`DELETE FROM mcp2_server_tool WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Utility: derive MCP2 URLs from http_base + name
  app.get('/api/mcp2/servers/derive', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const name = String(req.query?.name||'').trim();
      let http_base = String(req.query?.http_base||'').trim();
      if (!http_base) http_base = process.env.HA_BASE_URL || 'https://chat.piscinesondespro.fr';
      const d = deriveMcp2Endpoints(http_base, name);
      return res.json({ ok:true, http_base, name, ...d });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/mcp2/servers/derive', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      const name = String(b.name||'').trim();
      let http_base = String(b.http_base||'').trim();
      if (!http_base) http_base = process.env.HA_BASE_URL || 'https://chat.piscinesondespro.fr';
      const d = deriveMcp2Endpoints(http_base, name);
      return res.json({ ok:true, http_base, name, ...d });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // ---- Test DB connection for MCP2 type db_mariadb_prestashop ----
  app.post('/api/mcp2/servers/:id/test-db', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    const t0 = Date.now();
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const r = await pool.query(`SELECT type_id, options FROM mcp2_server WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      let typeCode = await getMcp2TypeCodeById(r.rows[0].type_id);
      typeCode = (typeCode||'').toLowerCase();
      if (typeCode !== 'db_mariadb_prestashop') return res.status(400).json({ ok:false, error:'unsupported_type' });
      let opts = r.rows[0].options; try { if (typeof opts === 'string') opts = JSON.parse(opts); } catch {}
      let values = opts && opts.type_config && opts.type_config.values ? opts.type_config.values : {};
      // Allow overrides from body
      try { const b = req.body || {}; if (b && b.values && typeof b.values === 'object') values = { ...values, ...b.values }; } catch {}
      const { db_host, db_port, db_name, db_user, db_password, charset, ssl } = values || {};
      if (!db_host || !db_name || !db_user || !db_password) return res.status(400).json({ ok:false, error:'missing_required', fields:['db_host','db_name','db_user','db_password'] });
      const mysql = await import('mysql2/promise');
      const conn = await mysql.createConnection({ host: db_host, port: db_port || 3306, user: db_user, password: db_password, database: db_name, charset: charset || 'utf8mb4', connectTimeout: 5000, ssl: ssl ? { rejectUnauthorized: false } : undefined });
      const [rows] = await conn.query('SELECT VERSION() AS v');
      try { await conn.end(); } catch {}
      const v = Array.isArray(rows) && rows.length ? (rows[0].v || rows[0].VERSION || rows[0]['VERSION()'] || '') : '';
      return res.json({ ok:true, vendor:'mysql', version: String(v||'').trim(), ms: Date.now()-t0 });
    } catch (e) {
      return res.status(200).json({ ok:false, error:'conn_failed', message: e?.message || String(e), ms: Date.now()-t0 });
    }
  });
  app.post('/api/mcp2/test-db', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    const t0 = Date.now();
    try {
      const b = req.body || {};
      const typeCode = String(b.type_code||'').toLowerCase();
      const values = (b && b.values && typeof b.values === 'object') ? b.values : {};
      if (typeCode !== 'db_mariadb_prestashop') return res.status(400).json({ ok:false, error:'unsupported_type' });
      const { db_host, db_port, db_name, db_user, db_password, charset, ssl } = values || {};
      if (!db_host || !db_name || !db_user || !db_password) return res.status(400).json({ ok:false, error:'missing_required', fields:['db_host','db_name','db_user','db_password'] });
      const mysql = await import('mysql2/promise');
      const conn = await mysql.createConnection({ host: db_host, port: db_port || 3306, user: db_user, password: db_password, database: db_name, charset: charset || 'utf8mb4', connectTimeout: 5000, ssl: ssl ? { rejectUnauthorized: false } : undefined });
      const [rows] = await conn.query('SELECT VERSION() AS v');
      try { await conn.end(); } catch {}
      const v = Array.isArray(rows) && rows.length ? (rows[0].v || rows[0].VERSION || rows[0]['VERSION()'] || '') : '';
      return res.json({ ok:true, vendor:'mysql', version: String(v||'').trim(), ms: Date.now()-t0 });
    } catch (e) {
      return res.status(200).json({ ok:false, error:'conn_failed', message: e?.message || String(e), ms: Date.now()-t0 });
    }
  });

  // ---- MCP2 server status (SSE/Stream) ----
  async function testMcp2ServerReachability(row) {
    try {
      let options = row.options; try { if (typeof options === 'string') options = JSON.parse(options); } catch {}
      const pref = (options && options.server_url_pref === 'stream') ? 'stream' : 'sse';
      let url = pref === 'stream' ? (row.stream_url || '') : (row.sse_url || '');
      const token = (row.token || '').trim();
      if (!url) return { ok:false, method:pref, error:'no_url' };
      try { const u = new URL(url, row.http_base || undefined); if (token && !u.searchParams.get('token')) u.searchParams.set('token', token); url = u.toString(); } catch {}
      const controller = new AbortController();
      const t0 = Date.now();
      const tm = setTimeout(() => controller.abort(), 2500);
      try {
        if (pref === 'stream') {
          const r = await fetch(url, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ jsonrpc:'2.0', id:'ping', method:'initialize', params:{} }),
            signal: controller.signal,
          });
          clearTimeout(tm);
          let ok = false; let msg = '';
          try { const j = await r.json(); ok = !!(j && j.result && (j.result.protocolVersion || j.result)); msg = j?.error?.message || ''; } catch (e) { msg = e?.message || String(e); }
          return { ok: r.ok && ok, method:'stream', ms: Date.now()-t0, url, status: r.status, error: ok ? '' : (msg || 'invalid_response') };
        } else {
          const r = await fetch(url, {
            method: 'GET',
            headers: { 'Accept': 'text/event-stream' },
            signal: controller.signal,
          });
          clearTimeout(tm);
          const ct = String(r.headers.get('content-type') || '').toLowerCase();
          const isSse = ct.includes('text/event-stream');
          return { ok: r.ok && isSse, method:'sse', ms: Date.now()-t0, url, status: r.status };
        }
      } catch (e) {
        clearTimeout(tm);
        return { ok:false, method:pref, error: e?.name === 'AbortError' ? 'timeout' : (e?.message || String(e)) };
      }
    } catch (e) {
      return { ok:false, method:'sse', error: e?.message || String(e) };
    }
  }

  app.get('/api/mcp2/servers/:id/status', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const q = await pool.query(`SELECT id, name, http_base, stream_url, sse_url, token, options FROM mcp2_server WHERE id=$1 LIMIT 1`, [id]);
      if (!q.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const st = await testMcp2ServerReachability(q.rows[0]);
      return res.json({ ok:true, status: st });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.get('/api/mcp2/servers/status', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const r = await pool.query(`SELECT id, name, http_base, stream_url, sse_url, token, options FROM mcp2_server ORDER BY updated_at DESC`);
      const out = [];
      for (const row of (r.rows || [])) {
        try { const st = await testMcp2ServerReachability(row); out.push({ id: row.id, ...st }); } catch { out.push({ id: row.id, ok:false, method:'sse', error:'check_failed' }); }
      }
      return res.json({ ok:true, items: out });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Test arbitrary (unsaved) MCP2 server payload
  app.post('/api/mcp2/servers/test', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      const row = {
        http_base: (typeof b.http_base==='string' && b.http_base.trim()) || null,
        stream_url: (typeof b.stream_url==='string' && b.stream_url.trim()) || null,
        sse_url: (typeof b.sse_url==='string' && b.sse_url.trim()) || null,
        token: (typeof b.token==='string' && b.token.trim()) || null,
        options: b.options && typeof b.options==='object' ? b.options : (typeof b.options==='string' ? b.options : null),
      };
      const st = await testMcp2ServerReachability(row);
      return res.json({ ok:true, status: st });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // ---- Imports from MCP v1 ----
  app.post('/api/mcp2/import/kinds-from-mcp', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const r = await pool.query(`SELECT DISTINCT kind FROM mcp_server_config WHERE COALESCE(kind,'') <> ''`);
      let created = 0; const items = [];
      for (const row of (r.rows||[])) {
        const label = String(row.kind||'').trim();
        const code = slugCode(label) || 'generic';
        const id = makeMcp2KindId();
        try {
          const q = await pool.query(`INSERT INTO mcp2_kind (id, code, name, description, created_at, updated_at) VALUES ($1,$2,$3,NULL,NOW(),NOW()) ON CONFLICT (code) DO NOTHING RETURNING id, code, name`, [id, code, label]);
          if (q.rowCount) { created++; items.push(q.rows[0]); }
        } catch {}
      }
      return res.json({ ok:true, created, items });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/import/types-from-mcp', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const r = await pool.query(`SELECT DISTINCT server_type FROM mcp_server_config WHERE COALESCE(server_type,'') <> ''`);
      let created = 0; const items = [];
      for (const row of (r.rows||[])) {
        const label = String(row.server_type||'').trim();
        const code = slugCode(label) || 'custom';
        const id = makeMcp2TypeId();
        try {
          const q = await pool.query(`INSERT INTO mcp2_type (id, code, name, description, created_at, updated_at) VALUES ($1,$2,$3,NULL,NOW(),NOW()) ON CONFLICT (code) DO NOTHING RETURNING id, code, name`, [id, code, label]);
          if (q.rowCount) { created++; items.push(q.rows[0]); }
        } catch {}
      }
      return res.json({ ok:true, created, items });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/import/servers-from-mcp', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      // Seed kinds and types first
      try { await pool.query(`WITH x AS (SELECT DISTINCT kind FROM mcp_server_config WHERE COALESCE(kind,'')<>'' ) SELECT 1`); } catch {}
      await (async ()=>{ const rr=await pool.query(`SELECT DISTINCT kind FROM mcp_server_config WHERE COALESCE(kind,'')<>''`); for (const rw of rr.rows||[]) { const label=String(rw.kind||'').trim(); const code=slugCode(label)||'generic'; const id=makeMcp2KindId(); try { await pool.query(`INSERT INTO mcp2_kind (id, code, name, created_at, updated_at) VALUES ($1,$2,$3,NOW(),NOW()) ON CONFLICT (code) DO NOTHING`, [id, code, label]); } catch {} } })();
      await (async ()=>{ const rr=await pool.query(`SELECT DISTINCT server_type FROM mcp_server_config WHERE COALESCE(server_type,'')<>''`); for (const rw of rr.rows||[]) { const label=String(rw.server_type||'').trim(); const code=slugCode(label)||'custom'; const id=makeMcp2TypeId(); try { await pool.query(`INSERT INTO mcp2_type (id, code, name, created_at, updated_at) VALUES ($1,$2,$3,NOW(),NOW()) ON CONFLICT (code) DO NOTHING`, [id, code, label]); } catch {} } })();
      // Build maps
      const kinds = await pool.query(`SELECT id, code FROM mcp2_kind`);
      const types = await pool.query(`SELECT id, code FROM mcp2_type`);
      const mapKind = new Map((kinds.rows||[]).map(r=>[String(r.code), String(r.id)]));
      const mapType = new Map((types.rows||[]).map(r=>[String(r.code), String(r.id)]));
      // Import servers (upsert by name)
      const src = await pool.query(`SELECT id, name, kind, http_base, ws_url, stream_url, sse_url, token, enabled, notes, server_type, options FROM mcp_server_config`);
      let upserted = 0;
      for (const s of (src.rows||[])) {
        const name = String(s.name||'').trim(); if (!name) continue;
        const kcode = slugCode(String(s.kind||''));
        const tcode = slugCode(String(s.server_type||''));
        const kind_id = kcode && mapKind.get(kcode) || null;
        const type_id = tcode && mapType.get(tcode) || null;
        let options = s.options; try { if (typeof options==='string') options = JSON.parse(options); } catch {}
        const id = makeMcp2ServerId();
        const q = await pool.query(`
          INSERT INTO mcp2_server (id, name, kind_id, type_id, http_base, ws_url, stream_url, sse_url, token, enabled, options, notes, created_at, updated_at)
          VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11::json,$12,NOW(),NOW())
          ON CONFLICT (name)
          DO UPDATE SET kind_id=EXCLUDED.kind_id, type_id=EXCLUDED.type_id, http_base=EXCLUDED.http_base, ws_url=EXCLUDED.ws_url, stream_url=EXCLUDED.stream_url, sse_url=EXCLUDED.sse_url, token=EXCLUDED.token, enabled=EXCLUDED.enabled, options=EXCLUDED.options, notes=EXCLUDED.notes, updated_at=NOW()
          RETURNING id
        `, [id, name, kind_id, type_id, s.http_base||null, s.ws_url||null, s.stream_url||null, s.sse_url||null, s.token||null, !!s.enabled, options?JSON.stringify(options):null, s.notes||null]);
        if (q.rowCount) upserted++;
      }
      return res.json({ ok:true, upserted });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/mcp2/import/tools-from-mcp', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      // Map server name to mcp2_server.id
      const m2 = await pool.query(`SELECT id, name FROM mcp2_server`);
      const map = new Map((m2.rows||[]).map(r=>[String(r.name||''), String(r.id||'')]));
      const src = await pool.query(`SELECT id, server_id, name, description, grp, kind, input_schema, code, enabled, version FROM mcp_tool_def`);
      let inserted = 0, skipped = 0;
      for (const t of (src.rows||[])) {
        // Resolve legacy server name
        let sname = '';
        try { const r = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [t.server_id]); if (r.rowCount) sname = r.rows[0].name || ''; } catch {}
        if (!sname) continue;
        const m2id = map.get(String(sname)); if (!m2id) { skipped++; continue; }
        const id = makeMcp2ToolId();
        let input_schema = t.input_schema; try { if (typeof input_schema==='string') input_schema = JSON.parse(input_schema); } catch {}
        let code = t.code; try { if (typeof code==='string') code = JSON.parse(code); } catch {}
        const q = await pool.query(`
          INSERT INTO mcp2_server_tool (id, server_id, name, description, input_schema, code, enabled, version, created_at, updated_at)
          VALUES ($1,$2,$3,$4,$5::json,$6::json,$7,$8,NOW(),NOW())
          ON CONFLICT (server_id, name) DO NOTHING
        `, [id, m2id, t.name, t.description||null, input_schema?JSON.stringify(input_schema):null, code?JSON.stringify(code):null, t.enabled!==false, Number.isFinite(Number(t.version))?Number(t.version):1]);
        if (q.rowCount) inserted++; else skipped++;
      }
      return res.json({ ok:true, inserted, skipped });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Import catalog (mcp2_tool) and type mappings (mcp2_type_tool) from legacy MCP (v1)
  app.post('/api/mcp2/import/catalog-from-mcp', async (req, res) => {
    if (!requireAdminEither(req, res)) return;
    try {
      await ensureTables();
      // 1) Ensure mcp2_type rows for distinct v1 server_type
      const st = await pool.query(`SELECT DISTINCT server_type FROM mcp_server_config WHERE COALESCE(server_type,'')<>''`);
      let typesUpserted = 0;
      for (const r of (st.rows||[])) {
        const label = String(r.server_type||'').trim(); if (!label) continue;
        const code = label.toLowerCase();
        try {
          const id = makeMcp2TypeId();
          await pool.query(`INSERT INTO mcp2_type (id, code, name, description, created_at, updated_at) VALUES ($1,$2,$3,NULL,NOW(),NOW()) ON CONFLICT (code) DO NOTHING`, [id, code, label]);
          typesUpserted++;
        } catch {}
      }

      // 2) Insert catalog tools from v1 mcp_tool_def (unique by name)
      const v1tools = await pool.query(`SELECT DISTINCT name, description, input_schema, code, COALESCE(version,1) as version FROM mcp_tool_def WHERE COALESCE(name,'')<>''`);
      let catalogUpserted = 0;
      for (const t of (v1tools.rows||[])) {
        const name = String(t.name||'').trim(); if (!name) continue;
        try {
          const id = makeMcp2ToolId();
          await pool.query(`INSERT INTO mcp2_tool (id, name, description, input_schema, code, version, created_at, updated_at)
                            VALUES ($1,$2,$3,$4::json,$5::json,$6,NOW(),NOW())
                            ON CONFLICT (name) DO NOTHING`,
            [id, name, t.description||null, t.input_schema?JSON.stringify(t.input_schema):null, t.code?JSON.stringify(t.code):null, Number(t.version)||1]);
          catalogUpserted++;
        } catch {}
      }

      // Load type ids by code and catalog tool ids by name
      const typesAll = await pool.query(`SELECT id, code FROM mcp2_type`);
      const mapType = new Map((typesAll.rows||[]).map(r => [String(r.code||'').toLowerCase(), String(r.id||'')]));
      const catAll = await pool.query(`SELECT id, name FROM mcp2_tool`);
      const mapTool = new Map((catAll.rows||[]).map(r => [String(r.name||''), String(r.id||'')]));

      // 3) Map v1 server_type + tool name -> mcp2_type_tool
      const joins = await pool.query(`
        SELECT DISTINCT m.server_type, d.name
          FROM mcp_tool_def d
          JOIN mcp_server_config m ON m.id = d.server_id
         WHERE COALESCE(m.server_type,'')<>'' AND COALESCE(d.name,'')<>''
      `);
      let typeMapsUpserted = 0;
      for (const row of (joins.rows||[])) {
        const code = String(row.server_type||'').toLowerCase();
        const typeId = mapType.get(code);
        const toolId = mapTool.get(String(row.name||''));
        if (!typeId || !toolId) continue;
        try { await pool.query(`INSERT INTO mcp2_type_tool (type_id, tool_id, default_enabled, created_at) VALUES ($1,$2,TRUE,NOW()) ON CONFLICT (type_id, tool_id) DO NOTHING`, [typeId, toolId]); typeMapsUpserted++; } catch {}
      }

      return res.json({ ok:true, typesUpserted, catalogUpserted, typeMapsUpserted });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Seed well-known tool families into mcp2_tool (psapi.*, stripe.*, packeta.*, google.gmail.*, postgresql.*, dhl.*)
  app.post('/api/mcp2/catalog/seed-common', async (req, res) => {
    if (!requireAdminEither(req, res)) return;
    try {
      await ensureTables();
      const common = [
        // Google Gmail
        { name: 'google.gmail.labels', description: 'List Gmail labels', input_schema: { type:'object', properties:{} }, code: { family:'gmail', op:'labels' } },
        { name: 'google.gmail.search', description: 'Search Gmail messages', input_schema: { type:'object', properties:{ q:{type:'string'} }, required:['q'] }, code: { family:'gmail', op:'search' } },
        { name: 'google.gmail.get', description: 'Get Gmail message by ID', input_schema: { type:'object', properties:{ id:{type:'string'} }, required:['id'] }, code: { family:'gmail', op:'get' } },
        { name: 'google.gmail.mark_read', description: 'Mark Gmail message as read', input_schema: { type:'object', properties:{ id:{type:'string'} }, required:['id'] }, code: { family:'gmail', op:'mark_read' } },
        { name: 'google.gmail.mark_unread', description: 'Mark Gmail message as unread', input_schema: { type:'object', properties:{ id:{type:'string'} }, required:['id'] }, code: { family:'gmail', op:'mark_unread' } },
        // Stripe
        { name: 'stripe.get', description: 'Stripe GET API path', input_schema: { type:'object', properties:{ path:{type:'string'}, query:{type:'object'} }, required:['path'] }, code: { family:'stripe', method:'GET' } },
        { name: 'stripe.post', description: 'Stripe POST API path', input_schema: { type:'object', properties:{ path:{type:'string'}, body:{type:'object'} }, required:['path'] }, code: { family:'stripe', method:'POST' } },
        { name: 'stripe.list_transactions', description: 'List recent charges', input_schema: { type:'object', properties:{ limit:{type:'integer'} } }, code: { family:'stripe', op:'list_transactions' } },
        { name: 'stripe.list_transactions_all', description: 'List all charges (paginated)', input_schema: { type:'object', properties:{ limit:{type:'integer'} } }, code: { family:'stripe', op:'list_transactions_all' } },
        { name: 'stripe.get_transaction', description: 'Get charge by ID', input_schema: { type:'object', properties:{ id:{type:'string'} }, required:['id'] }, code: { family:'stripe', op:'get_transaction' } },
        { name: 'stripe.get_customer_by_email', description: 'Find customer by email', input_schema: { type:'object', properties:{ email:{type:'string'} }, required:['email'] }, code: { family:'stripe', op:'get_customer_by_email' } },
        { name: 'stripe.get_customer_details', description: 'Get customer by ID', input_schema: { type:'object', properties:{ id:{type:'string'} }, required:['id'] }, code: { family:'stripe', op:'get_customer_details' } },
        { name: 'stripe.get_failed_payments', description: 'List failed payments', input_schema: { type:'object', properties:{ since:{type:'string'} } }, code: { family:'stripe', op:'get_failed_payments' } },
        { name: 'stripe.get_failed_payments_all', description: 'List all failed payments', input_schema: { type:'object', properties:{ since:{type:'string'} } }, code: { family:'stripe', op:'get_failed_payments_all' } },
        // Packeta (Zásilkovna)
        { name: 'packeta.track', description: 'Track a Zásilkovna shipment', input_schema: { type:'object', properties:{ number:{type:'string'} }, required:['number'] }, code: { family:'packeta', op:'track' } },
        { name: 'packeta.list', description: 'List Packeta packets', input_schema: { type:'object', properties:{ status:{type:'string'} } }, code: { family:'packeta', op:'list' } },
        // DHL
        { name: 'dhl.track_shipment', description: 'Track DHL shipment', input_schema: { type:'object', properties:{ number:{type:'string'} }, required:['number'] }, code: { family:'dhl', op:'track_shipment' } },
        { name: 'dhl.track_shipments', description: 'Track multiple DHL shipments', input_schema: { type:'object', properties:{ numbers:{ type:'array', items:{type:'string'} } }, required:['numbers'] }, code: { family:'dhl', op:'track_shipments' } },
        // PostgreSQL
        { name: 'postgresql.query', description: 'Run a read-only SQL query (SELECT)', input_schema: { type:'object', properties:{ sql:{type:'string'} }, required:['sql'] }, code: { family:'postgresql', op:'query', read_only:true } },
        { name: 'postgresql.list_tables', description: 'List database tables', input_schema: { type:'object', properties:{} }, code: { family:'postgresql', op:'list_tables' } },
        { name: 'postgresql.table_schema', description: 'Get table schema', input_schema: { type:'object', properties:{ table:{type:'string'} }, required:['table'] }, code: { family:'postgresql', op:'table_schema' } },
        // PrestaShop API
        { name: 'psapi.get', description: 'GET a PrestaShop API path', input_schema: { type:'object', properties:{ path:{type:'string'}, query:{type:'object'} }, required:['path'] }, code: { family:'psapi', method:'GET' } },
        { name: 'psapi.post', description: 'POST to a PrestaShop API path', input_schema: { type:'object', properties:{ path:{type:'string'}, body:{type:'object'} }, required:['path'] }, code: { family:'psapi', method:'POST' } },
        { name: 'psapi.update', description: 'PUT to a PrestaShop API path', input_schema: { type:'object', properties:{ path:{type:'string'}, body:{type:'object'} }, required:['path'] }, code: { family:'psapi', method:'PUT' } },
        { name: 'psapi.delete', description: 'DELETE a PrestaShop API path', input_schema: { type:'object', properties:{ path:{type:'string'} }, required:['path'] }, code: { family:'psapi', method:'DELETE' } },
      ];
      let inserted = 0;
      for (const t of common) {
        try {
          const id = makeMcp2ToolId();
          await pool.query(`INSERT INTO mcp2_tool (id, name, description, input_schema, code, version, created_at, updated_at)
                            VALUES ($1,$2,$3,$4::json,$5::json,$6,NOW(),NOW())
                            ON CONFLICT (name) DO NOTHING`,
            [id, t.name, t.description||null, JSON.stringify(t.input_schema||{}), JSON.stringify(t.code||{}), 1]);
          inserted++;
        } catch {}
      }
      // Optional: try to map families to existing types automatically
      const typesAll = await pool.query(`SELECT id, code FROM mcp2_type`);
      const mapType = new Map((typesAll.rows||[]).map(r => [String(r.code||'').toLowerCase(), String(r.id||'')]));
      const catAll = await pool.query(`SELECT id, name FROM mcp2_tool`);
      const mapTool = new Map((catAll.rows||[]).map(r => [String(r.name||''), String(r.id||'')]));
      const familyToTypeCodes = new Map(Object.entries({
        'google.gmail.': ['google_gmail','google.gmail','gmail'],
        'stripe.': ['stripe'],
        'packeta.': ['packeta','zasilkovana_api','zasilkovana'],
        'dhl.': ['dhl'],
        'postgresql.': ['db_postgresql','postgresql'],
        'psapi.': ['api_prestashop','prestashop','prestashop_api'],
      }));
      let mapped = 0;
      for (const [prefix, codes] of familyToTypeCodes.entries()) {
        for (const [name, toolId] of mapTool.entries()) {
          if (!name.startsWith(prefix)) continue;
          for (const code of codes) {
            const typeId = mapType.get(String(code).toLowerCase());
            if (!typeId) continue;
            try { await pool.query(`INSERT INTO mcp2_type_tool (type_id, tool_id, default_enabled, created_at) VALUES ($1,$2,TRUE,NOW()) ON CONFLICT (type_id, tool_id) DO NOTHING`, [typeId, toolId]); mapped++; } catch {}
          }
        }
      }
      return res.json({ ok:true, catalogInserted: inserted, typeMappingsInserted: mapped });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Upsert (update) mcp2_tool catalog from legacy mcp_tool_def (by name)
  // One-shot sync to refresh descriptions/schemas/code/versions for matching names.
  app.post('/api/mcp2/catalog/sync-from-mcp', async (req, res) => {
    if (!requireAdminEither(req, res)) return;
    try {
      await ensureTables();
      // Optional prefix filter to limit which legacy tools to sync (e.g., 'stripe.' or 'psapi.')
      const prefix = String(req.body?.prefix || '').trim();
      const where = prefix ? `WHERE COALESCE(name,'') <> '' AND name ILIKE $1` : `WHERE COALESCE(name,'') <> ''`;
      const params = prefix ? [prefix.replace(/%/g,'') + '%'] : [];
      const v1 = await pool.query(`SELECT name, description, input_schema, code, COALESCE(version,1) AS version FROM mcp_tool_def ${where}`, params);
      let inserted = 0, updated = 0;
      for (const row of (v1.rows || [])) {
        const name = String(row.name || '').trim(); if (!name) continue;
        const desc = row.description || null;
        const inputSchema = row.input_schema ? JSON.stringify(row.input_schema) : null;
        const code = row.code ? JSON.stringify(row.code) : null;
        const ver = Number(row.version) || 1;
        try {
          const id = makeMcp2ToolId();
          const r = await pool.query(
            `INSERT INTO mcp2_tool (id, name, description, input_schema, code, version, created_at, updated_at)
             VALUES ($1,$2,$3,$4::json,$5::json,$6,NOW(),NOW())
             ON CONFLICT (name)
             DO UPDATE SET description=EXCLUDED.description,
                           input_schema=EXCLUDED.input_schema,
                           code=EXCLUDED.code,
                           version=EXCLUDED.version,
                           updated_at=NOW()
             RETURNING (xmax = 0) AS inserted`,
            [id, name, desc, inputSchema, code, ver]
          );
          // In Postgres, xmax==0 indicates freshly inserted row in some cases; if not reliable, count via separate select
          if (r.rows && r.rows[0] && r.rows[0].inserted) inserted++; else updated++;
        } catch (e) {
          // Fallback: check if exists to categorize
          try { const q = await pool.query(`SELECT 1 FROM mcp2_tool WHERE name=$1`, [name]); if (q.rowCount) updated++; else inserted++; } catch {}
        }
      }
      return res.json({ ok:true, inserted, updated, total: (v1.rowCount || 0) });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // List vector store files for prompts linked to a given MCP server
  app.get('/api/mcp-servers/:id/vector-files', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const useCached = String(req.query?.source || 'live').toLowerCase() === 'cached';
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      // Resolve server name
      const rName = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!rName.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const serverName = rName.rows[0].name || '';
      // Collect prompt ids linked to this server via mapping and via chatbot_config mcp_server_name
      const promptIds = new Set();
      try {
        const r1 = await pool.query(
          `SELECT x.prompt_config_id AS id
             FROM prompt_config_mcp x
            WHERE x.mcp_server_id = $1`,
          [id]
        );
        for (const row of r1.rows || []) { const v = String(row.id||'').trim(); if (v) promptIds.add(v); }
      } catch {}
      try {
        const r2 = await pool.query(
          `SELECT DISTINCT prompt_config_id AS id
             FROM chatbot_config
            WHERE mcp_server_name = $1 AND COALESCE(prompt_config_id,'') <> ''`,
          [serverName]
        );
        for (const row of r2.rows || []) { const v = String(row.id||'').trim(); if (v) promptIds.add(v); }
      } catch {}
      // Return cached results when explicitly requested; otherwise fall back to live
      if (useCached) {
        try {
          const ids = Array.from(promptIds);
          if (!ids.length) return res.json({ ok:true, files: [] });
          const q = await pool.query(`
            SELECT v.vector_store_id, v.openai_file_id AS id, v.file_name, v.bytes AS file_bytes, v.status, v.purpose, v.updated_at, v.prompt_config_id, p.name AS prompt_name
              FROM vector_file_cache v
              LEFT JOIN prompt_config p ON p.id = v.prompt_config_id
             WHERE v.prompt_config_id = ANY($1::text[])
             ORDER BY v.updated_at DESC
          `, [ids]);
          return res.json({ ok:true, files: q.rows || [] });
        } catch (_) {
          // Table likely removed: fall through to live enumeration
        }
      }
      // Fetch prompt rows (live)
      const files = [];
      for (const pid of promptIds) {
        const rp = await pool.query(`SELECT id, name, openai_api_key, vector_store_id, vector_store_ids FROM prompt_config WHERE id=$1 LIMIT 1`, [pid]);
        if (!rp.rowCount) continue;
        const pc = rp.rows[0];
        let vectorStoreIds = [];
        try { if (Array.isArray(pc.vector_store_ids)) vectorStoreIds = pc.vector_store_ids.filter(Boolean).map(String); } catch {}
        try { const single = String(pc.vector_store_id || '').trim(); if (single) vectorStoreIds.push(single); } catch {}
        vectorStoreIds = Array.from(new Set(vectorStoreIds));
        if (!vectorStoreIds.length) continue;
        // Resolve API key: prompt -> org -> server/global
        let apiKeyUse = (pc.openai_api_key && String(pc.openai_api_key).trim()) || null;
        if (!apiKeyUse) {
          try {
            const oid = getUserOrgId(req);
            if (oid) {
              const rOrg = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]);
              if (rOrg.rowCount) apiKeyUse = (rOrg.rows[0].openai_api_key && String(rOrg.rows[0].openai_api_key).trim()) || null;
            }
          } catch {}
        }
        if (!apiKeyUse) apiKeyUse = getOpenaiApiKey();
        if (!apiKeyUse) continue;
        const client = createOpenAIClient({ apiKey: apiKeyUse });
        for (const vsId of vectorStoreIds) {
          try {
            let arr = [];
            try {
              const list = await client.vectorStores.files.list(vsId, { limit: 100 });
              arr = Array.isArray(list?.data) ? list.data : [];
            } catch (sdkErr) {
              try {
                const http = await openaiHttp(`/vector_stores/${encodeURIComponent(vsId)}/files?limit=100`, { method:'GET', apiKey: apiKeyUse });
                arr = Array.isArray(http?.data) ? http.data : (Array.isArray(http?.files)? http.files: []);
              } catch {}
            }
            for (const f of arr) {
              const fileId = String((f && (f.file_id || (f.file && f.file.id) || f.id)) || '').trim();
              let fileName = (f && (f.filename || (f.file && (f.file.filename || f.file.name)))) || '';
              let fileBytes = (typeof f?.bytes === 'number') ? f.bytes : null;
              let purpose = f?.purpose || null;
              try {
                if (fileId) {
                  const meta = await client.files.retrieve(fileId);
                  fileName = fileName || meta?.filename || meta?.name || '';
                  fileBytes = fileBytes ?? ((typeof meta?.bytes === 'number') ? meta.bytes : null);
                  purpose = purpose || meta?.purpose || null;
                }
              } catch {
                try {
                  if (fileId) {
                    const meta = await openaiHttp(`/files/${encodeURIComponent(fileId)}`, { method:'GET', apiKey: apiKeyUse });
                    fileName = fileName || meta?.filename || meta?.name || '';
                    fileBytes = fileBytes ?? ((typeof meta?.bytes === 'number') ? meta.bytes : null);
                    purpose = purpose || meta?.purpose || null;
                  }
                } catch {}
              }
              files.push({ prompt_id: pc.id, prompt_name: pc.name || '', vector_store_id: vsId, id: f.id, openai_file_id: fileId || f.id, status: f.status || null, created_at: f.created_at || null, usage_bytes: f.usage_bytes || null, file_name: fileName, file_bytes: fileBytes, purpose });
            }
          } catch (e) {
            // log silently and continue
          }
        }
      }
      return res.json({ ok:true, files });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Admin: list MCP uploads stored in our DB for a given server (scoped by server_name)
  app.get('/api/mcp-servers/:id/uploads', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const limit = Math.max(1, Math.min(500, Number(req.query.limit || 100)));
      const verify = /^(1|true|yes)$/i.test(String(req.query.verify || '0'));
      const r = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const name = r.rows[0].name || '';
      const q = await pool.query(`SELECT id, file_name, content_type, size_bytes, server_name, bot_id, file_path, is_remote, remote_provider, remote_file_id, created_at
                                    FROM mcp_files
                                   WHERE server_name = $1
                                   ORDER BY created_at DESC
                                   LIMIT $2`, [name, limit]);
      let files = q.rows || [];
      if (verify) {
        files = files.filter((row) => {
          try { return !!row.file_path && fs.existsSync(path.join(mcpUploadDir, row.file_path)); } catch { return false; }
        });
      }
      // Expose exists flag for UI, so it can offer cleanup
      files = files.map((row) => {
        let exists = true;
        try { exists = !!row.file_path && fs.existsSync(path.join(mcpUploadDir, row.file_path)); } catch { exists = false; }
        const { file_path, ...rest } = row;
        return { ...rest, exists };
      });
      return res.json({ ok:true, files });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Admin: get absolute folder path used to store MCP uploads for a given server
  app.get('/api/mcp-servers/:id/uploads/path', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const name = r.rows[0].name || '';
      const dir = path.join(mcpUploadDir, slugifyName(name));
      return res.json({ ok:true, path: dir });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Admin: list raw directory contents of the MCP uploads folder for this server (filesystem view)
  app.get('/api/mcp-servers/:id/uploads/folder', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const name = r.rows[0].name || '';
      const dir = path.join(mcpUploadDir, slugifyName(name));
      let entries = [];
      try {
        const ents = fs.readdirSync(dir, { withFileTypes: true });
        for (const e of ents) {
          if (!e.isFile()) continue;
          const full = path.join(dir, e.name);
          let st = null; try { st = fs.statSync(full); } catch {}
          entries.push({ name: e.name, size_bytes: st ? st.size : null, mtime: st ? st.mtime : null });
        }
      } catch {}
      return res.json({ ok:true, path: dir, entries });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Admin: cleanup missing disk files from mcp_files for this server
  app.post('/api/mcp-servers/:id/uploads/cleanup', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const name = r.rows[0].name || '';
      const q = await pool.query(`SELECT id, file_path FROM mcp_files WHERE server_name=$1`, [name]);
      let deleted = 0;
      for (const row of (q.rows || [])) {
        try {
          const full = row.file_path ? path.join(mcpUploadDir, row.file_path) : '';
          if (!full || !fs.existsSync(full)) {
            await pool.query(`DELETE FROM mcp_files WHERE id=$1`, [row.id]);
            deleted++;
          }
        } catch {}
      }
      return res.json({ ok:true, deleted });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Admin: sync local files from Files server root into MCP uploads folder (no OpenAI)
  // Body: { recursive?: boolean, overwrite?: boolean, reset?: boolean, keep_names?: boolean, limit?: number, files?: string[] }
  app.post('/api/mcp-servers/:id/local-sync', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT name, server_type, options FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const row = r.rows[0];
      const serverName = row.name || '';
      let opts = row.options; try { if (typeof opts === 'string') opts = JSON.parse(opts); } catch { opts = {}; }
      const root = String((opts && (opts.root || opts.base_path)) || '').trim();
      if (!root) return res.status(400).json({ ok:false, error:'files_root_missing' });
      const recursive = !!(req.body && req.body.recursive);
      const overwrite = !!(req.body && req.body.overwrite);
      const reset = !!(req.body && req.body.reset);
      const keepNames = !!(req.body && req.body.keep_names);
      const limit = Math.max(1, Math.min(5000, Number(req.body && req.body.limit || 5000)));
      const subdir = slugifyName(serverName);
      const dstDir = path.join(mcpUploadDir, subdir);
      try {
        if (reset) {
          try { fs.rmSync(dstDir, { recursive: true, force: true }); } catch {}
          try { await pool.query(`DELETE FROM mcp_files WHERE server_name=$1`, [serverName]); } catch {}
        }
        fs.mkdirSync(dstDir, { recursive: true });
      } catch {}

      const allowSet = (() => {
        try {
          const arr = Array.isArray(req.body?.files) ? req.body.files : [];
          if (!arr.length) return null;
          const s = new Set();
          for (const n of arr) { if (n) s.add(String(n).trim().toLowerCase()); }
          return s.size ? s : null;
        } catch { return null; }
      })();

      function* walk(dir, prefix = '') {
        const ents = (()=>{ try { return fs.readdirSync(dir, { withFileTypes:true }); } catch { return []; } })();
        for (const ent of ents) {
          const rel = prefix ? path.join(prefix, ent.name) : ent.name;
          const full = path.join(dir, ent.name);
          if (ent.isDirectory()) {
            if (recursive) yield* walk(full, rel);
          } else if (ent.isFile()) {
            // If allow list is provided, only include matching basenames
            if (allowSet) {
              const base = ent.name.toLowerCase();
              if (!allowSet.has(base)) continue;
            }
            yield { rel, full };
          }
        }
      }

      let copied = 0, skipped = 0, errors = 0, total = 0;
      for (const f of walk(root, '')) {
        if (total >= limit) break; total++;
        try {
          const filename = path.basename(f.rel);
          // Skip if an uploads file already exists ending with -filename unless overwrite requested
          const existsMatch = (()=>{ try {
            const ents = fs.readdirSync(dstDir, { withFileTypes:true });
            return ents.find(e => e.isFile() && e.name.toLowerCase().endsWith(`-${filename.toLowerCase()}`));
          } catch { return null; } })();
          if (existsMatch && !overwrite) { skipped++; continue; }
          const idLocal = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
          const safeName = filename.replace(/[^a-zA-Z0-9._-]+/g,'_');
          const relName = keepNames ? safeName : `${idLocal}-${safeName}`;
          const dest = path.join(dstDir, relName);
          fs.copyFileSync(f.full, dest);
          const st = fs.statSync(dest);
          await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, server_name, bot_id) VALUES ($1,$2,$3,$4,$5,$6,$7)`, [idLocal, filename, path.join(subdir, relName), 'application/octet-stream', st.size, serverName, null]);
          copied++;
        } catch (e) { errors++; }
      }
      return res.json({ ok:true, copied, skipped, errors, total_scanned: total, dst: dstDir, root, reset, keep_names: keepNames });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Admin: Rebuild mcp_files rows from disk for this server (adds missing DB records)
  app.post('/api/mcp-servers/:id/uploads/rebuild', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const serverName = r.rows[0].name || '';
      const subdir = slugifyName(serverName);
      const dir = path.join(mcpUploadDir, subdir);
      try { fs.mkdirSync(dir, { recursive: true }); } catch {}
      const entries = fs.existsSync(dir) ? fs.readdirSync(dir, { withFileTypes: true }) : [];
      let added = 0;
      for (const ent of entries) {
        try {
          if (!ent.isFile()) continue;
          const rel = path.join(subdir, ent.name);
          const full = path.join(mcpUploadDir, rel);
          const st = fs.statSync(full);
          const fileNamePart = ent.name.replace(/^[^\-]+\-/, '');
          // Check if a DB row already exists
          const q = await pool.query(`SELECT 1 FROM mcp_files WHERE file_path=$1 LIMIT 1`, [rel]);
          if (q.rowCount) continue;
          const idLocal = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
          await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, server_name, bot_id) VALUES ($1,$2,$3,$4,$5,$6,$7)`, [idLocal, fileNamePart || ent.name, rel, 'application/octet-stream', st.size, serverName, null]);
          added++;
        } catch {}
      }
      return res.json({ ok:true, added });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Admin: import vector store file(s) into MCP uploads for this server
  // Body: { items: [{ vector_store_id, file_id, file_name? }] } or single { vector_store_id, file_id, file_name? }
  app.post('/api/mcp-servers/:id/vector-files/import', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const rName = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!rName.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const serverName = rName.rows[0].name || '';
      const destDir = path.join(mcpUploadDir, slugifyName(serverName));
      try { fs.mkdirSync(destDir, { recursive: true }); } catch {}

      const body = req.body && typeof req.body === 'object' ? req.body : {};
      const items = Array.isArray(body.items) ? body.items : ([body.vector_store_id && body.file_id ? body : null].filter(Boolean));
      if (!items.length) return res.status(400).json({ ok:false, error:'bad_request', message:'no items' });

      // Build a map vector_store_id -> API key using prompts linked to this server (mapping + chatbot server_name)
      const keyByVector = new Map();
      try {
        const r1 = await pool.query(
          `SELECT pc.openai_api_key, pc.vector_store_id, pc.vector_store_ids
             FROM prompt_config_mcp x JOIN prompt_config pc ON pc.id = x.prompt_config_id
            WHERE x.mcp_server_id = $1`,
          [id]
        );
        const r2 = await pool.query(
          `SELECT DISTINCT pc.openai_api_key, pc.vector_store_id, pc.vector_store_ids
             FROM chatbot_config c JOIN prompt_config pc ON pc.id = c.prompt_config_id
            WHERE c.mcp_server_name = $1 AND COALESCE(c.prompt_config_id,'') <> ''`,
          [serverName]
        );
        const rows = [...(r1.rows||[]), ...(r2.rows||[])];
        for (const pc of rows) {
          const single = String(pc.vector_store_id || '').trim();
          const ids = Array.isArray(pc.vector_store_ids) ? pc.vector_store_ids : [];
          const key = (pc.openai_api_key && String(pc.openai_api_key).trim()) || null;
          if (single) keyByVector.set(single, key);
          for (const v of (ids||[])) { const s=String(v||'').trim(); if (s) keyByVector.set(s, key); }
        }
      } catch {}

      const results = [];
      for (const it of items) {
        try {
          let fileId = String(it.file_id || '').trim();
          const vectorId = String(it.vector_store_id || '').trim();
          if (!fileId) { results.push({ ok:false, error:'bad_item' }); continue; }
          // Fetch file metadata
          // Resolve api key for this item: vector-specific -> global
          let apiKeyUse = String(keyByVector.get(String(it.vector_store_id||'').trim()) || '').trim();
          if (!apiKeyUse) apiKeyUse = getOpenaiApiKey() || process.env.OPENAI_API_KEY || '';
          if (!apiKeyUse) { results.push({ ok:false, file_id:fileId, error:'openai_key_missing' }); continue; }
          // Resolve underlying Files API id if we received a vector-store file id
          try {
            if (vectorId && !/^file(_|\-)?/i.test(fileId)) {
              const vf = await openaiHttp(`/vector_stores/${encodeURIComponent(vectorId)}/files/${encodeURIComponent(fileId)}`, { method:'GET', apiKey: apiKeyUse });
              const resolved = vf?.file?.id || vf?.file_id || null;
              if (resolved) fileId = String(resolved);
            }
          } catch {}
          let meta = null;
          try { meta = await openaiHttp(`/files/${encodeURIComponent(fileId)}`, { method:'GET', apiKey: apiKeyUse }); } catch {}
          const filename = String(it.file_name || meta?.filename || meta?.name || `${fileId}.bin`).replace(/[^a-zA-Z0-9._-]+/g,'_');

          // 0) Try to satisfy from existing local sources (uploads dir or configured root)
          try {
            const subdir = slugifyName(serverName);
            // a) Already in uploads dir? (match files that end with -filename)
            try {
              const ents = fs.readdirSync(destDir, { withFileTypes: true });
              const found = ents.find(e => e.isFile() && e.name.toLowerCase().endsWith(`-${filename.toLowerCase()}`));
              if (found) {
                const full = path.join(destDir, found.name);
                const st = fs.statSync(full);
                const idLocal = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
                await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, server_name, bot_id) VALUES ($1,$2,$3,$4,$5,$6,$7)`, [idLocal, filename, path.join(subdir, found.name), 'application/octet-stream', st.size, serverName, null]);
                results.push({ ok:true, file_id:fileId, id:idLocal, source:'local_uploads' });
                continue;
              }
            } catch {}
            // b) Configured root: copy a matching filename into uploads
            const root = srvOpts && typeof srvOpts==='object' ? (srvOpts.root || srvOpts.base_path || '') : '';
            if (root && fs.existsSync(root)) {
              const candidate = path.join(root, filename);
              if (fs.existsSync(candidate) && fs.statSync(candidate).isFile()) {
                const idLocal = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
                const relName = `${idLocal}-${filename}`;
                const dest = path.join(destDir, relName);
                fs.copyFileSync(candidate, dest);
                const st = fs.statSync(dest);
                await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, server_name, bot_id) VALUES ($1,$2,$3,$4,$5,$6,$7)`, [idLocal, filename, path.join(subdir, relName), 'application/octet-stream', st.size, serverName, null]);
                results.push({ ok:true, file_id:fileId, id:idLocal, source:'local_root' });
                continue;
              }
            }
          } catch {}
          // Download content
          const base = normalizeOpenAIBase(process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1');
          const url = `${base}/files/${encodeURIComponent(fileId)}/content`;
          const resp = await fetch(url, { headers: buildOpenAIHeaders(apiKeyUse) });
          if (!resp.ok) {
            const t = await resp.text().catch(()=>'' );
            // If OpenAI forbids download (assistants purpose), create a remote placeholder instead
            if (resp.status === 403 && /not allowed to download files of purpose/i.test(t)) {
              const idLocal = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
              const rel = path.join('remote', 'openai', fileId);
              const filename = String(meta?.filename || meta?.name || `openai_${fileId}`).replace(/[^a-zA-Z0-9._-]+/g,'_');
              await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, server_name, bot_id, is_remote, remote_provider, remote_file_id) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10)`, [idLocal, filename, rel, 'application/octet-stream', 0, serverName, null, true, 'openai', fileId]);
              results.push({ ok:true, file_id:fileId, id:idLocal, remote:true, note:'linked (not downloadable)' });
              continue;
            }
            results.push({ ok:false, file_id:fileId, error:`download_failed ${resp.status}`, details: t });
            continue;
          }
          const buf = Buffer.from(await resp.arrayBuffer());
          const idLocal = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
          const rel = `${idLocal}-${filename}`;
          const full = path.join(destDir, rel);
          fs.writeFileSync(full, buf);
          const ct = 'application/octet-stream';
          await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, server_name, bot_id) VALUES ($1,$2,$3,$4,$5,$6,$7)`, [idLocal, filename, path.join(slugifyName(serverName), rel), ct, buf.length, serverName, null]);
          results.push({ ok:true, file_id:fileId, id:idLocal, file_name: filename, size_bytes: buf.length });
        } catch (e) {
          results.push({ ok:false, error:String(e?.message || e) });
        }
      }
      return res.json({ ok:true, results });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Sync and cache vector files for all prompts linked to a given MCP server
  app.post('/api/mcp-servers/:id/vector-files/sync', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const rName = await pool.query(`SELECT name FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!rName.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const serverName = rName.rows[0].name || '';
      // Collect prompt ids
      const promptIds = new Set();
      try {
        const r1 = await pool.query(`SELECT prompt_config_id AS id FROM prompt_config_mcp WHERE mcp_server_id=$1`, [id]);
        for (const row of r1.rows || []) { const v=String(row.id||'').trim(); if (v) promptIds.add(v); }
      } catch {}
      try {
        const r2 = await pool.query(`SELECT DISTINCT prompt_config_id AS id FROM chatbot_config WHERE mcp_server_name=$1 AND COALESCE(prompt_config_id,'')<>''`, [serverName]);
        for (const row of r2.rows || []) { const v=String(row.id||'').trim(); if (v) promptIds.add(v); }
      } catch {}
      let total = 0;
      for (const pid of promptIds) {
        total += await syncVectorFilesForPrompt(pid);
      }
      return res.json({ ok:true, synced: total, prompts: Array.from(promptIds) });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // List vector files for a prompt (cached or live)
  app.get('/api/prompt-configs/:id/vector-files', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const useCached = String(req.query?.source || 'live').toLowerCase() === 'cached';
      if (useCached) {
        try {
          const q = await pool.query(`
            SELECT v.vector_store_id, v.openai_file_id AS id, v.file_name, v.bytes AS file_bytes, v.status, v.purpose, v.updated_at
              FROM vector_file_cache v
             WHERE v.prompt_config_id = $1
             ORDER BY v.updated_at DESC
          `, [id]);
          return res.json({ ok:true, files: q.rows || [] });
        } catch (_) {
          // Table likely removed; fall through to live fetch
        }
      }
      const files = await enumerateVectorFilesForPromptLive(id);
      return res.json({ ok:true, files });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // Sync and cache vector files for a prompt
  app.post('/api/prompt-configs/:id/vector-files/sync', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const n = await syncVectorFilesForPrompt(id);
      return res.json({ ok:true, synced: n });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  async function enumerateVectorFilesForPromptLive(promptId) {
    const rp = await pool.query(`SELECT id, name, openai_api_key, vector_store_id, vector_store_ids FROM prompt_config WHERE id=$1 LIMIT 1`, [promptId]);
    if (!rp.rowCount) return [];
    const pc = rp.rows[0];
    let vectorStoreIds = [];
    try { if (Array.isArray(pc.vector_store_ids)) vectorStoreIds = pc.vector_store_ids.filter(Boolean).map(String); } catch {}
    try { const single = String(pc.vector_store_id || '').trim(); if (single) vectorStoreIds.push(single); } catch {}
    vectorStoreIds = Array.from(new Set(vectorStoreIds));
    if (!vectorStoreIds.length) return [];
    let apiKeyUse = (pc.openai_api_key && String(pc.openai_api_key).trim()) || null;
    if (!apiKeyUse) apiKeyUse = getOpenaiApiKey() || process.env.OPENAI_API_KEY || null;
    if (!apiKeyUse) return [];
    const client = createOpenAIClient({ apiKey: apiKeyUse });
    const out = [];
    for (const vsId of vectorStoreIds) {
      try {
        let arr = [];
        try { const list = await client.vectorStores.files.list(vsId, { limit: 100 }); arr = Array.isArray(list?.data) ? list.data : []; }
        catch { try { const http = await openaiHttp(`/vector_stores/${encodeURIComponent(vsId)}/files?limit=100`, { method:'GET', apiKey: apiKeyUse }); arr = Array.isArray(http?.data)? http.data: (Array.isArray(http?.files)? http.files: []); } catch {} }
        for (const f of arr) {
          const fileId = String((f && (f.file_id || (f.file && f.file.id) || f.id)) || '').trim();
          let fileName = (f && (f.filename || (f.file && (f.file.filename || f.file.name)))) || '';
          let fileBytes = (typeof f?.bytes === 'number') ? f.bytes : null;
          let purpose = f?.purpose || null;
          try { if (fileId) { const meta = await client.files.retrieve(fileId); fileName = fileName || meta?.filename || meta?.name || ''; fileBytes = fileBytes ?? ((typeof meta?.bytes === 'number') ? meta.bytes : null); purpose = purpose || meta?.purpose || null; } }
          catch { try { if (fileId) { const meta = await openaiHttp(`/files/${encodeURIComponent(fileId)}`, { method:'GET', apiKey: apiKeyUse }); fileName = fileName || meta?.filename || meta?.name || ''; fileBytes = fileBytes ?? ((typeof meta?.bytes === 'number') ? meta.bytes : null); purpose = purpose || meta?.purpose || null; } } catch {} }
          out.push({ prompt_id: pc.id, prompt_name: pc.name || '', vector_store_id: vsId, id: f.id, openai_file_id: fileId || f.id, status: f.status || null, created_at: f.created_at || null, usage_bytes: f.usage_bytes || null, file_name: fileName, file_bytes: fileBytes, purpose });
        }
      } catch {}
    }
    return out;
  }

  async function syncVectorFilesForPrompt(promptId) {
    const files = await enumerateVectorFilesForPromptLive(promptId);
    let up = 0;
    for (const f of files) {
      try {
        await pool.query(`
          INSERT INTO vector_file_cache (vector_store_id, openai_file_id, prompt_config_id, file_name, bytes, status, purpose, created_at, updated_at)
          VALUES ($1,$2,$3,$4,$5,$6,$7,NOW(),NOW())
          ON CONFLICT (vector_store_id, openai_file_id)
          DO UPDATE SET prompt_config_id = EXCLUDED.prompt_config_id, file_name = EXCLUDED.file_name, bytes = EXCLUDED.bytes, status = EXCLUDED.status, purpose = EXCLUDED.purpose, updated_at = NOW()
        `, [f.vector_store_id, f.openai_file_id || f.id, promptId, f.file_name || null, f.file_bytes || null, f.status || null, f.purpose || null]);
        up++;
      } catch {}
    }
    return up;
  }

  // Test database connection for a database-type MCP server
  app.post('/api/mcp-servers/:id/test-db', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    const t0 = Date.now();
    try {
      await ensureTables();
      const id = String(req.params.id||'').trim();
      const override = (req.body && typeof req.body.options === 'object') ? req.body.options : null;
      const r = await pool.query(`SELECT server_type, options FROM mcp_server_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const serverType = String(r.rows[0].server_type || '').toLowerCase();
      let opts = r.rows[0].options;
      try { if (opts && typeof opts === 'string') opts = JSON.parse(opts); } catch { opts = {}; }
      if (override && typeof override === 'object') opts = { ...opts, ...override };
      if (serverType !== 'database') return res.status(400).json({ ok:false, error:'bad_request', message:'server_type is not database' });

      const dbKind = (opts.db_kind || '').toString().toLowerCase();
      const url = (opts.connection_url || '').toString();
      const host = (opts.host || '').toString();
      const port = (opts.port || '').toString();
      const user = (opts.user || '').toString();
      const password = (opts.password || '').toString();
      const database = (opts.database || '').toString();

      // Determine driver
      const scheme = (() => { try { const u = new URL(url); return u.protocol.replace(':',''); } catch { return ''; } })().toLowerCase();
      // Prefer URL scheme when present, fallback to explicit db_kind
      const kind = scheme || dbKind;

      const timeoutMs = Math.max(2000, Math.min(15000, Number(req.query?.timeout_ms || 5000)));
      const withTimeout = (p) => Promise.race([
        p,
        new Promise((_r, rej) => setTimeout(() => rej(new Error('timeout')), timeoutMs))
      ]);

      if (kind.startsWith('postgres')) {
        // Postgres test via 'pg'
        let connectionString = url;
        if (!connectionString) {
          const portUse = port || '5432';
          const auth = user ? `${encodeURIComponent(user)}${password?':'+encodeURIComponent(password):''}@` : '';
          const hostUse = host || 'localhost';
          const dbUse = database || 'postgres';
          connectionString = `postgresql://${auth}${hostUse}:${portUse}/${encodeURIComponent(dbUse)}`;
        }
        const mod = await import('pg');
        const { Client } = mod;
        const client = new Client({ connectionString });
        try {
          await withTimeout(client.connect());
          const pong = await withTimeout(client.query('SELECT version() as v, 1 as ok'));
          try { await client.end(); } catch {}
          const ms = Date.now() - t0;
          return res.json({ ok:true, vendor:'postgresql', ms, version: pong?.rows?.[0]?.v || null });
        } catch (e) {
          try { await client.end(); } catch {}
          return res.status(400).json({ ok:false, error:'connect_failed', message: e?.message || String(e) });
        }
      }
      if (kind.startsWith('mysql') || kind === 'mariadb') {
        // MySQL/MariaDB via mysql2/promise if available
        let cfg = null;
        if (url) {
          try { const u = new URL(url); cfg = { host: u.hostname, port: Number(u.port||3306), user: decodeURIComponent(u.username||''), password: decodeURIComponent(u.password||''), database: (u.pathname||'').replace(/^\//,'') }; } catch { cfg = null; }
        }
        if (!cfg) cfg = { host: host||'localhost', port: Number(port||3306), user: user||'root', password: password||'', database: database||'' };
        try {
          const mod = await import('mysql2/promise');
          const conn = await withTimeout(mod.createConnection(cfg));
          const [rows] = await withTimeout(conn.query('SELECT VERSION() as v'));
          try { await conn.end(); } catch {}
          const ms = Date.now() - t0;
          return res.json({ ok:true, vendor: (kind==='mariadb'?'mariadb':'mysql'), ms, version: rows?.[0]?.v || null });
        } catch (e) {
          // Driver missing or connect error
          const msg = /Cannot find module|Cannot use import/i.test(String(e?.message||'')) ? 'mysql2 driver not installed on server' : (e?.message || String(e));
          return res.status(400).json({ ok:false, error:'connect_failed', message: msg });
        }
      }
      return res.status(400).json({ ok:false, error:'unsupported_db', message:`Unsupported db_kind/scheme: ${kind || 'unknown'}` });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // ============== MCP Designer (Tool definitions) ==============
  app.get('/api/mcp/designer/servers', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const r = await pool.query(`SELECT id, name, server_type, options, enabled, updated_at FROM mcp_server_config ORDER BY updated_at DESC`); return res.json({ ok:true, items: r.rows }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });
  app.get('/api/mcp/designer/servers/:id/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); const r = await pool.query(`SELECT id, server_id, name, description, grp, kind, input_schema, code, enabled, version, created_at, updated_at FROM mcp_tool_def WHERE server_id = $1 ORDER BY updated_at DESC`, [id]); return res.json({ ok:true, items: r.rows }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });
  app.post('/api/mcp/designer/servers/:id/tools', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const serverId = String(req.params.id||'').trim();
      const b = req.body || {};
      const name = String(b.name||'').trim(); if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });
      const id = `mt_${Math.random().toString(36).slice(2)}${Date.now()}`;
      const description = typeof b.description==='string' ? b.description : null;
      const grp = typeof b.grp==='string' ? b.grp : null;
      const kind = typeof b.kind==='string' ? b.kind : null;
      let input_schema = null; try { if (b.input_schema) input_schema = typeof b.input_schema==='string' ? JSON.parse(b.input_schema) : b.input_schema; } catch {}
      let code = null; try { if (b.code) code = typeof b.code==='string' ? JSON.parse(b.code) : b.code; } catch {}
      const enabled = !!b.enabled;
      const r = await pool.query(`INSERT INTO mcp_tool_def (id, server_id, name, description, grp, kind, input_schema, code, enabled, version, created_at, updated_at) VALUES ($1,$2,$3,$4,$5,$6,$7::json,$8::json,$9,1,NOW(),NOW()) RETURNING id, server_id, name, description, grp, kind, input_schema, code, enabled, version, created_at, updated_at`, [id, serverId, name, description, grp, kind, input_schema ? JSON.stringify(input_schema) : null, code ? JSON.stringify(code) : null, enabled]);
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });
  app.patch('/api/mcp/designer/servers/:id/tools/:name', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const serverId = String(req.params.id||'').trim();
      const name = String(req.params.name||'').trim();
      const b = req.body || {};
      const allowed = ['description','grp','kind','input_schema','code','enabled','name'];
      const entries = Object.entries(b).filter(([k])=>allowed.includes(k));
      if (!entries.length) return res.status(400).json({ ok:false, error:'bad_request' });
      const sets = []; const vals = []; let i=0;
      for (const [k,v] of entries) {
        if (k==='input_schema' || k==='code') { sets.push(`${k} = $${++i}::json`); try { vals.push(typeof v==='string'? JSON.stringify(JSON.parse(v)): JSON.stringify(v)); } catch { vals.push(JSON.stringify(null)); } }
        else { sets.push(`${k} = $${++i}`); vals.push(v); }
      }
      sets.push('updated_at = NOW()');
      const r = await pool.query(`UPDATE mcp_tool_def SET ${sets.join(', ')} WHERE server_id=$${++i} AND name=$${++i} RETURNING id, server_id, name, description, grp, kind, input_schema, code, enabled, version, created_at, updated_at`, [...vals, serverId, name]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });
  app.delete('/api/mcp/designer/servers/:id/tools/:name', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const serverId = String(req.params.id||'').trim(); const name = String(req.params.name||'').trim(); const r = await pool.query(`DELETE FROM mcp_tool_def WHERE server_id=$1 AND name=$2`, [serverId, name]); return res.json({ ok:true, deleted: r.rowCount||0 }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });

  // ================= MCP Groups (CRUD) ==================
  app.get('/api/mcp-groups', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const r = await pool.query(`SELECT id, name, description, created_at, updated_at FROM mcp_group ORDER BY updated_at DESC`); return res.json({ ok:true, items: r.rows }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/mcp-groups', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const b = req.body || {}; const id = makeMcpGroupId(); const name = String(b.name||'').trim(); if (!name) return res.status(400).json({ ok:false, error:'bad_request' }); const desc = typeof b.description==='string'?b.description:null; await pool.query(`INSERT INTO mcp_group (id, name, description, created_at, updated_at) VALUES ($1,$2,$3,NOW(),NOW())`, [id, name, desc]); return res.status(201).json({ ok:true, item: { id, name, description: desc } }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.patch('/api/mcp-groups/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); const b=req.body||{}; const allowed=['name','description']; const entries=Object.entries(b).filter(([k])=>allowed.includes(k)); if(!entries.length) return res.status(400).json({ ok:false, error:'bad_request' }); const sets = entries.map(([k],i)=>`${k} = $${i+1}`); const vals = entries.map(([,v])=>v); sets.push('updated_at = NOW()'); const r=await pool.query(`UPDATE mcp_group SET ${sets.join(', ')} WHERE id = $${vals.length+1} RETURNING id, name, description, created_at, updated_at`, [...vals, id]); if(!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' }); return res.json({ ok:true, item: r.rows[0] }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.delete('/api/mcp-groups/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id||'').trim(); await pool.query(`UPDATE mcp_server_config SET group_id=NULL, updated_at=NOW() WHERE group_id=$1`, [id]); await pool.query(`DELETE FROM mcp_group WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.get('/api/mcp-groups/:id/servers', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id=String(req.params.id||'').trim(); const r = await pool.query(`SELECT id, name, kind, group_id, http_base, ws_url, stream_url, sse_url, token, enabled, notes, server_type, options, created_at, updated_at FROM mcp_server_config WHERE group_id=$1 ORDER BY updated_at DESC`, [id]); return res.json({ ok:true, items: r.rows }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Force re-sync of MCP server config from legacy env/settings
  app.post('/api/admin/mcp-servers/sync-legacy', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await syncMcpServersFromLegacy(); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Create or ensure a Vector Store for a prompt_config (name = prompt's name)
  app.post('/api/prompt-configs/:id/vector-store', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const previewOnly = (req.body?.preview === true) || String(req.query?.preview || '').toLowerCase() === 'true';
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT id, name, openai_api_key, vector_store_id FROM prompt_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const pc = r.rows[0];
      let apiKeyUse = (pc.openai_api_key && String(pc.openai_api_key).trim()) || null;
      if (!apiKeyUse) {
        try {
          const oid = getUserOrgId(req);
          if (oid) {
            const rOrg = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]);
            if (rOrg.rowCount) apiKeyUse = (rOrg.rows[0].openai_api_key && String(rOrg.rows[0].openai_api_key).trim()) || null;
          }
        } catch {}
      }
      if (!apiKeyUse) apiKeyUse = getOpenaiApiKey();
      if (!apiKeyUse && !previewOnly) return res.status(400).json({ ok:false, error:'openai_key_missing' });
      const openai = new OpenAI({ apiKey: apiKeyUse });
      let vectorStoreId = pc.vector_store_id || null;
      if (!vectorStoreId) {
        const vsName = String(req.body?.name || pc.name || `kb_${pc.id}`);
        const vs = await openai.vectorStores.create({ name: vsName });
        vectorStoreId = vs?.id || null;
        if (vectorStoreId) {
          await pool.query(`UPDATE prompt_config SET vector_store_id=$1, updated_at=NOW() WHERE id=$2`, [vectorStoreId, id]);
        }
      }
      if (!vectorStoreId) return res.status(500).json({ ok:false, error:'create_failed' });
      res.json({ ok:true, vector_store_id: vectorStoreId });
    } catch (e) {
      try { logToFile(`[PROMPT_CONFIG_VECTOR_ERR] id=${req.params.id} code=${e?.code||''} msg=${e?.message||e}`); } catch {}
      res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Get prompt_config's vector store info (and list files)
  // Query: ensure=1 to create if missing
  app.get('/api/prompt-configs/:id/vector-store', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      await ensurePromptVectorIdsColumn();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT id, name, openai_api_key, vector_store_id, vector_store_ids FROM prompt_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const pc = r.rows[0];
      let apiKeyUse = (pc.openai_api_key && String(pc.openai_api_key).trim()) || null;
      if (!apiKeyUse) {
        try {
          const oid = getUserOrgId(req);
          if (oid) {
            const rOrg = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]);
            if (rOrg.rowCount) apiKeyUse = (rOrg.rows[0].openai_api_key && String(rOrg.rows[0].openai_api_key).trim()) || null;
          }
        } catch {}
      }
      if (!apiKeyUse) apiKeyUse = getOpenaiApiKey();
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });
      const openai = new OpenAI({ apiKey: apiKeyUse });
      let vectorStoreId = String(pc.vector_store_id || '').trim();
      let vectorStoreIds = Array.isArray(pc.vector_store_ids) ? pc.vector_store_ids.filter(Boolean) : [];
      if (vectorStoreId && !vectorStoreIds.includes(vectorStoreId)) vectorStoreIds.push(vectorStoreId);
      const wantEnsure = String(req.query?.ensure || '').toLowerCase() === '1' || String(req.query?.ensure || '').toLowerCase() === 'true';
      if (!vectorStoreId && wantEnsure) {
        const vs = await openai.vectorStores.create({ name: pc.name || `kb_${pc.id}` });
        vectorStoreId = vs?.id || '';
        if (vectorStoreId) {
          if (!vectorStoreIds.includes(vectorStoreId)) vectorStoreIds.push(vectorStoreId);
          await pool.query(`UPDATE prompt_config SET vector_store_id=$1, vector_store_ids=$2::json, updated_at=NOW() WHERE id=$3`, [vectorStoreId, JSON.stringify(vectorStoreIds), id]);
        }
      }
      let files = [];
      if (vectorStoreId) {
        try {
          const list = await openai.vectorStores.files.list(vectorStoreId, { limit: 100 });
          files = Array.isArray(list?.data) ? list.data.map(f => ({ id: f.id, status: f.status })) : [];
        } catch {}
      }
      return res.json({ ok:true, vector_store_id: vectorStoreId || null, vector_store_ids: vectorStoreIds, files });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Compute embeddings via OpenAI (optionally per-bot key)
  // Body: { input: string | string[], model?: string, id_bot?: string, api_key?: string }
  app.post('/api/embeddings', async (req, res) => {
    try {
      const b = req.body || {};
      let input = b.input;
      if (typeof input === 'string') input = input.trim();
      if ((typeof input !== 'string' || !input) && !(Array.isArray(input) && input.length)) {
        return res.status(400).json({ ok:false, error: 'bad_request', message: 'input required' });
      }
      const model = String(b.model || 'text-embedding-3-large');

      let apiKeyUse = null, orgUse = null, projUse = null, baseUrlUse = null;
      if (b.id_bot) {
        const id = String(b.id_bot || '').trim();
        if (id) {
          const r = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [id]);
          if (r.rowCount) {
            const row = r.rows[0];
            apiKeyUse = (row.openai_api_key && String(row.openai_api_key).trim()) || null;
            orgUse = row.openai_org || null;
            projUse = row.openai_project || null;
            baseUrlUse = row.openai_base_url || null;
          }
        }
        if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_disabled', message:'Bot has no OpenAI API key' });
      } else if (b.api_key) {
        apiKeyUse = String(b.api_key || '').trim();
      } else {
        apiKeyUse = getOpenaiApiKey();
      }
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });

      const openai = new OpenAI({ apiKey: apiKeyUse, organization: orgUse || undefined, project: projUse || undefined, baseURL: baseUrlUse || undefined });
      const r = await openai.embeddings.create({ model, input });
      return res.json({ ok:true, model: r.model || model, data: r.data });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Create a Vector Store (OpenAI)
  // Body: { name: string, id_bot?: string, api_key?: string }
  app.post('/api/vector-stores', async (req, res) => {
    try {
      const name = String((req.body && req.body.name) || '').trim();
      if (!name) return res.status(400).json({ ok:false, error:'bad_request', message:'name required' });

      let apiKeyUse = null, orgUse = null, projUse = null, baseUrlUse = null;
      if (req.body && req.body.id_bot) {
        const id = String(req.body.id_bot || '').trim();
        if (id) {
          const r = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [id]);
          if (r.rowCount) {
            const row = r.rows[0];
            apiKeyUse = (row.openai_api_key && String(row.openai_api_key).trim()) || null;
            orgUse = row.openai_org || null;
            projUse = row.openai_project || null;
            baseUrlUse = row.openai_base_url || null;
          }
        }
        if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_disabled', message:'Bot has no OpenAI API key' });
      } else if (req.body && req.body.org_id) {
        let oid = String(req.body.org_id || '').trim();
        if (oid === '__me__') {
          try { const u = authFromRequest(req); if (u && u.org_id) oid = String(u.org_id); } catch {}
        }
        if (oid) {
          const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]);
          if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null;
        }
      } else if (req.body && req.body.api_key) {
        apiKeyUse = String(req.body.api_key || '').trim();
      } else {
        apiKeyUse = getOpenaiApiKey();
      }
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });

      const openai = new OpenAI({ apiKey: apiKeyUse, organization: orgUse || undefined, project: projUse || undefined, baseURL: baseUrlUse || undefined });
      const vs = await openai.vectorStores.create({ name });
      return res.status(201).json({ ok:true, item: vs });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // List Vector Stores (OpenAI)
  // Query: id_bot? api_key? limit? after?
  app.get('/api/vector-stores', async (req, res) => {
    try {
      const limit = Math.max(1, Math.min(100, Number(req.query?.limit || 50)));
      const after = (req.query && req.query.after) ? String(req.query.after) : undefined;

      let apiKeyUse = null, orgUse = null, projUse = null, baseUrlUse = null;
      const idBot = req.query && req.query.id_bot ? String(req.query.id_bot).trim() : '';
      if (idBot) {
        const r = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [idBot]);
        if (r.rowCount) {
          const row = r.rows[0];
          apiKeyUse = (row.openai_api_key && String(row.openai_api_key).trim()) || null;
          orgUse = row.openai_org || null;
          projUse = row.openai_project || null;
          baseUrlUse = row.openai_base_url || null;
        }
        if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_disabled', message:'Bot has no OpenAI API key' });
      } else if (req.query && req.query.org_id) {
        const oid = String(req.query.org_id || '').trim();
        if (oid) {
          const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]);
          if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null;
        }
      } else if (req.query && req.query.org === 'me') {
        try { const oid = (authFromRequest(req) && authFromRequest(req).org_id) || null; if (oid) { const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]); if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null; } } catch {}
      } else if (req.query && req.query.api_key) {
        apiKeyUse = String(req.query.api_key || '').trim();
      } else {
        apiKeyUse = getOpenaiApiKey();
      }
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });

      const openai = new OpenAI({ apiKey: apiKeyUse, organization: orgUse || undefined, project: projUse || undefined, baseURL: baseUrlUse || undefined });
      const list = await openai.vectorStores.list({ limit, after });
      // Try to normalize pagination fields
      const items = Array.isArray(list?.data) ? list.data : [];
      const out = { ok:true, items };
      if (Object.prototype.hasOwnProperty.call(list || {}, 'has_more')) out.has_more = !!list.has_more;
      if (Object.prototype.hasOwnProperty.call(list || {}, 'last_id')) out.next_after = list.last_id;
      return res.json(out);
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Upload file(s) to an existing Vector Store by ID
  // Auth: admin cookie
  // Body: { file_url?, filename?, content_b64?, items?: [{ file_url|content_b64, filename? }], api_key?, org_id? }
  app.post('/api/vector-stores/:id/files', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const vectorStoreId = String(req.params.id || '').trim();
      if (!vectorStoreId) return res.status(400).json({ ok:false, error:'bad_request' });

      // Resolve OpenAI API key: explicit api_key > org_id > org=me > global key
      let apiKeyUse = null, orgUse = null, projUse = null, baseUrlUse = null;
      const b = req.body || {};
      if (b.api_key) {
        apiKeyUse = String(b.api_key || '').trim();
      } else if (b.id_bot) {
        const id = String(b.id_bot || '').trim();
        if (id) {
          try { const r = await pool.query(`SELECT openai_api_key, openai_org, openai_project, openai_base_url FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [id]); if (r.rowCount) { const row = r.rows[0]; apiKeyUse = (row.openai_api_key && String(row.openai_api_key).trim()) || null; orgUse = row.openai_org || null; projUse = row.openai_project || null; baseUrlUse = row.openai_base_url || null; } } catch {}
        }
      } else if (b.org_id) {
        let oid = String(b.org_id || '').trim();
        if (oid === '__me__') {
          try { const u = authFromRequest(req); if (u && u.org_id) oid = String(u.org_id); } catch {}
        }
        if (oid) {
          try { const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]); if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null; } catch {}
        }
      } else if (String(req.query?.org || '') === 'me') {
        try { const oid = (authFromRequest(req) && authFromRequest(req).org_id) || null; if (oid) { const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]); if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null; } } catch {}
      }
      if (!apiKeyUse) apiKeyUse = getOpenaiApiKey();
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });

      const openai = new OpenAI({ apiKey: apiKeyUse, organization: orgUse || undefined, project: projUse || undefined, baseURL: baseUrlUse || undefined });

      // Retrieve vector store name once for categorization
      let vectorStoreName = '';
      try { const meta = await openai.vectorStores.retrieve(vectorStoreId); vectorStoreName = String(meta?.name || '').trim(); } catch {}
      if (!vectorStoreName) vectorStoreName = vectorStoreId;

      // Local helpers for app_file + categories
      const TMP_DIR = path.join(__dirname, 'tmp_uploads');
      const ensureTmp = () => { try { fs.mkdirSync(TMP_DIR, { recursive: true }); } catch {} };
      ensureTmp();
      const APP_DIR = path.join(__dirname, 'app_files');
      try { fs.mkdirSync(APP_DIR, { recursive: true }); } catch {}
      const makeId = (pfx) => { try { return `${pfx}_${crypto.randomBytes(8).toString('hex')}`; } catch { return `${pfx}_${Date.now()}`; } };
      async function getOrCreateCategoryByName(name) {
        try { const r = await pool.query(`SELECT id FROM file_category WHERE name = $1 LIMIT 1`, [name]); if (r.rowCount) return r.rows[0].id; } catch {}
        const id = makeId('fc');
        try { await pool.query(`INSERT INTO file_category (id, name, archived, created_at, updated_at) VALUES ($1,$2,FALSE,NOW(),NOW())`, [id, name]); } catch {}
        return id;
      }
      async function saveAppFileLocal(baseName, buf) {
        const safe = String(baseName||'').replace(/[^A-Za-z0-9._-]+/g, '_') || `file_${Date.now()}`;
        const dest = path.join(APP_DIR, safe);
        await fs.promises.writeFile(dest, buf);
        let st = null; try { st = await fs.promises.stat(dest); } catch {}
        const id = makeId('af');
        try {
          await pool.query(`INSERT INTO app_file (id, filename, path, size_bytes, mtime, title, description, archived, created_at, updated_at) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,NOW(),NOW())`, [id, safe, dest, st?.size || buf.length, st?.mtime || new Date(), null, null, false]);
        } catch {}
        return id;
      }

      const { file_url, filename, content_b64, items, app_file_id } = b;
      const uploads = [];

      const uploadOne = async (payload) => {
        let name = String(payload.filename || '').trim() || 'attachment.txt';
        let dataBuf = null;
        let localAppFileId = null;
        if (payload.content_b64) {
          try { dataBuf = Buffer.from(String(payload.content_b64), 'base64'); } catch {}
        } else if (payload.app_file_id) {
          try {
            const rid = String(payload.app_file_id||'').trim();
            const r = await pool.query(`SELECT filename, path FROM app_file WHERE id = $1 LIMIT 1`, [rid]);
            if (r.rowCount) {
              const row = r.rows[0];
              name = row.filename || name;
              try { dataBuf = await fs.promises.readFile(String(row.path||'')); localAppFileId = rid; } catch {}
            }
          } catch {}
        } else if (payload.file_url) {
          let urlStr = String(payload.file_url);
          if (/^\//.test(urlStr)) {
            try {
              const proto = (req.protocol || 'http');
              const host = req.get('host') || 'localhost';
              urlStr = `${proto}://${host}${urlStr}`;
            } catch {}
          }
          const resp = await fetch(urlStr);
          if (!resp.ok) throw new Error(`download_failed_${resp.status}`);
          const ab = await resp.arrayBuffer();
          dataBuf = Buffer.from(ab);
          if (!payload.filename) { try { const u = new URL(urlStr); const base = u.pathname.split('/').pop(); if (base) name = base; } catch {} }
        }
        if (!dataBuf || !dataBuf.length) throw new Error('no_content');
        // Preserve original filename as the uploaded basename (use unique subfolder for collisions)
        const tmpSub = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
        const tmpDir = path.join(TMP_DIR, tmpSub);
        try { fs.mkdirSync(tmpDir, { recursive: true }); } catch {}
        const tmpPath = path.join(tmpDir, name);
        await fs.promises.writeFile(tmpPath, dataBuf);
        const stream = fs.createReadStream(tmpPath);
        const up = await openai.files.create({ file: stream, purpose: 'assistants' });
        const fileId = up?.id; if (!fileId) throw new Error('upload_failed');
        await openai.vectorStores.files.create(vectorStoreId, { file_id: fileId });

        // Save locally and map to category
        try {
          if (!localAppFileId) localAppFileId = await saveAppFileLocal(name, dataBuf);
          const catId = await getOrCreateCategoryByName(vectorStoreName);
          if (localAppFileId && catId) {
            try { await pool.query(`INSERT INTO app_file_category_map (file_id, category_id, created_at) VALUES ($1,$2,NOW()) ON CONFLICT DO NOTHING`, [localAppFileId, catId]); } catch {}
          }
          uploads.push({ filename: name, file_id: fileId, vector_store_id: vectorStoreId, app_file_id: localAppFileId, category: vectorStoreName });
        } catch {
          uploads.push({ filename: name, file_id: fileId, vector_store_id: vectorStoreId });
        }
      };

      if (Array.isArray(items) && items.length) {
        for (const it of items) {
          try { await uploadOne(it || {}); } catch (e) { uploads.push({ error: String(e?.message || e) }); }
        }
      } else {
        try { await uploadOne({ file_url, filename, content_b64, app_file_id }); } catch (e) { return res.status(400).json({ ok:false, error: 'upload_failed', message: String(e?.message || e) }); }
      }

      res.status(201).json({ ok:true, uploads, vector_store_id: vectorStoreId });
      // Fire-and-forget: ensure any MCP folders linked via prompts mirror this vector's files
      try { setTimeout(() => { updateMcpFoldersForVector(vectorStoreId).catch(()=>{}); }, 10); } catch {}
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // List files linked to a Vector Store
  // Auth: admin cookie
  // Query supports: id_bot, org_id, org=me, api_key (same resolution order as POST)
  app.get('/api/vector-stores/:id/files', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const vectorStoreId = String(req.params.id || '').trim();
      if (!vectorStoreId) return res.status(400).json({ ok:false, error:'bad_request' });
      let apiKeyUse = null, orgUse = null, projUse = null, baseUrlUse = null;
      const q = req.query || {};
      if (q.api_key) {
        apiKeyUse = String(q.api_key || '').trim();
      } else if (q.id_bot) {
        const id = String(q.id_bot || '').trim();
        if (id) {
          try { const r = await pool.query(`SELECT openai_api_key, openai_org, openai_project, openai_base_url FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [id]); if (r.rowCount) { const row = r.rows[0]; apiKeyUse = (row.openai_api_key && String(row.openai_api_key).trim()) || null; orgUse = row.openai_org || null; projUse = row.openai_project || null; baseUrlUse = row.openai_base_url || null; } } catch {}
        }
      } else if (q.org_id) {
        const oid = String(q.org_id || '').trim();
        if (oid) {
          try { const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]); if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null; } catch {}
        }
      } else if (String(q.org || '') === 'me') {
        try { const oid = (authFromRequest(req) && authFromRequest(req).org_id) || null; if (oid) { const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]); if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null; } } catch {}
      }
      if (!apiKeyUse) apiKeyUse = getOpenaiApiKey();
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });

      const openai = new OpenAI({ apiKey: apiKeyUse, organization: orgUse || undefined, project: projUse || undefined, baseURL: baseUrlUse || undefined });
      const limit = Math.max(1, Math.min(100, Number(q.limit || 100)));
      const after = q.after ? String(q.after) : undefined;
      const list = await openai.vectorStores.files.list(vectorStoreId, { limit, after });
      const raw = Array.isArray(list?.data) ? list.data : [];
      // Enrich with filename and bytes
      const items = [];
      for (const it of raw) {
        const id = it?.id || '';
        let filename = '';
        let bytes = null;
        let created_at = it?.created_at || null;
        try {
          if (id) {
            const f = await openai.files.retrieve(id);
            filename = f?.filename || filename;
            if (typeof f?.bytes === 'number') bytes = f.bytes;
            if (!created_at && f?.created_at) created_at = f.created_at;
          }
        } catch {}
        items.push({ id, filename, size_bytes: bytes, created_at, status: it?.status || null });
      }
      const out = { ok:true, items };
      if (Object.prototype.hasOwnProperty.call(list || {}, 'has_more')) out.has_more = !!list.has_more;
      if (Object.prototype.hasOwnProperty.call(list || {}, 'last_id')) out.next_after = list.last_id;
      return res.json(out);
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Unlink a file from a Vector Store (does not delete the file in OpenAI; removes association)
  app.delete('/api/vector-stores/:id/files/:fileId', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const vectorStoreId = String(req.params.id || '').trim();
      const fileId = String(req.params.fileId || '').trim();
      if (!vectorStoreId || !fileId) return res.status(400).json({ ok:false, error:'bad_request' });

      // Resolve key as in GET (org=me fallback)
      let apiKeyUse = null, orgUse = null, projUse = null, baseUrlUse = null;
      const q = req.query || {};
      if (q.api_key) apiKeyUse = String(q.api_key||'').trim();
      else if (q.id_bot) {
        const id = String(q.id_bot||'').trim();
        if (id) { try { const r = await pool.query(`SELECT openai_api_key, openai_org, openai_project, openai_base_url FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [id]); if (r.rowCount){ const row=r.rows[0]; apiKeyUse=(row.openai_api_key&&String(row.openai_api_key).trim())||null; orgUse=row.openai_org||null; projUse=row.openai_project||null; baseUrlUse=row.openai_base_url||null; } } catch {} }
      } else if (q.org_id) {
        const oid = String(q.org_id||'').trim(); if (oid) { try { const r=await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]); if (r.rowCount) apiKeyUse=(r.rows[0].openai_api_key&&String(r.rows[0].openai_api_key).trim())||null; } catch {} }
      } else if (String(q.org||'')==='me') {
        try { const oid=(authFromRequest(req)&&authFromRequest(req).org_id)||null; if (oid) { const r=await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]); if (r.rowCount) apiKeyUse=(r.rows[0].openai_api_key&&String(r.rows[0].openai_api_key).trim())||null; } } catch {}
      }
      if (!apiKeyUse) apiKeyUse = getOpenaiApiKey();
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });

      const openai = new OpenAI({ apiKey: apiKeyUse, organization: orgUse || undefined, project: projUse || undefined, baseURL: baseUrlUse || undefined });
      // Try multiple SDK shapes then fallback to raw HTTP
      let ok = false;
      try {
        const api = openai && openai.vectorStores && openai.vectorStores.files;
        if (api && typeof api.del === 'function') {
          await api.del(vectorStoreId, fileId);
          ok = true;
        }
      } catch {}
      if (!ok) {
        try {
          const api = openai && openai.vectorStores && openai.vectorStores.files;
          if (api && typeof api.delete === 'function') {
            await api.delete(vectorStoreId, fileId);
            ok = true;
          }
        } catch {}
      }
      if (!ok) {
        // Fallback to REST
        const base = (baseUrlUse && String(baseUrlUse).replace(/\/+$/, '')) || 'https://api.openai.com';
        const url = `${base}/v1/vector_stores/${encodeURIComponent(vectorStoreId)}/files/${encodeURIComponent(fileId)}`;
        const headers = buildOpenAIHeaders(apiKeyUse, { organization: orgUse || undefined, project: projUse || undefined });
        const r = await fetch(url, { method: 'DELETE', headers });
        if (!r.ok) {
          const t = await r.text().catch(() => '');
          return res.status(502).json({ ok:false, error:'openai_delete_failed', status: r.status, message: t });
        }
      }
      const out = { ok:true, unlinked:true };
      try { setTimeout(() => { updateMcpFoldersForVector(vectorStoreId).catch(()=>{}); }, 10); } catch {}
      return res.json(out);
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Helper: For a given Vector Store, reset MCP uploads folders of all linked MCP servers
  // (based on prompts that reference the vector) so they exactly mirror the vector's files.
  async function updateMcpFoldersForVector(vectorStoreId) {
    try {
      await ensureTables();
      const vsId = String(vectorStoreId || '').trim(); if (!vsId) return;

      // 1) Collect MCP server IDs linked via prompts that reference this vector
      const mcpIds = new Set();
      try {
        const r = await pool.query(`
          SELECT x.mcp_server_id, pc.vector_store_id, pc.vector_store_ids
            FROM prompt_config_mcp x JOIN prompt_config pc ON pc.id = x.prompt_config_id
        `);
        for (const row of (r.rows||[])) {
          const ids = [];
          try { const single = String(row.vector_store_id||'').trim(); if (single) ids.push(single); } catch {}
          try { if (Array.isArray(row.vector_store_ids)) { for (const v of row.vector_store_ids) { const s=String(v||'').trim(); if (s) ids.push(s); } } } catch {}
          if (ids.includes(vsId) && row.mcp_server_id) mcpIds.add(String(row.mcp_server_id));
        }
      } catch {}
      try {
        const r2 = await pool.query(`
          SELECT c.mcp_server_name AS name, pc.vector_store_id, pc.vector_store_ids
            FROM chatbot_config c JOIN prompt_config pc ON pc.id = c.prompt_config_id
           WHERE COALESCE(c.mcp_server_name,'') <> ''
        `);
        const mapNames = new Map();
        try { const m = await pool.query(`SELECT id, name FROM mcp_server_config`); for (const it of (m.rows||[])) mapNames.set(String(it.name||''), String(it.id||'')); } catch {}
        for (const row of (r2.rows||[])) {
          const ids = [];
          try { const single = String(row.vector_store_id||'').trim(); if (single) ids.push(single); } catch {}
          try { if (Array.isArray(row.vector_store_ids)) { for (const v of row.vector_store_ids) { const s=String(v||'').trim(); if (s) ids.push(s); } } } catch {}
          if (ids.includes(vsId)) {
            const sid = mapNames.get(String(row.name||'')); if (sid) mcpIds.add(sid);
          }
        }
      } catch {}
      if (!mcpIds.size) return;

      // 2) Enumerate current files for the vector store to derive filenames
      let apiKeyUse = getOpenaiApiKey() || process.env.OPENAI_API_KEY || '';
      try {
        // Prefer a prompt-specific key if available
        const r3 = await pool.query(`SELECT openai_api_key, vector_store_id, vector_store_ids FROM prompt_config`);
        for (const row of (r3.rows||[])) {
          const ids=[]; try { const single=String(row.vector_store_id||'').trim(); if (single) ids.push(single); } catch {}
          try { if (Array.isArray(row.vector_store_ids)) { for (const v of row.vector_store_ids) { const s=String(v||'').trim(); if (s) ids.push(s); } } } catch {}
          if (ids.includes(vsId) && row.openai_api_key && String(row.openai_api_key).trim()) { apiKeyUse = String(row.openai_api_key).trim(); break; }
        }
      } catch {}
      if (!apiKeyUse) return;
      let list = [];
      try {
        const resp = await openaiHttp(`/vector_stores/${encodeURIComponent(vsId)}/files?limit=100`, { method:'GET', apiKey: apiKeyUse });
        list = Array.isArray(resp?.data) ? resp.data : (Array.isArray(resp?.files)? resp.files: []);
      } catch { list = []; }
      const fileNames = [];
      for (const f of (list||[])) {
        try {
          let fileId = String((f && (f.file_id || (f.file && f.file.id) || f.id)) || '').trim();
          if (!fileId) continue;
          // If this is a vector-file id, resolve underlying file id
          if (!/^file(_|\-)?/i.test(fileId)) {
            try {
              const vf = await openaiHttp(`/vector_stores/${encodeURIComponent(vsId)}/files/${encodeURIComponent(fileId)}`, { method:'GET', apiKey: apiKeyUse });
              const resolved = vf?.file?.id || vf?.file_id || null; if (resolved) fileId = String(resolved);
            } catch {}
          }
          const meta = await openaiHttp(`/files/${encodeURIComponent(fileId)}`, { method:'GET', apiKey: apiKeyUse });
          const name = String(meta?.filename || meta?.name || '').trim();
          if (name) fileNames.push(name);
        } catch {}
      }
      // 3) For each MCP server, reset uploads and copy from local root only the listed filenames
      for (const sid of mcpIds) {
        try {
          const r = await pool.query(`SELECT name, options FROM mcp_server_config WHERE id=$1 LIMIT 1`, [sid]);
          if (!r.rowCount) continue;
          const srv = r.rows[0]; const serverName = String(srv.name||'');
          let opts = srv.options; try { if (typeof opts === 'string') opts = JSON.parse(opts); } catch { opts = {}; }
          const root = String((opts && (opts.root || opts.base_path)) || '').trim();
          if (!root) continue; // no local root configured
          const subdir = slugifyName(serverName);
          const dstDir = path.join(mcpUploadDir, subdir);
          try { fs.rmSync(dstDir, { recursive: true, force: true }); } catch {}
          try { await pool.query(`DELETE FROM mcp_files WHERE server_name=$1`, [serverName]); } catch {}
          try { fs.mkdirSync(dstDir, { recursive: true }); } catch {}
          const allow = new Set(fileNames.map(n => String(n).trim().toLowerCase()).filter(Boolean));

          // Walk root non-recursively; keep_names=true behavior
          const ents = (()=>{ try { return fs.readdirSync(root, { withFileTypes:true }); } catch { return []; } })();
          for (const ent of ents) {
            try {
              if (!ent.isFile()) continue;
              const filename = ent.name;
              if (allow.size && !allow.has(String(filename).toLowerCase())) continue;
              const idLocal = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
              const safeName = filename.replace(/[^a-zA-Z0-9._-]+/g,'_');
              const relName = safeName; // keep_names
              const src = path.join(root, filename);
              const dest = path.join(dstDir, relName);
              fs.copyFileSync(src, dest);
              const st = fs.statSync(dest);
              await pool.query(`INSERT INTO mcp_files (id, file_name, file_path, content_type, size_bytes, server_name, bot_id) VALUES ($1,$2,$3,$4,$5,$6,$7)`, [idLocal, filename, path.join(subdir, relName), 'application/octet-stream', st.size, serverName, null]);
            } catch {}
          }
        } catch {}
      }
    } catch {}
  }

  // ================================= APP FILES (local folder) ================================
  const APP_FILES_DIR = (process.env.APP_FILES_DIR && String(process.env.APP_FILES_DIR).trim()) || path.join(__dirname, 'app_files');
  function ensureAppFilesDir() { try { fs.mkdirSync(APP_FILES_DIR, { recursive: true }); } catch {} }
  async function syncAppFilesFromDisk() {
    try {
      ensureAppFilesDir();
      let names = [];
      try { names = await fs.promises.readdir(APP_FILES_DIR); } catch { names = []; }
      for (const name of names) {
        if (!name || name.startsWith('.')) continue;
        const full = path.join(APP_FILES_DIR, name);
        let st = null;
        try { st = await fs.promises.stat(full); } catch { continue; }
        if (!st.isFile()) continue;
        try {
          const r = await pool.query(`SELECT id FROM app_file WHERE path = $1 OR filename = $2 LIMIT 1`, [full, name]);
          if (r.rowCount) continue;
        } catch {}
        try {
          const id = makeAppFileId();
          await pool.query(`INSERT INTO app_file (id, filename, path, size_bytes, mtime, title, description, archived, created_at, updated_at) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,NOW(),NOW())`, [id, name, full, st.size, st.mtime, null, null, false]);
        } catch {}
      }
    } catch {}
  }
  function makeAppFileId() { try { return `af_${crypto.randomBytes(8).toString('hex')}`; } catch { return `af_${Date.now()}`; } }
  function makeCategoryId() { try { return `fc_${crypto.randomBytes(8).toString('hex')}`; } catch { return `fc_${Date.now()}`; } }

  // Presta downloads directory (absolute preferred; fallback to local folder)
  const PREFERRED_PRESTA_DL_DIR = process.env.PRESTA_DL_DIR || '/root/livechat-app/backend/downloaded_files';
  function ensureDirSafe(p) { try { fs.mkdirSync(p, { recursive: true }); return true; } catch { return false; } }
  function resolvePrestaDownloadDir() {
    if (ensureDirSafe(PREFERRED_PRESTA_DL_DIR)) return PREFERRED_PRESTA_DL_DIR;
    const local = path.join(__dirname, 'downloaded_files');
    ensureDirSafe(local);
    return local;
  }
  // Public token (optional) for downloading Presta files via GET without session
  let prestaFilesToken = String(process.env.PRESTA_LIVECHAT_API_TOKEN || process.env.PRESTA_FILES_TOKEN || '');
  async function loadPrestaFilesTokenFromDb() {
    try {
      let v = await getSetting('PRESTA_LIVECHAT_API_TOKEN');
      if (typeof v !== 'string' || !v) v = await getSetting('PRESTA_FILES_TOKEN');
      if (typeof v === 'string' && v) prestaFilesToken = v;
    } catch {}
  }
  await loadPrestaFilesTokenFromDb().catch(()=>{});
  function extractBearer(req) {
    const h = String(req.headers?.authorization || '').trim();
    const m = /^Bearer\s+(.+)$/i.exec(h);
    return (m && m[1]) ? String(m[1]).trim() : '';
  }
  function isPrestaTokenValid(req) {
    try {
      const qTok = (req.query?.token && String(req.query.token).trim()) || '';
      const bTok = extractBearer(req);
      const presented = qTok || bTok || '';
      return !!prestaFilesToken && presented === prestaFilesToken;
    } catch { return false; }
  }

  // List files in the app folder
  app.get('/api/app-files', async (req, res) => {
    try {
      await ensureTables();
      ensureAppFilesDir();
      await syncAppFilesFromDisk();
      const includeArchived = String(req.query?.include_archived || '').toLowerCase();
      const byCat = String(req.query?.category_id || '').trim();
      const where = (includeArchived === '1' || includeArchived === 'true') ? '' : 'WHERE f.archived = FALSE';
      const joinByCat = byCat ? 'JOIN app_file_category_map m2 ON m2.file_id = f.id AND m2.category_id = $1' : '';
      const params = byCat ? [byCat] : [];
      const sql = `SELECT f.id, f.filename, f.path, f.size_bytes, f.mtime, f.title, f.description, f.archived,
                          COALESCE(json_agg(json_build_object('id', c.id, 'name', c.name) ORDER BY c.name) FILTER (WHERE c.id IS NOT NULL), '[]') AS categories
                   FROM app_file f
                   ${joinByCat}
                   LEFT JOIN app_file_category_map m ON m.file_id = f.id
                   LEFT JOIN file_category c ON c.id = m.category_id
                   ${where}
                   GROUP BY f.id
                   ORDER BY f.updated_at DESC`;
      const r = await pool.query(sql, params);
      const items = (r.rows || []).map(row => ({ id: row.id, name: row.filename, path: row.path, size: row.size_bytes, mtime: row.mtime ? new Date(row.mtime).toISOString() : null, title: row.title || '', description: row.description || '', archived: !!row.archived, categories: row.categories || [] }));
      res.json({ ok: true, dir: APP_FILES_DIR, items });
    } catch (e) {
      res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
    }
  });

  // Upload file(s) into the app folder (JSON body with base64 content)
  // Body: { filename, content_b64 } OR { items: [{ filename, content_b64 }, ...] }
  app.post('/api/app-files', async (req, res) => {
    try {
      await ensureTables();
      ensureAppFilesDir();
      const b = req.body || {};
      let items = [];
      if (Array.isArray(b.items) && b.items.length) items = b.items;
      else if (b.filename && b.content_b64) items = [{ filename: b.filename, content_b64: b.content_b64, title: b.title, description: b.description }];
      if (!items.length) return res.status(400).json({ ok: false, error: 'bad_request', message: 'no files provided' });

      const saved = [];
      for (const it of items) {
        const name = String(it.filename || '').replace(/\\/g, '/').split('/').pop();
        if (!name) continue;
        const safeName = name.replace(/[^A-Za-z0-9._-]+/g, '_');
        const buf = Buffer.from(String(it.content_b64 || ''), 'base64');
        if (!buf.length) continue;
        const dest = path.join(APP_FILES_DIR, safeName);
        await fs.promises.writeFile(dest, buf);
        try {
          const st = await fs.promises.stat(dest);
          const id = makeAppFileId();
          const title = typeof it.title === 'string' ? it.title : null;
          const description = typeof it.description === 'string' ? it.description : null;
          await pool.query(`INSERT INTO app_file (id, filename, path, size_bytes, mtime, title, description, archived, created_at, updated_at) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,NOW(),NOW())`, [id, safeName, dest, st.size, st.mtime, title, description, false]);
          // Optional category assignments
          try {
            const cats = Array.isArray(it.category_ids) ? it.category_ids.map(String) : [];
            for (const cid of cats) { try { await pool.query(`INSERT INTO app_file_category_map (file_id, category_id, created_at) VALUES ($1,$2,NOW()) ON CONFLICT DO NOTHING`, [id, cid]); } catch {} }
          } catch {}
          saved.push({ id, name: safeName, size: st.size, mtime: st.mtime.toISOString(), path: dest, title: title || '', description: description || '', archived: false });
        } catch {
          saved.push({ name: safeName, path: dest });
        }
      }
      if (!saved.length) return res.status(400).json({ ok: false, error: 'save_failed' });
      res.status(201).json({ ok: true, dir: APP_FILES_DIR, items: saved });
    } catch (e) {
      res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
    }
  });

  // Delete an app file by id (and its category links); also tries to remove from disk
  app.delete('/api/app-files/:id', async (req, res) => {
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT id, path FROM app_file WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const filePath = String(r.rows[0].path || '').trim();
      try { if (filePath && fs.existsSync(filePath)) await fs.promises.unlink(filePath); } catch {}
      try { await pool.query(`DELETE FROM app_file_category_map WHERE file_id=$1`, [id]); } catch {}
      await pool.query(`DELETE FROM app_file WHERE id=$1`, [id]);
      return res.json({ ok:true, id });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Download a remote file (HTTP/HTTPS) and save it into the app folder
  // Body: { url: string, filename?: string, title?: string, description?: string, category_ids?: string[] }
  app.post('/api/app-files/fetch', async (req, res) => {
    try {
      await ensureTables();
      ensureAppFilesDir();
      const b = req.body || {};
      const urlStr = String(b.url || '').trim();
      if (!urlStr) return res.status(400).json({ ok:false, error:'bad_request', message:'url_required' });
      let url;
      try { url = new URL(urlStr); } catch { return res.status(400).json({ ok:false, error:'bad_request', message:'invalid_url' }); }
      if (url.protocol !== 'http:' && url.protocol !== 'https:') {
        return res.status(400).json({ ok:false, error:'bad_request', message:'unsupported_protocol' });
      }

      // Fetch remote content
      const resp = await fetch(url.toString());
      if (!resp.ok) {
        const t = await (async () => { try { return await resp.text(); } catch { return ''; } })();
        return res.status(502).json({ ok:false, error:'upstream_error', status: resp.status, body: t?.slice?.(0,2000) || '' });
      }

      // Determine filename
      let name = (typeof b.filename === 'string' && b.filename.trim()) || '';
      if (!name) {
        // Try Content-Disposition
        try {
          const cd = resp.headers.get('content-disposition') || '';
          const m = cd.match(/filename\*=UTF-8''([^;]+)|filename="?([^";]+)"?/i);
          const fn = decodeURIComponent(m?.[1] || m?.[2] || '');
          if (fn) name = fn;
        } catch {}
      }
      if (!name) {
        try { const base = url.pathname.split('/').pop(); if (base) name = base; } catch {}
      }
      if (!name) name = 'file';
      const safeName = String(name).replace(/[^A-Za-z0-9._-]+/g, '_');

      // Optional size guard (default ~25MB)
      const maxBytes = 25 * 1024 * 1024;
      const cl = Number(resp.headers.get('content-length') || 0);
      if (Number.isFinite(cl) && cl > 0 && cl > maxBytes) {
        return res.status(413).json({ ok:false, error:'too_large', message:`content_length_exceeds_limit:${cl}` });
      }

      // Read body
      const ab = await resp.arrayBuffer();
      const buf = Buffer.from(ab);
      if (buf.length > maxBytes) return res.status(413).json({ ok:false, error:'too_large', message:`body_exceeds_limit:${buf.length}` });

      // Save to disk
      const dest = path.join(APP_FILES_DIR, safeName);
      await fs.promises.writeFile(dest, buf);

      // Insert into DB
      let id = makeAppFileId();
      try {
        const st = await fs.promises.stat(dest);
        const title = typeof b.title === 'string' ? b.title : null;
        const description = typeof b.description === 'string' ? b.description : null;
        await pool.query(
          `INSERT INTO app_file (id, filename, path, size_bytes, mtime, title, description, archived, created_at, updated_at)
           VALUES ($1,$2,$3,$4,$5,$6,$7,$8,NOW(),NOW())`,
          [id, safeName, dest, st.size, st.mtime, title, description, false]
        );
        // Optional categories
        try {
          const cats = Array.isArray(b.category_ids) ? b.category_ids.map(String) : [];
          for (const cid of cats) { try { await pool.query(`INSERT INTO app_file_category_map (file_id, category_id, created_at) VALUES ($1,$2,NOW()) ON CONFLICT DO NOTHING`, [id, cid]); } catch {} }
        } catch {}
        return res.status(201).json({ ok:true, item: { id, name: safeName, path: dest, size: st.size, mtime: st.mtime?.toISOString?.() || null, title: title || '', description: description || '', archived: false } });
      } catch (e) {
        // If DB insert fails, still return basic info
        return res.status(201).json({ ok:true, item: { name: safeName, path: dest } });
      }
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // ======================= PRESTASHOP FILES (download to local folder) =======================
  // Status: where files will be stored
  app.get('/api/prestashop/files/status', async (req, res) => {
    try {
      const dir = resolvePrestaDownloadDir();
      return res.json({ ok:true, dir });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });

  // List local downloaded files
  app.get('/api/prestashop/files', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const dir = resolvePrestaDownloadDir();
      let files = [];
      try { files = await fs.promises.readdir(dir); } catch { files = []; }
      const items = [];
      for (const name of files) {
        const full = path.join(dir, name);
        try { const st = await fs.promises.stat(full); if (st.isFile()) items.push({ name, size: st.size, mtime: st.mtime.toISOString() }); } catch {}
      }
      items.sort((a,b) => (new Date(b.mtime) - new Date(a.mtime)));
      return res.json({ ok:true, dir, items });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });

  // Admin: get/set public token for GET downloads
  app.get('/api/prestashop/files/token', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      // Avoid leaking secret; only indicate if set
      const set = !!(prestaFilesToken && prestaFilesToken.length);
      // Since this endpoint is admin-only, return the token value as well for convenience
      res.json({ ok:true, set, token: prestaFilesToken || '' });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });
  app.post('/api/prestashop/files/token', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const t = String(req.body?.token || '').trim();
      if (!t) return res.status(400).json({ ok:false, error:'bad_request', message:'token_required' });
      // Store under the new key, and also legacy for backwards compatibility
      await setSetting('PRESTA_LIVECHAT_API_TOKEN', t);
      await setSetting('PRESTA_FILES_TOKEN', t);
      prestaFilesToken = t;
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });

  // Admin: fetch remote file list from Presta module base (action=download_list)
  app.post('/api/prestashop/files/list-remote', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      let base = String(b.base || '').trim();
      const dir = String(b.dir || 'config').trim();
      let tok = String(b.token || '').trim();
      if (!tok) {
        try { tok = (await getSetting('PRESTA_LIVECHAT_API_TOKEN')) || (await getSetting('PRESTA_FILES_TOKEN')) || ''; } catch {}
        if (!tok) tok = process.env.PRESTA_LIVECHAT_API_TOKEN || process.env.PRESTA_FILES_TOKEN || '';
      }
      if (!base) return res.status(400).json({ ok:false, error:'bad_request', message:'base_required' });

      // Build a proper URL, whether base already includes params or not
      const clean = (s) => String(s || '').replace(/\/$/, '');
      let finalUrl = '';
      try {
        let candidate = base;
        // Ensure absolute URL
        try { new URL(candidate); } catch { return res.status(400).json({ ok:false, error:'invalid_base' }); }
        const u = new URL(candidate);
        const p = u.searchParams;
        p.set('action', 'download_list');
        p.set('dir', dir || 'config');
        if (tok) p.set('token', tok);
        u.search = p.toString();
        finalUrl = u.toString();
      } catch {
        return res.status(400).json({ ok:false, error:'invalid_base' });
      }

      const f = (globalThis.fetch || (await import('node-fetch')).default);
      const ctrl = new AbortController();
      const tmo = setTimeout(() => ctrl.abort('timeout'), 15000);
      try {
        const r = await f(finalUrl, { method:'GET', headers:{ Accept: 'application/json, text/plain;q=0.8, */*;q=0.5' }, signal: ctrl.signal });
        const ct = String(r.headers.get('content-type') || '').toLowerCase();
        let text = '';
        let data = null;
        if (/json/.test(ct)) {
          try { data = await r.json(); } catch {}
        }
        if (!data) {
          try { text = await r.text(); } catch {}
        }
        // Normalize list
        const normItems = [];
        const pushName = (name, extra={}) => {
          const nm = String(name||'').trim(); if (!nm) return;
          normItems.push({ name: nm, ...extra });
        };
        if (data) {
          let arr = null;
          if (Array.isArray(data)) arr = data;
          else if (Array.isArray(data.files)) arr = data.files;
          else if (Array.isArray(data.items)) arr = data.items;
          if (arr) {
            for (const it of arr) {
              if (typeof it === 'string') pushName(it);
              else if (it && typeof it === 'object') {
                const name = it.name || it.file || it.filename || it.path || '';
                const size = it.size || it.bytes || null;
                const mtime = it.mtime || it.modified || it.updated_at || null;
                const url = it.url || it.href || null;
                pushName(name, { size, mtime, url });
              }
            }
          }
        }
        if (!normItems.length && text) {
          const lines = text.split(/\r?\n/).map(s => s.trim()).filter(Boolean);
          for (const ln of lines) pushName(ln);
        }
        return res.json({ ok:true, items: normItems, url: finalUrl });
      } finally {
        clearTimeout(tmo);
      }
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Admin: delete a remote file from Presta module base (action=delete_file)
  app.post('/api/prestashop/files/delete-remote', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      let base = String(b.base || '').trim();
      const dir = String(b.dir || 'config').trim();
      const filename = String(b.filename || b.fn || '').trim();
      let tok = String(b.token || '').trim();
      if (!filename) return res.status(400).json({ ok:false, error:'bad_request', message:'filename_required' });
      if (!tok) {
        try { tok = (await getSetting('PRESTA_LIVECHAT_API_TOKEN')) || (await getSetting('PRESTA_FILES_TOKEN')) || ''; } catch {}
        if (!tok) tok = process.env.PRESTA_LIVECHAT_API_TOKEN || process.env.PRESTA_FILES_TOKEN || '';
      }
      if (!base) return res.status(400).json({ ok:false, error:'bad_request', message:'base_required' });

      let finalUrl = '';
      try {
        const u = new URL(base);
        const p = u.searchParams;
        if (!p.get('action')) p.set('action', 'delete_file');
        if (!p.get('dir')) p.set('dir', dir || 'config');
        p.set('fn', filename);
        if (p.has('file')) p.delete('file');
        if (tok) p.set('token', tok);
        u.search = p.toString();
        finalUrl = u.toString();
      } catch {
        return res.status(400).json({ ok:false, error:'invalid_base' });
      }

      const f = (globalThis.fetch || (await import('node-fetch')).default);
      const ctrl = new AbortController();
      const tmo = setTimeout(() => ctrl.abort('timeout'), 15000);
      try {
        const r = await f(finalUrl, { method:'GET', headers:{ Accept: 'application/json, text/plain;q=0.8, */*;q=0.5' }, signal: ctrl.signal });
        const status = r.status;
        let ok = r.ok;
        // Some modules always 200, consider any 2xx as success
        return res.json({ ok, status, url: finalUrl });
      } finally {
        clearTimeout(tmo);
      }
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Admin: get/set public base URLs used to build copyable GET links in UI
  app.get('/api/prestashop/files/public-base', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const [savedLatest, savedFile] = await Promise.all([
        getSetting('PRESTA_FILES_LATEST_BASE'),
        getSetting('PRESTA_FILES_FILE_BASE'),
      ]);
      const envLatest = process.env.PRESTA_FILES_LATEST_BASE || '';
      const envFile = process.env.PRESTA_FILES_FILE_BASE || '';
      res.json({ ok:true, latest_base: savedLatest || envLatest || '', file_base: savedFile || envFile || '' });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });
  app.post('/api/prestashop/files/public-base', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const b = req.body || {};
      if (b.latest_base !== undefined) await setSetting('PRESTA_FILES_LATEST_BASE', String(b.latest_base||''));
      if (b.file_base !== undefined) await setSetting('PRESTA_FILES_FILE_BASE', String(b.file_base||''));
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });

  // Serve a downloaded file
  app.get('/api/prestashop/files/local/:name/download', async (req, res) => {
    // Allow with token OR admin session
    if (!isPrestaTokenValid(req)) { const u = requireAdminAuth(req, res); if (!u) return; }
    try {
      const dir = resolvePrestaDownloadDir();
      const name = String(req.params.name || '').replace(/[/\\]/g, '');
      const full = path.join(dir, name);
      if (!fs.existsSync(full)) return res.status(404).type('text/plain').send('not_found');
      const ext = path.extname(name).toLowerCase();
      const mime = (
        ext === '.txt' ? 'text/plain; charset=utf-8' :
        ext === '.md' ? 'text/markdown; charset=utf-8' :
        ext === '.html' || ext === '.htm' ? 'text/html; charset=utf-8' :
        ext === '.json' ? 'application/json; charset=utf-8' :
        ext === '.pdf' ? 'application/pdf' :
        ext === '.png' ? 'image/png' :
        ext === '.jpg' || ext === '.jpeg' ? 'image/jpeg' :
        ext === '.gif' ? 'image/gif' :
        ext === '.svg' ? 'image/svg+xml' :
        'application/octet-stream'
      );
      res.setHeader('Content-Type', mime);
      res.setHeader('Content-Disposition', `attachment; filename="${encodeURIComponent(name)}"`);
      const stream = fs.createReadStream(full);
      stream.on('error', () => { try { res.status(500).end('read_error'); } catch {} });
      return stream.pipe(res);
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });

  // Download the most recently modified file
  // GET /api/prestashop/files/latest/download?token=...  (or Authorization: Bearer <token>)
  app.get('/api/prestashop/files/latest/download', async (req, res) => {
    // Allow with token OR admin session
    if (!isPrestaTokenValid(req)) { const u = requireAdminAuth(req, res); if (!u) return; }
    try {
      const dir = resolvePrestaDownloadDir();
      let entries = [];
      try { entries = await fs.promises.readdir(dir); } catch {}
      let best = null;
      for (const name of entries) {
        const full = path.join(dir, name);
        try {
          const st = await fs.promises.stat(full);
          if (st.isFile()) {
            if (!best || st.mtimeMs > best.st.mtimeMs) best = { name, full, st };
          }
        } catch {}
      }
      if (!best) return res.status(404).type('text/plain').send('no_files');
      const ext = path.extname(best.name).toLowerCase();
      const mime = (
        ext === '.txt' ? 'text/plain; charset=utf-8' :
        ext === '.md' ? 'text/markdown; charset=utf-8' :
        ext === '.html' || ext === '.htm' ? 'text/html; charset=utf-8' :
        ext === '.json' ? 'application/json; charset=utf-8' :
        ext === '.pdf' ? 'application/pdf' :
        ext === '.png' ? 'image/png' :
        ext === '.jpg' || ext === '.jpeg' ? 'image/jpeg' :
        ext === '.gif' ? 'image/gif' :
        ext === '.svg' ? 'image/svg+xml' :
        'application/octet-stream'
      );
      res.setHeader('Content-Type', mime);
      res.setHeader('Content-Disposition', `attachment; filename="${encodeURIComponent(best.name)}"`);
      const stream = fs.createReadStream(best.full);
      stream.on('error', () => { try { res.status(500).end('read_error'); } catch {} });
      return stream.pipe(res);
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });

  // Fetch one or many URLs from Presta (using configured API key as Basic Auth) and save to download dir
  // Body: { url?: string, urls?: string[], filename?: string }
  app.post('/api/prestashop/files/fetch', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      // Resolve Presta config
      const [savedBase, savedKey] = await Promise.all([
        getSetting('COMPANY_CHAT_PRESTA_BASE'),
        getSetting('COMPANY_CHAT_PRESTA_KEY'),
      ]);
      const envBase = process.env.PRESTASHOP_BASE_URL || '';
      const envKey = process.env.PRESTASHOP_API_KEY || '';
      const prestaBase = String(savedBase || envBase || '').trim();
      const prestaKey = String(savedKey || envKey || '').trim();
      if (!prestaBase || !prestaKey) return res.status(400).json({ ok:false, error:'prestashop_not_configured' });

      const b = req.body || {};
      const urls = Array.isArray(b.urls) && b.urls.length ? b.urls : (b.url ? [String(b.url)] : []);
      if (!urls.length) return res.status(400).json({ ok:false, error:'bad_request', message:'no_urls' });

      const dir = resolvePrestaDownloadDir();
      const results = [];
      const f = (globalThis.fetch || (await import('node-fetch')).default);
      for (const raw of urls) {
        let urlStr = String(raw || '').trim();
        if (!urlStr) continue;
        // If relative path, resolve against Presta base
        try { const uo = new URL(urlStr); } catch { urlStr = `${prestaBase.replace(/\/$/, '')}/${urlStr.replace(/^\//,'')}`; }
        // Fetch with Presta Basic auth
        const resp = await f(urlStr, { headers: { Authorization: `Basic ${Buffer.from(`${prestaKey}:`).toString('base64')}` } });
        if (!resp.ok) {
          const t = await resp.text().catch(()=> '');
          results.push({ url: urlStr, ok:false, status: resp.status, error: t.slice(0,400) });
          continue;
        }
        const ab = await resp.arrayBuffer();
        const buf = Buffer.from(ab);
        // Derive name
        let name = (typeof b.filename === 'string' && b.filename.trim()) || '';
        if (!name) {
          try {
            const cd = resp.headers.get('content-disposition') || '';
            const m = cd.match(/filename\*=UTF-8''([^;]+)|filename="?([^";]+)"?/i);
            const fn = decodeURIComponent(m?.[1] || m?.[2] || '');
            if (fn) name = fn;
          } catch {}
        }
        if (!name) {
          try { const uo = new URL(urlStr); const base = uo.pathname.split('/').pop(); if (base) name = base; } catch {}
        }
        if (!name) name = `presta_file_${Date.now()}`;
        const safeName = name.replace(/[^A-Za-z0-9._-]+/g, '_');
        const dest = path.join(dir, safeName);
        await fs.promises.writeFile(dest, buf);
        try { const st = await fs.promises.stat(dest); results.push({ url: urlStr, ok:true, name: safeName, size: st.size, mtime: st.mtime.toISOString(), path: dest }); }
        catch { results.push({ url: urlStr, ok:true, name: safeName, path: dest }); }
      }
      return res.status(201).json({ ok:true, dir, results });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
  });

  // Update metadata or archive/unarchive a file
  app.patch('/api/app-files/:id', async (req, res) => {
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const allowed = ['title','description','archived'];
      const b = req.body || {};
      const entries = Object.entries(b).filter(([k]) => allowed.includes(k));
      if (!entries.length) return res.status(400).json({ ok:false, error:'bad_request' });
      const sets = entries.map(([k],i)=> `${k} = $${i+1}`);
      const vals = entries.map(([,v]) => v);
      sets.push('updated_at = NOW()');
      const sql = `UPDATE app_file SET ${sets.join(', ')} WHERE id = $${vals.length+1} RETURNING id, filename, path, size_bytes, mtime, title, description, archived, created_at, updated_at`;
      const r = await pool.query(sql, [...vals, id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      // Replace categories if provided
      if (Array.isArray(b.category_ids)) {
        try {
          await pool.query(`DELETE FROM app_file_category_map WHERE file_id = $1`, [id]);
          const cats = b.category_ids.map(String);
          for (const cid of cats) { try { await pool.query(`INSERT INTO app_file_category_map (file_id, category_id, created_at) VALUES ($1,$2,NOW()) ON CONFLICT DO NOTHING`, [id, cid]); } catch {} }
        } catch {}
      }
      const row = r.rows[0];
      // Fetch categories
      let cats = [];
      try { const rc = await pool.query(`SELECT c.id, c.name FROM app_file_category_map m JOIN file_category c ON c.id = m.category_id WHERE m.file_id = $1 ORDER BY c.name`, [id]); cats = rc.rows || []; } catch {}
      return res.json({ ok:true, item: { id: row.id, name: row.filename, path: row.path, size: row.size_bytes, mtime: row.mtime ? new Date(row.mtime).toISOString() : null, title: row.title || '', description: row.description || '', archived: !!row.archived, categories: cats } });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Download a stored app file by id
  app.get('/api/app-files/:id/download', async (req, res) => {
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).type('text/plain').send('bad_request');
      const r = await pool.query(`SELECT filename, path FROM app_file WHERE id = $1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).type('text/plain').send('not_found');
      const row = r.rows[0];
      const filePath = String(row.path || '').trim();
      const fileName = String(row.filename || 'file');
      if (!filePath || !fs.existsSync(filePath)) return res.status(404).type('text/plain').send('missing_file');
      const ext = path.extname(fileName).toLowerCase();
      const mime = (
        ext === '.txt' ? 'text/plain; charset=utf-8' :
        ext === '.md' ? 'text/markdown; charset=utf-8' :
        ext === '.html' || ext === '.htm' ? 'text/html; charset=utf-8' :
        ext === '.json' ? 'application/json; charset=utf-8' :
        ext === '.pdf' ? 'application/pdf' :
        ext === '.png' ? 'image/png' :
        ext === '.jpg' || ext === '.jpeg' ? 'image/jpeg' :
        ext === '.gif' ? 'image/gif' :
        ext === '.svg' ? 'image/svg+xml' :
        'application/octet-stream'
      );
      res.setHeader('Content-Type', mime);
      const forceDl = String(req.query?.dl || '').toLowerCase();
      const disp = (forceDl === '1' || forceDl === 'true' || forceDl === 'download') ? 'attachment' : 'inline';
      res.setHeader('Content-Disposition', `${disp}; filename="${encodeURIComponent(fileName)}"`);
      const stream = fs.createReadStream(filePath);
      stream.on('error', () => { try { res.status(500).end('read_error'); } catch {} });
      return stream.pipe(res);
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

  // Validate JSON content of a stored app file by id (with size cap)
  app.get('/api/app-files/:id/validate-json', async (req, res) => {
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT filename, path FROM app_file WHERE id = $1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const row = r.rows[0];
      const filePath = String(row.path || '').trim();
      const fileName = String(row.filename || 'file');
      if (!filePath || !fs.existsSync(filePath)) return res.status(404).json({ ok:false, error:'missing_file' });
      const st = await fs.promises.stat(filePath);
      const clamp = (n, a, b) => Math.max(a, Math.min(b, n));
      const lim = clamp(Number(req.query?.max_bytes || 2_000_000) || 2_000_000, 1000, 20_000_000);
      if (st.size > lim) return res.json({ ok:true, valid:false, error:'too_large', size: st.size, limit: lim, filename: fileName });
      let text = '';
      try {
        text = await fs.promises.readFile(filePath, 'utf8');
        // Strip UTF-8 BOM and leading invisible chars that break JSON.parse
        if (text && text.charCodeAt(0) === 0xFEFF) text = text.slice(1);
        text = text.replace(/^\uFEFF/, '');
      } catch (e) {
        return res.status(500).json({ ok:false, error:'read_failed', message: String(e?.message || e) });
      }
      try {
        const obj = JSON.parse(text);
        const isArr = Array.isArray(obj);
        const isObj = !isArr && obj && typeof obj === 'object';
        const meta = isArr ? { type:'array', length: obj.length } : (isObj ? { type:'object', keys: Object.keys(obj).length } : { type: typeof obj });
        return res.json({ ok:true, valid:true, filename: fileName, size: st.size, ...meta });
      } catch (e) {
        let at = null, line = null, column = null;
        try {
          const m = /position\s+(\d+)/i.exec(String(e?.message || ''));
          if (m) {
            at = Number(m[1]);
            const upto = text.slice(0, at);
            const lines = upto.split(/\n/);
            line = lines.length;
            column = lines[lines.length - 1].length + 1;
          }
        } catch {}
        let snippetBefore = '', snippetAfter = '';
        try {
          const start = Math.max(0, (at || 0) - 120);
          const end = Math.min(text.length, (at || 0) + 120);
          snippetBefore = text.slice(start, at || 0);
          snippetAfter = text.slice(at || 0, end);
        } catch {}
        return res.json({ ok:true, valid:false, filename: fileName, size: st.size, error: String(e?.message || e), at, line, column, snippetBefore, snippetAfter });
      }
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: String(e?.message || e) });
    }
  });

  // --------------------- FILE CATEGORIES ----------------------
  app.get('/api/file-categories', async (_req, res) => {
    try {
      await ensureTables();
      const r = await pool.query(`SELECT id, name, archived FROM file_category ORDER BY name ASC`);
      return res.json({ ok:true, items: r.rows || [] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/file-categories', async (req, res) => {
    try {
      await ensureTables();
      const name = String(req.body?.name || '').trim();
      if (!name) return res.status(400).json({ ok:false, error:'bad_request' });
      const id = makeCategoryId();
      const r = await pool.query(`INSERT INTO file_category (id, name, archived, created_at, updated_at) VALUES ($1,$2,FALSE,NOW(),NOW()) RETURNING id, name, archived`, [id, name]);
      return res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.patch('/api/file-categories/:id', async (req, res) => {
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      const b = req.body || {};
      const allowed = ['name','archived'];
      const entries = Object.entries(b).filter(([k]) => allowed.includes(k));
      if (!id || !entries.length) return res.status(400).json({ ok:false, error:'bad_request' });
      const sets = entries.map(([k],i)=> `${k} = $${i+1}`);
      const vals = entries.map(([,v]) => v);
      sets.push('updated_at = NOW()');
      const r = await pool.query(`UPDATE file_category SET ${sets.join(', ')} WHERE id = $${vals.length+1} RETURNING id, name, archived`, [...vals, id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // ================ ORGANIZATIONS + ORG OPENAI KEY ==================
  function requireSuperAdmin(req, res) {
    const u = authFromRequest(req);
    if (!u) { res.status(401).json({ ok:false, error:'unauthorized' }); return null; }
    if (String(u.role||'')==='admin' && u.is_superadmin) return u;
    if (u.is_superadmin) return u;
    res.status(403).json({ ok:false, error:'forbidden' }); return null;
  }
  function requireOrgAdmin(req, res) {
    const u = authFromRequest(req);
    if (!u) { res.status(401).json({ ok:false, error:'unauthorized' }); return null; }
    if (u.is_superadmin) return u;
    if (String(u.role||'')==='admin') return u;
    res.status(403).json({ ok:false, error:'forbidden' }); return null;
  }
  function getUserOrgId(req) { const u = authFromRequest(req); return (u && u.org_id) || null; }

  app.get('/api/orgs', async (req, res) => {
    const u = requireSuperAdmin(req, res); if (!u) return;
    try { const r = await pool.query(`SELECT id, name, (openai_api_key IS NOT NULL AND openai_api_key<>'') AS has_key, created_at, updated_at FROM organizations ORDER BY name ASC`); return res.json({ ok:true, items: r.rows }); } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
  });
  app.get('/api/orgs/me', async (req, res) => {
    if (!requireAuth(req, res)) return;
    try { const id = getUserOrgId(req); if (!id) return res.json({ ok:true, item: null }); const r = await pool.query(`SELECT id, name, (openai_api_key IS NOT NULL AND openai_api_key<>'') AS has_key FROM organizations WHERE id=$1`, [id]); return res.json({ ok:true, item: r.rowCount? r.rows[0]: null }); } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
  });
  app.post('/api/orgs', async (req, res) => {
    const u = requireSuperAdmin(req, res); if (!u) return;
    try { const name = String(req.body?.name||'').trim(); if (!name) return res.status(400).json({ ok:false, error:'bad_request' }); const id = `org_${Math.random().toString(16).slice(2)}`; await pool.query(`INSERT INTO organizations (id, name, created_at, updated_at) VALUES ($1,$2,NOW(),NOW())`, [id, name]); return res.status(201).json({ ok:true, item:{ id, name } }); } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.patch('/api/orgs/:id', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try { const id = String(req.params.id||'').trim(); if (!id) return res.status(400).json({ ok:false, error:'bad_request' }); if (!u.is_superadmin && id !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' }); const name = req.body?.name; if (name == null) return res.status(400).json({ ok:false, error:'bad_request' }); const r = await pool.query(`UPDATE organizations SET name=$1, updated_at=NOW() WHERE id=$2 RETURNING id, name`, [String(name), id]); if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' }); return res.json({ ok:true, item: r.rows[0] }); } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.get('/api/orgs/:id/openai/key', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try { const id = String(req.params.id||'').trim(); if (!id) return res.status(400).json({ ok:false, error:'bad_request' }); if (!u.is_superadmin && id !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' }); const r = await pool.query(`SELECT (openai_api_key IS NOT NULL AND openai_api_key<>'') AS has_key FROM organizations WHERE id=$1`, [id]); if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' }); return res.json({ ok:true, has_key: !!r.rows[0].has_key }); } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/orgs/:id/openai/key', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try { const id = String(req.params.id||'').trim(); const v = String(req.body?.value||'').trim(); if (!u.is_superadmin && id !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' }); await pool.query(`UPDATE organizations SET openai_api_key=$1, updated_at=NOW() WHERE id=$2`, [v||null, id]); return res.json({ ok:true }); } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });
  app.post('/api/orgs/:id/openai/key/clear', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try { const id = String(req.params.id||'').trim(); if (!u.is_superadmin && id !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' }); await pool.query(`UPDATE organizations SET openai_api_key=NULL, updated_at=NOW() WHERE id=$1`, [id]); return res.json({ ok:true }); } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) }); }
  });

  // List agents for an organization
  app.get('/api/orgs/:id/agents', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      if (!u.is_superadmin && id !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' });
      const q = req.query || {};
      const limit = Math.max(1, Math.min(100, Number(q.limit || 50)));
      const after = Math.max(0, Number(q.after || 0));
      const r = await pool.query(`
        SELECT id, name, email, is_active, role, last_login
        FROM agents
        WHERE org_id = $1 AND id > $2
        ORDER BY id ASC
        LIMIT $3
      `, [id, after, limit]);
      const items = r.rows || [];
      const next_after = items.length === limit ? items[items.length - 1].id : null;
      return res.json({ ok:true, items, next_after });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message:e?.message||String(e) });
    }
  });

  // Permissions: list all atomic permissions
  app.get('/api/rbac/permissions', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const r = await pool.query(`SELECT name, COALESCE(description,'') AS description FROM permissions ORDER BY name ASC`);
      // Fallback defaults if table empty
      let items = r.rows || [];
      if (!items.length) {
        items = [
          { name: 'chatbot.read', description: '' },
          { name: 'chatbot.write', description: '' },
          { name: 'prompt.read', description: '' },
          { name: 'prompt.write', description: '' },
          { name: 'mcp.read', description: '' },
          { name: 'mcp.write', description: '' },
          { name: 'files.read', description: '' },
          { name: 'files.write', description: '' },
          { name: 'visitors.read', description: '' },
          { name: 'visitors.write', description: '' },
          { name: 'settings.read', description: '' },
          { name: 'settings.write', description: '' },
        ];
      }
      res.json({ ok:true, items });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });

  // Roles
  app.get('/api/rbac/roles', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const qOrg = String(req.query?.org_id || getUserOrgId(req) || '').trim();
      const params = [];
      let sql = `SELECT id, org_id, name, description, COALESCE(is_system,false) AS is_system, created_at, updated_at FROM roles`;
      if (qOrg) { sql += ` WHERE org_id IS NULL OR org_id = $1`; params.push(qOrg); }
      sql += ` ORDER BY (org_id IS NULL) DESC, name ASC`;
      const r = await pool.query(sql, params);
      res.json({ ok:true, items: r.rows || [] });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.post('/api/rbac/roles', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const name = String(req.body?.name||'').trim();
      const description = (req.body && req.body.description != null) ? String(req.body.description) : null;
      let orgId = String(req.body?.org_id || '').trim();
      if (!u.is_superadmin) orgId = getUserOrgId(req) || '';
      if (!name || !orgId) return res.status(400).json({ ok:false, error:'bad_request' });
      const id = `role_${Math.random().toString(16).slice(2)}`;
      await pool.query(`INSERT INTO roles (id, org_id, name, description, is_system, created_at, updated_at) VALUES ($1,$2,$3,$4,false,NOW(),NOW())`, [id, orgId, name, description]);
      res.status(201).json({ ok:true, item: { id, org_id: orgId, name, description, is_system: false } });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.patch('/api/rbac/roles/:id', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r0 = await pool.query(`SELECT id, org_id, is_system FROM roles WHERE id=$1`, [id]);
      if (!r0.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const row = r0.rows[0];
      if (!u.is_superadmin && row.org_id !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' });
      if (row.is_system) return res.status(400).json({ ok:false, error:'system_role' });
      const allowed = ['name','description'];
      const entries = Object.entries(req.body || {}).filter(([k])=>allowed.includes(k));
      if (!entries.length) return res.status(400).json({ ok:false, error:'bad_request' });
      const sets = entries.map(([k],i)=>`${k} = $${i+1}`);
      const vals = entries.map(([,v])=>v);
      sets.push('updated_at = NOW()');
      const r = await pool.query(`UPDATE roles SET ${sets.join(', ')} WHERE id = $${vals.length+1} RETURNING id, org_id, name, description, is_system`, [...vals, id]);
      res.json({ ok:true, item: r.rows[0] });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.delete('/api/rbac/roles/:id', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      const r0 = await pool.query(`SELECT id, org_id, is_system FROM roles WHERE id=$1`, [id]);
      if (!r0.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const row = r0.rows[0];
      if (row.is_system) return res.status(400).json({ ok:false, error:'system_role' });
      if (!u.is_superadmin && row.org_id !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' });
      await pool.query(`DELETE FROM role_permissions WHERE role_id=$1`, [id]);
      await pool.query(`DELETE FROM assignments WHERE role_id=$1`, [id]);
      await pool.query(`DELETE FROM roles WHERE id=$1`, [id]);
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });

  // Role permissions
  app.get('/api/rbac/role_permissions', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const roleId = String(req.query?.role_id || '').trim();
      if (!roleId) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT permission_name FROM role_permissions WHERE role_id=$1 ORDER BY permission_name ASC`, [roleId]);
      res.json({ ok:true, items: r.rows.map(x=>x.permission_name) });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.post('/api/rbac/role_permissions', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const roleId = String(req.body?.role_id || '').trim();
      const perm = String(req.body?.permission_name || '').trim();
      if (!roleId || !perm) return res.status(400).json({ ok:false, error:'bad_request' });
      await pool.query(`INSERT INTO role_permissions (role_id, permission_name) VALUES ($1,$2) ON CONFLICT DO NOTHING`, [roleId, perm]);
      res.status(201).json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.delete('/api/rbac/role_permissions', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const roleId = String(req.query?.role_id || '').trim();
      const perm = String(req.query?.permission_name || '').trim();
      if (!roleId || !perm) return res.status(400).json({ ok:false, error:'bad_request' });
      await pool.query(`DELETE FROM role_permissions WHERE role_id=$1 AND permission_name=$2`, [roleId, perm]);
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });

  // Users: search helper (by email/name)
  app.get('/api/rbac/users/search', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const q = String(req.query?.q || '').trim().toLowerCase();
      if (!q) return res.json({ ok:true, items: [] });
      const r = await pool.query(`SELECT id, email, name FROM users WHERE lower(email) LIKE $1 OR lower(name) LIKE $1 ORDER BY email ASC LIMIT 50`, [ `%${q}%` ]);
      res.json({ ok:true, items: r.rows || [] });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });

  // Memberships
  app.get('/api/rbac/memberships', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const orgId = String(req.query?.org_id || getUserOrgId(req) || '').trim();
      if (!orgId) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`
        SELECT m.id, m.user_id, m.org_id, m.status, m.joined_at,
               u.email, u.name
          FROM memberships m
          JOIN users u ON u.id = m.user_id
         WHERE m.org_id = $1
         ORDER BY m.joined_at ASC
      `, [orgId]);
      res.json({ ok:true, items: r.rows || [] });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.post('/api/rbac/memberships', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      let orgId = String(req.body?.org_id || '').trim();
      const email = String(req.body?.email || '').trim().toLowerCase();
      let userId = String(req.body?.user_id || '').trim();
      if (!u.is_superadmin) orgId = getUserOrgId(req) || '';
      if (!orgId || (!email && !userId)) return res.status(400).json({ ok:false, error:'bad_request' });
      if (!userId && email) {
        // ensure user exists
        let rU = await pool.query(`SELECT id FROM users WHERE lower(email) = $1 LIMIT 1`, [email]);
        if (!rU.rowCount) {
          // Best-effort: check agents and create a mirror user
          const rA = await pool.query(`SELECT id, name, email, password FROM agents WHERE lower(email) = $1 LIMIT 1`, [email]);
          if (rA.rowCount) {
            const a = rA.rows[0];
            const uid = `usr_${a.id}`;
            await pool.query(`INSERT INTO users (id, email, name, password, created_at, updated_at) VALUES ($1,$2,$3,$4,NOW(),NOW()) ON CONFLICT (id) DO NOTHING`, [uid, email, a.name || email, a.password || null]);
            userId = uid;
          } else {
            // Create a light user without password (for assignment only)
            const uid = `usr_${Math.random().toString(16).slice(2)}`;
            await pool.query(`INSERT INTO users (id, email, name, created_at, updated_at) VALUES ($1,$2,$3,NOW(),NOW())`, [uid, email, email]);
            userId = uid;
          }
        } else {
          userId = rU.rows[0].id;
        }
      }
      const mid = `mem_${Math.random().toString(16).slice(2)}`;
      await pool.query(`INSERT INTO memberships (id, user_id, org_id, status, joined_at) VALUES ($1,$2,$3,'active', NOW()) ON CONFLICT (user_id, org_id) DO NOTHING`, [mid, userId, orgId]);
      const r = await pool.query(`SELECT id, user_id, org_id, status, joined_at FROM memberships WHERE user_id=$1 AND org_id=$2`, [userId, orgId]);
      res.status(201).json({ ok:true, item: r.rows[0] });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.delete('/api/rbac/memberships/:id', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r0 = await pool.query(`SELECT org_id FROM memberships WHERE id=$1`, [id]);
      if (!r0.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const orgId = r0.rows[0].org_id;
      if (!u.is_superadmin && orgId !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' });
      await pool.query(`DELETE FROM assignments WHERE membership_id=$1`, [id]);
      await pool.query(`DELETE FROM memberships WHERE id=$1`, [id]);
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });

  // Assignments: roles per membership
  app.get('/api/rbac/assignments', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const membershipId = String(req.query?.membership_id || '').trim();
      const orgId = String(req.query?.org_id || getUserOrgId(req) || '').trim();
      if (!membershipId && !orgId) return res.status(400).json({ ok:false, error:'bad_request' });
      if (membershipId) {
        const r = await pool.query(`SELECT a.id, a.membership_id, a.role_id, r.name AS role_name FROM assignments a JOIN roles r ON r.id=a.role_id WHERE a.membership_id=$1 ORDER BY r.name ASC`, [membershipId]);
        return res.json({ ok:true, items: r.rows || [] });
      }
      const r = await pool.query(`
        SELECT a.id, a.membership_id, a.role_id, r.name AS role_name
          FROM assignments a
          JOIN roles r ON r.id = a.role_id
          JOIN memberships m ON m.id = a.membership_id
         WHERE a.org_id = $1 AND m.org_id = $1
         ORDER BY r.name ASC
      `, [orgId]);
      res.json({ ok:true, items: r.rows || [] });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.post('/api/rbac/assignments', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const roleId = String(req.body?.role_id || '').trim();
      const membershipId = String(req.body?.membership_id || '').trim();
      if (!roleId || !membershipId) return res.status(400).json({ ok:false, error:'bad_request' });
      const rM = await pool.query(`SELECT id, org_id FROM memberships WHERE id=$1`, [membershipId]);
      if (!rM.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const orgId = rM.rows[0].org_id;
      if (!u.is_superadmin && orgId !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' });
      const rRole = await pool.query(`SELECT id, org_id, is_system FROM roles WHERE id=$1`, [roleId]);
      if (!rRole.rowCount) return res.status(400).json({ ok:false, error:'invalid_role' });
      const rid = `asg_${Math.random().toString(16).slice(2)}`;
      await pool.query(`INSERT INTO assignments (id, membership_id, role_id, org_id, created_at) VALUES ($1,$2,$3,$4,NOW()) ON CONFLICT (membership_id, role_id) DO NOTHING`, [rid, membershipId, roleId, orgId]);
      res.status(201).json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.delete('/api/rbac/assignments/:id', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const id = String(req.params.id||'').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      // Verify org ownership
      const r0 = await pool.query(`SELECT org_id FROM assignments WHERE id=$1`, [id]);
      if (!r0.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const orgId = r0.rows[0].org_id;
      if (!u.is_superadmin && orgId !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' });
      await pool.query(`DELETE FROM assignments WHERE id=$1`, [id]);
      res.json({ ok:true });
    } catch (e) { res.status(500).json({ ok:false, error:'server_error' }); }
  });

  // Memberships per agent (multi-org) — map agent -> users.id = usr_{agent.id}
  app.get('/api/rbac/memberships/user/:agentId', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const agentId = Number(req.params.agentId);
      if (!Number.isFinite(agentId)) return res.status(400).json({ ok:false, error:'bad_request' });
      const uid = `usr_${agentId}`;
      const params = [uid];
      let sql = `SELECT m.id, m.user_id, m.org_id, m.status, m.joined_at, o.name AS org_name
                 FROM memberships m JOIN organizations o ON o.id = m.org_id
                 WHERE m.user_id = $1`;
      if (!u.is_superadmin) { sql += ` AND m.org_id = $2`; params.push(getUserOrgId(req)); }
      sql += ` ORDER BY o.name ASC`;
      const r = await pool.query(sql, params);
      return res.json({ ok:true, items: r.rows || [] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error' }); }
  });
  app.post('/api/rbac/memberships/user/:agentId', async (req, res) => {
    const u = requireOrgAdmin(req, res); if (!u) return;
    try {
      const agentId = Number(req.params.agentId);
      const orgId = String(req.body?.org_id || '').trim();
      if (!Number.isFinite(agentId) || !orgId) return res.status(400).json({ ok:false, error:'bad_request' });
      if (!u.is_superadmin && orgId !== getUserOrgId(req)) return res.status(403).json({ ok:false, error:'forbidden' });
      const uid = `usr_${agentId}`;
      // Ensure users row exists for this agent
      const rUser = await pool.query(`SELECT id FROM users WHERE id=$1`, [uid]);
      if (!rUser.rowCount) {
        const rA = await pool.query(`SELECT id, email, name, password FROM agents WHERE id=$1`, [agentId]);
        if (!rA.rowCount) return res.status(404).json({ ok:false, error:'agent_not_found' });
        const a = rA.rows[0];
        await pool.query(`INSERT INTO users (id, email, name, password, created_at, updated_at) VALUES ($1,$2,$3,$4,NOW(),NOW()) ON CONFLICT (id) DO NOTHING`, [uid, (a.email||'').toLowerCase(), a.name || a.email, a.password || null]);
      }
      const mid = `mem_${Math.random().toString(16).slice(2)}`;
      await pool.query(`INSERT INTO memberships (id, user_id, org_id, status, joined_at) VALUES ($1,$2,$3,'active', NOW()) ON CONFLICT (user_id, org_id) DO NOTHING`, [mid, uid, orgId]);
      const r = await pool.query(`SELECT m.id, m.user_id, m.org_id, m.status, m.joined_at, o.name AS org_name FROM memberships m JOIN organizations o ON o.id=m.org_id WHERE m.user_id=$1 AND m.org_id=$2`, [uid, orgId]);
      return res.status(201).json({ ok:true, item: r.rows[0] || null });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error' }); }
  });

  // Upload files to prompt_config's vector store
  app.post('/api/prompt-configs/:id/files', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT id, name, openai_api_key, vector_store_id FROM prompt_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const pc = r.rows[0];
      let apiKeyUse = (pc.openai_api_key && String(pc.openai_api_key).trim()) || null;
      if (!apiKeyUse) {
        try {
          const oid = getUserOrgId(req);
          if (oid) {
            const rOrg = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]);
            if (rOrg.rowCount) apiKeyUse = (rOrg.rows[0].openai_api_key && String(rOrg.rows[0].openai_api_key).trim()) || null;
          }
        } catch {}
      }
      if (!apiKeyUse) apiKeyUse = getOpenaiApiKey();
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });
      const openai = new OpenAI({ apiKey: apiKeyUse });
      let vectorStoreId = String(pc.vector_store_id || '').trim();
      if (!vectorStoreId) {
        const vs = await openai.vectorStores.create({ name: pc.name || `kb_${pc.id}` });
        vectorStoreId = vs?.id || '';
        if (vectorStoreId) await pool.query(`UPDATE prompt_config SET vector_store_id=$1, updated_at=NOW() WHERE id=$2`, [vectorStoreId, id]);
      }
      if (!vectorStoreId) return res.status(500).json({ ok:false, error:'no_vector_store' });

      const { file_url, filename, content_b64, items } = req.body || {};
      const uploads = [];
      const TMP_PROMPT_DIR = path.join(__dirname, 'tmp_uploads');
      try { fs.mkdirSync(TMP_PROMPT_DIR, { recursive: true }); } catch {}

      const uploadOne = async (payload) => {
        let name = String(payload.filename || '').trim() || 'attachment.txt';
        let dataBuf = null;
        if (payload.content_b64) {
          try { dataBuf = Buffer.from(String(payload.content_b64), 'base64'); } catch {}
        } else if (payload.file_url) {
          const resp = await fetch(String(payload.file_url));
          if (!resp.ok) throw new Error(`download_failed_${resp.status}`);
          const ab = await resp.arrayBuffer();
          dataBuf = Buffer.from(ab);
          if (!payload.filename) {
            try { const u = new URL(String(payload.file_url)); const base = u.pathname.split('/').pop(); if (base) name = base; } catch {}
          }
        }
        if (!dataBuf || !dataBuf.length) throw new Error('no_content');
        // Preserve basename by using unique subfolder
        const sub = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
        const d = path.join(TMP_PROMPT_DIR, sub);
        try { fs.mkdirSync(d, { recursive: true }); } catch {}
        const tmpPath = path.join(d, name);
        await fs.promises.writeFile(tmpPath, dataBuf);
        const stream = fs.createReadStream(tmpPath);
        const up = await openai.files.create({ file: stream, purpose: 'assistants' });
        const fileId = up?.id;
        if (!fileId) throw new Error('upload_failed');
        await openai.vectorStores.files.create(vectorStoreId, { file_id: fileId });
        uploads.push({ filename: name, file_id: fileId, vector_store_id: vectorStoreId });
      };

      if (Array.isArray(items) && items.length) {
        for (const it of items) {
          try { await uploadOne(it || {}); } catch (e) { uploads.push({ error: String(e?.message || e) }); }
        }
      } else {
        try { await uploadOne({ file_url, filename, content_b64 }); } catch (e) { return res.status(400).json({ ok:false, error: 'upload_failed', message: String(e?.message || e) }); }
      }

      res.status(201).json({ ok:true, uploads, vector_store_id: vectorStoreId });
    } catch (e) {
      try { logToFile(`[PROMPT_CONFIG_UPLOAD_ERR] id=${req.params.id} code=${e?.code||''} msg=${e?.message||e}`); } catch {}
      res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });
  app.patch('/api/prompt-configs/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      await ensurePromptVectorIdsColumn();
      await ensurePromptModelColumn();
      const id = String(req.params.id || '').trim();
      const b = req.body || {};
      const allowed = ['name','dev_message','messages','tools','openai_api_key','prompt_id','prompt_version','model','vector_store_id','vector_store_ids'];
      // Coerce messages/tools when they come as strings
      if (Object.prototype.hasOwnProperty.call(b, 'messages')) {
        try {
          const mv = b.messages;
          if (typeof mv === 'string') {
            b.messages = mv.trim() ? JSON.parse(mv) : null;
          }
          if (b.messages && !Array.isArray(b.messages)) b.messages = null;
        } catch { b.messages = null; }
      }
      if (Object.prototype.hasOwnProperty.call(b, 'tools')) {
        try {
          const tv = b.tools;
          if (typeof tv === 'string') {
            b.tools = tv.trim() ? JSON.parse(tv) : null;
          }
          if (b.tools && (Array.isArray(b.tools) || typeof b.tools !== 'object')) b.tools = null;
        } catch { b.tools = null; }
      }
      // Force JSON strings for casts
      if (b.messages != null) {
        try { b.messages = JSON.stringify(b.messages); } catch { b.messages = null; }
      }
      if (b.tools != null) {
        try { b.tools = JSON.stringify(b.tools); } catch { b.tools = null; }
      }
      // Normalize vector_store_ids if present
      if (Object.prototype.hasOwnProperty.call(b, 'vector_store_ids')) {
        try {
          let arr = b.vector_store_ids;
          if (typeof arr === 'string') arr = JSON.parse(arr);
          if (!Array.isArray(arr)) arr = [];
          arr = arr.map((x)=>String(x||'').trim()).filter(Boolean);
          arr = Array.from(new Set(arr));
          b.vector_store_ids = JSON.stringify(arr);
        } catch { b.vector_store_ids = JSON.stringify([]); }
      }
      const entries = Object.entries(b).filter(([k]) => allowed.includes(k));
      try { logToFile(`[PROMPT_CONFIG_UPDATE] id=${id} fields=${entries.map(([k])=>k).join(',')}`); } catch {}
      if (!entries.length) return res.status(400).json({ ok:false, error:'bad_request' });
      const sets = entries.map(([k], i) => {
        if (k === 'messages' || k === 'tools') return `${k} = $${i + 1}::json`;
        if (k === 'vector_store_ids') return `${k} = $${i + 1}::json`;
        return `${k} = $${i + 1}`;
      });
      const vals = entries.map(([, v]) => v);
      sets.push('updated_at = NOW()');
      const r = await pool.query(`UPDATE prompt_config SET ${sets.join(', ')} WHERE id = $${vals.length + 1}
        RETURNING id, name, dev_message, messages, tools, openai_api_key, prompt_id, prompt_version, model, created_at, updated_at`, [...vals, id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      return res.json({ ok:true, item: r.rows[0] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // Convenience ops to add/remove a single vector store ID
  app.post('/api/prompt-configs/:id/vector-stores/link', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables(); await ensurePromptVectorIdsColumn();
      const id = String(req.params.id||'').trim();
      const vs = String(req.body?.id||'').trim();
      if (!id || !vs) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT vector_store_ids FROM prompt_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      let arr = r.rows[0].vector_store_ids; try { if (typeof arr === 'string') arr = JSON.parse(arr); } catch {}
      if (!Array.isArray(arr)) arr = [];
      if (!arr.includes(vs)) arr.push(vs);
      await pool.query(`UPDATE prompt_config SET vector_store_ids=$1::json, updated_at=NOW() WHERE id=$2`, [JSON.stringify(arr), id]);
      return res.json({ ok:true, vector_store_ids: arr });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
  });
  app.post('/api/prompt-configs/:id/vector-stores/unlink', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables(); await ensurePromptVectorIdsColumn();
      const id = String(req.params.id||'').trim();
      const vs = String(req.body?.id||'').trim();
      if (!id || !vs) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT vector_store_ids FROM prompt_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      let arr = r.rows[0].vector_store_ids; try { if (typeof arr === 'string') arr = JSON.parse(arr); } catch {}
      if (!Array.isArray(arr)) arr = [];
      arr = arr.filter((x)=>String(x||'').trim() !== vs);
      await pool.query(`UPDATE prompt_config SET vector_store_ids=$1::json, updated_at=NOW() WHERE id=$2`, [JSON.stringify(arr), id]);
      return res.json({ ok:true, vector_store_ids: arr });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message||String(e) }); }
  });
  app.delete('/api/prompt-configs/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { await ensureTables(); const id = String(req.params.id || '').trim(); await pool.query(`DELETE FROM prompt_config WHERE id=$1`, [id]); return res.json({ ok:true }); }
    catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // List assigned chatbots
  app.get('/api/prompt-configs/:id/chatbots', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      const r = await pool.query(`SELECT id_bot FROM chatbot_config WHERE prompt_config_id = $1`, [id]);
      return res.json({ ok:true, chatbot_ids: r.rows.map(x => x.id_bot) });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // List associated MCP servers for a prompt (with details + tools)
  app.get('/api/prompt-configs/:id/mcp-servers', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(
        `SELECT m.id, m.name, m.kind, m.server_type, m.group_id, g.name AS group_name,
                m.http_base, m.ws_url, m.stream_url, m.sse_url, m.enabled, m.token, m.options
           FROM prompt_config_mcp x
           JOIN mcp_server_config m ON m.id = x.mcp_server_id
           LEFT JOIN mcp_group g ON g.id = m.group_id
          WHERE x.prompt_config_id = $1
          ORDER BY m.updated_at DESC`,
        [id]
      );
      const servers = await Promise.all(
        (r.rows || []).map(async (row) => {
          let tools = [];
          try { tools = await listToolsForClientForServer(row.name); } catch {}
          let options = row.options;
          try { if (typeof options === 'string') options = JSON.parse(options); } catch { options = {}; }
          const allowed_tools = Array.isArray(options?.allowed_tools) ? options.allowed_tools : null;
          return { ...row, options, allowed_tools, tools };
        })
      );
      return res.json({ ok:true, servers });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // List associated MCP2 servers for a prompt (with details + tools)
  app.get('/api/prompt-configs/:id/mcp2-servers', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(
        `SELECT s.id, s.name, s.kind_id, s.type_id, s.http_base, s.ws_url, s.stream_url, s.sse_url, s.enabled, s.token, s.options, s.notes
           FROM prompt_config_mcp2 x
           JOIN mcp2_server s ON s.id = x.mcp2_server_id
          WHERE x.prompt_config_id = $1
          ORDER BY s.updated_at DESC`,
        [id]
      );
      // For each server, attach resolved tool list if available (best-effort via catalog/types)
      const servers = await Promise.all((r.rows || []).map(async (row) => {
        let options = row.options; try { if (typeof options === 'string') options = JSON.parse(options); } catch { options = {}; }
        const allowed_tools = Array.isArray(options?.allowed_tools) ? options.allowed_tools : null;
        // No dedicated tool listing for MCP2 yet; return options + endpoints
        return { ...row, options, allowed_tools };
      }));
      return res.json({ ok:true, servers });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // Assign MCP servers to a prompt
  app.post('/api/prompt-configs/:id/mcp-servers/assign', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      const ids = Array.isArray(req.body?.server_ids) ? req.body.server_ids.map(String) : [];
      if (!id || !ids.length) return res.json({ ok:true, inserted: 0 });
      let inserted = 0;
      for (const sid of ids) {
        try {
          await pool.query(
            `INSERT INTO prompt_config_mcp (prompt_config_id, mcp_server_id, created_at) VALUES ($1,$2,NOW()) ON CONFLICT DO NOTHING`,
            [id, sid]
          );
          inserted++;
        } catch {}
      }
      return res.json({ ok:true, inserted });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // Unassign MCP servers from a prompt
  app.post('/api/prompt-configs/:id/mcp-servers/unassign', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      const ids = Array.isArray(req.body?.server_ids) ? req.body.server_ids.map(String) : [];
      if (!id || !ids.length) return res.json({ ok:true, deleted: 0 });
      const placeholders = ids.map((_, i) => `$${i + 2}`).join(',');
      const q = `DELETE FROM prompt_config_mcp WHERE prompt_config_id = $1 AND mcp_server_id IN (${placeholders})`;
      const r = await pool.query(q, [id, ...ids]);
      return res.json({ ok:true, deleted: r.rowCount || 0 });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // Assign MCP2 servers to a prompt
  app.post('/api/prompt-configs/:id/mcp2-servers/assign', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      const ids = Array.isArray(req.body?.server_ids) ? req.body.server_ids.map(String) : [];
      if (!id || !ids.length) return res.json({ ok:true, inserted: 0 });
      let inserted = 0;
      for (const sid of ids) {
        try {
          await pool.query(
            `INSERT INTO prompt_config_mcp2 (prompt_config_id, mcp2_server_id, created_at) VALUES ($1,$2,NOW()) ON CONFLICT DO NOTHING`,
            [id, sid]
          );
          inserted++;
        } catch {}
      }
      return res.json({ ok:true, inserted });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // Unassign MCP2 servers from a prompt
  app.post('/api/prompt-configs/:id/mcp2-servers/unassign', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      const ids = Array.isArray(req.body?.server_ids) ? req.body.server_ids.map(String) : [];
      if (!id || !ids.length) return res.json({ ok:true, deleted: 0 });
      const placeholders = ids.map((_, i) => `$${i + 2}`).join(',');
      const q = `DELETE FROM prompt_config_mcp2 WHERE prompt_config_id = $1 AND mcp2_server_id IN (${placeholders})`;
      const r = await pool.query(q, [id, ...ids]);
      return res.json({ ok:true, deleted: r.rowCount || 0 });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // Assign / Unassign chatbots
  app.post('/api/prompt-configs/:id/assign', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      const ids = Array.isArray(req.body?.chatbot_ids) ? req.body.chatbot_ids.map(String) : [];
      if (!id || !ids.length) return res.json({ ok:true, updated: 0 });
      const params = [id, ...ids];
      const placeholders = ids.map((_, i) => `$${i + 2}`).join(',');
      const r = await pool.query(`UPDATE chatbot_config SET prompt_config_id = $1, updated_at = NOW() WHERE id_bot IN (${placeholders})`, params);
      return res.json({ ok:true, updated: r.rowCount || 0 });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.post('/api/prompt-configs/:id/unassign', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const ids = Array.isArray(req.body?.chatbot_ids) ? req.body.chatbot_ids.map(String) : [];
      if (!ids.length) return res.json({ ok:true, updated: 0 });
      const placeholders = ids.map((_, i) => `$${i + 1}`).join(',');
      const r = await pool.query(`UPDATE chatbot_config SET prompt_config_id = NULL, updated_at = NOW() WHERE id_bot IN (${placeholders})`, ids);
      return res.json({ ok:true, updated: r.rowCount || 0 });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });

  // One-off test for a prompt_config (no chatbot assignment required)
  app.post('/api/prompt-configs/:id/test', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`SELECT * FROM prompt_config WHERE id=$1 LIMIT 1`, [id]);
      if (!r.rowCount) return res.status(404).json({ ok:false, error:'not_found' });
      const pc = r.rows[0];
      const b = req.body || {};
      const previewOnly = (b.preview === true) || String(req.query?.preview || '').toLowerCase() === 'true';
      const input = (b.input || b.message || '').toString();
      if (!input.trim()) return res.status(400).json({ ok:false, error:'bad_request', message:'input required' });
      let apiKeyUse = (pc.openai_api_key && String(pc.openai_api_key).trim()) || null;
      if (!apiKeyUse) {
        try {
          const oid = getUserOrgId(req);
          if (oid) {
            const rOrg = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]);
            if (rOrg.rowCount) apiKeyUse = (rOrg.rows[0].openai_api_key && String(rOrg.rows[0].openai_api_key).trim()) || null;
          }
        } catch {}
      }
      if (!apiKeyUse) apiKeyUse = getOpenaiApiKey();
      if (!apiKeyUse && !previewOnly) return res.status(400).json({ ok:false, error:'openai_key_missing' });
      // Build MCP tool entries from linked servers for this prompt
      let extraTools = [];
      try {
        const rs = await pool.query(
          `SELECT m.id, m.name, m.kind, m.http_base, m.ws_url, m.stream_url, m.sse_url, m.token, m.enabled, m.options
             FROM prompt_config_mcp x
             JOIN mcp_server_config m ON m.id = x.mcp_server_id
            WHERE x.prompt_config_id = $1
            ORDER BY m.updated_at DESC`,
          [id]
        );
        // Build absolute base from forwarded headers (works behind proxy)
        const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
        const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
        const proto = (fproto || req.protocol || 'http').toLowerCase();
        const host = (fhost || req.headers.host || 'localhost').trim();
        const base = `${proto}://${host}`;

        extraTools = (rs.rows || []).map((row) => {
          let options = row.options; try { if (typeof options === 'string') options = JSON.parse(options); } catch { options = {}; }
          const allowed = Array.isArray(options?.allowed_tools) ? options.allowed_tools : undefined;
          const label = row.name || (row.kind || 'mcp');
          const pref = (options && options.server_url_pref === 'sse') ? 'sse' : 'stream';
          // Fallback to inferred URL when explicit stream/sse URLs are not set
          let serverUrl = pref === 'stream'
            ? (row.stream_url || row.sse_url || `${base}/mcp/${encodeURIComponent(label)}/stream`)
            : (row.sse_url || row.stream_url || `${base}/mcp/${encodeURIComponent(label)}/events`);
          const tool = { type: 'mcp', server_label: label };
          // Append token in query for better client compatibility
          if (row.token) { try { const u = new URL(serverUrl, base); if (!u.searchParams.get('token')) u.searchParams.set('token', row.token); serverUrl = u.toString(); } catch {} }
          if (serverUrl) tool.server_url = serverUrl;
          if (row.token) tool.authorization = row.token;
          if (allowed && allowed.length) tool.allowed_tools = allowed;
          tool.require_approval = 'never';
          return tool;
        }).filter((t) => t.server_url);
        // Also include MCP2 servers linked to this prompt
        try {
          const rs2 = await pool.query(
            `SELECT s.id, s.name, s.http_base, s.ws_url, s.stream_url, s.sse_url, s.token, s.enabled, s.options
               FROM prompt_config_mcp2 x
               JOIN mcp2_server s ON s.id = x.mcp2_server_id
              WHERE x.prompt_config_id = $1
              ORDER BY s.updated_at DESC`,
            [id]
          );
          const more = (rs2.rows || []).map((srow) => {
            let options = srow.options; try { if (typeof options === 'string') options = JSON.parse(options); } catch { options = {}; }
            const allowed = Array.isArray(options?.allowed_tools) ? options.allowed_tools : undefined;
            const pref = (options && options.server_url_pref === 'sse') ? 'sse' : 'stream';
            let serverUrl = '';
            if (pref === 'stream') {
              serverUrl = srow.stream_url || deriveMcp2Endpoints(srow.http_base, srow.name).stream_url || `${base}/mcp2/${encodeURIComponent(srow.name)}/stream`;
            } else {
              serverUrl = srow.sse_url || deriveMcp2Endpoints(srow.http_base, srow.name).sse_url || `${base}/mcp2/${encodeURIComponent(srow.name)}/events`;
            }
            if (srow.token) { try { const u = new URL(serverUrl, base); if (!u.searchParams.get('token')) u.searchParams.set('token', srow.token); serverUrl = u.toString(); } catch {} }
            const tool = { type: 'mcp', server_label: srow.name };
            if (serverUrl) tool.server_url = serverUrl;
            if (srow.token) tool.authorization = srow.token;
            if (allowed && allowed.length) tool.allowed_tools = allowed;
            tool.require_approval = 'never';
            return tool;
          }).filter((t) => t.server_url);
          extraTools = [...extraTools, ...more];
        } catch {}
      } catch {}

      const t0 = Date.now();
      const effectiveModel = String(pc.model || b.model || process.env.OPENAI_MODEL || 'gpt-4o-mini');
      const seedMessagesEff = Array.isArray(pc.messages) ? pc.messages : undefined;
      const instructionsEff = pc.dev_message || undefined;
      const toolsEff = pc.tools && typeof pc.tools === 'object' ? pc.tools : {};
      const vectorStoreIdEff = pc.vector_store_id || undefined;
      const vectorStoreIdsEff = Array.isArray(pc.vector_store_ids) ? pc.vector_store_ids : undefined;
      const hasVectorsEff = (!!vectorStoreIdEff) || (Array.isArray(vectorStoreIdsEff) && vectorStoreIdsEff.length > 0);
      const toolsFileSearchEff = !!(toolsEff.file_search || hasVectorsEff);
      const { text, raw, request, request_body } = await respondWithPrompt({
        apiKey: apiKeyUse,
        // Prefer the saved prompt_config model over any request override
        model: effectiveModel,
        promptId: pc.prompt_id || undefined,
        promptVersion: pc.prompt_version || undefined,
        input,
        seedMessages: seedMessagesEff,
        instructions: instructionsEff,
        toolsFileSearch: toolsFileSearchEff,
        toolsCodeInterpreter: !!toolsEff.code_interpreter,
        webSearchEnabled: !!toolsEff.web_search,
        webSearchAllowedDomains: Array.isArray(toolsEff.web_search_allowed_domains) ? toolsEff.web_search_allowed_domains : undefined,
        vectorStoreId: vectorStoreIdEff,
        vectorStoreIds: vectorStoreIdsEff,
        extraTools,
      }, {
        includeToolsOnGpt5: ((String(effectiveModel||'').toLowerCase().startsWith('gpt-5')) && (toolsFileSearchEff || hasVectorsEff)),
        buildOnly: previewOnly,
      });
      const ms = Date.now() - t0;
      if (!previewOnly) {
        // Persist test record for retry history
        try {
          const idRec = (()=>{ try { return `pth_${crypto.randomBytes(8).toString('hex')}`; } catch { return `pth_${Date.now()}`; } })();
          await pool.query(
            `INSERT INTO prompt_test_history (id, prompt_config_id, input, output, request, response, ms, created_at)
             VALUES ($1,$2,$3,$4,$5,$6,$7,NOW())`,
            [idRec, id, input, text || null, (request_body || request) ? JSON.stringify(request_body || request) : null, raw ? JSON.stringify(raw) : null, ms]
          );
        } catch {}
      }
      // Summarize effective config used for transparency in the tester
      const mcpSummary = (Array.isArray(extraTools) ? extraTools : []).map(t => ({
        type: t.type,
        server_label: t.server_label,
        server_url: t.server_url,
        allowed_tools: Array.isArray(t.allowed_tools) ? t.allowed_tools : undefined,
        require_approval: t.require_approval || undefined,
      }));
      // Build a display-friendly request that mirrors Effective config when previewing (esp. for gpt-5)
      const request_display = (() => {
        try {
          const base = { ...(request_body || {}), model: effectiveModel };
          if (pc.prompt_id) base.prompt_id = pc.prompt_id;
          base.prompt_version = pc.prompt_version || null;
          if (Array.isArray(vectorStoreIdsEff) && vectorStoreIdsEff.length) base.vector_store_ids = vectorStoreIdsEff;
          if (vectorStoreIdEff && !base.vector_store_id) base.vector_store_id = vectorStoreIdEff;
          // Mirror boolean tools flags for transparency
          if (toolsEff && typeof toolsEff === 'object') {
            base.tools = {
              file_search: !!toolsEff.file_search,
              code_interpreter: !!toolsEff.code_interpreter,
              web_search: !!toolsEff.web_search,
            };
          }
          return base;
        } catch { return request_body || request || {}; }
      })();
      return res.json({
        ok: true,
        text,
        raw,
        request,
        request_body,
        request_display,
        effective: {
          model: effectiveModel,
          prompt_id: pc.prompt_id || null,
          prompt_version: pc.prompt_version || null,
          instructions: instructionsEff || null,
          messages_count: Array.isArray(seedMessagesEff) ? seedMessagesEff.length : 0,
          tools: {
            file_search: toolsFileSearchEff,
            code_interpreter: !!toolsEff.code_interpreter,
            web_search: !!toolsEff.web_search,
            web_search_allowed_domains: Array.isArray(toolsEff.web_search_allowed_domains) ? toolsEff.web_search_allowed_domains : undefined,
          },
          vector_store_id: vectorStoreIdEff || null,
          vector_store_ids: Array.isArray(vectorStoreIdsEff) ? vectorStoreIdsEff : undefined,
          mcp_tools: mcpSummary.length ? mcpSummary : undefined,
        },
        ms,
        seconds: ms/1000,
      });
    } catch (e) {
      // Also record failed tests in history
      try {
        const dbg = getOpenaiDebug() || {};
        const ms = (typeof t0 !== 'undefined') ? (Date.now() - t0) : null;
        const idRec = (()=>{ try { return `pth_${crypto.randomBytes(8).toString('hex')}`; } catch { return `pth_${Date.now()}`; } })();
        const reqBody = dbg.lastRequestBody || null;
        const resp = { ok:false, error:'server_error', message: e?.message || String(e), retry: dbg.lastRetryBody || null, continue: dbg.lastContinue || null };
        try {
          await pool.query(
            `INSERT INTO prompt_test_history (id, prompt_config_id, input, output, request, response, ms, created_at)
             VALUES ($1,$2,$3,$4,$5,$6,$7,NOW())`,
            [idRec, String(req.params.id||'').trim(), (req.body?.input||req.body?.message||'').toString(), null, reqBody ? JSON.stringify(reqBody) : null, JSON.stringify(resp), ms]
          );
        } catch {}
        return res.status(500).json({
          ok: false,
          error:'server_error',
          message: e?.message || String(e),
          request: dbg.lastRequestBody || null,
          request_body: dbg.lastRequestBody || null,
          retry: dbg.lastRetryBody || null,
          continue: dbg.lastContinue || null,
        });
      } catch {
        return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
      }
    }
  });
  // List recent tests for a prompt
  app.get('/api/prompt-configs/:id/tests', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const lim = Math.max(1, Math.min(200, Number(req.query.limit || 20)));
      const r = await pool.query(
        `SELECT id, input, output, request, response, ms, created_at FROM prompt_test_history
         WHERE prompt_config_id=$1 ORDER BY created_at DESC LIMIT $2`, [id, lim]
      );
      return res.json({ ok:true, items: r.rows || [] });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  // Delete a single test record
  app.delete('/api/prompt-configs/:id/tests/:testId', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      const id = String(req.params.id || '').trim();
      const testId = String(req.params.testId || '').trim();
      if (!id || !testId) return res.status(400).json({ ok:false, error:'bad_request' });
      const r = await pool.query(`DELETE FROM prompt_test_history WHERE id=$1 AND prompt_config_id=$2`, [testId, id]);
      return res.json({ ok:true, deleted: r.rowCount || 0 });
    } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
  });
  app.get('/mcp/admin/openai/prompts/debug', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { res.json({ ok: true, ...(getPromptsDebug() || {}) }); }
    catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });
  app.get('/mcp/mcp-dev-prestashop/admin/openai/prompts/debug', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try { res.json({ ok: true, ...(getPromptsDebug() || {}) }); }
    catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });

  // List recent OpenAI models (sorted by created desc, top 10)
  app.get('/api/openai/models', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      // Prefer org key, then server key
      let apiKeyUse = null;
      try {
        const oid = getUserOrgId(req);
        if (oid) {
          const rOrg = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1 LIMIT 1`, [oid]);
          if (rOrg.rowCount) apiKeyUse = (rOrg.rows[0].openai_api_key && String(rOrg.rows[0].openai_api_key).trim()) || null;
        }
      } catch {}
      if (!apiKeyUse) apiKeyUse = getOpenaiApiKey() || process.env.OPENAI_API_KEY || null;
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });
      const data = await openaiHttp('/models', { method:'GET', apiKey: apiKeyUse });
      const arr = Array.isArray(data?.data) ? data.data : [];
      const items = arr
        .map(m => ({ id: String(m?.id||''), created: Number(m?.created||0) }))
        .filter(x => x.id)
        .sort((a,b)=> (b.created||0) - (a.created||0))
        .slice(0, 10);
      return res.json({ ok:true, items });
    } catch (e) {
      return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
    }
  });

// ---- Admin: MCP-DEV-Prestashop token/public-base ----
app.post('/api/admin/mcp-dev-prestashop/token/regenerate', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const tok = crypto.randomBytes(24).toString('hex');
    await setSetting('MCP_DEV_PRESTA_TOKEN', tok);
    mcpDevPrestaToken = tok;
    try { await pool.query(`INSERT INTO mcp_server_config (id, name, kind, token, created_at, updated_at) VALUES ($1,'MCP-DEV-Prestashop','dev-prestashop',$2,NOW(),NOW()) ON CONFLICT (name) DO UPDATE SET token=EXCLUDED.token, updated_at=NOW()`, [makeMcpServerId(), tok]); } catch {}
    res.json({ ok:true, token: tok });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});
app.get('/api/admin/mcp-dev-prestashop/token', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    await loadMcpDevPrestaTokenFromDb();
    res.json({ ok:true, token: getMcpDevPrestaToken() || '' });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/admin/mcp-dev-prestashop/token/disable', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    await setSetting('MCP_DEV_PRESTA_TOKEN', '');
    mcpDevPrestaToken = '';
    try { await pool.query(`UPDATE mcp_server_config SET token=NULL, updated_at=NOW() WHERE name='MCP-DEV-Prestashop'`); } catch {}
    res.json({ ok:true });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/admin/mcp-dev-prestashop/token', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const t = String(req.body?.token || '').trim();
    await setSetting('MCP_DEV_PRESTA_TOKEN', t);
    mcpDevPrestaToken = t;
    try { await pool.query(`INSERT INTO mcp_server_config (id, name, kind, token, created_at, updated_at) VALUES ($1,'MCP-DEV-Prestashop','dev-prestashop',$2,NOW(),NOW()) ON CONFLICT (name) DO UPDATE SET token=EXCLUDED.token, updated_at=NOW()`, [makeMcpServerId(), t || null]); } catch {}
    res.json({ ok:true, token: t });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});
app.get('/api/admin/mcp-dev-prestashop/public-base', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try { res.json({ ok:true, value: getMcpDevPrestaPublicBase() || null }); } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});
app.post('/api/admin/mcp-dev-prestashop/public-base', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const v = String(req.body?.value || '').trim();
    await setSetting('MCP_DEV_PRESTA_PUBLIC_BASE', v);
    mcpDevPrestaPublicBase = v;
    try {
      const seedDisabled = /^(1|true|yes)$/i.test(String(process.env.DISABLE_LEGACY_MCP_SEED || ''));
      if (!seedDisabled) {
        await pool.query(`INSERT INTO mcp_server_config (id, name, kind, http_base, created_at, updated_at) VALUES ($1,'MCP-DEV-Prestashop','dev-prestashop',$2,NOW(),NOW()) ON CONFLICT (name) DO UPDATE SET http_base=EXCLUDED.http_base, updated_at=NOW()`, [makeMcpServerId(), v || null]);
      }
    } catch {}
    res.json({ ok:true, value: v || null });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Enable/disable admin endpoints
app.get('/api/admin/mcp-dev/enabled', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try { await loadMcpDevEnabledFromDb(); res.json({ ok:true, enabled: getMcpDevEnabled() }); } catch (e) { res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
});
app.post('/api/admin/mcp-dev/enabled', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try { const enabled = !!req.body?.enabled; await setSetting('MCP_DEV_ENABLED', enabled ? 'true' : 'false'); mcpDevEnabled = enabled; res.json({ ok:true, enabled }); } catch (e) { res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
});
app.get('/api/admin/mcp-dev-prestashop/enabled', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try { await loadMcpDevPrestaEnabledFromDb(); res.json({ ok:true, enabled: getMcpDevPrestaEnabled() }); } catch (e) { res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
});
app.post('/api/admin/mcp-dev-prestashop/enabled', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try { const enabled = !!req.body?.enabled; await setSetting('MCP_DEV_PRESTA_ENABLED', enabled ? 'true' : 'false'); mcpDevPrestaEnabled = enabled; res.json({ ok:true, enabled }); } catch (e) { res.status(500).json({ ok:false, error:'server_error', message:String(e?.message||e) }); }
});

const CC_KEYS = {
  apiKey: 'COMPANY_CHAT_OPENAI_API_KEY',
  model: 'COMPANY_CHAT_OPENAI_MODEL',
  promptId: 'COMPANY_CHAT_OPENAI_PROMPT_ID',
  promptVersion: 'COMPANY_CHAT_OPENAI_PROMPT_VERSION',
  approval: 'COMPANY_CHAT_APPROVAL',
  promptConfigId: 'COMPANY_CHAT_PROMPTCFG_ID',
  botIds: 'COMPANY_CHAT_BOT_IDS',
};

app.get('/api/company-chat/config', async (req, res) => {
  const u = authFromRequest(req);
  const isAdmin = !!(u && String(u.role||'')==='admin');
  try {
    const [k, m, p, v, a, pcfg, botsRaw] = await Promise.all([
      getSetting(CC_KEYS.apiKey),
      getSetting(CC_KEYS.model),
      getSetting(CC_KEYS.promptId),
      getSetting(CC_KEYS.promptVersion),
      getSetting(CC_KEYS.approval),
      getSetting(CC_KEYS.promptConfigId),
      getSetting(CC_KEYS.botIds),
    ]);
    let chatbot_ids = [];
    try { if (botsRaw && typeof botsRaw === 'string') { const arr = JSON.parse(botsRaw); if (Array.isArray(arr)) chatbot_ids = arr.map(String); } } catch {}
    res.json({ ok: true, model: m || '', prompt_id: p || '', prompt_version: v || '', approval: (a || 'never'), prompt_cfg_id: pcfg || '', chatbot_ids, api_key: isAdmin ? (k || '') : (k ? '__set__' : '') });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/company-chat/config', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const b = req.body || {};
    if (b.api_key !== undefined) await setSetting(CC_KEYS.apiKey, String(b.api_key||''));
    if (b.model !== undefined) await setSetting(CC_KEYS.model, String(b.model||''));
    if (b.prompt_id !== undefined) await setSetting(CC_KEYS.promptId, String(b.prompt_id||''));
    if (b.prompt_version !== undefined) await setSetting(CC_KEYS.promptVersion, String(b.prompt_version||''));
    if (b.prompt_cfg_id !== undefined) await setSetting(CC_KEYS.promptConfigId, String(b.prompt_cfg_id||''));
    if (b.chatbot_ids !== undefined) {
      try {
        const arr = Array.isArray(b.chatbot_ids) ? b.chatbot_ids.map(String) : [];
        await setSetting(CC_KEYS.botIds, JSON.stringify(arr));
      } catch { await setSetting(CC_KEYS.botIds, '[]'); }
    }
    if (b.approval !== undefined) {
      const v = String(b.approval||'').toLowerCase();
      const norm = (v === 'never' || v === 'always') ? v : 'never';
      await setSetting(CC_KEYS.approval, norm);
    }
    res.json({ ok: true });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// ---- Company Chat: PrestaShop config (base URL + API key)
const PRESTA_KEYS = {
  base: 'COMPANY_CHAT_PRESTA_BASE',
  apiKey: 'COMPANY_CHAT_PRESTA_KEY',
};

app.get('/api/company-chat/prestashop/config', async (req, res) => {
  const u = authFromRequest(req);
  const isAdmin = !!(u && String(u.role||'')==='admin');
  try {
    const [base, key] = await Promise.all([
      getSetting(PRESTA_KEYS.base),
      getSetting(PRESTA_KEYS.apiKey),
    ]);
    res.json({ ok: true, base: base || '', api_key: isAdmin ? (key || '') : (key ? '__set__' : '') });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/company-chat/prestashop/config', async (req, res) => {
  if (!requireAdminAuth(req, res)) return;
  try {
    const b = req.body || {};
    if (b.base !== undefined) await setSetting(PRESTA_KEYS.base, String(b.base||''));
    if (b.api_key !== undefined) await setSetting(PRESTA_KEYS.apiKey, String(b.api_key||''));
    res.json({ ok: true });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Test PrestaShop connection (admin only)
app.post('/api/company-chat/prestashop/test', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const b = req.body || {};
    const [savedBase, savedKey] = await Promise.all([
      getSetting(PRESTA_KEYS.base),
      getSetting(PRESTA_KEYS.apiKey),
    ]);
    const envBase = process.env.PRESTASHOP_BASE_URL || '';
    const envKey = process.env.PRESTASHOP_API_KEY || '';
    const base = String(b.base || savedBase || envBase || '').trim();
    const key = String(b.api_key || savedKey || envKey || '').trim();
    if (!base || !key) return res.status(400).json({ ok:false, error:'missing_config', message:'Base or API key missing' });

    const asApi = base.endsWith('/api') ? base : `${base.replace(/\/$/, '')}/api`;
    const tryFetch = async (url) => {
      const f = (globalThis.fetch || (await import('node-fetch')).default);
      const ctrl = new AbortController();
      const t = setTimeout(() => ctrl.abort('timeout'), 10000);
      try {
        const r = await f(url, {
          headers: {
            Accept: 'application/json',
            Authorization: `Basic ${Buffer.from(`${key}:`).toString('base64')}`,
          },
          signal: ctrl.signal,
        });
        const txt = await r.text().catch(()=> '');
        return { status: r.status, ok: r.ok, body: txt.slice(0, 400), type: r.headers.get('content-type') || '' };
      } finally {
        clearTimeout(t);
      }
    };

    const t0 = Date.now();
    // Try API root first
    let first = await tryFetch(`${asApi}?ws_key=${encodeURIComponent(key)}&output_format=JSON`);
    if (first.ok) {
      const ms = Date.now() - t0;
      return res.json({ ok:true, ms, via:'root', status:first.status, content_type:first.type });
    }
    // Then try a resource with limit=1
    const resources = ['products','customers','orders'];
    for (const rsc of resources) {
      const resp = await tryFetch(`${asApi}/${rsc}?ws_key=${encodeURIComponent(key)}&output_format=JSON&limit=1`);
      if (resp.ok) {
        const ms = Date.now() - t0;
        return res.json({ ok:true, ms, via:rsc, status:resp.status, content_type:resp.type });
      }
    }
    const ms = Date.now() - t0;
    return res.status(400).json({ ok:false, error:'connect_failed', ms, first: { status:first.status, body:first.body } });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/company-chat/respond', async (req, res) => {
  try {
    const t0 = Date.now();
    const b = req.body || {};
    let [apiKey, modelDef, pid, pver, savedApproval, savedPromptCfgId, savedBotIdsRaw] = await Promise.all([
      getSetting(CC_KEYS.apiKey),
      getSetting(CC_KEYS.model),
      getSetting(CC_KEYS.promptId),
      getSetting(CC_KEYS.promptVersion),
      getSetting(CC_KEYS.approval),
      getSetting(CC_KEYS.promptConfigId),
      getSetting(CC_KEYS.botIds),
    ]);
    // Allow per-call override of chatbot_ids
    try {
      if (Array.isArray(b?.chatbot_ids)) savedBotIdsRaw = JSON.stringify(b.chatbot_ids);
    } catch {}
    // Fallback to Automation Suite > Conversation Hub selection
    if (!savedBotIdsRaw) {
      try {
        const hubRaw = await getSetting('conversation_hub_bots');
        const j = hubRaw ? JSON.parse(hubRaw) : null;
        const ids = j && Array.isArray(j.ids) ? j.ids.map(String) : [];
        if (ids.length) savedBotIdsRaw = JSON.stringify(ids);
      } catch {}
    }
    // Fallbacks from Prompt Configuration or selected Chatbots
    let promptCfgRow = null;
    let derivedPromptCfgId = String(b.prompt_cfg_id || savedPromptCfgId || '').trim();
    let botModel = '';
    try {
      if (!derivedPromptCfgId && savedBotIdsRaw) {
        try {
          const arr = JSON.parse(savedBotIdsRaw);
          if (Array.isArray(arr) && arr.length) {
            const firstBot = String(arr[0] || '').trim();
            if (firstBot) {
              const rBot = await pool.query(`SELECT prompt_config_id, openai_api_key, prompt_id, prompt_version, model FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [firstBot]);
              if (rBot.rowCount) {
                const row = rBot.rows[0];
                if (row.prompt_config_id) derivedPromptCfgId = row.prompt_config_id;
                // If no prompt_config_id, we will still be able to fallback to row.openai_api_key/prompt_id/version
                if (!promptCfgRow && row.openai_api_key) promptCfgRow = { openai_api_key: row.openai_api_key, prompt_id: row.prompt_id, prompt_version: row.prompt_version };
                if (row.model) botModel = String(row.model);
              }
            }
          }
        } catch {}
      }
      if (derivedPromptCfgId) {
        const rPC = await pool.query(`SELECT id, name, tools, openai_api_key, prompt_id, prompt_version, model FROM prompt_config WHERE id=$1 LIMIT 1`, [derivedPromptCfgId]);
        if (rPC.rowCount) promptCfgRow = rPC.rows[0];
      }
    } catch {}

    // API key precedence: per-call > Company Chat saved > Prompt Config > env
    const apiKeyUse = String(b.api_key || apiKey || (promptCfgRow && promptCfgRow.openai_api_key) || process.env.OPENAI_API_KEY || '').trim();
    if (!apiKeyUse) return res.status(400).json({ ok:false, error:'bad_request', message:'OpenAI API key not set (derive it from the selected Prompt or Chatbot configuration)' });
    // Model precedence: per-call > prompt_config.model > chatbot-config model > Company Chat saved > env default
    const model = String(b.model || (promptCfgRow && promptCfgRow.model) || botModel || modelDef || process.env.OPENAI_MODEL || 'gpt-4o-mini');
    // Prompt precedence: enforce using the Prompt tied to the selected Chatbot/Prompt Config first.
    // Never fallback to global server defaults here.
    const promptId = String((promptCfgRow && promptCfgRow.prompt_id) || b.prompt_id || pid || '').trim();
    const promptVersion = (promptCfgRow && promptCfgRow.prompt_version) || b.prompt_version || pver || undefined;
    if (!promptId) return res.status(400).json({ ok:false, error:'prompt_missing', message:'No Prompt ID resolved from the selected Chatbot/Prompt configuration or request.' });
    const transport = String(b.transport || '').toLowerCase();
    let requireApproval = String(b.requireApproval || savedApproval || 'never').toLowerCase();
    if (requireApproval === 'auto') requireApproval = 'never';
    let sessionId = String(b.sessionId || b.session_id || req.headers['x-company-chat-session'] || '').trim();
    if (!sessionId) sessionId = (globalThis.crypto?.randomUUID?.() || `${Date.now()}-${Math.random().toString(16).slice(2)}`);

    // Build input from conversational messages
    const messages = Array.isArray(b.messages) ? b.messages : [];
    let input = '';
    if (messages.length) {
      const parts = [];
      for (const m of messages) {
        const role = String(m?.role||'user');
        const text = String(m?.content||'');
        if (text) parts.push(`${role}: ${text}`);
      }
      input = parts.join('\n');
    } else {
      input = String(b.input || b.content || '').trim();
    }
    if (!input) return res.status(400).json({ ok:false, error:'bad_request', message:'input/messages required' });

    // Persist the last user message (if provided)
    try {
      const lastUser = messages.length ? messages[messages.length-1] : null;
      const utext = (lastUser && String(lastUser.content||'').trim()) || (String(b.input||b.content||'').trim());
      if (utext) {
        await pool.query(`CREATE TABLE IF NOT EXISTS company_chat_messages (
          session_id TEXT NOT NULL,
          role TEXT NOT NULL,
          content TEXT NOT NULL,
          created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
          response_id TEXT
        )`);
        // Ensure new column exists if table was created previously without it
        await pool.query(`ALTER TABLE company_chat_messages ADD COLUMN IF NOT EXISTS response_id TEXT`);
        await pool.query(`INSERT INTO company_chat_messages (session_id, role, content) VALUES ($1,$2,$3)`, [sessionId, 'user', utext]);
      }
    } catch (e) { logToFile(`company_chat persist user msg error: ${e?.message||e}`); }

    let outText, raw, request, requestBody;
    if (transport === 'mcp') {
      const proto = (req.headers['x-forwarded-proto']?.toString().split(',')[0] || req.protocol || 'http').toLowerCase();
      const host = (req.headers['x-forwarded-host']?.toString().split(',')[0] || req.headers.host || 'localhost').trim();
      const base = `${proto}://${host}`;
      // Prefer MCP servers linked to the selected Prompt Config (if any)
      const promptCfgIdPrimary = String(derivedPromptCfgId || '').trim();
      let extraTools = [];
      const added = new Set();
      async function addServersForPromptId(pid) {
        if (!pid) return;
        try {
          const r = await pool.query(
            `SELECT m.name, m.token, m.options, m.stream_url, m.sse_url
               FROM prompt_config_mcp x JOIN mcp_server_config m ON m.id = x.mcp_server_id
              WHERE x.prompt_config_id = $1`,
            [pid]
          );
          for (const row of r.rows || []) {
            const name = String(row.name || '').trim();
            if (!name || added.has(name)) continue;
            added.add(name);
            let opts = row.options;
            try { if (typeof opts === 'string') opts = JSON.parse(opts); } catch { opts = {}; }
            const allowed = Array.isArray(opts?.allowed_tools) ? opts.allowed_tools : undefined;
            const pref = (opts && opts.server_url_pref === 'sse') ? 'sse' : 'stream';
            let url = pref === 'stream'
              ? (row.stream_url || row.sse_url || `${base}/mcp/${encodeURIComponent(name)}/stream`)
              : (row.sse_url || row.stream_url || `${base}/mcp/${encodeURIComponent(name)}/stream`);
            // Append token in query for clients that don't propagate Authorization
            if (row.token) { try { const u = new URL(url, base); if (!u.searchParams.get('token')) u.searchParams.set('token', row.token); url = u.toString(); } catch {} }
            extraTools.push({ type:'mcp', server_url: url, server_label: name, authorization: row.token || undefined, allowed_tools: allowed, require_approval: (requireApproval || 'always') });
          }
        } catch {}
      }
      if (promptCfgIdPrimary) await addServersForPromptId(promptCfgIdPrimary);
      // Also add servers from all selected Chatbots' prompt/local prompt
      if (savedBotIdsRaw) {
        try {
          const arr = JSON.parse(savedBotIdsRaw);
          if (Array.isArray(arr) && arr.length) {
            for (const botId of arr.map(String)) {
              if (!botId) continue;
              try {
                const r = await pool.query(`SELECT prompt_config_id, mcp_server_name, mcp_tools, mcp_token FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [botId]);
                if (!r.rowCount) continue;
                const row = r.rows[0];
                await addServersForPromptId(String(row.prompt_config_id || ''));
                const name = String(row.mcp_server_name || '').trim();
                if (name && !added.has(name)) {
                  added.add(name);
                  // Load server config for URLs and default allowed tools
                  let sseUrl = '', streamUrl = '', optsServer = {};
                  try {
                    const r2 = await pool.query(`SELECT sse_url, stream_url, options FROM mcp_server_config WHERE name=$1 LIMIT 1`, [name]);
                    if (r2.rowCount) {
                      sseUrl = r2.rows[0].sse_url || '';
                      streamUrl = r2.rows[0].stream_url || '';
                      let o = r2.rows[0].options; try { if (typeof o === 'string') o = JSON.parse(o); } catch { o = {}; }
                      optsServer = o || {};
                    }
                  } catch {}
                  let allowed = row.mcp_tools;
                  if (typeof allowed === 'string') { try { allowed = JSON.parse(allowed); } catch { allowed = null; } }
                  if (!Array.isArray(allowed)) {
                    const def = Array.isArray(optsServer?.allowed_tools) ? optsServer.allowed_tools : null;
                    allowed = def || undefined;
                  }
                  let requireApprovalNorm = (requireApproval || 'always').toLowerCase();
                  if (requireApprovalNorm === 'auto') requireApprovalNorm = 'never';
                  if (!['always','never'].includes(requireApprovalNorm)) requireApprovalNorm = 'always';
                  const pref = (optsServer && optsServer.server_url_pref === 'sse') ? 'sse' : 'stream';
                  let serverUrl = pref === 'stream'
                    ? (streamUrl || sseUrl || `${base}/mcp/${encodeURIComponent(name)}/stream`)
                    : (sseUrl || streamUrl || `${base}/mcp/${encodeURIComponent(name)}/events`);
                  if (row.mcp_token) { try { const u = new URL(serverUrl, base); if (!u.searchParams.get('token')) u.searchParams.set('token', row.mcp_token); serverUrl = u.toString(); } catch {} }
                  extraTools.push({ type:'mcp', server_url: serverUrl, server_label: name, authorization: row.mcp_token || undefined, allowed_tools: allowed, require_approval: requireApprovalNorm });
                }
              } catch {}
            }
          }
        } catch {}
      }
      // If no MCP servers are resolved, proceed without tools (log for diagnostics)
      if (!extraTools.length) {
        try {
          const selected = (()=>{ try{ return JSON.parse(savedBotIdsRaw||'[]'); } catch { return []; } })();
          logToFile(`company_chat: no MCP servers resolved; proceeding without MCP tools. chatbots=${JSON.stringify(selected)} promptCfgId=${promptCfgIdPrimary||''}`);
        } catch {}
      }
      const labels = extraTools.map(t => t.server_label || '').filter(Boolean);
      const hasPresta = labels.some(l => /presta/i.test(l));
      const list = labels.length ? labels.join(', ') : 'your MCP servers';
      // Detect web_search flag from prompt config when available
      let webSearchFlag = false;
      try {
        let t = promptCfgRow?.tools;
        if (typeof t === 'string') { try { t = JSON.parse(t); } catch { t = null; } }
        if (t && typeof t === 'object' && t.web_search) webSearchFlag = true;
      } catch {}
      try { logToFile(`company_chat: MCP servers resolved: [${labels.join(', ')}] for promptCfgId=${promptCfgIdPrimary||''}`); } catch {}
      // Match Chatbot Test payload: no extra instructions or text block; rely on Prompt/Tools only
      let webDomains = undefined;
      try { let t = promptCfgRow?.tools; if (typeof t === 'string') t = JSON.parse(t); if (t && Array.isArray(t.web_search_allowed_domains)) webDomains = t.web_search_allowed_domains; } catch {}
      const r = await respondWithPrompt({ apiKey: apiKeyUse, model, promptId, promptVersion, input, extraTools, webSearchEnabled: !!webSearchFlag, webSearchAllowedDomains: webDomains, vectorStoreIds: Array.isArray(promptCfgRow?.vector_store_ids) ? promptCfgRow.vector_store_ids : undefined, vectorStoreId: promptCfgRow?.vector_store_id || undefined });
      outText = r.text; raw = r.raw; request = r.request; requestBody = r.request_body;
      try {
        const reqLog = JSON.stringify(safeObj(request, 4000));
        logToFile(`company_chat: request to openai session=${sessionId} transport=mcp payload=${reqLog}`);
      } catch {}
    } else {
      // Company-specific function tools (PrestaShop + demo stubs) + standard tools
      const companyFunctionTools = [
        // PrestaShop tools
        { type:'function', function: { name:'ps_get_customer', description:'PrestaShop: get customer by email or id', parameters: { type:'object', properties:{ email:{ type:'string', description:'Customer email' }, id:{ anyOf:[{type:'integer'},{type:'string'}], description:'Customer ID' } }, additionalProperties:false } } },
        { type:'function', function: { name:'ps_search_customers', description:'PrestaShop: search customers by name/email', parameters: { type:'object', properties:{ name:{ type:'string' }, firstname:{ type:'string' }, lastname:{ type:'string' }, email:{ type:'string' }, limit:{ type:'integer', minimum:1, maximum:50, default:5 } }, additionalProperties:false } } },
        { type:'function', function: { name:'ps_get_order', description:'PrestaShop: get order by id or reference', parameters: { type:'object', properties:{ id:{ anyOf:[{type:'integer'},{type:'string'}], description:'Order ID' }, reference:{ type:'string', description:'Order reference' } }, additionalProperties:false } } },
        { type:'function', function: { name:'ps_list_orders', description:'PrestaShop: list orders by customer or filters', parameters: { type:'object', properties:{ customer_id:{ anyOf:[{type:'integer'},{type:'string'}] }, reference:{ type:'string' }, date_from:{ type:'string', description:'YYYY-MM-DD' }, date_to:{ type:'string', description:'YYYY-MM-DD' }, limit:{ type:'integer', minimum:1, maximum:50, default:10 } }, additionalProperties:false } } },
        { type:'function', function: { name:'ps_get_product', description:'PrestaShop: get product by id or reference', parameters: { type:'object', properties:{ id:{ anyOf:[{type:'integer'},{type:'string'}], description:'Product ID' }, reference:{ type:'string', description:'Product reference' } }, additionalProperties:false } } },
        { type:'function', function: { name:'ps_find_product', description:'PrestaShop: find products by name (wildcard) or reference', parameters: { type:'object', properties:{ name:{ type:'string', description:'Name contains' }, reference:{ type:'string', description:'Exact reference' }, limit:{ type:'integer', minimum:1, maximum:50, default:5 } }, additionalProperties:false } } },
        { type:'function', function: { name:'ps_get_stock', description:'PrestaShop: get stock by product id', parameters: { type:'object', properties:{ product_id:{ anyOf:[{type:'integer'},{type:'string'}], description:'Product ID' } }, required:['product_id'], additionalProperties:false } } },

        // Demo company tools (stubs)
        { type:'function', function: { name:'company_find_customer', description:'Find a customer by email', parameters: { type:'object', properties:{ email:{ type:'string' } }, required:['email'] } } },
        { type:'function', function: { name:'company_get_order', description:'Get order details by order_id', parameters: { type:'object', properties:{ order_id:{ type:'string' } }, required:['order_id'] } } },
        { type:'function', function: { name:'company_revenue_summary', description:'Get revenue summary (period)', parameters: { type:'object', properties:{ period:{ type:'string', enum:['today','7d','30d','qtd','ytd'] } }, required:['period'] } } },
      ];
      // Heuristics to nudge tool usage (match DEV behavior)
      let toolChoiceName = undefined;
      let extraHint = '';
      try {
        // Manual override (if ever provided by UI)
        const manualTool = String(b.toolChoiceName || '').trim();
        let manualArgs = b.toolArgs;
        if (typeof manualArgs === 'string') { try { manualArgs = JSON.parse(manualArgs); } catch { manualArgs = undefined; } }
        if (manualTool) {
          toolChoiceName = manualTool;
          if (manualArgs && typeof manualArgs === 'object' && !Array.isArray(manualArgs)) {
            extraHint = `\n\nForce: Call ${manualTool} with ${JSON.stringify(manualArgs)} and return only the JSON.`;
          } else {
            extraHint = `\n\nForce: Call ${manualTool} and return only the JSON.`;
          }
        } else {
          // Detect a UUID visitor_id or "last visitor" intent in the input
          const m = input.match(/[\"'\s]visitor[_-]?id[\"'\s:]*[\"']?([0-9a-fA-F-]{36})[\"']?/i) || input.match(/\b([0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[1-5][0-9a-fA-F]{3}-[89abAB][0-9a-fA-F]{3}-[0-9a-fA-F]{12})\b/);
          if (m && m[1]) {
            toolChoiceName = 'postgresql.get_visitor';
            const vid = m[1];
            extraHint = `\n\nForce: Call postgresql.get_visitor with {"visitorId":"${vid}"} and return only the JSON.`;
          } else if (/\b(last\s+visitor|dernier\s+visiteur|ultimo\s+visitante)\b/i.test(input)) {
            toolChoiceName = 'postgresql.list_recent_visitors';
            extraHint = `\n\nForce: Call postgresql.list_recent_visitors with {"limit":1} and summarize the row.`;
          }
        }
      } catch {}

      const r = await respondWithPromptAndTools({
        apiKey: apiKeyUse,
        model,
        promptId,
        promptVersion,
        input,
        // Encourage the model to use company + MCP function tools
        instructions:
          (b.instructions && String(b.instructions)) ||
          `You have function tools to access livechat, PrestaShop, and company data.\n\n- postgresql.get_visitor({ visitorId: string }) → returns a visitor row by id.\n- postgresql.list_recent_visitors({ limit?: number }) → returns recent visitors.\n- postgresql.send_agent_message({ visitorId: string, message: string }) → posts a message.\n- list_files(), fetch_document({ id }), search_documents({ query }), openai_upload_file(...) for files.\n- ps_search_customers({ name?|firstname?|lastname?|email?, limit? }) → find customers.\n- ps_get_customer({ email? string, id? number|string }) → fetch one customer.\n- ps_list_orders({ customer_id?|reference?|date_from?|date_to?, limit? }) → list orders.\n- ps_get_order({ id? number|string, reference? string }) → fetch one order.\n- ps_get_product({ id? number|string, reference? string }) → PrestaShop product.\n- ps_find_product({ name? string, reference? string, limit? number }) → list products.\n- ps_get_stock({ product_id: number|string }) → stock entries for product.\n- company_find_customer({ email }), company_get_order({ order_id }), company_revenue_summary({ period }) for demo internal data.\n\nWhen asked about products, customers, or orders, prefer the PrestaShop tools. If a name is provided (e.g., “Olivier Michaud”), search customers by name, then fetch their orders by id. Return concise, structured answers. If PrestaShop is not configured, briefly inform the user.` + extraHint,
        functionTools: [...(MCP.toFunctionTools()||[]), ...companyFunctionTools],
        toolChoiceName,
        onToolCall: async ({ name, arguments: args }) => {
          const ctx = { id_bot: 'company_chat', session: { authed: true } };
          // ----- PrestaShop integration -----
          if (name.startsWith('ps_')) {
            try {
              const [base, key] = await Promise.all([
                getSetting(PRESTA_KEYS.base),
                getSetting(PRESTA_KEYS.apiKey),
              ]);
              const envBase = process.env.PRESTASHOP_BASE_URL || '';
              const envKey = process.env.PRESTASHOP_API_KEY || '';
              const prestaBase = String(base || envBase || '').trim();
              const prestaKey = String(key || envKey || '').trim();
              if (!prestaBase || !prestaKey) {
                return { ok:false, error:'prestashop_not_configured', message:'PrestaShop base/key missing. Set them in /api/company-chat/prestashop/config or .env.' };
              }
              const presta = createPrestaClient({ baseURL: prestaBase, apiKey: prestaKey });
              if (name === 'ps_get_customer') {
                const email = args?.email ? String(args.email).trim() : '';
                const id = args?.id != null ? String(args.id).trim() : '';
                let data;
                if (email) data = await presta.getCustomerByEmail(email);
                else if (id) data = await presta.getCustomer(id);
                else return { ok:false, error:'bad_args', message:'email or id required' };
                const arr = normalizePrestaCollection(data, 'customers');
                return { ok:true, count: arr.length, customers: arr };
              }
          if (name === 'ps_search_customers') {
            const limit = Number(args?.limit || 5) || 5;
            const email = args?.email ? String(args.email).trim() : '';
            const firstname = args?.firstname ? String(args.firstname).trim() : '';
            const lastname = args?.lastname ? String(args.lastname).trim() : '';
            const full = args?.name ? String(args.name).trim() : '';
            const data = await presta.searchCustomers({ email, firstname, lastname, name: full, limit });
            const arr = normalizePrestaCollection(data, 'customers');
            return { ok:true, count: arr.length, customers: arr };
          }
          if (name === 'ps_get_order') {
            const id = args?.id != null ? String(args.id).trim() : '';
            const ref = args?.reference ? String(args.reference).trim() : '';
            let data;
            if (id) data = await presta.getOrder(id);
            else if (ref) data = await presta.getOrderByReference(ref);
            else return { ok:false, error:'bad_args', message:'id or reference required' };
            const arr = normalizePrestaCollection(data, 'orders');
            return { ok:true, count: arr.length, orders: arr };
          }
          if (name === 'ps_list_orders') {
            const customer_id = args?.customer_id != null ? String(args.customer_id).trim() : '';
            const reference = args?.reference ? String(args.reference).trim() : '';
            const date_from = args?.date_from ? String(args.date_from).trim() : '';
            const date_to = args?.date_to ? String(args.date_to).trim() : '';
            const limit = Number(args?.limit || 10) || 10;
            const data = await presta.listOrders({ customerId: customer_id, reference, dateFrom: date_from, dateTo: date_to, limit });
            const arr = normalizePrestaCollection(data, 'orders');
            return { ok:true, count: arr.length, orders: arr };
          }
              if (name === 'ps_get_product') {
                const id = args?.id != null ? String(args.id).trim() : '';
                const reference = args?.reference ? String(args.reference).trim() : '';
                let data;
                if (id) data = await presta.getProduct(id);
                else if (reference) data = await presta.getProductByReference(reference);
                else return { ok:false, error:'bad_args', message:'id or reference required' };
                const arr = normalizePrestaCollection(data, 'products');
                return { ok:true, count: arr.length, products: arr };
              }
              if (name === 'ps_find_product') {
                const reference = args?.reference ? String(args.reference).trim() : '';
                const nameQ = args?.name ? String(args.name).trim() : '';
                const limit = Number(args?.limit || 5) || 5;
                let data;
                if (reference) data = await presta.getProductByReference(reference);
                else if (nameQ) data = await presta.findProductsByName(nameQ, limit);
                else return { ok:false, error:'bad_args', message:'name or reference required' };
                const arr = normalizePrestaCollection(data, 'products');
                // Provide a thin projection for brevity if many
                const compact = arr.slice(0, limit).map(p => pick(p, ['id', 'reference', 'price', 'weight', 'active', 'id_manufacturer', 'id_category_default', 'name', 'description_short']));
                return { ok:true, count: arr.length, products: compact };
              }
              if (name === 'ps_get_stock') {
                const productId = args?.product_id != null ? String(args.product_id).trim() : '';
                if (!productId) return { ok:false, error:'bad_args', message:'product_id required' };
                const data = await presta.getStockByProductId(productId);
                const arr = normalizePrestaCollection(data, 'stock_availables');
                return { ok:true, count: arr.length, stock: arr };
              }
            } catch (e) {
              return { ok:false, error:'prestashop_error', message: e?.message || String(e) };
            }
          }
          // Company-specific stubs
          if (name === 'company_find_customer') {
            const email = String(args?.email||'');
            return { ok:true, customer:{ id:'C123', email, name:'Acme Co.' } };
          }
          if (name === 'company_get_order') {
            const orderId = String(args?.order_id||'');
            return { ok:true, order:{ id: orderId, total: 199.9, status:'shipped' } };
          }
          if (name === 'company_revenue_summary') {
            const period = String(args?.period||'today');
            return { ok:true, period, revenue: 12345.67 };
          }
          return await MCP.run(name, args, ctx);
        },
      });
      outText = r.text; raw = r.raw; request = r.request; requestBody = r.request_body;
      try {
        const reqLog = JSON.stringify(safeObj(request, 4000));
        logToFile(`company_chat: request to openai session=${sessionId} transport=function-tools payload=${reqLog}`);
      } catch {}
      if (!outText) {
        try {
          const outs = Array.isArray(request?.tool_outputs) ? request.tool_outputs : [];
          if (outs.length) {
            const last = outs[outs.length - 1];
            const rawOut = last?.output;
            if (typeof rawOut === 'string') {
              try {
                const parsed = JSON.parse(rawOut);
                outText = typeof parsed === 'string' ? parsed : JSON.stringify(parsed, null, 2);
              } catch {
                outText = rawOut;
              }
            }
          }
        } catch {}
      }
    }
    // Log OpenAI response (truncated for safety)
    try {
      const summary = {
        id: raw?.id || null,
        model: raw?.model || null,
        text_len: (outText || '').length,
        usage: raw?.usage || undefined,
        status: raw?.status || undefined,
      };
      const rawLog = JSON.stringify(safeObj(raw, 3000));
      logToFile(`company_chat: response from openai session=${sessionId} summary=${JSON.stringify(summary)} raw=${rawLog}`);
    } catch {}

    // Persist assistant reply (store OpenAI response id when available)
    const responseId = raw?.id || null;
    try {
      if (outText) {
        await pool.query(`ALTER TABLE company_chat_messages ADD COLUMN IF NOT EXISTS response_id TEXT`);
        await pool.query(`INSERT INTO company_chat_messages (session_id, role, content, response_id) VALUES ($1,$2,$3,$4)`, [sessionId, 'assistant', outText, responseId]);
      }
    } catch (e) { logToFile(`company_chat persist assistant msg error: ${e?.message||e}`); }

    const ms = Date.now() - t0;
    res.json({ ok:true, sessionId, text: outText, request, request_body: requestBody || null, raw, response_id: responseId, ms, seconds: ms/1000 });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// List sessions
app.get('/api/company-chat/sessions', async (req, res) => {
  try {
    const limit = Math.max(1, Math.min(200, Number(req.query.limit || 50)));
    await pool.query(`CREATE TABLE IF NOT EXISTS company_chat_messages (
      session_id TEXT NOT NULL,
      role TEXT NOT NULL,
      content TEXT NOT NULL,
      created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
      response_id TEXT
    )`);
    await pool.query(`ALTER TABLE company_chat_messages ADD COLUMN IF NOT EXISTS response_id TEXT`);
    const q = await pool.query(`SELECT session_id, MIN(created_at) AS first_seen, MAX(created_at) AS last_seen, COUNT(*) AS message_count
      FROM company_chat_messages
      GROUP BY session_id
      ORDER BY last_seen DESC
      LIMIT $1`, [limit]);
    res.json({ ok:true, sessions: q.rows });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Messages for a session
app.get('/api/company-chat/sessions/:id/messages', async (req, res) => {
  try {
    const id = String(req.params.id||'').trim(); if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
    const q = await pool.query(`SELECT role, content, created_at, response_id FROM company_chat_messages WHERE session_id=$1 ORDER BY created_at ASC LIMIT 1000`, [id]);
    res.json({ ok:true, messages: q.rows });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Delete a session (all messages, and any feedback if present)
app.delete('/api/company-chat/sessions/:id', async (req, res) => {
  try {
    const id = String(req.params.id||'').trim();
    if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
    await pool.query(`CREATE TABLE IF NOT EXISTS company_chat_messages (
      session_id TEXT NOT NULL,
      role TEXT NOT NULL,
      content TEXT NOT NULL,
      created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
      response_id TEXT
    )`);
    const delMsg = await pool.query(`DELETE FROM company_chat_messages WHERE session_id=$1`, [id]);
    try {
      await pool.query(`CREATE TABLE IF NOT EXISTS company_chat_feedback (
        session_id TEXT NOT NULL,
        msg_index INTEGER NOT NULL,
        rating TEXT NOT NULL,
        created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
      )`);
      await pool.query(`DELETE FROM company_chat_feedback WHERE session_id=$1`, [id]);
    } catch {}
    return res.json({ ok:true, deleted: delMsg.rowCount || 0 });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Simple feedback capture for assistant messages (optional)
app.post('/api/company-chat/feedback', async (req, res) => {
  try {
    const b = req.body || {};
    const session_id = String(b.sessionId || b.session_id || '').trim();
    const msg_index = Number.isFinite(Number(b.index)) ? Number(b.index) : null;
    const rating = String(b.rating || '').toLowerCase();
    if (!session_id || msg_index == null || !['up','down'].includes(rating)) {
      return res.status(400).json({ ok:false, error:'bad_request' });
    }
    await pool.query(`CREATE TABLE IF NOT EXISTS company_chat_feedback (
      session_id TEXT NOT NULL,
      msg_index INTEGER NOT NULL,
      rating TEXT NOT NULL,
      created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    )`);
    await pool.query(`INSERT INTO company_chat_feedback (session_id, msg_index, rating) VALUES ($1,$2,$3)`, [session_id, msg_index, rating]);
    res.json({ ok:true });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/admin/openai/key', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const v = String(req.body?.value || '').trim();
    await setSetting('OPENAI_API_KEY', v);
    openaiApiKey = v; process.env.OPENAI_API_KEY = v;
    res.json({ ok: true, value: v || null });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});
  app.post('/api/admin/openai/key/clear', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await setSetting('OPENAI_API_KEY', '');
      openaiApiKey = ''; process.env.OPENAI_API_KEY = '';
      res.json({ ok: true, value: null });
    } catch (e) {
      res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
    }
  });

  // Manually trigger DB migrations (admin only)
  app.post('/api/admin/migrations/run', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      await ensureTables();
      return res.json({ ok: true, message: 'Migrations applied' });
    } catch (e) {
      try { logToFile(`❌ ensureTables (manual) failed: ${e?.code || ''} ${e?.message || e}`); } catch {}
      return res.status(500).json({ ok: false, error: 'migrations_failed', message: e?.message || String(e) });
    }
  });

// ---- Admin: Database connection (save/test) ----
// Note: Changing DB connection requires a server restart to apply.
app.get('/api/admin/db/connection', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const savedUrl = await getSetting('DATABASE_URL');
    const savedSsl = await getSetting('PGSSL');
    const envUrl = process.env.DATABASE_URL || '';
    const envSsl = process.env.PGSSL || '';
    const database_url = (savedUrl ?? envUrl) || '';
    const pgssl = (savedSsl ?? envSsl ?? '').toString();
    res.json({ ok: true, database_url, pgssl, note: 'Saving requires server restart to take effect.' });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/admin/db/connection', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const database_url = String(req.body?.database_url || '').trim();
    const pgssl = String(req.body?.pgssl ?? '').trim();
    await setSetting('DATABASE_URL', database_url);
    await setSetting('PGSSL', pgssl);
    // Optionally reflect in env for scripts spawned from this process
    process.env.DATABASE_URL = database_url;
    process.env.PGSSL = pgssl;
    res.json({ ok: true, database_url, pgssl, note: 'Saved. Restart server to apply.' });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/admin/db/connection/test', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const database_url = String(req.body?.database_url || '').trim();
    const pgsslRaw = String(req.body?.pgssl ?? '').trim().toLowerCase();
    const ssl = pgsslRaw === 'true' ? { rejectUnauthorized: false } : false;
    const testPool = createPool({ connectionString: database_url, ssl });
    const t0 = Date.now();
    const r = await testPool.query('SELECT NOW() as now');
    await testPool.end().catch(()=>{});
    const ms = Date.now() - t0;
    res.json({ ok: true, ms, now: r?.rows?.[0]?.now || null });
  } catch (e) {
    res.status(400).json({ ok: false, error: 'db_connect_failed', message: e?.message || String(e) });
  }
});

// ---- Admin: Development panel note (server-side) ----
app.get('/api/admin/dev/note', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const v = await getSetting('DEV_PANEL_NOTE');
    res.json({ ok: true, value: v || '' });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});
app.post('/api/admin/dev/note', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const v = String(req.body?.value ?? '');
    await setSetting('DEV_PANEL_NOTE', v);
    res.json({ ok: true, value: v });
  } catch (e) {
    res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) });
  }
});

// --- Minimal Messages endpoint (Responses API + Prompt-only) ---
// Usage: POST /messages { content: "..." }
// Env required: OPENAI_API_KEY, PROMPT_ID (and optional PROMPT_VERSION)
app.post("/messages", async (req, res) => {
  try {
    const input = String(
      req.body?.content ?? req.body?.message ?? req.body?.input ?? ""
    ).trim();
    if (!input) return res.status(400).json({ error: "bad_request", message: "content required" });

    let apiKey = process.env.OPENAI_API_KEY || "";
    if (!apiKey) apiKey = (await getSetting('OPENAI_API_KEY')) || "";
    let promptId = process.env.PROMPT_ID || process.env.OPENAI_PROMPT_ID || "";
    if (!promptId) promptId = (await getSetting('PROMPT_ID')) || "";
    let promptVersion = process.env.PROMPT_VERSION || process.env.OPENAI_PROMPT_VERSION || undefined;
    if (!promptVersion) promptVersion = await getSetting('PROMPT_VERSION');
    if (!apiKey) return res.status(400).json({ error: "bad_request", message: "OPENAI_API_KEY missing" });
    if (!promptId) return res.status(400).json({ error: "bad_request", message: "PROMPT_ID missing" });

    const t0 = Date.now();
    const { text, request } = await respondWithPrompt({
      apiKey,
      model: String(req.body?.model || req.query?.model || "").trim() || undefined,
      promptId,
      promptVersion,
      input,
    });
    const ms = Date.now() - t0;
    res.json({ content: text, text, request, ms, seconds: ms/1000 });
  } catch (e) {
    logToFile(`❌ POST /messages error: ${e.message}`);
    res.status(500).json({ error: "server_error", message: e.message });
  }
});

// Prompt-only runner: accepts promptId/promptVersion and optional input, but does not require it
// Usage: POST /messages/prompt-only { promptId?: string, promptVersion?: string|number, input?: string, model?: string }
app.post("/messages/prompt-only", async (req, res) => {
  try {
    const body = req.body || {};

    let apiKey = process.env.OPENAI_API_KEY || "";
    if (!apiKey) apiKey = (await getSetting('OPENAI_API_KEY')) || "";
    if (!apiKey) return res.status(400).json({ error: 'bad_request', message: 'OPENAI_API_KEY missing' });

    // Allow both flat fields and { prompt: { id, version } } shape
    let promptId = body.promptId || body.prompt_id || body.prompt?.id || process.env.PROMPT_ID || process.env.OPENAI_PROMPT_ID || (await getSetting('PROMPT_ID')) || "";
    let promptVersion = body.promptVersion || body.prompt_version || body.prompt?.version || process.env.PROMPT_VERSION || process.env.OPENAI_PROMPT_VERSION || (await getSetting('PROMPT_VERSION')) || undefined;
    if (!promptId) return res.status(400).json({ error: 'bad_request', message: 'PROMPT_ID missing' });

    const model = String(body.model || req.query?.model || process.env.OPENAI_MODEL || 'gpt-4o-mini');
    const input = typeof body.input === 'string' ? body.input : '';

    const t0 = Date.now();
    const { text, request } = await respondWithPrompt({
      apiKey,
      model,
      promptId,
      promptVersion,
      input,
    });
    const ms = Date.now() - t0;
    res.json({ ok: true, text, request, ms, seconds: ms/1000 });
  } catch (e) {
    logToFile(`? POST /messages/prompt-only error: ${e.message}`);
    res.status(500).json({ error: 'server_error', message: e?.message || String(e) });
  }
});

// Messages endpoint with MCP function-tools enabled (DEV helper)
// Usage: POST /messages/tools { content: "...", model?: "gpt-..." }
app.post("/messages/tools", async (req, res) => {
  try {
    const input = String(
      req.body?.content ?? req.body?.message ?? req.body?.input ?? ""
    ).trim();
    if (!input) return res.status(400).json({ error: "bad_request", message: "content required" });

    let apiKey = process.env.OPENAI_API_KEY || "";
    if (!apiKey) apiKey = (await getSetting('OPENAI_API_KEY')) || "";
    let promptId = process.env.PROMPT_ID || process.env.OPENAI_PROMPT_ID || "";
    if (!promptId) promptId = (await getSetting('PROMPT_ID')) || "";
    let promptVersion = process.env.PROMPT_VERSION || process.env.OPENAI_PROMPT_VERSION || undefined;
    if (!promptVersion) promptVersion = await getSetting('PROMPT_VERSION');
    if (!apiKey) return res.status(400).json({ error: "bad_request", message: "OPENAI_API_KEY missing" });
    if (!promptId) return res.status(400).json({ error: "bad_request", message: "PROMPT_ID missing" });

    // Determine effective model (always include one)
    const effectiveModel = String(
      (req.body?.model || req.query?.model || process.env.OPENAI_MODEL || "gpt-4o-mini")
    );
    try { logToFile(`[messages/tools] model=${effectiveModel}`); } catch {}

    const functionTools = MCP.toFunctionTools();

    // Optional: force a specific tool call (manual or heuristic)
    let toolChoiceName = undefined;
    let extraHint = '';
    const manualTool = String(req.body?.toolChoiceName || req.query?.tool || '').trim();
    let manualArgs = req.body?.toolArgs;
    if (typeof manualArgs === 'string') { try { manualArgs = JSON.parse(manualArgs); } catch { manualArgs = undefined; } }
    if (manualTool) {
      toolChoiceName = manualTool;
      if (manualArgs && typeof manualArgs === 'object' && !Array.isArray(manualArgs)) {
        extraHint = `\n\nForce: Call ${manualTool} with ${JSON.stringify(manualArgs)} and return only the JSON.`;
      } else {
        extraHint = `\n\nForce: Call ${manualTool} and return only the JSON.`;
      }
    } else if (req.body?.forceTools) {
      // Detect a UUID visitor_id in input
      const m = input.match(/[\"'\s]visitor[_-]?id[\"'\s:]*[\"']?([0-9a-fA-F-]{36})[\"']?/i) || input.match(/\b([0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[1-5][0-9a-fA-F]{3}-[89abAB][0-9a-fA-F]{3}-[0-9a-fA-F]{12})\b/);
      if (m && m[1]) {
        toolChoiceName = 'postgresql.get_visitor';
        const vid = m[1];
        extraHint = `\n\nForce: Call postgresql.get_visitor with {"visitorId":"${vid}"} and return only the JSON.`;
      } else if (/\b(last\s+visitor|dernier\s+visiteur|ultimo\s+visitante)\b/i.test(input)) {
        toolChoiceName = 'postgresql.list_recent_visitors';
        extraHint = `\n\nForce: Call postgresql.list_recent_visitors with {"limit":1} and summarize the row.`;
      }
    }

    // MCP transport mode (OpenAI MCP tool) — bypass function-tools path
    try {
      const transport = String(req.body?.transport || req.query?.transport || '').toLowerCase();
      if (transport === 'mcp' || req.body?.mcpTool === true) {
        const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
        const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
        const proto = (fproto || req.protocol || 'http').toLowerCase();
        const host = (fhost || req.headers.host || 'localhost').trim();
        const base = `${proto}://${host}`;
        const server_url = `${base}/mcp-dev/stream`;
        const token = getMcpDevToken() || '';
        let allowed = [];
        try { allowed = (MCP.tools() || []).map(t => t.name).filter(Boolean); } catch {}
        // Normalize approval policy: allow 'always' | 'auto' | 'never'
        let requireApproval = String(req.body?.requireApproval || 'always').toLowerCase();
        if (requireApproval === 'auto') requireApproval = 'never';
        if (!['always','never'].includes(requireApproval)) requireApproval = 'always';
      const extraTools = [{
        type: 'mcp',
        server_url,
        server_label: 'stream',
        authorization: token || undefined,
        allowed_tools: allowed,
        require_approval: requireApproval,
      }];
        const t0 = Date.now();
        const { text: t, raw: r, request: q } = await respondWithPrompt({
          apiKey,
          model: effectiveModel,
          promptId,
          promptVersion,
          input,
          responseFormat: 'text',
          extraTools,
        });
        const jsonOnlyM = !!req.body?.jsonOnly;
        const contentOutM = jsonOnlyM ? '' : (t || '');
        const ms = Date.now() - t0;
        return res.json({ content: contentOutM, text: contentOutM, raw: r, request: q, ms, seconds: ms/1000 });
      }
    } catch (e) { logToFile(`mcp-transport error: ${e?.message || e}`); }

    const t0 = Date.now();
    const { text, raw, request } = await respondWithPromptAndTools({
      apiKey,
      model: effectiveModel,
      promptId,
      promptVersion,
      input,
      // Nudge the model to use function tools for DB queries (+ optional force hint)
      instructions: `You have function tools to access the livechat database and MCP files.\n\n- postgresql.get_visitor({ visitorId: string }) → returns a visitor row by id.\n- postgresql.list_recent_visitors({ limit?: number }) → returns recent visitors.\n- postgresql.send_agent_message({ visitorId: string, message: string }) → posts a message.\n- list_files(), fetch_document({ id }), search_documents({ query }), openai_upload_file(...) for files.\n\nWhen the user asks anything about visitors, visits, messages, or files, call the appropriate tool instead of guessing. If the user mentions a visitor_id, call postgresql.get_visitor with that id and return the JSON result. Keep answers concise.` + extraHint,
      functionTools,
      toolChoiceName,
      onToolCall: async ({ name, arguments: args }) => {
        const ctx = { id_bot: 'mcp_dev', session: { authed: true } };
        return await MCP.run(name, args, ctx);
      },
    });
    const jsonOnly = !!req.body?.jsonOnly;
    let contentOut = jsonOnly ? '' : (text || '');
    if (!contentOut) {
      try {
        const outs = Array.isArray(request?.tool_outputs) ? request.tool_outputs : [];
        if (outs.length) {
          const last = outs[outs.length - 1];
          const rawOut = last?.output;
          if (typeof rawOut === 'string') {
            try {
              const parsed = JSON.parse(rawOut);
              contentOut = typeof parsed === 'string' ? parsed : JSON.stringify(parsed, null, 2);
            } catch {
              contentOut = rawOut;
            }
          }
        }
      } catch {}
    }
    const ms = Date.now() - t0;
    res.json({ content: contentOut, text: contentOut, raw, request, ms, seconds: ms/1000 });
  } catch (e) {
    logToFile(`❌ POST /messages/tools error: ${e.message}`);
    res.status(500).json({ error: "server_error", message: e.message });
  }
});

// Suggest an AI draft for the latest visitor message using bot config (Prompt-only)
app.post("/api/assistant/draft", async (req, res) => {
  try {
    const b = req.body || {};
    const visitorId = String(b.visitorId || "").trim();
    if (!visitorId) return res.status(400).json({ ok: false, error: "bad_request", message: "visitorId required" });

    // Resolve chatbot id: explicit external chatbot_id -> mapping table -> visitor.assistant_id map -> shop/lang fallback
    let botId = null;
    const extId = String(b.chatbot_id || '').trim();
    if (extId) {
      try { await ensureHubBotMapTable(); const mr = await pool.query(`SELECT id_bot FROM hub_bot_map WHERE assistant_id_ext=$1 LIMIT 1`, [extId]); if (mr.rowCount) botId = mr.rows[0].id_bot; } catch {}
      if (!botId) { try { const chk = await pool.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [extId]); if (chk.rowCount) botId = extId; } catch {} }
    }
    if (!botId) {
      const vrow = await pool.query(
        `SELECT shop_name, lang_iso, assistant_id, chatbot_id FROM visitors WHERE (visitor_id = $1 OR id = $1) LIMIT 1`,
        [visitorId]
      );
      const shop = vrow.rows?.[0]?.shop_name || null;
      const lang = vrow.rows?.[0]?.lang_iso || null;
      const chatbotExt = vrow.rows?.[0]?.chatbot_id || null;
      const assistantExt = vrow.rows?.[0]?.assistant_id || null;
      // Prefer visitor.chatbot_id (external) if set
      if (chatbotExt && !botId) {
        try { await ensureHubBotMapTable(); const mrv = await pool.query(`SELECT id_bot FROM hub_bot_map WHERE assistant_id_ext=$1 LIMIT 1`, [chatbotExt]); if (mrv.rowCount) botId = mrv.rows[0].id_bot; } catch {}
        if (!botId) { try { const chk2 = await pool.query(`SELECT 1 FROM chatbot_config WHERE id_bot=$1 LIMIT 1`, [chatbotExt]); if (chk2.rowCount) botId = chatbotExt; } catch {} }
      }
      // Then fallback to visitor.assistant_id if present
      if (!botId && assistantExt) {
        try { await ensureHubBotMapTable(); const mr2 = await pool.query(`SELECT id_bot FROM hub_bot_map WHERE assistant_id_ext=$1 LIMIT 1`, [assistantExt]); if (mr2.rowCount) botId = mr2.rows[0].id_bot; } catch {} }
      // Finally, use shop/lang fallback
      if (!botId) {
        if (!shop || !lang) return res.status(400).json({ ok: false, error: "no_bot_context", message: "shop_name/lang_iso missing for visitor" });
        botId = makeBotId(shop, lang);
      }
    }
    const cr = await pool.query(`SELECT * FROM chatbot_config WHERE id_bot = $1 LIMIT 1`, [botId]);
    if (!cr.rowCount) return res.status(404).json({ ok: false, error: "bot_not_found", message: `No chatbot_config for ${botId}` });
    const cfg = cr.rows[0];
    if (!cfg.openai_api_key) return res.status(400).json({ ok: false, error: "openai_key_missing" });
    if (!cfg.prompt_id) return res.status(400).json({ ok: false, error: "prompt_missing" });

    // Fetch latest visitor message
    const mr = await pool.query(
      `SELECT COALESCE(content, message) AS m
         FROM messages
        WHERE visitor_id = $1 AND (sender IS NULL OR sender <> 'agent')
        ORDER BY created_at DESC
        LIMIT 1`,
      [visitorId]
    );
    const lastMsg = (mr.rows?.[0]?.m || "").trim();
    if (!lastMsg) return res.status(400).json({ ok: false, error: "no_visitor_message" });

    const extraContext = String(b.extraContext || "").trim();
    const input = extraContext ? `${lastMsg}\n\n${extraContext}` : lastMsg;

    // Load assigned prompt_config (if any) and apply its settings
    let pc = null;
    try {
      if (cfg.prompt_config_id) {
        const rPc = await pool.query(`SELECT * FROM prompt_config WHERE id=$1 LIMIT 1`, [cfg.prompt_config_id]);
        if (rPc.rowCount) pc = rPc.rows[0];
      }
    } catch {}

    // Resolve MCP extra tools for this prompt (if linked)
    let extraTools = [];
    try {
      const pid = (pc && pc.id) ? pc.id : '';
      if (pid) {
        const rs = await pool.query(
          `SELECT m.id, m.name, m.kind, m.http_base, m.ws_url, m.stream_url, m.sse_url, m.token, m.enabled, m.options
             FROM prompt_config_mcp x
             JOIN mcp_server_config m ON m.id = x.mcp_server_id
            WHERE x.prompt_config_id = $1
            ORDER BY m.updated_at DESC`,
          [pid]
        );
        const fproto = String(req.headers['x-forwarded-proto'] || '').split(',')[0]?.trim();
        const fhost = String(req.headers['x-forwarded-host'] || '').split(',')[0]?.trim();
        const proto = (fproto || req.protocol || 'http').toLowerCase();
        const host = (fhost || req.headers.host || 'localhost').trim();
        const base = `${proto}://${host}`;
        extraTools = (rs.rows || []).map((row) => {
          let options = row.options; try { if (typeof options === 'string') options = JSON.parse(options); } catch { options = {}; }
          const allowed = Array.isArray(options?.allowed_tools) ? options.allowed_tools : undefined;
          const label = row.name || (row.kind || 'mcp');
          const pref = (options && options.server_url_pref === 'sse') ? 'sse' : 'stream';
          let serverUrl = pref === 'stream'
            ? (row.stream_url || row.sse_url || `${base}/mcp/${encodeURIComponent(label)}/stream`)
            : (row.sse_url || row.stream_url || `${base}/mcp/${encodeURIComponent(label)}/events`);
          if (row.token) { try { const u = new URL(serverUrl, base); if (!u.searchParams.get('token')) u.searchParams.set('token', row.token); serverUrl = u.toString(); } catch {} }
          const tool = { type: 'mcp', server_label: label, server_url: serverUrl, require_approval: 'never' };
          if (row.token) tool.authorization = row.token;
          if (allowed && allowed.length) tool.allowed_tools = allowed;
          return tool;
        }).filter((t) => t.server_url);
      }
    } catch {}

    const t0 = Date.now();
    const effectiveModel = String((pc?.model) || cfg.model || process.env.OPENAI_MODEL || 'gpt-4o-mini');
    const toolsEff = (pc && typeof pc.tools === 'object') ? pc.tools : {};
    const vectorStoreIdEff = pc?.vector_store_id || undefined;
    const vectorStoreIdsEff = Array.isArray(pc?.vector_store_ids) ? pc.vector_store_ids : undefined;
    const hasVectorsEff = (!!vectorStoreIdEff) || (Array.isArray(vectorStoreIdsEff) && vectorStoreIdsEff.length > 0);
    const toolsFileSearchEff = !!(toolsEff.file_search || hasVectorsEff);
    const { text, raw, request, request_body } = await respondWithPrompt({
      apiKey: cfg.openai_api_key,
      model: effectiveModel,
      promptId: (pc?.prompt_id) ? pc.prompt_id : cfg.prompt_id,
      promptVersion: (pc?.prompt_version) ? pc.prompt_version : (cfg.prompt_version || undefined),
      input,
      seedMessages: Array.isArray(pc?.messages) ? pc.messages : undefined,
      instructions: pc?.dev_message || undefined,
      toolsFileSearch: toolsFileSearchEff,
      toolsCodeInterpreter: !!toolsEff.code_interpreter,
      webSearchEnabled: !!toolsEff.web_search,
      webSearchAllowedDomains: Array.isArray(toolsEff.web_search_allowed_domains) ? toolsEff.web_search_allowed_domains : undefined,
      vectorStoreId: vectorStoreIdEff,
      vectorStoreIds: vectorStoreIdsEff,
      extraTools,
    }, {
      includeToolsOnGpt5: ((String(effectiveModel||'').toLowerCase().startsWith('gpt-5')) && (toolsFileSearchEff || hasVectorsEff))
    });
    try {
      logToFile(`AI_DRAFT visitor=${visitorId} bot=${botId} text_len=${(text||'').length}`);
      logToFile(`AI_DRAFT_RAW ${JSON.stringify(raw)?.slice(0,2000)}`);
    } catch {}
    const ms = Date.now() - t0;
    return res.json({ ok: true, draft: text || "", request, request_body, ms, seconds: ms/1000 });
  } catch (e) {
    logToFile(`❌ /api/assistant/draft: ${e.message}`);
    return res.status(500).json({ ok: false, error: "server_error", message: e.message });
  }
});

// ---- Admin endpoints for Prompt settings (Responses API) ----
app.get('/api/admin/prompt/id', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const dbVal = await getSetting('PROMPT_ID');
    const envVal = process.env.PROMPT_ID || process.env.OPENAI_PROMPT_ID || '';
    res.json({ ok: true, value: dbVal || envVal || null });
  }
  catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
});
app.post('/api/admin/prompt/id', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const v = String(req.body?.value || '').trim();
    await setSetting('PROMPT_ID', v);
    process.env.PROMPT_ID = v;
    res.json({ ok: true, value: v || null });
  } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
});
app.get('/api/admin/prompt/version', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const dbVal = await getSetting('PROMPT_VERSION');
    const envVal = process.env.PROMPT_VERSION || process.env.OPENAI_PROMPT_VERSION || '';
    res.json({ ok: true, value: dbVal || envVal || null });
  }
  catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
});
  app.post('/api/admin/prompt/version', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const v = String(req.body?.value || '').trim();
      await setSetting('PROMPT_VERSION', v);
      process.env.PROMPT_VERSION = v;
      res.json({ ok: true, value: v || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });

  // Aliases under /mcp for environments where only /mcp* is routed
  app.get('/mcp/admin/prompt/id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const dbVal = await getSetting('PROMPT_ID');
      const envVal = process.env.PROMPT_ID || process.env.OPENAI_PROMPT_ID || '';
      res.json({ ok: true, value: dbVal || envVal || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });
  app.post('/mcp/admin/prompt/id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const v = String(req.body?.value || '').trim();
      await setSetting('PROMPT_ID', v);
      process.env.PROMPT_ID = v;
      res.json({ ok: true, value: v || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });
  app.get('/mcp/admin/prompt/version', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const dbVal = await getSetting('PROMPT_VERSION');
      const envVal = process.env.PROMPT_VERSION || process.env.OPENAI_PROMPT_VERSION || '';
      res.json({ ok: true, value: dbVal || envVal || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });
  app.post('/mcp/admin/prompt/version', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const v = String(req.body?.value || '').trim();
      await setSetting('PROMPT_VERSION', v);
      process.env.PROMPT_VERSION = v;
      res.json({ ok: true, value: v || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });

  // Aliases under /mcp/mcp-dev-prestashop
  app.get('/mcp/mcp-dev-prestashop/admin/prompt/id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const dbVal = await getSetting('PROMPT_ID');
      const envVal = process.env.PROMPT_ID || process.env.OPENAI_PROMPT_ID || '';
      res.json({ ok: true, value: dbVal || envVal || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });
  app.post('/mcp/mcp-dev-prestashop/admin/prompt/id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const v = String(req.body?.value || '').trim();
      await setSetting('PROMPT_ID', v);
      process.env.PROMPT_ID = v;
      res.json({ ok: true, value: v || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });
  app.get('/mcp/mcp-dev-prestashop/admin/prompt/version', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const dbVal = await getSetting('PROMPT_VERSION');
      const envVal = process.env.PROMPT_VERSION || process.env.OPENAI_PROMPT_VERSION || '';
      res.json({ ok: true, value: dbVal || envVal || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });
  app.post('/mcp/mcp-dev-prestashop/admin/prompt/version', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const v = String(req.body?.value || '').trim();
      await setSetting('PROMPT_VERSION', v);
      process.env.PROMPT_VERSION = v;
      res.json({ ok: true, value: v || null });
    } catch (e) { res.status(500).json({ ok: false, error: 'server_error', message: e?.message || String(e) }); }
  });

  // ---- Admin: OpenAI Prompts (Responses API) ----
  // Create a new Prompt
  app.post('/api/admin/openai/prompts', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      setPromptsDebug({ lastRoute: captureReqMeta(req), lastAction: 'admin_create_prompt' });
      const b = req.body || {};
      const name = String(b.name || '').trim() || undefined;
      const instructions = String(b.instructions || b.definition || '').trim();
      const messages = Array.isArray(b.messages) ? b.messages : undefined;
      const model = (b.model && String(b.model).trim()) || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      if (!instructions && !messages) return res.status(400).json({ ok:false, error:'bad_request', message:'instructions or messages required' });
      const body = {};
      if (instructions) body.instructions = instructions;
      if (messages) body.messages = messages;
      if (model) body.model = model;
      if (name) body.name = name;
      if (description) body.description = description;
      if (metadata) body.metadata = metadata;
      const json = await openaiPromptCreate(body);
      promptDbgOk(req, 'admin_create_prompt', { prompt_id: json?.id || null });
      return res.json({ ok:true, prompt: json });
    } catch (e) {
      promptDbgErr(req, 'admin_create_prompt', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });
  // Retrieve a Prompt by ID
  app.get('/api/admin/openai/prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptRetrieve(id);
      promptDbgOk(req, 'admin_get_prompt', { prompt_id: id });
      return res.json({ ok:true, prompt: json });
    } catch (e) {
      promptDbgErr(req, 'admin_get_prompt', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });
  // List Prompt versions
  app.get('/api/admin/openai/prompts/:id/versions', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptListVersions(id);
      promptDbgOk(req, 'admin_list_prompt_versions', { prompt_id: id });
      return res.json({ ok:true, versions: json });
    } catch (e) {
      promptDbgErr(req, 'admin_list_prompt_versions', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });
  // Create a new Prompt version (modify)
  app.post('/api/admin/openai/prompts/:id/versions', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const instructions = String(b.instructions || b.definition || '').trim();
      const messages = Array.isArray(b.messages) ? b.messages : undefined;
      const model = (b.model && String(b.model).trim()) || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      if (!instructions && !messages) return res.status(400).json({ ok:false, error:'bad_request', message:'instructions or messages required' });
      const body = {};
      if (instructions) body.instructions = instructions;
      if (messages) body.messages = messages;
      if (model) body.model = model;
      if (description) body.description = description;
      if (metadata) body.metadata = metadata;
      const json = await openaiPromptCreateVersion(id, body);
      promptDbgOk(req, 'admin_create_prompt_version', { prompt_id: id, version_id: json?.id || json?.version || null });
      return res.json({ ok:true, version: json });
    } catch (e) {
      promptDbgErr(req, 'admin_create_prompt_version', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });
  // Update Prompt metadata (name/description)
  app.patch('/api/admin/openai/prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const name = String(b.name || '').trim() || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      const body = {};
      if (name !== undefined) body.name = name;
      if (description !== undefined) body.description = description;
      if (metadata !== undefined) body.metadata = metadata;
      if (!Object.keys(body).length) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptPatch(id, body);
      promptDbgOk(req, 'admin_patch_prompt', { prompt_id: id });
      return res.json({ ok:true, prompt: json });
    } catch (e) {
      promptDbgErr(req, 'admin_patch_prompt', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });

  // List Prompts (OpenAI Responses API)
  // Query: limit? after? api_key? org_id? org=me?
  app.get('/api/admin/openai/prompts', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const q = req.query || {};
      const limit = Math.max(1, Math.min(200, Number(q.limit || 50)));
      const after = q.after ? String(q.after) : undefined;
      let apiKeyUse = null, orgUse = null, projUse = null, baseUrlUse = null;
      if (q.api_key) {
        apiKeyUse = String(q.api_key || '').trim();
      } else if (q.org_id) {
        const oid = String(q.org_id || '').trim();
        if (oid) {
          const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]);
          if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null;
        }
      } else if (String(q.org || '').toLowerCase() === 'me') {
        try { const oid = (authFromRequest(req) && authFromRequest(req).org_id) || null; if (oid) { const r = await pool.query(`SELECT openai_api_key FROM organizations WHERE id=$1`, [oid]); if (r.rowCount) apiKeyUse = (r.rows[0].openai_api_key && String(r.rows[0].openai_api_key).trim()) || null; } } catch {}
      } else {
        apiKeyUse = getOpenaiApiKey();
      }
      if (!apiKeyUse) return res.status(400).json({ ok:false, error:'openai_key_missing' });
      const json = await openaiPromptList({ limit, after }, { apiKey: apiKeyUse, organization: orgUse || undefined, project: projUse || undefined, baseURL: baseUrlUse || undefined });
      const items = Array.isArray(json?.data) ? json.data : (Array.isArray(json?.items) ? json.items : (Array.isArray(json) ? json : []));
      const out = { ok: true, items };
      if (Object.prototype.hasOwnProperty.call(json || {}, 'has_more')) out.has_more = !!json.has_more;
      if (Object.prototype.hasOwnProperty.call(json || {}, 'last_id')) out.next_after = json.last_id;
      return res.json(out);
    } catch (e) {
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });

  // ---- Automations alias for Prompts (same handlers; behind admin check) ----
  app.post('/api/automations/prompts', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      setPromptsDebug({ lastRoute: captureReqMeta(req), lastAction: 'automations_create_prompt' });
      const b = req.body || {};
      const name = String(b.name || '').trim() || undefined;
      const instructions = String(b.instructions || b.definition || '').trim();
      const messages = Array.isArray(b.messages) ? b.messages : undefined;
      const model = (b.model && String(b.model).trim()) || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      if (!instructions && !messages) return res.status(400).json({ ok:false, error:'bad_request', message:'instructions or messages required' });
      const body = {};
      if (instructions) body.instructions = instructions;
      if (messages) body.messages = messages;
      if (model) body.model = model;
      if (name) body.name = name;
      if (description) body.description = description;
      if (metadata) body.metadata = metadata;
      const json = await openaiPromptCreate(body);
      promptDbgOk(req, 'automations_create_prompt', { prompt_id: json?.id || null });
      return res.json({ ok:true, prompt: json });
    } catch (e) {
      promptDbgErr(req, 'automations_create_prompt', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });
  app.get('/api/automations/prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptRetrieve(id);
      promptDbgOk(req, 'automations_get_prompt', { prompt_id: id });
      return res.json({ ok:true, prompt: json });
    } catch (e) {
      promptDbgErr(req, 'automations_get_prompt', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });
  app.get('/api/automations/prompts/:id/versions', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptListVersions(id);
      promptDbgOk(req, 'automations_list_prompt_versions', { prompt_id: id });
      return res.json({ ok:true, versions: json });
    } catch (e) {
      promptDbgErr(req, 'automations_list_prompt_versions', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });
  app.post('/api/automations/prompts/:id/versions', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const instructions = String(b.instructions || b.definition || '').trim();
      const messages = Array.isArray(b.messages) ? b.messages : undefined;
      const model = (b.model && String(b.model).trim()) || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      if (!instructions && !messages) return res.status(400).json({ ok:false, error:'bad_request', message:'instructions or messages required' });
      const body = {};
      if (instructions) body.instructions = instructions;
      if (messages) body.messages = messages;
      if (model) body.model = model;
      if (description) body.description = description;
      if (metadata) body.metadata = metadata;
      const json = await openaiPromptCreateVersion(id, body);
      promptDbgOk(req, 'automations_create_prompt_version', { prompt_id: id, version_id: json?.id || json?.version || null });
      return res.json({ ok:true, version: json });
    } catch (e) {
      promptDbgErr(req, 'automations_create_prompt_version', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });
  app.patch('/api/automations/prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const name = String(b.name || '').trim() || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      const body = {};
      if (name !== undefined) body.name = name;
      if (description !== undefined) body.description = description;
      if (metadata !== undefined) body.metadata = metadata;
      if (!Object.keys(body).length) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptPatch(id, body);
      promptDbgOk(req, 'automations_patch_prompt', { prompt_id: id });
      return res.json({ ok:true, prompt: json });
    } catch (e) {
      promptDbgErr(req, 'automations_patch_prompt', e);
      return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined });
    }
  });

  // ---- MCP prefixes aliases (for environments where only /mcp* is routed) ----
  // Base: /mcp/automations/prompts
  app.post('/mcp/automations/prompts', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      setPromptsDebug({ lastRoute: captureReqMeta(req), lastAction: 'mcp_create_prompt' });
      const b = req.body || {};
      const name = String(b.name || '').trim() || undefined;
      const instructions = String(b.instructions || b.definition || '').trim();
      const messages = Array.isArray(b.messages) ? b.messages : undefined;
      const model = (b.model && String(b.model).trim()) || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      if (!instructions && !messages) return res.status(400).json({ ok:false, error:'bad_request', message:'instructions or messages required' });
      const body = {};
      if (instructions) body.instructions = instructions;
      if (messages) body.messages = messages;
      if (model) body.model = model;
      if (name) body.name = name;
      if (description) body.description = description;
      if (metadata) body.metadata = metadata;
      const json = await openaiPromptCreate(body);
      promptDbgOk(req, 'mcp_create_prompt', { prompt_id: json?.id || null });
      return res.json({ ok:true, prompt: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });
  app.get('/mcp/automations/prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptRetrieve(id);
      promptDbgOk(req, 'mcp_get_prompt', { prompt_id: id });
      return res.json({ ok:true, prompt: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });
  app.get('/mcp/automations/prompts/:id/versions', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptListVersions(id);
      promptDbgOk(req, 'mcp_list_prompt_versions', { prompt_id: id });
      return res.json({ ok:true, versions: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });
  app.post('/mcp/automations/prompts/:id/versions', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const instructions = String(b.instructions || b.definition || '').trim();
      const messages = Array.isArray(b.messages) ? b.messages : undefined;
      const model = (b.model && String(b.model).trim()) || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      if (!instructions && !messages) return res.status(400).json({ ok:false, error:'bad_request', message:'instructions or messages required' });
      const body = {};
      if (instructions) body.instructions = instructions;
      if (messages) body.messages = messages;
      if (model) body.model = model;
      if (description) body.description = description;
      if (metadata) body.metadata = metadata;
      const json = await openaiPromptCreateVersion(id, body);
      promptDbgOk(req, 'mcp_create_prompt_version', { prompt_id: id, version_id: json?.id || json?.version || null });
      return res.json({ ok:true, version: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });
  app.patch('/mcp/automations/prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const name = String(b.name || '').trim() || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      const body = {};
      if (name !== undefined) body.name = name;
      if (description !== undefined) body.description = description;
      if (metadata !== undefined) body.metadata = metadata;
      if (!Object.keys(body).length) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiPromptPatch(id, body);
      promptDbgOk(req, 'mcp_patch_prompt', { prompt_id: id });
      return res.json({ ok:true, prompt: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });

  // Base: /mcp/mcp-dev-prestashop/automations/prompts
  app.post('/mcp/mcp-dev-prestashop/automations/prompts', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      setPromptsDebug({ lastRoute: captureReqMeta(req), lastAction: 'mcp_presta_create_prompt' });
      const b = req.body || {};
      const name = String(b.name || '').trim() || undefined;
      const instructions = String(b.instructions || b.definition || '').trim();
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      if (!instructions) return res.status(400).json({ ok:false, error:'bad_request', message:'instructions required' });
      const body = { instructions };
      if (name) body.name = name;
      if (description) body.description = description;
      if (metadata) body.metadata = metadata;
      const json = await openaiHttp('/prompts', { method:'POST', body });
      promptDbgOk(req, 'mcp_presta_create_prompt', { prompt_id: json?.id || null });
      return res.json({ ok:true, prompt: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });
  app.get('/mcp/mcp-dev-prestashop/automations/prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiHttp(`/prompts/${encodeURIComponent(id)}`, { method:'GET' });
      promptDbgOk(req, 'mcp_presta_get_prompt', { prompt_id: id });
      return res.json({ ok:true, prompt: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });
  app.get('/mcp/mcp-dev-prestashop/automations/prompts/:id/versions', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiHttp(`/prompts/${encodeURIComponent(id)}/versions`, { method:'GET' });
      promptDbgOk(req, 'mcp_presta_list_prompt_versions', { prompt_id: id });
      return res.json({ ok:true, versions: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });
  app.post('/mcp/mcp-dev-prestashop/automations/prompts/:id/versions', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const instructions = String(b.instructions || b.definition || '').trim();
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      if (!instructions) return res.status(400).json({ ok:false, error:'bad_request', message:'instructions required' });
      const body = { instructions };
      if (description) body.description = description;
      if (metadata) body.metadata = metadata;
      const json = await openaiHttp(`/prompts/${encodeURIComponent(id)}/versions`, { method:'POST', body });
      promptDbgOk(req, 'mcp_presta_create_prompt_version', { prompt_id: id, version_id: json?.id || json?.version || null });
      return res.json({ ok:true, version: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });
  app.patch('/mcp/mcp-dev-prestashop/automations/prompts/:id', async (req, res) => {
    const u = requireAdminAuth(req, res); if (!u) return;
    try {
      const id = String(req.params.id || '').trim();
      if (!id) return res.status(400).json({ ok:false, error:'bad_request' });
      const b = req.body || {};
      const name = String(b.name || '').trim() || undefined;
      const description = String(b.description || '').trim() || undefined;
      const metadata = (typeof b.metadata === 'object' && b.metadata) || undefined;
      const body = {};
      if (name !== undefined) body.name = name;
      if (description !== undefined) body.description = description;
      if (metadata !== undefined) body.metadata = metadata;
      if (!Object.keys(body).length) return res.status(400).json({ ok:false, error:'bad_request' });
      const json = await openaiHttp(`/prompts/${encodeURIComponent(id)}`, { method:'PATCH', body });
      promptDbgOk(req, 'mcp_presta_patch_prompt', { prompt_id: id });
      return res.json({ ok:true, prompt: json });
    } catch (e) { return res.status(e?.status || 500).json({ ok:false, error:'openai_error', message: e?.message || String(e), details: e?.details || undefined }); }
  });

// Lightweight config lookup for a visitor → returns chatbot behavior
// GET /api/assistant/config?visitorId=...
app.get("/api/assistant/config", async (req, res) => {
  try {
    const visitorId = String(req.query.visitorId || "").trim();
    if (!visitorId) return res.status(400).json({ ok: false, error: "bad_request" });

    // Find shop/lang for this visitor
    const vrow = await pool.query(
      `SELECT shop_name, lang_iso
         FROM visitors
        WHERE (visitor_id = $1 OR id = $1)
        LIMIT 1`,
      [visitorId]
    );
    const shop = vrow.rows?.[0]?.shop_name || null;
    const lang = vrow.rows?.[0]?.lang_iso || null;
    if (!shop || !lang) return res.json({ ok: true, bot_behavior: 'manual' });

    const botId = makeBotId(shop, lang);
    const cr = await pool.query(
      `SELECT bot_behavior, enabled, prompt_id, openai_api_key
         FROM chatbot_config
        WHERE id_bot = $1
        LIMIT 1`,
      [botId]
    );
    if (!cr.rowCount) return res.json({ ok: true, bot_behavior: 'manual' });
    const row = cr.rows[0] || {};
    return res.json({
      ok: true,
      id_bot: botId,
      bot_behavior: row.bot_behavior || 'manual',
      enabled: !!row.enabled,
      has_prompt: !!row.prompt_id,
      has_api_key: !!row.openai_api_key,
    });
  } catch (e) {
    logToFile(`❌ /api/assistant/config: ${e.message}`);
    return res.status(500).json({ ok: false, error: 'server_error' });
  }
});

// Minimal JSON-only Streamable HTTP endpoints so the MCP Inspector can
// connect using transport "streamable-http". These respond with JSON rather
// than opening SSE streams.

function jsonrpcResponse(id, result) {
  return { jsonrpc: '2.0', id, result };
}
function jsonrpcError(id, code, message) {
  return { jsonrpc: '2.0', id, error: { code, message } };
}

app.post('/mcp-dev/stream', async (req, res) => {
  if (!await requireMcpDevAuth(req, res)) return;
  try {
    const msg = req.body || {};
    const id = msg.id; const method = msg.method; const params = msg.params || {};
    res.setHeader('Content-Type', 'application/json; charset=utf-8');
    res.setHeader('mcp-session-id', 'mcp-dev-' + (Date.now()));

    if (method === 'initialize') {
      return res.status(200).json(jsonrpcResponse(id, {
        protocolVersion: '2024-11-05',
        serverInfo: { name: 'livechat-mcp-dev', version: '0.1' },
        capabilities: {
          logging: {},
          tools: { listChanged: true },
          resources: { subscribe: true, listChanged: true },
          prompts: { listChanged: true },
        }
      }));
    }
    if (method === 'tools/list') {
      const allow = await getAllowedMcpToolNamesForReq(req);
      return res.status(200).json(jsonrpcResponse(id, { tools: listToolsForClientFiltered(allow) }));
    }
    if (method === 'resources/list') {
      return res.status(200).json(jsonrpcResponse(id, { resources: [] }));
    }
    if (method === 'prompts/list') {
      return res.status(200).json(jsonrpcResponse(id, { prompts: [] }));
    }
    if (method === 'resources/subscribe') {
      return res.status(200).json(jsonrpcResponse(id, { ok: true }));
    }
    if (method === 'resources/unsubscribe') {
      return res.status(200).json(jsonrpcResponse(id, { ok: true }));
    }
    if (method === 'resources/templates/list') {
      return res.status(200).json(jsonrpcResponse(id, { templates: [] }));
    }
    if (method === 'ping') {
      return res.status(200).json(jsonrpcResponse(id, { pong: true, time: new Date().toISOString() }));
    }
    if (method === 'tools/call') {
      const name = params.name || params.tool || '';
      const args = params.arguments || params.args || {};
      const allow = await getAllowedMcpToolNamesForReq(req);
      if (Array.isArray(allow) && !allow.includes(name)) {
        return res.status(200).json(jsonrpcError(id, -32601, `Tool not allowed: ${name}`));
      }
      try {
        const result = await MCP.run(name, args, { id_bot: 'mcp_dev', session: { authed: true } });
        return res.status(200).json(jsonrpcResponse(id, { content: [{ type: 'text', text: JSON.stringify(result) }] }));
      } catch (e) {
        const msg = e?.message || 'tool_error';
        return res.status(200).json(jsonrpcError(id, -32000, msg));
      }
    }
    return res.status(200).json(jsonrpcError(id, -32601, `Unknown method: ${method}`));
  } catch (e) {
    return res.status(500).json({ jsonrpc: '2.0', id: null, error: { code: -32000, message: e?.message || 'server_error' } });
  }
});

app.post('/mcp/stream', async (req, res) => {
  if (!await requireMcpAuth(req, res)) return;
  try {
    const msg = req.body || {};
    const id = msg.id; const method = msg.method; const params = msg.params || {};
    res.setHeader('Content-Type', 'application/json; charset=utf-8');
    res.setHeader('mcp-session-id', 'mcp-' + (Date.now()));

    if (method === 'initialize') {
      return res.status(200).json(jsonrpcResponse(id, {
        protocolVersion: '2024-11-05',
        serverInfo: { name: 'livechat-mcp', version: '0.1' },
        capabilities: {
          logging: {},
          tools: { listChanged: true },
          resources: { subscribe: true, listChanged: true },
          prompts: { listChanged: true },
        }
      }));
    }
    if (method === 'tools/list') {
      const allow = await getAllowedMcpToolNamesForReq(req);
      return res.status(200).json(jsonrpcResponse(id, { tools: listToolsForClientFiltered(allow) }));
    }
    if (method === 'resources/list') {
      return res.status(200).json(jsonrpcResponse(id, { resources: [] }));
    }
    if (method === 'prompts/list') {
      return res.status(200).json(jsonrpcResponse(id, { prompts: [] }));
    }
    if (method === 'resources/subscribe') {
      return res.status(200).json(jsonrpcResponse(id, { ok: true }));
    }
    if (method === 'resources/unsubscribe') {
      return res.status(200).json(jsonrpcResponse(id, { ok: true }));
    }
    if (method === 'resources/templates/list') {
      return res.status(200).json(jsonrpcResponse(id, { templates: [] }));
    }
    if (method === 'ping') {
      return res.status(200).json(jsonrpcResponse(id, { pong: true, time: new Date().toISOString() }));
    }
    if (method === 'tools/call') {
      const name = params.name || params.tool || '';
      const args = params.arguments || params.args || {};
      const allow = await getAllowedMcpToolNamesForReq(req);
      if (Array.isArray(allow) && !allow.includes(name)) {
        return res.status(200).json(jsonrpcError(id, -32601, `Tool not allowed: ${name}`));
      }
      const serverNameCtx = await resolveServerNameFromReq(req);
      const ctx = { id_bot: String(args?.bot_id || req.query?.bot_id || ''), server_name: serverNameCtx || undefined, session: { authed: true } };
      try {
        const result = await MCP.run(name, args, ctx);
        return res.status(200).json(jsonrpcResponse(id, { content: [{ type: 'text', text: JSON.stringify(result) }] }));
      } catch (e) {
        const msg = e?.message || 'tool_error';
        return res.status(200).json(jsonrpcError(id, -32000, msg));
      }
    }
    return res.status(200).json(jsonrpcError(id, -32601, `Unknown method: ${method}`));
  } catch (e) {
    return res.status(500).json({ jsonrpc: '2.0', id: null, error: { code: -32000, message: e?.message || 'server_error' } });
  }
});

// Helpful GET handlers so a direct browser visit doesn't show "Cannot GET".
app.get('/mcp-dev/stream', (_req, res) => {
  res.status(405).type('text/plain; charset=utf-8').send('Use POST JSON (application/json) to /mcp-dev/stream for Streamable HTTP (MCP).');
});
app.get('/mcp/stream', (_req, res) => {
  res.status(405).type('text/plain; charset=utf-8').send('Use POST JSON (application/json) to /mcp/stream for Streamable HTTP (MCP).');
});
app.get('/mcp/:name/stream', (_req, res) => {
  res.status(405).type('text/plain; charset=utf-8').send('Use POST JSON (application/json) to /mcp/:name/stream for Streamable HTTP (MCP). For GET, use /mcp/:name/events');
});
app.get('/mcp2/:name/stream', (_req, res) => {
  res.status(405).type('text/plain; charset=utf-8').send('Use POST JSON (application/json) to /mcp2/:name/stream for Streamable HTTP (MCP). For GET, use /mcp2/:name/events');
});
// MCP2 aliases -> redirect to MCP v1 handlers
// (Replaced redirects with direct handlers above)
// Unified aliases so reverse proxy only needs /mcp/*
app.post('/mcp/mcp-dev/stream', async (req, res) => {
  if (!await requireMcpDevAuth(req, res)) return;
  try {
    const msg = req.body || {};
    const id = msg.id; const method = msg.method; const params = msg.params || {};
    res.setHeader('Content-Type', 'application/json; charset=utf-8');
    res.setHeader('mcp-session-id', 'mcp-dev-' + (Date.now()));
    if (method === 'initialize') {
      return res.status(200).json(jsonrpcResponse(id, { protocolVersion: '2024-11-05', serverInfo: { name: 'livechat-mcp-dev', version: '0.1' }, capabilities: { logging: {}, tools: { listChanged: true }, resources: { subscribe: true, listChanged: true }, prompts: { listChanged: true } } }));
    }
    if (method === 'tools/list') { const tools = await listToolsForClient(); return res.status(200).json(jsonrpcResponse(id, { tools })); }
    if (method === 'resources/list') { return res.status(200).json(jsonrpcResponse(id, { resources: [] })); }
    if (method === 'prompts/list') { return res.status(200).json(jsonrpcResponse(id, { prompts: [] })); }
    if (method === 'resources/subscribe') { return res.status(200).json(jsonrpcResponse(id, { ok: true })); }
    if (method === 'resources/unsubscribe') { return res.status(200).json(jsonrpcResponse(id, { ok: true })); }
    if (method === 'resources/templates/list') { return res.status(200).json(jsonrpcResponse(id, { templates: [] })); }
    if (method === 'ping') { return res.status(200).json(jsonrpcResponse(id, { pong: true, time: new Date().toISOString() })); }
    if (method === 'tools/call') {
      const name = params.name || params.tool || '';
      const args = params.arguments || params.args || {};
      const result = await MCP.run(name, args, { id_bot: 'mcp_dev', session: { authed: true } });
      return res.status(200).json(jsonrpcResponse(id, { content: [{ type: 'text', text: JSON.stringify(result) }] }));
    }
    return res.status(200).json(jsonrpcError(id, -32601, `Unknown method: ${method}`));
  } catch (e) {
    return res.status(500).json({ jsonrpc: '2.0', id: null, error: { code: -32000, message: e?.message || 'server_error' } });
  }
});

// Alias: name-scoped stream path -> same handler
app.post(['/mcp/:name/stream','/mcp2/:name/stream'], async (req, res) => {
  if (!await requireMcpAuth(req, res)) return;
  try {
    const msg = req.body || {};
    const id = msg.id; const method = msg.method; const params = msg.params || {};
    res.setHeader('Content-Type', 'application/json; charset=utf-8');
    res.setHeader('mcp-session-id', 'mcp-' + (Date.now()));

    if (method === 'initialize') {
      return res.status(200).json(jsonrpcResponse(id, {
        protocolVersion: '2024-11-05',
        serverInfo: { name: 'livechat-mcp', version: '0.1' },
        capabilities: {
          logging: {},
          tools: { listChanged: true },
          resources: { subscribe: true, listChanged: true },
          prompts: { listChanged: true },
        }
      }));
    }
    if (method === 'tools/list') {
      const allow = await getAllowedMcpToolNamesForReq(req);
      const tools = await listToolsForClientFiltered(allow, String(req.params.name||''));
      return res.status(200).json(jsonrpcResponse(id, { tools }));
    }
    if (method === 'resources/list') {
      return res.status(200).json(jsonrpcResponse(id, { resources: [] }));
    }
    if (method === 'prompts/list') {
      return res.status(200).json(jsonrpcResponse(id, { prompts: [] }));
    }
    if (method === 'resources/subscribe') {
      return res.status(200).json(jsonrpcResponse(id, { ok: true }));
    }
    if (method === 'resources/unsubscribe') {
      return res.status(200).json(jsonrpcResponse(id, { ok: true }));
    }
    if (method === 'resources/templates/list') {
      return res.status(200).json(jsonrpcResponse(id, { templates: [] }));
    }
    if (method === 'ping') {
      return res.status(200).json(jsonrpcResponse(id, { pong: true, time: new Date().toISOString() }));
    }
    if (method === 'tools/call') {
      const name = params.name || params.tool || '';
      const args = params.arguments || params.args || {};
      const allow = await getAllowedMcpToolNamesForReq(req);
      if (Array.isArray(allow) && allow.length && !allow.includes(name)) {
        return res.status(200).json(jsonrpcError(id, -32601, `Tool not allowed: ${name}`));
      }
      // Resolve default bot_id: args.bot_id -> ?bot_id= query -> latest enabled bot
      let idBot = '';
      try { idBot = String((args && (args.bot_id ?? args.botId)) || (req.query && (req.query.bot_id ?? req.query.botId)) || '').trim(); } catch {}
      if (!idBot) {
        try {
          const rb = await pool.query(`SELECT id_bot FROM chatbot_config WHERE enabled = 1 ORDER BY updated_at DESC LIMIT 1`);
          if (rb.rowCount) idBot = rb.rows[0].id_bot || '';
        } catch {}
      }
      const serverName = String(req.params.name||'');
      const me = authFromRequest(req) || null;
      const ctx = { id_bot: idBot, server_name: serverName, user_id: me?.id || null, user_email: me?.email || null, session: { authed: true } };
      const customResult = await runCustomToolIfAny(serverName, name, args, ctx);
      const result = (customResult !== undefined) ? customResult : await MCP.run(name, args, ctx);
      return res.status(200).json(jsonrpcResponse(id, { content: [{ type: 'text', text: JSON.stringify(result) }] }));
    }
    return res.status(200).json(jsonrpcError(id, -32601, `Unknown method: ${method}`));
  } catch (e) {
    return res.status(500).json({ jsonrpc: '2.0', id: null, error: { code: -32000, message: e?.message || 'server_error' } });
  }
});
app.get('/mcp/mcp-dev/stream', (_req, res) => {
  res.status(405).type('text/plain; charset=utf-8').send('Use POST JSON (application/json) to /mcp/mcp-dev/stream for Streamable HTTP (MCP).');
});
app.get('/mcp-dev-prestashop/stream', (_req, res) => {
  res.status(405).type('text/plain; charset=utf-8').send('Use POST JSON (application/json) to /mcp-dev-prestashop/stream for Streamable HTTP (MCP).');
});

// Persist simple Kanban JSON under settings
const DEV_KANBAN_KEY = 'DEV_KANBAN_BOARD';
const DEV_KANBAN_FILES_KEY = 'DEV_KANBAN_FILES';

function isSubPath(parent, child) {
  try {
    const norm = (p) => path.resolve(p).replace(/\\/g, '/').toLowerCase();
    const pa = norm(parent);
    const ch = norm(child);
    return ch.startsWith(pa + '/') || ch === pa;
  } catch { return false; }
}

app.get('/api/dev/kanban', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const raw = await getSetting(DEV_KANBAN_KEY);
    let board = null;
    try { board = raw ? JSON.parse(raw) : null; } catch {}
    if (!board || typeof board !== 'object') {
      board = {
        columns: [
          { id: 'todo', title: 'À faire', order: 0 },
          { id: 'doing', title: 'En cours', order: 1 },
          { id: 'review', title: 'Revue', order: 2 },
          { id: 'done', title: 'Fait', order: 3 },
        ],
        cards: [],
        updatedAt: Date.now(),
      };
    }
    res.json({ ok: true, board });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

app.post('/api/dev/kanban', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const board = req.body && typeof req.body === 'object' ? req.body : null;
    if (!board || !Array.isArray(board.columns) || !Array.isArray(board.cards)) {
      return res.status(400).json({ ok:false, error:'invalid_board' });
    }
    const toSave = JSON.stringify({ ...board, updatedAt: Date.now() });
    await setSetting(DEV_KANBAN_KEY, toSave);
    res.json({ ok:true });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Persist Dev Projects JSON (projects, templates, docs) under settings
const DEV_PROJECTS_KEY = 'DEV_PROJECTS_JSON';

app.get('/api/dev/projects', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const raw = await getSetting(DEV_PROJECTS_KEY);
    let data = null; try { data = raw ? JSON.parse(raw) : null; } catch {}
    res.json({ ok:true, data });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

app.post('/api/dev/projects', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const body = req.body && (req.body.data !== undefined ? req.body.data : req.body);
    if (!body || typeof body !== 'object') return res.status(400).json({ ok:false, error:'bad_request' });
    await setSetting(DEV_PROJECTS_KEY, JSON.stringify(body));
    res.json({ ok:true });
  } catch (e) { res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

async function getKanbanFilesIndex() {
  try {
    const raw = await getSetting(DEV_KANBAN_FILES_KEY);
    if (!raw) return {};
    const j = JSON.parse(raw);
    if (j && typeof j === 'object') return j;
  } catch {}
  return {};
}
async function saveKanbanFilesIndex(idx) {
  try { await setSetting(DEV_KANBAN_FILES_KEY, JSON.stringify(idx)); } catch {}
}

// Upload attachment (binary stream)
app.post('/api/dev/kanban/upload', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const filename = String(req.query.filename || '').trim();
    if (!filename) return res.status(400).json({ ok:false, error:'bad_request', message:'filename required' });
    const id = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
    const safe = filename.replace(/[^a-zA-Z0-9._-]+/g, '_');
    const rel = id + '-' + safe;
    const full = path.join(devTrackerUploadDir, rel);
    const ct = String(req.query.content_type || req.headers['content-type'] || 'application/octet-stream');
    let size = 0;
    let aborted = false;
    const ws = fs.createWriteStream(full);
    req.on('data', (chunk) => {
      if (aborted) return;
      try {
        size += chunk.length;
        if (size > MAX_UPLOAD_BYTES) {
          aborted = true;
          try { ws.destroy(); } catch {}
          try { req.destroy(); } catch {}
          try { fs.unlinkSync(full); } catch {}
          return res.status(413).json({ ok:false, error:'too_large' });
        }
      } catch {}
    });
    req.on('error', () => { if (aborted) return; try { ws.destroy(); } catch {}; try { fs.unlinkSync(full); } catch {}; });
    ws.on('error', () => { try { fs.unlinkSync(full); } catch {}; });
    ws.on('finish', async () => {
      try {
        if (aborted) return;
        const idx = await getKanbanFilesIndex();
        idx[id] = { id, file_name: filename, file_path: rel, content_type: ct, size_bytes: size, created_at: new Date().toISOString() };
        await saveKanbanFilesIndex(idx);
        res.json({ ok:true, id, file_name: filename, size_bytes: size, content_type: ct, url: `/api/dev/kanban/file/${id}` });
      } catch (e) {
        res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
      }
    });
    req.pipe(ws);
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Upload attachment (base64 JSON fallback)
app.post('/api/dev/kanban/upload/base64', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const b = req.body || {};
    const filename = String(b.filename || '').trim();
    const base64 = String(b.content_base64 || '').trim();
    if (!filename || !base64) return res.status(400).json({ ok:false, error:'bad_request' });
    const buf = Buffer.from(base64, 'base64');
    if (buf.length > MAX_UPLOAD_BYTES) return res.status(413).json({ ok:false, error:'too_large' });
    const id = `${Date.now()}-${Math.random().toString(16).slice(2)}`;
    const safe = filename.replace(/[^a-zA-Z0-9._-]+/g, '_');
    const rel = id + '-' + safe;
    const full = path.join(devTrackerUploadDir, rel);
    fs.writeFileSync(full, buf);
    const ct = String(b.content_type || 'application/octet-stream');
    const idx = await getKanbanFilesIndex();
    idx[id] = { id, file_name: filename, file_path: rel, content_type: ct, size_bytes: buf.length, created_at: new Date().toISOString() };
    await saveKanbanFilesIndex(idx);
    res.json({ ok:true, id, file_name: filename, size_bytes: buf.length, content_type: ct, url: `/api/dev/kanban/file/${id}` });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Stream attachment
app.get('/api/dev/kanban/file/:id', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const id = String(req.params.id || '').trim();
    const idx = await getKanbanFilesIndex();
    const row = idx[id];
    if (!row) return res.status(404).end();
    const full = path.join(devTrackerUploadDir, row.file_path);
    if (!fs.existsSync(full)) return res.status(404).end();
    res.setHeader('Content-Type', row.content_type || 'application/octet-stream');
    res.setHeader('Content-Disposition', `inline; filename="${row.file_name}"`);
    fs.createReadStream(full).pipe(res);
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Delete attachment (and unlink from any cards)
app.delete('/api/dev/kanban/file/:id', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const id = String(req.params.id || '').trim();
    const idx = await getKanbanFilesIndex();
    const row = idx[id];
    if (!row) return res.status(404).json({ ok:false, error:'not_found' });
    try {
      const full = path.join(devTrackerUploadDir, row.file_path);
      if (fs.existsSync(full)) fs.unlinkSync(full);
    } catch {}
    delete idx[id];
    await saveKanbanFilesIndex(idx);
    // Also remove references in the board
    try {
      const raw = await getSetting(DEV_KANBAN_KEY);
      let board = null; try { board = raw ? JSON.parse(raw) : null; } catch {}
      if (board && Array.isArray(board.cards)) {
        for (const c of board.cards) {
          if (Array.isArray(c.attachments)) {
            c.attachments = c.attachments.filter(a => a?.id !== id);
          }
        }
        await setSetting(DEV_KANBAN_KEY, JSON.stringify({ ...board, updatedAt: Date.now() }));
      }
    } catch {}
    res.json({ ok:true, id });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

// Summarize a code folder using OpenAI
app.post('/api/dev/summary', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    const projectRoot = path.join(__dirname, '..');
    const folderRaw = String(req.body?.folder || '.');
    const mode = String(req.body?.mode || 'summary'); // 'summary' | 'tech'
    const includeExts = (Array.isArray(req.body?.includeExts) ? req.body.includeExts : String(req.body?.includeExts || '').split(/[,\s]+/).filter(Boolean))
      .map((s)=> s.replace(/^\./,'').toLowerCase());
    const model = String(req.body?.model || process.env.OPENAI_MODEL || 'gpt-4o-mini');
    const saveToFile = String(req.body?.saveToFile || '').trim();
    const maxFiles = Math.max(1, Math.min(Number(req.body?.maxFiles || 80), 400));
    const perFileMax = Math.max(200, Math.min(Number(req.body?.perFileMax || 4000), 20000));
    const totalMax = Math.max(10000, Math.min(Number(req.body?.totalMax || 150000), 1500000));

    const folderAbs = path.isAbsolute(folderRaw)
      ? path.resolve(folderRaw)
      : path.resolve(projectRoot, folderRaw);
    if (!isSubPath(projectRoot, folderAbs)) {
      return res.status(400).json({ ok:false, error:'invalid_folder', message:'Folder must be inside project root' });
    }
    // Walk files
    const ignoreDirs = new Set(['node_modules', '.git', 'dist', 'build', '.next', 'uploads', '.vscode', '.idea', '.cache']);
    const pickedExts = includeExts.length ? new Set(includeExts) : new Set(['js','jsx','ts','tsx','json','mjs','cjs','md','css','scss','html','sql']);
    const files = [];
    function walk(dir) {
      let entries = [];
      try { entries = fs.readdirSync(dir, { withFileTypes: true }); } catch { return; }
      for (const ent of entries) {
        const full = path.join(dir, ent.name);
        if (ent.isDirectory()) {
          if (ignoreDirs.has(ent.name)) continue;
          walk(full);
          if (files.length >= maxFiles) return;
        } else if (ent.isFile()) {
          const ext = (ent.name.split('.').pop() || '').toLowerCase();
          if (!pickedExts.has(ext)) continue;
          files.push(full);
          if (files.length >= maxFiles) return;
        }
      }
    }
    walk(folderAbs);

    let total = 0;
    const parts = [];
    for (const f of files) {
      try {
        const rel = path.relative(projectRoot, f).replace(/\\/g,'/');
        let content = fs.readFileSync(f, 'utf8');
        if (content.length > perFileMax) content = content.slice(0, perFileMax) + `\n... (truncated ${content.length - perFileMax} chars)`;
        const head = `\n=== ${rel} ===\n`;
        parts.push(head);
        parts.push(content);
        total += head.length + content.length;
        if (total >= totalMax) break;
      } catch {}
    }

    const instruction = mode === 'tech'
      ? `Tu es un assistant technique. À partir des extraits de fichiers ci-dessous, fournis une synthèse concise des points techniques clés: architecture, modules, endpoints/API, modèles de données, dépendances et décisions importantes. Utilise des puces claires. Réponds en français.`
      : `Tu es un assistant produit/technique. À partir des extraits de fichiers ci-dessous, rédige: (1) un résumé du projet (objectif, fonctionnalités principales, stack), (2) une liste de points techniques clés, (3) les zones de risques ou TODO majeurs. Réponds en français, en listes courtes.`;

    const input = `${instruction}\n\n[FICHIERS]\n${parts.join('\n')}`.slice(0, totalMax);

    const client = createOpenAIClient();
    const r = await client.responses.create({ model, input });
    const text = extractTextFromResponse(r) || '';

    let saved = null;
    if (saveToFile) {
      const targetAbs = path.resolve(projectRoot, saveToFile);
      if (!isSubPath(projectRoot, targetAbs)) {
        return res.status(400).json({ ok:false, error:'invalid_save_path', message:'saveToFile must be inside project' });
      }
      try {
        fs.mkdirSync(path.dirname(targetAbs), { recursive: true });
        fs.writeFileSync(targetAbs, text, 'utf8');
        saved = path.relative(projectRoot, targetAbs).replace(/\\/g,'/');
      } catch (e) {
        return res.status(500).json({ ok:false, error:'save_failed', message: e?.message || String(e), summary: text });
      }
    }

    res.json({ ok:true, summary: text, files: files.map(f=> path.relative(projectRoot, f).replace(/\\/g,'/')), savedTo: saved });
  } catch (e) {
    res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) });
  }
});

const PORT = Number(process.env.PORT || 3010);

server.on("error", (err) => {
  if (err && err.code === "EADDRINUSE") {
    logToFile(`❌ Port ${PORT} already in use. Exiting.`);
    process.exit(1);
  } else {
    throw err;
  }
});

if (!server.listening) {
  server.listen(PORT, "0.0.0.0", () => {
    logToFile(`🚀 Serveur démarré sur http://0.0.0.0:${PORT}`);
  });
}

// Persist selected sitemaps for a domain
// POST /api/grabbings/jerome/domains/select { domain: string, sitemaps: string[] }
app.post('/api/grabbings/jerome/domains/select', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const pool = await getPg();
    if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    try { await ensurePgTables(); } catch {}
    const rawIn = String(req.body?.domain || '').trim();
    const list = Array.isArray(req.body?.sitemaps) ? req.body.sitemaps : [];
    if (!rawIn) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    if (!list.length) return res.status(400).json({ ok:false, error:'bad_request', message:'sitemaps required' });
    let domain = rawIn.toLowerCase();
    try { if (/^https?:\/\//i.test(rawIn)) { const u = new URL(rawIn); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./, '');
    if (!/^[a-z0-9.-]+$/.test(domain)) return res.status(400).json({ ok:false, error:'bad_request', message:'invalid domain' });
    // Normalize sitemaps (any host is allowed)
    const norm = [];
    for (const s of list) {
      try { const abs = new URL(String(s), `https://${domain}`).toString(); norm.push(abs); } catch {}
    }
    const uniq = Array.from(new Set(norm));
    if (!uniq.length) return res.status(400).json({ ok:false, error:'bad_request', message:'no valid sitemaps' });
    await pool.query(
      `insert into grabbing_jerome_domains(domain, selected_sitemaps, updated_at)
       values($1,$2::jsonb, now())
       on conflict (domain)
       do update set selected_sitemaps = EXCLUDED.selected_sitemaps, updated_at = now()`,
      [domain, JSON.stringify(uniq)]
    );
    return res.json({ ok:true, domain, selected_sitemaps: uniq });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'select_failed', message: e?.message || String(e) });
  }
});

// List URLs for a domain from grabbing_jerome_domains_url
// GET /api/grabbings/jerome/domains/urls?domain=example.com&limit=200&offset=0 -> { ok, domain, total, items:[{id,url}] }
app.get('/api/grabbings/jerome/domains/urls', async (req, res) => {
  try {
    const raw = String(req.query?.domain || '').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const limit = Math.min(1000, Math.max(1, Number(req.query?.limit || 200)));
    const offset = Math.max(0, Number(req.query?.offset || 0));
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    const c = await pool.query('select count(*)::int as c from public.grabbing_jerome_domains_url where domain=$1', [domain]);
    const total = Number(c.rows?.[0]?.c || 0);
    const { rows } = await pool.query(
      `select u.id, u.url,
              coalesce(u.page_type, u.type) as page_type,
              u.explored,
              coalesce(u.title, (u.meta->>'title')) as title,
              (u.meta->>'type_reason') as type_reason,
              -- best-effort join to latest explore snapshot for config_version
              (select e.config_version from public.grabbing_jerome_domains_url_page_explore e where e.domain=u.domain and lower(trim(both from e.url))=lower(trim(both from u.url)) order by e.explored_at desc nulls last limit 1) as config_version
         from public.grabbing_jerome_domains_url u
        where u.domain=$1
        order by u.id asc limit $2 offset $3`,
      [domain, limit, offset]
    );
    return res.json({ ok:true, domain, total, items: rows });
  } catch (e) { return res.status(500).json({ ok:false, error:'list_failed', message: e?.message || String(e) }); }
});

// List recent page explores for a domain
// GET /api/grabbings/jerome/page/explore/list?domain=example.com&limit=100 -> { ok, domain, total, items:[{url,page_type,explored_at}] }
app.get('/api/grabbings/jerome/page/explore/list', async (req, res) => {
  try {
    const raw = String(req.query?.domain || '').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const limit = Math.min(500, Math.max(1, Number(req.query?.limit || 100)));
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    const c = await pool.query('select count(*)::int as c from public.grabbing_jerome_domains_url_page_explore where domain=$1', [domain]);
    const total = Number(c.rows?.[0]?.c || 0);
    const { rows } = await pool.query('select url, page_type, explored_at from public.grabbing_jerome_domains_url_page_explore where domain=$1 order by explored_at desc limit $2', [domain, limit]);
    return res.json({ ok:true, domain, total, items: rows });
  } catch (e) { return res.status(500).json({ ok:false, error:'list_failed', message: e?.message || String(e) }); }
});

// Get per-domain extraction config (from file or DB) and surface current version
// GET /api/grabbings/jerome/domains/config?domain=example.com -> { ok, domain, config, config_text, version? }
app.get('/api/grabbings/jerome/domains/config', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const raw = String(req.query?.domain||'').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const safe = domain.replace(/[^a-z0-9.-]/g,'_');
    const filePath = path.join(grabbingJeromeConfigDir, `${safe}.json`);
    // Try DB first
    try {
      const pool = await getPg();
      if (pool) {
        const r = await pool.query('select config, (select max(version) from grabbing_jerome_domain_config_history where domain=$1) as version from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
        if (r.rows && r.rows.length && r.rows[0].config) {
          let config_text = '';
          try { if (fs.existsSync(filePath)) config_text = fs.readFileSync(filePath, 'utf8'); } catch {}
          if (!config_text) { try { config_text = JSON.stringify(r.rows[0].config, null, 2); } catch {} }
          const version = Number(r.rows?.[0]?.version ?? '') || null;
          return res.json({ ok:true, domain, config: r.rows[0].config, config_text, version });
        }
      }
    } catch {}
    // Fallback to file
    const cfg = loadJeromeDomainConfig(domain) || {};
    let config_text = '';
    try { if (fs.existsSync(filePath)) config_text = fs.readFileSync(filePath, 'utf8'); } catch {}
    if (!config_text) { try { config_text = JSON.stringify(cfg, null, 2); } catch {} }
    // Best-effort version lookup from history if DB available
    let version = null;
    try {
      const pool2 = await getPg();
      if (pool2) {
        const vr = await pool2.query('select max(version) as v from grabbing_jerome_domain_config_history where domain=$1', [domain]);
        version = Number(vr.rows?.[0]?.v ?? '') || null;
      }
    } catch {}
    return res.json({ ok:true, domain, config: cfg, config_text, version, source: 'file' });
  } catch (e) { return res.status(500).json({ ok:false, error:'config_failed', message: e?.message || String(e) }); }
});

// Preflight for re-sending images: resolves sources and expected destinations without writing files
// Body: { id_product?, images?: string[], domain?, url? }
// Returns: { ok, id_product, images, existing, items: [{ idx, src, src_resolved, source_type, local_path?, local_exists?, id_image?, dest?, will_update }] }
app.post('/api/presta/products/images/resend/preflight', async (req, res) => {
  try {
    const body = req.body || {};
    let idProduct = Number(body.id_product || 0) || 0;
    let images = Array.isArray(body.images) ? body.images : [];
    const rawDomain = String(body.domain || '').trim();
    const rawUrl = String(body.url || '').trim();

    let referenceFromMapped = '';
    let productRaw = null;
    // Resolve ready-transfer for id_product/images if needed
    if ((!idProduct || !images.length) && rawDomain && rawUrl) {
      try {
        const pool = await getPg();
        if (pool) {
          let domain = rawDomain.toLowerCase();
          try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
          domain = domain.replace(/^www\./,'');
          const r = await pool.query(
            `select notes, mapped, product_raw from public.grabbing_jerome_domains_url_ready_transfert where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2)) limit 1`,
            [domain, rawUrl]
          );
          if (r.rows.length) {
            const notes = String(r.rows[0].notes || '');
            const m = /id_product\s*=\s*(\d+)/i.exec(notes);
            if (m && !idProduct) idProduct = Number(m[1]) || idProduct;
            const mapped = r.rows[0].mapped || {};
            if (!images.length && mapped && Array.isArray(mapped.images)) images = mapped.images;
            try { if (mapped && mapped.sku) referenceFromMapped = String(mapped.sku); } catch {}
            productRaw = r.rows[0].product_raw || null;
          }
        }
      } catch {}
    }

    const toAbsUrl = (u) => { try { const s=String(u||'').trim(); if (!s) return ''; if (/^https?:\/\//i.test(s)) return s; const base = publicBaseFromReq(req) || ''; return base ? new URL(s, base).toString() : s; } catch { return String(u||''); } };
    try {
      // If explicit images provided, normalize and use them
      if (Array.isArray(body.images) && body.images.length) {
        images = body.images.map(toAbsUrl).filter(Boolean);
      }
      if ((!Array.isArray(images) || !images.length) && productRaw && Array.isArray(productRaw.images_local)) {
        const files = productRaw.images_local.map(it => {
          try {
            if (!it) return '';
            const local = it.file ? path.join(grabbingJeromeDir, it.file) : '';
            if (local && fs.existsSync(local)) return local;
            return toAbsUrl((it.url || it.href || it.download_url || '') || '');
          } catch { return ''; }
        }).filter(Boolean);
        images = files;
      }
      if ((!Array.isArray(images) || !images.length) && productRaw && Array.isArray(productRaw.images)) {
        images = productRaw.images.map(u => String(u||'')).filter(Boolean);
      }
      if ((!Array.isArray(images) || !images.length) && rawDomain && rawUrl) {
        try {
          const pool = await getPg();
          if (pool) {
            let domain = rawDomain.toLowerCase();
            try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
            domain = domain.replace(/^www\./,'');
            const hs = await pool.query(
              `select result_json from public.grabbing_jerome_domains_url_page_explore where domain=$1 and lower(trim(both from url))=lower(trim(both from $2)) order by explored_at desc nulls last limit 1`,
              [domain, rawUrl]
            );
            if (hs.rows && hs.rows.length && hs.rows[0].result_json) {
              const data = hs.rows[0].result_json || {};
              const locs = Array.isArray(data?.product?.images_local) ? data.product.images_local : [];
              const files = locs.map(it => { try { if (!it) return ''; const local = it.file ? path.join(grabbingJeromeDir, it.file) : ''; if (local && fs.existsSync(local)) return local; return toAbsUrl((it.url || it.href || it.download_url || '') || ''); } catch { return ''; } }).filter(Boolean);
              if (files.length) images = files;
              if ((!images || !images.length) && data?.meta?.og_image) images = [String(data.meta.og_image)];
            }
          }
        } catch {}
      }
      // normalize + dedupe
      const seen = new Set();
      images = images.map(u=>toAbsUrl(u)).filter(u=>{ const k=(u||'').trim().toLowerCase(); if(!k||seen.has(k)) return false; seen.add(k); return true; });
    } catch {}

    // Load Presta config + existing images to compute expected dests
    let cfg = null; try { const active = await getSetting('PRESTA_DB_ACTIVE'); if (active) { const profilesRaw = await getSetting('PRESTA_DB_PROFILES'); const profiles = profilesRaw ? JSON.parse(profilesRaw) : []; const prof = Array.isArray(profiles) ? profiles.find(x => x && x.name === active) : null; if (prof) cfg = { ...prof }; } } catch {}
    if (!cfg) { try { const raw = await getSetting('PRESTA_DB_JSON'); cfg = raw ? JSON.parse(raw) : null; } catch {} }
    if (!cfg || !cfg.host || !cfg.user || !cfg.database) return res.status(412).json({ ok:false, error:'presta_db_not_configured' });

    const mysql2 = await import('mysql2/promise');
    const conn = await mysql2.createConnection({ host: cfg.host, port: Number(cfg.port||3306), user: cfg.user, password: cfg.password, database: cfg.database, multipleStatements: true });
    const p = String(cfg.table_prefix||'ps_');
    if (!idProduct && referenceFromMapped) {
      try { const [rr] = await conn.execute(`SELECT id_product FROM \`${p}product\` WHERE reference=? LIMIT 1`, [referenceFromMapped]); if (Array.isArray(rr) && rr.length) idProduct = Number(rr[0].id_product)||0; } catch {}
    }
    if (!idProduct) { try { await conn.end(); } catch {}; return res.status(400).json({ ok:false, error:'bad_request', message:'id_product required (or provide domain+url linked to a transferred item)' }); }
    const [rows] = await conn.execute(`SELECT id_image, position, cover FROM \`${p}image\` WHERE id_product=? ORDER BY position ASC, id_image ASC`, [idProduct]);
    try { await conn.end(); } catch {}

    const root = String(process.env.PRESTA_ROOT || '').trim();
    const makePath = (id) => { const parts = String(id).split(''); const dir = path.join(root, 'img', 'p', ...parts); const file = path.join(dir, `${id}.jpg`); return { dir, file }; };

    const items = images.map((src, idx) => {
      let srcResolved = String(src||'');
      let sourceType = /^https?:\/\//i.test(srcResolved) ? 'remote' : (srcResolved.startsWith('/') ? 'doc_url' : (fs.existsSync(srcResolved) ? 'local_file' : 'unknown'));
      // Improve detection: treat relative Jerome doc URLs as doc_url even when not starting with '/'
      try { if (sourceType === 'unknown' && /^\/?api\/grabbings\/jerome\/doc\//i.test(srcResolved)) sourceType = 'doc_url'; } catch {}
      let localPath = '';
      let localExists = false;
      try {
        if (sourceType === 'remote') {
          try {
            const uo = new URL(srcResolved);
            if (/^\/api\/grabbings\/jerome\/doc\//i.test(uo.pathname) || /\/api\/grabbings\/jerome\/doc\//i.test(srcResolved)) {
              sourceType = 'doc_url';
            }
          } catch {}
        }
        if (sourceType === 'doc_url') {
          try { const name = decodeURIComponent(srcResolved.split('/').pop()||''); const pth = path.join(grabbingJeromeDir, name); localPath = pth; localExists = fs.existsSync(pth); } catch {}
        } else if (sourceType === 'local_file') {
          localPath = srcResolved; localExists = fs.existsSync(srcResolved);
        }
      } catch {}
      const existingRow = Array.isArray(rows) && rows[idx] ? rows[idx] : null;
      const id_image = existingRow ? existingRow.id_image : null;
      const dest = (id_image && root) ? makePath(id_image).file : null;
      return { idx, src, src_resolved: srcResolved, source_type: sourceType, local_path: localPath || null, local_exists: localExists || false, id_image, dest, will_update: !!existingRow };
    });

    return res.json({ ok:true, id_product: idProduct, images: images.length, existing: Array.isArray(rows)? rows.length: 0, items });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'preflight_failed', message: e?.message || String(e) });
  }
});

// Resolve stored config_version for a batch of URLs from history only (no fallbacks)
// POST /api/grabbings/jerome/domains/urls/versions { domain, urls: ["https://..."] }
// -> { ok, domain, items: [{ url, config_version, explored_at }] }
app.post('/api/grabbings/jerome/domains/urls/versions', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    let domain = String(req.body?.domain || '').trim().toLowerCase();
    const urls = Array.isArray(req.body?.urls) ? req.body.urls.map(x=>String(x||'').trim()).filter(Boolean) : [];
    if (!domain || !urls.length) return res.status(400).json({ ok:false, error:'bad_request', message:'domain and urls required' });
    try { if (/^https?:\/\//i.test(domain)) { const u = new URL(domain); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    // Normalize url keys to lower-trimmed for matching
    const keys = urls.map(s => s.toLowerCase().trim());
    const sql = `
      select distinct on (lower(trim(both from url)))
             url,
             coalesce(config_version, nullif((result_json->'meta'->'config_used'->>'version'),'')::int) as config_version,
             explored_at
        from public.grabbing_jerome_domains_url_page_explore
       where domain = $1
         and lower(trim(both from url)) = any($2)
       order by lower(trim(both from url)), explored_at desc nulls last`;
    const { rows } = await pool.query(sql, [domain, keys]);
    return res.json({ ok:true, domain, items: rows });
  } catch (e) { return res.status(500).json({ ok:false, error:'versions_failed', message: e?.message || String(e) }); }
});

// Get per-domain transfer config (per type) and current version
// GET /api/grabbings/jerome/domains/config-transfert?domain=example.com&type=product
app.get('/api/grabbings/jerome/domains/config-transfert', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const raw = String(req.query?.domain||'').trim();
    const type = String(req.query?.type||'product').trim().toLowerCase() || 'product';
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    const r = await pool.query('select config_transfert from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
    const all = r.rows?.[0]?.config_transfert || {};
    const cfg = (all && typeof all === 'object') ? (all[type] || {}) : {};
    let version = null;
    try {
      const vr = await pool.query('select max(version) as v from grabbing_jerome_domain_config_transfert_history where domain=$1 and type=$2', [domain, type]);
      version = Number(vr.rows?.[0]?.v ?? '') || null;
    } catch {}
    return res.json({ ok:true, domain, type, config: cfg, version });
  } catch (e) { return res.status(500).json({ ok:false, error:'config_transfert_failed', message: e?.message || String(e) }); }
});

// Save per-domain transfer config (per type) and append to history with versioning
// POST /api/grabbings/jerome/domains/config-transfert { domain, type, config }
app.post('/api/grabbings/jerome/domains/config-transfert', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    let domain = String(req.body?.domain||'').trim().toLowerCase();
    const type = String(req.body?.type||'product').trim().toLowerCase() || 'product';
    const config = (req.body && typeof req.body.config === 'object') ? req.body.config : {};
    if (!domain) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    // Merge into config_transfert JSON by type
    let current = {};
    try {
      const r = await pool.query('select config_transfert from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
      current = r.rows?.[0]?.config_transfert || {};
    } catch {}
    const nextAll = { ...(current || {}) };
    nextAll[type] = config || {};
    await pool.query(
      `insert into grabbing_jerome_domains(domain, config_transfert, updated_at)
       values($1,$2::jsonb, now())
       on conflict (domain) do update set config_transfert = EXCLUDED.config_transfert, updated_at = now()`,
      [domain, JSON.stringify(nextAll)]
    );
    // History version per domain+type
    let nextVer = 1;
    try {
      const vr = await pool.query('select coalesce(max(version),0)+1 as v from grabbing_jerome_domain_config_transfert_history where domain=$1 and type=$2', [domain, type]);
      nextVer = Number(vr.rows?.[0]?.v || 1);
    } catch {}
    await pool.query('insert into grabbing_jerome_domain_config_transfert_history(domain, type, config, version) values($1,$2,$3::jsonb,$4)', [domain, type, JSON.stringify(config), nextVer]);
    return res.json({ ok:true, domain, type, saved: true, version: nextVer });
  } catch (e) { return res.status(500).json({ ok:false, error:'config_transfert_failed', message: e?.message || String(e) }); }
});

// List transfer config history for a domain/type
// GET /api/grabbings/jerome/domains/config-transfert/history?domain=example.com&type=product
app.get('/api/grabbings/jerome/domains/config-transfert/history', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const raw = String(req.query?.domain||'').trim();
    const type = String(req.query?.type||'product').trim().toLowerCase() || 'product';
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.json({ ok:true, domain, type, items: [] });
    const { rows } = await pool.query('select id, saved_at, config, version from grabbing_jerome_domain_config_transfert_history where domain=$1 and type=$2 order by saved_at desc limit 50', [domain, type]);
    return res.json({ ok:true, domain, type, items: rows });
  } catch (e) { return res.status(500).json({ ok:false, error:'history_failed', message: e?.message || String(e) }); }
});

// Revert transfer config to a specific history entry
// POST /api/grabbings/jerome/domains/config-transfert/revert { domain, type, id }
app.post('/api/grabbings/jerome/domains/config-transfert/revert', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    let domain = String(req.body?.domain||'').trim().toLowerCase();
    const type = String(req.body?.type||'product').trim().toLowerCase() || 'product';
    const id = Number(req.body?.id||0);
    if (!domain || !id) return res.status(400).json({ ok:false, error:'bad_request', message:'domain and id required' });
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    const one = await pool.query('select config from grabbing_jerome_domain_config_transfert_history where id=$1 and domain=$2 and type=$3 limit 1', [id, domain, type]);
    if (!one.rows.length) return res.status(404).json({ ok:false, error:'not_found' });
    const config = one.rows[0].config || {};
    // Merge into config_transfert by type and persist
    let current = {};
    try {
      const r = await pool.query('select config_transfert from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
      current = r.rows?.[0]?.config_transfert || {};
    } catch {}
    const nextAll = { ...(current || {}) };
    nextAll[type] = config || {};
    await pool.query(
      `insert into grabbing_jerome_domains(domain, config_transfert, updated_at)
       values($1,$2::jsonb, now())
       on conflict (domain) do update set config_transfert = EXCLUDED.config_transfert, updated_at = now()`,
      [domain, JSON.stringify(nextAll)]
    );
    // Append new history entry (new version)
    let nextVer = 1;
    try {
      const vr = await pool.query('select coalesce(max(version),0)+1 as v from grabbing_jerome_domain_config_transfert_history where domain=$1 and type=$2', [domain, type]);
      nextVer = Number(vr.rows?.[0]?.v || 1);
    } catch {}
    await pool.query('insert into grabbing_jerome_domain_config_transfert_history(domain, type, config, version) values($1, $2, $3::jsonb, $4)', [domain, type, JSON.stringify(config), nextVer]);
    return res.json({ ok:true, domain, type, id, reverted: true, version: nextVer });
  } catch (e) { return res.status(500).json({ ok:false, error:'revert_failed', message: e?.message || String(e) }); }
});

// Delete a specific transfer config history entry by id
app.delete('/api/grabbings/jerome/domains/config-transfert/history/:id', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const id = Number(req.params.id || 0);
    if (!id) return res.status(400).json({ ok:false, error:'bad_request', message:'id required' });
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    await pool.query('delete from grabbing_jerome_domain_config_transfert_history where id=$1', [id]);
    return res.json({ ok:true, id });
  } catch (e) { return res.status(500).json({ ok:false, error:'delete_failed', message: e?.message || String(e) }); }
});

// GET stored snapshot (result_json) for a domain+url
app.get('/api/grabbings/jerome/domains/url/stored', async (req, res) => {
  try {
    const rawDomain = String(req.query?.domain || '').trim();
    const rawUrl = String(req.query?.url || '').trim();
    if (!rawDomain || !rawUrl) return res.status(400).json({ ok:false, error:'bad_request', message:'domain and url required' });
    let domain = rawDomain.toLowerCase();
    try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    const q = await pool.query(
      `select url, page_type, explored_at, result_json
         from public.grabbing_jerome_domains_url_page_explore
        where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2))
        order by explored_at desc nulls last
        limit 1`,
      [domain, rawUrl]
    );
    if (!q.rows?.length) return res.status(404).json({ ok:false, error:'not_found' });
    const row = q.rows[0];
    return res.json({ ok:true, item:{ domain, url: row.url, page_type: row.page_type || null, explored_at: row.explored_at || null, result_json: row.result_json || null } });
  } catch (e) { return res.status(500).json({ ok:false, error:'stored_read_failed', message: e?.message || String(e) }); }
});

// Save per-domain extraction config
// POST /api/grabbings/jerome/domains/config { domain, config }
app.post('/api/grabbings/jerome/domains/config', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    let domain = String(req.body?.domain||'').trim().toLowerCase();
    let config = req.body?.config;
    const configText = String(req.body?.config_text || '').trim();
    if (!domain) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    if (typeof config !== 'object') {
      if (!configText) return res.status(400).json({ ok:false, error:'bad_request', message:'config or config_text required' });
      try { config = JSON.parse(configText); }
      catch (e) {
        const msg = String(e?.message||'');
        const m = msg.match(/position\s+(\d+)/i);
        if (m) {
          const pos = Number(m[1]);
          let line = 1, col = 1;
          for (let i=0;i<configText.length && i<pos;i++){ if (configText[i]==='\n'){ line++; col=1; } else { col++; } }
          return res.status(400).json({ ok:false, error:'bad_json', message:`Invalid JSON at ${line}:${col} (pos ${pos})` });
        }
        return res.status(400).json({ ok:false, error:'bad_json', message:'config_text is not valid JSON' });
      }
    }
    // Validate regex fields eagerly to surface errors at save time
    try {
      const bad = (field, pat) => res.status(400).json({ ok:false, error:'bad_regex', message:`Invalid regex in ${field}: ${pat}` });
      // images.exclude_regex
      if (Array.isArray(config?.images?.exclude_regex)) {
        for (let i=0;i<config.images.exclude_regex.length;i++) {
          const p = String(config.images.exclude_regex[i] ?? '');
          try { void new RegExp(p, 'i'); } catch { return bad(`images.exclude_regex[${i}]`, p); }
        }
      }
      // content.exclude
      if (Array.isArray(config?.content?.exclude)) {
        for (let i=0;i<config.content.exclude.length;i++) {
          const p = String(config.content.exclude[i] ?? '');
          try { void new RegExp(p, 'gi'); } catch { return bad(`content.exclude[${i}]`, p); }
        }
      }
      // classify.path_rules.pattern
      if (Array.isArray(config?.classify?.path_rules)) {
        for (let i=0;i<config.classify.path_rules.length;i++) {
          const pr = config.classify.path_rules[i] || {};
          const p = String(pr.pattern ?? '');
          if (!p) continue;
          try { void new RegExp(p, 'i'); } catch { return bad(`classify.path_rules[${i}].pattern`, p); }
        }
      }
    } catch {}
    domain = domain.replace(/^www\./,'');
    // DB-only: do not write file copy
    // Save to DB (upsert) + history
  let db_ok = false, hist_ok = false;
  let nextVer = null;
    const note = String(req.body?.note || req.body?.message || '').trim();
    try {
      const pool = await getPg();
      if (pool) {
        try { await ensurePgTables(); } catch {}
        try {
          await pool.query(
            `insert into grabbing_jerome_domains(domain, config, updated_at)
             values($1,$2::jsonb, now())
             on conflict (domain) do update set config = EXCLUDED.config, updated_at = now()`,
            [domain, JSON.stringify(config)]
          );
          db_ok = true;
        } catch {}
        try {
          // Compute next version per domain
          try {
            const vr = await pool.query('select coalesce(max(version),0)+1 as v from grabbing_jerome_domain_config_history where domain=$1', [domain]);
            nextVer = Number(vr.rows?.[0]?.v || 1);
          } catch {}
          if (note) await pool.query('insert into grabbing_jerome_domain_config_history(domain, config, version, note) values($1, $2::jsonb, $3, $4)', [domain, JSON.stringify(config), nextVer, note]);
          else await pool.query('insert into grabbing_jerome_domain_config_history(domain, config, version) values($1, $2::jsonb, $3)', [domain, JSON.stringify(config), nextVer]);
          hist_ok = true;
        } catch {}
      }
    } catch {}
    return res.json({ ok:true, domain, persisted: true, db_ok, hist_ok, version: (Number.isFinite(Number(nextVer)) ? Number(nextVer) : null) });
  } catch (e) { return res.status(500).json({ ok:false, error:'config_failed', message: e?.message || String(e) }); }
});

// Validate current (or provided) Presta DB profile against required entities
app.post('/api/admin/presta-db/validate', async (req, res) => {
  const u = requireAdmin(req, res); if (!u) return;
  try {
    // Resolve config from body > active profile > base config
    let cfg = req.body && typeof req.body === 'object' ? req.body : {};
    const needConn = !cfg || !cfg.host || !cfg.user || !cfg.database;
    if (needConn) {
      try {
        const active = await getSetting('PRESTA_DB_ACTIVE');
        if (active) {
          const profilesRaw = await getSetting('PRESTA_DB_PROFILES');
          const profiles = profilesRaw ? JSON.parse(profilesRaw) : [];
          const p = Array.isArray(profiles) ? profiles.find(x => x && x.name === active) : null;
          if (p) cfg = { ...p, ...(cfg||{}) };
        }
      } catch {}
      if (!cfg || !cfg.host) {
        try { const baseRaw = await getSetting('PRESTA_DB_JSON'); const base = baseRaw ? JSON.parse(baseRaw) : null; if (base) cfg = { ...base, ...(cfg||{}) }; } catch {}
      }
    }
    if (!cfg || !cfg.host || !cfg.user || !cfg.database) return res.status(400).json({ ok:false, error:'bad_request', message:'host, user, database required' });
    // Fill password from saved config if omitted
    if (!cfg.password) {
      try {
        const active = await getSetting('PRESTA_DB_ACTIVE');
        if (active) {
          const profilesRaw = await getSetting('PRESTA_DB_PROFILES');
          const profiles = profilesRaw ? JSON.parse(profilesRaw) : [];
          const p = Array.isArray(profiles) ? profiles.find(x => x && x.name === active) : null;
          if (p && p.password) cfg.password = p.password;
        }
      } catch {}
      if (!cfg.password) {
        try { const baseRaw = await getSetting('PRESTA_DB_JSON'); const base = baseRaw ? JSON.parse(baseRaw) : null; if (base && base.password) cfg.password = base.password; } catch {}
      }
    }
    const mysql2 = await import('mysql2/promise');
    const conn = await mysql2.createConnection({ host: cfg.host, port: Number(cfg.port||3306), user: cfg.user, password: cfg.password, database: cfg.database });
    const pfx = String(cfg.table_prefix||'ps_');
    const idCategory = Number(cfg.default_category_id||0);
    const idLang = Number(cfg.default_lang_id||1)||1;
    const idTax = Number(cfg.default_tax_rules_group_id||0)||0;
    let shops = [];
    if (Array.isArray(cfg.default_shop_ids)) shops = cfg.default_shop_ids.map(n=>Number(n)).filter(n=>!isNaN(n)&&n>0); else shops = String(cfg.default_shop_ids||'1').split(',').map(s=>Number(s.trim())).filter(n=>!isNaN(n)&&n>0);
    const out = { ok:true, details:{} };
    const q = async (sql, params=[]) => { try { const [rows] = await conn.execute(sql, params); return Array.isArray(rows)? rows: []; } catch { return []; } };
    // Shops
    let existShops = [];
    if (shops.length) { const ph = shops.map(()=>'?').join(','); const rows = await q(`SELECT id_shop FROM \`${pfx}shop\` WHERE id_shop IN (${ph})`, shops); existShops = rows.map(r=>Number(r.id_shop||0)); }
    const missingShops = shops.filter(s => !existShops.includes(Number(s)));
    out.details.shops = { input: shops, exists: existShops, missing: missingShops };
    // Category + category_shop
    let catExists = false; if (idCategory>0) { const r = await q(`SELECT id_category FROM \`${pfx}category\` WHERE id_category=? LIMIT 1`, [idCategory]); catExists = r.length>0; }
    out.details.category = { id: idCategory, exists: !!catExists };
    let catShopMissing = [];
    if (catExists && existShops.length) {
      const ph = existShops.map(()=>'?').join(',');
      const rows = await q(`SELECT id_shop FROM \`${pfx}category_shop\` WHERE id_category=? AND id_shop IN (${ph})`, [idCategory, ...existShops]);
      const have = new Set(rows.map(r=>Number(r.id_shop||0)));
      catShopMissing = existShops.filter(s => !have.has(Number(s)));
    }
    out.details.category_shop = { id_category: idCategory, missing: catShopMissing };
    // Tax rules group
    let taxExists = false; if (idTax>0) { const r = await q(`SELECT id_tax_rules_group FROM \`${pfx}tax_rules_group\` WHERE id_tax_rules_group=? LIMIT 1`, [idTax]); taxExists = r.length>0; }
    out.details.tax_group = { id: idTax, exists: !!taxExists };
    // product_lang id_shop presence (for info)
    let plHasIdShop = false; try { const [cols] = await conn.execute(`SHOW COLUMNS FROM \`${pfx}product_lang\``); plHasIdShop = Array.isArray(cols) && cols.some(c=> (c.Field||c.COLUMN_NAME)==='id_shop'); } catch {}
    out.details.product_lang_has_id_shop = !!plHasIdShop;
    try { await conn.end(); } catch {}
    return res.json(out);
  } catch (e) {
    return res.status(500).json({ ok:false, error:'validate_failed', message: e?.message || String(e) });
  }
});

// List config history for a domain
app.get('/api/grabbings/jerome/domains/config/history', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const raw = String(req.query?.domain||'').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.json({ ok:true, domain, items: [] });
    const { rows } = await pool.query('select id, saved_at, config, version, note from grabbing_jerome_domain_config_history where domain=$1 order by saved_at desc limit 50', [domain]);
    return res.json({ ok:true, domain, items: rows });
  } catch (e) { return res.status(500).json({ ok:false, error:'history_failed', message: e?.message || String(e) }); }
});

// Revert current config to a specific history entry
app.post('/api/grabbings/jerome/domains/config/revert', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    let domain = String(req.body?.domain||'').trim().toLowerCase();
    const id = Number(req.body?.id||0);
    if (!domain || !id) return res.status(400).json({ ok:false, error:'bad_request', message:'domain and id required' });
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    const one = await pool.query('select config from grabbing_jerome_domain_config_history where id=$1 and domain=$2 limit 1', [id, domain]);
    if (!one.rows.length) return res.status(404).json({ ok:false, error:'not_found' });
    const config = one.rows[0].config || {};
    const note = String(req.body?.note || `revert to id=${id}`).trim();
    // Persist as current and add new history entry
    await pool.query(
      `insert into grabbing_jerome_domains(domain, config, updated_at)
       values($1,$2::jsonb, now())
       on conflict (domain) do update set config = EXCLUDED.config, updated_at = now()`,
      [domain, JSON.stringify(config)]
    );
    // Compute next version and persist it
    let nextVer = 1;
    try {
      const vr = await pool.query('select coalesce(max(version),0)+1 as v from grabbing_jerome_domain_config_history where domain=$1', [domain]);
      nextVer = Number(vr.rows?.[0]?.v || 1);
    } catch {}
    if (note) await pool.query('insert into grabbing_jerome_domain_config_history(domain, config, version, note) values($1, $2::jsonb, $3, $4)', [domain, JSON.stringify(config), nextVer, note]);
    else await pool.query('insert into grabbing_jerome_domain_config_history(domain, config, version) values($1, $2::jsonb, $3)', [domain, JSON.stringify(config), nextVer]);
    // DB-only: no file write
    return res.json({ ok:true, domain, id, reverted: true, version: nextVer });
  } catch (e) { return res.status(500).json({ ok:false, error:'revert_failed', message: e?.message || String(e) }); }
});

// Delete a specific config history entry by id
app.delete('/api/grabbings/jerome/domains/config/history/:id', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const id = Number(req.params.id || 0);
    if (!id) return res.status(400).json({ ok:false, error:'bad_request', message:'id required' });
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    await pool.query('delete from grabbing_jerome_domain_config_history where id=$1', [id]);
    return res.json({ ok:true, id });
  } catch (e) { return res.status(500).json({ ok:false, error:'delete_failed', message: e?.message || String(e) }); }
});

// Bulk delete history entries for a domain
// POST /api/grabbings/jerome/domains/config/history/delete { domain, ids?, before_version?, before_date?, keep_last? }
app.post('/api/grabbings/jerome/domains/config/history/delete', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const domainRaw = String(req.body?.domain||'').trim();
    if (!domainRaw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    const domain = domainRaw.toLowerCase().replace(/^www\./,'');
    const ids = Array.isArray(req.body?.ids) ? req.body.ids.map(x=>Number(x)).filter(n=>Number.isFinite(n)&&n>0) : [];
    const beforeVersion = Number(req.body?.before_version||0) || 0;
    const beforeDate = String(req.body?.before_date||'').trim(); // ISO date
    const keepLast = Number(req.body?.keep_last||0) || 0;
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });

    let where = 'domain = $1';
    const params = [domain];
    if (ids.length) {
      // delete explicit ids only
      const placeholders = ids.map((_,i)=>`$${i+2}`).join(',');
      where += ` AND id IN (${placeholders})`;
      for (const id of ids) params.push(id);
    } else if (beforeVersion > 0) {
      params.push(beforeVersion);
      where += ` AND version < $${params.length}`;
    } else if (beforeDate) {
      params.push(new Date(beforeDate));
      where += ` AND saved_at < $${params.length}`;
    } else if (keepLast > 0) {
      // delete all except latest N
      params.push(keepLast);
      where += ` AND id NOT IN (
        SELECT id FROM grabbing_jerome_domain_config_history WHERE domain=$1 ORDER BY saved_at DESC LIMIT $${params.length}
      )`;
    } else {
      return res.status(400).json({ ok:false, error:'bad_request', message:'Provide ids, before_version, before_date, or keep_last' });
    }
    const q = `DELETE FROM grabbing_jerome_domain_config_history WHERE ${where}`;
    const r = await pool.query(q, params);
    return res.json({ ok:true, domain, deleted: r.rowCount||0 });
  } catch (e) { return res.status(500).json({ ok:false, error:'bulk_delete_failed', message: e?.message || String(e) }); }
});

// Build a sitemap tree (index → child sitemaps → urls) from a starting URL
// GET /api/grabbings/jerome/sitemap/tree?url=https://example.com/sitemap_index.xml&max_sitemaps=1000&max_urls=10000
// Returns: { ok, root: { url, type:'index'|'urlset', lastmod?, children:[...] }, flat_sitemaps: [url,...] }
app.get('/api/grabbings/jerome/sitemap/tree', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const startUrl = String(req.query?.url || '').trim();
    if (!/^https?:\/\//i.test(startUrl)) return res.status(400).json({ ok:false, error:'bad_request', message:'Valid url required' });
    const maxSitemaps = Math.max(1, Math.min(Number(req.query?.max_sitemaps || 2000), 100000));
    const maxUrls = Math.max(100, Math.min(Number(req.query?.max_urls || 10000), 1000000));
    const origin = new URL(startUrl);
    const visited = new Set();
    const flat = new Set();

    const parseXml = (xml) => {
      const locs = Array.from(xml.matchAll(/<loc>\s*([^<\s][^<]*)\s*<\/loc>/gi)).map(m => (m && m[1] ? m[1].trim() : '')).filter(Boolean);
      const isIndex = /<sitemapindex[\s>]/i.test(xml);
      // Map lastmod for <sitemap> entries (best-effort)
      const lastmods = [];
      try {
        const smRe = /<sitemap>([\s\S]*?)<\/sitemap>/gi;
        let m;
        while ((m = smRe.exec(xml))) {
          const block = m[1] || '';
          const loc = ((block.match(/<loc>\s*([^<]+)\s*<\/loc>/i) || [])[1] || '').trim();
          const lm = ((block.match(/<lastmod>\s*([^<]+)\s*<\/lastmod>/i) || [])[1] || '').trim();
          if (loc) lastmods.push({ loc, lastmod: lm });
        }
      } catch {}
      return { isIndex, locs, lastmods };
    };

    const gunzipMaybe = async (buf, url) => {
      try { if (/\.gz($|\?)/i.test(url)) { const z = await import('zlib'); return z.gunzipSync(Buffer.from(buf)).toString('utf8'); } } catch {}
      return Buffer.isBuffer(buf) ? buf.toString('utf8') : String(buf);
    };

    const fetchSitemap = async (url) => {
      const node = { url, type:'urlset', children:[] };
      if (!url || visited.has(url) || visited.size >= maxSitemaps) return node;
      visited.add(url); flat.add(url);
      const r = await fetch(url, { method:'GET' });
      if (!r.ok) return node;
      const arr = Buffer.from(await r.arrayBuffer());
      const xml = await gunzipMaybe(arr, url);
      const { isIndex, locs, lastmods } = parseXml(xml || '');
      if (isIndex) node.type = 'index';
      // lastmod for this node (first match in file)
      try { const lmSelf = (xml.match(/<lastmod>\s*([^<]+)\s*<\/lastmod>/i) || [])[1]; if (lmSelf) node.lastmod = lmSelf.trim(); } catch {}
      if (isIndex) {
        for (const loc of (locs||[])) {
          if (node.children.length >= maxSitemaps) break;
          try {
            const abs = new URL(loc, origin).toString();
            const child = await fetchSitemap(abs);
            // attach lastmod from index listing if found
            const lm = (lastmods.find(x => (x.loc||'').trim() === loc.trim()) || {}).lastmod;
            if (lm && !child.lastmod) child.lastmod = lm;
            node.children.push(child);
          } catch {}
        }
      } else {
        // urlset: keep a small sample but avoid heavy payloads
        node.sample = (locs||[]).slice(0, 25).map(loc => { try { return new URL(loc, origin).toString(); } catch { return loc; } });
      }
      return node;
    };

    const root = await fetchSitemap(new URL(startUrl).toString());
    return res.json({ ok:true, root, flat_sitemaps: Array.from(flat) });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'tree_failed', message: e?.message || String(e) });
  }
});

// Fetch stored details for a specific domain+url from canonical table (fallback to history)
// GET /api/grabbings/jerome/domains/url?domain=example.com&url=https://example.com/p/123
// -> { ok, domain, url, page_type, title, meta, product, links_sample? }
app.get('/api/grabbings/jerome/domains/url', async (req, res) => {
  try {
    const rawDomain = String(req.query?.domain || '').trim();
    const rawUrl = String(req.query?.url || '').trim();
    if (!rawDomain || !rawUrl) return res.status(400).json({ ok:false, error:'bad_request', message:'domain and url required' });
    let domain = rawDomain.toLowerCase();
    try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    // Try canonical table first
    const one = await pool.query(
      `select coalesce(page_type, type) as page_type,
              coalesce(title, (meta->>'title')) as title,
              meta, product
         from public.grabbing_jerome_domains_url
        where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2))
        limit 1`,
      [domain, rawUrl]
    );
    if (one.rows.length) {
      const r = one.rows[0];
      // Try to enrich with latest links_sample from history table (optional)
      let links_sample = undefined;
      try {
        const h = await pool.query(
          `select links_sample from public.grabbing_jerome_domains_url_page_explore
             where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2))
             order by explored_at desc limit 1`,
          [domain, rawUrl]
        );
        if (h.rows && h.rows[0] && Array.isArray(h.rows[0].links_sample)) links_sample = h.rows[0].links_sample;
      } catch {}
      return res.json({ ok:true, domain, url: rawUrl, page_type: r.page_type || '', title: r.title || '', meta: r.meta || {}, product: r.product || {}, ...(links_sample? { links_sample } : {}) });
    }
    // Fallback to history table
    const two = await pool.query(
      `select page_type, meta, product, links_sample
         from public.grabbing_jerome_domains_url_page_explore
        where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2))
        limit 1`,
      [domain, rawUrl]
    );
    if (two.rows.length) {
      const r = two.rows[0];
      const title = (r.meta && r.meta.title) ? r.meta.title : '';
      return res.json({ ok:true, domain, url: rawUrl, page_type: r.page_type || '', title, meta: r.meta || {}, product: r.product || {}, links_sample: Array.isArray(r.links_sample)? r.links_sample: undefined });
    }
    return res.status(404).json({ ok:false, error:'not_found' });
  } catch (e) { return res.status(500).json({ ok:false, error:'server_error', message: e?.message || String(e) }); }
});

// Reset explored status and snapshots
// POST /api/grabbings/jerome/domains/urls/reset-explored
// Body: { domain: string, urls?: string[], all?: boolean }
// Effect:
//  - Deletes snapshots from grabbing_jerome_domains_url_page_explore for the domain (+ optional URL filter)
//  - Sets explored = NULL in grabbing_jerome_domains_url for the domain (+ optional URL filter)
app.post('/api/grabbings/jerome/domains/urls/reset-explored', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const raw = String(req.body?.domain || '').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const urlsRaw = Array.isArray(req.body?.urls) ? req.body.urls : [];
    const urls = urlsRaw.map(s => String(s||'').trim()).filter(Boolean);
    const all = !!req.body?.all;
    const deleteUrls = !!req.body?.delete_urls;
    if (!all && !urls.length) return res.status(400).json({ ok:false, error:'bad_request', message:'provide urls[] or set all=true' });

    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    let deleted = 0, updated = 0;
    if (all) {
      const del = await pool.query('delete from public.grabbing_jerome_domains_url_page_explore where domain=$1', [domain]);
      deleted = Number(del.rowCount||0);
      if (deleteUrls) {
        const del2 = await pool.query('delete from public.grabbing_jerome_domains_url where domain=$1', [domain]);
        updated = Number(del2.rowCount||0);
      } else {
        const upd = await pool.query('update public.grabbing_jerome_domains_url set explored = NULL where domain=$1', [domain]);
        updated = Number(upd.rowCount||0);
      }
    } else {
      // Delete by URL list (case/space insensitive)
      // Build a lower(trim(url)) IN (...) list using UNNEST
      const list = urls.map(s => s.toLowerCase().trim());
      const del = await pool.query(
        `delete from public.grabbing_jerome_domains_url_page_explore
           where domain=$1 and lower(trim(both from url)) = any($2::text[])`,
        [domain, list]
      );
      deleted = Number(del.rowCount||0);
      if (deleteUrls) {
        const del2 = await pool.query(
          `delete from public.grabbing_jerome_domains_url
             where domain=$1 and lower(trim(both from url)) = any($2::text[])`,
          [domain, list]
        );
        updated = Number(del2.rowCount||0);
      } else {
        const upd = await pool.query(
          `update public.grabbing_jerome_domains_url
              set explored = NULL
            where domain=$1 and lower(trim(both from url)) = any($2::text[])`,
          [domain, list]
        );
        updated = Number(upd.rowCount||0);
      }
    }
    return res.json({ ok:true, domain, deleted_snapshots: deleted, affected_rows: updated, deleted_urls: deleteUrls });
  } catch (e) { return res.status(500).json({ ok:false, error:'reset_failed', message: e?.message || String(e) }); }
});

// Clear metadata fields on stored domain URLs (without deleting rows)
// POST /api/grabbings/jerome/domains/urls/clear-fields
// Body: { domain: string, urls?: string[], all?: boolean, reset_discovered_at?: boolean }
// Clears: type, title, page_type, meta, product, explored; optionally resets discovered_at to now()
app.post('/api/grabbings/jerome/domains/urls/clear-fields', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const raw = String(req.body?.domain || '').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const urlsRaw = Array.isArray(req.body?.urls) ? req.body.urls : [];
    const urls = urlsRaw.map(s => String(s||'').trim()).filter(Boolean);
    const all = !!req.body?.all;
    const resetDiscoveredAt = !!req.body?.reset_discovered_at;
    if (!all && !urls.length) return res.status(400).json({ ok:false, error:'bad_request', message:'provide urls[] or set all=true' });

    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    let affected = 0;
    if (all) {
      const upd = await pool.query(
        `update public.grabbing_jerome_domains_url
            set type = NULL,
                title = NULL,
                page_type = NULL,
                meta = NULL,
                product = NULL,
                explored = NULL,
                discovered_at = case when $2 then now() else discovered_at end
          where domain = $1`,
        [domain, resetDiscoveredAt]
      );
      affected = Number(upd.rowCount||0);
    } else {
      const list = urls.map(s => s.toLowerCase().trim());
      const upd = await pool.query(
        `update public.grabbing_jerome_domains_url
            set type = NULL,
                title = NULL,
                page_type = NULL,
                meta = NULL,
                product = NULL,
                explored = NULL,
                discovered_at = case when $3 then now() else discovered_at end
          where domain = $1 and lower(trim(both from url)) = any($2::text[])`,
        [domain, list, resetDiscoveredAt]
      );
      affected = Number(upd.rowCount||0);
    }
    return res.json({ ok:true, domain, affected_rows: affected, reset_discovered_at: resetDiscoveredAt });
  } catch (e) { return res.status(500).json({ ok:false, error:'clear_failed', message: e?.message || String(e) }); }
});

// Normalizer for mapped Presta payloads
import { mapProductForPresta } from './lib/grabbing/normalize.js';

function applyTransferConfig(mappedIn = {}, meta = {}, product = {}, cfg = {}) {
  try {
    const out = JSON.parse(JSON.stringify(mappedIn || {}));
    const safeArr = (a) => Array.isArray(a) ? a : [];
    const cfgProd = (cfg && cfg.product) || {};
    const cfgImgs = (cfg && cfg.images) || {};
    const cfgVars = (cfg && cfg.variants) || {};
    const get = (root, path) => {
      try {
        if (!path) return undefined;
        const parts = String(path).split('.');
        let cur = root;
        for (const p of parts) { if (!cur) return undefined; cur = cur[p]; }
        return cur;
      } catch { return undefined; }
    };
    const preferText = (paths, ctx = {}) => {
      try {
        for (const p of (Array.isArray(paths)? paths: [])) {
          let v = undefined;
          if (p.startsWith('product.')) v = get(ctx.product, p.slice(8));
          else if (p.startsWith('meta.')) v = get(ctx.meta, p.slice(5));
          else v = get(ctx, p);
          if (v == null) continue;
          const s = String(v).trim();
          if (s) return s;
        }
      } catch {}
      return undefined;
    };

    // Currency default
    try { if (!out.currency && cfgProd.currency && cfgProd.currency.default) out.currency = String(cfgProd.currency.default||'').trim(); } catch {}

    // Price normalization (cents→decimal when value>threshold)
    const normCents = (val, th) => {
      const n = Number(val);
      if (!Number.isFinite(n)) return val;
      return (th && n > th) ? Number((n/100).toFixed(2)) : n;
    };
    try {
      if (out.price != null && cfgProd.price && cfgProd.price.normalize_cents_when_gt) {
        out.price = normCents(out.price, Number(cfgProd.price.normalize_cents_when_gt)||0);
      }
    } catch {}

    // Prefer rules for name/sku/description
    try {
      const ctx = { meta, product };
      if (cfgProd.name && Array.isArray(cfgProd.name.prefer)) {
        const v = preferText(cfgProd.name.prefer, ctx);
        if (v) out.name = v;
      }
      if (cfgProd.sku && Array.isArray(cfgProd.sku.prefer)) {
        const v = preferText(cfgProd.sku.prefer, ctx);
        if (v) out.sku = v;
      }
      if (cfgProd.description && Array.isArray(cfgProd.description.prefer)) {
        const v = preferText(cfgProd.description.prefer, ctx);
        if (v) out.description = v;
      }
    } catch {}

    // Images: filter, dedupe, limit; optionally add variant images
    try {
      let imgs = [];
      // Start from mapped images
      try { for (const it of safeArr(out.images)) { if (it && it.url) imgs.push({ url: it.url, alt: it.alt||'', position: it.position||null }); } } catch {}
      // Optionally include variant images
      try {
        const wantVar = Array.isArray(cfgImgs.sources) && cfgImgs.sources.some(s => String(s||'').toLowerCase().includes('variants[].image'));
        if (wantVar) {
          for (const v of safeArr(out.variants)) { if (v && v.image) imgs.push({ url: v.image, alt: v.title||'', position: null }); }
        }
      } catch {}
      // Optionally include meta.og_image when requested or as a fallback when no images collected
      try {
        const wantOg = Array.isArray(cfgImgs.sources) && cfgImgs.sources.some(s => String(s||'').toLowerCase().includes('meta.og_image'));
        const addOgFallback = (!imgs.length && meta && meta.og_image);
        if (wantOg || addOgFallback) {
          const u = (meta && (meta.og_image || meta.image || meta.og_image_url)) || '';
          if (String(u||'').trim()) imgs.push({ url: String(u), alt: out.name || meta.title || '', position: null });
        }
      } catch {}
      // Exclude by regex
      try {
        const patterns = safeArr(cfgImgs.exclude_regex).map(p => { try { return new RegExp(String(p||''), 'i'); } catch { return null; } }).filter(Boolean);
        if (patterns.length) imgs = imgs.filter(it => !patterns.some(re => re.test(String(it.url||''))));
      } catch {}
      // Dedupe by lowercase URL
      try {
        const seen = new Set();
        const uniq = [];
        for (const it of imgs) { const k = String(it.url||'').toLowerCase().trim(); if (!k || seen.has(k)) continue; seen.add(k); uniq.push(it); }
        imgs = uniq;
      } catch {}
      // Limit
      try { const lim = Number(cfgImgs.limit||0); if (lim>0) imgs = imgs.slice(0, lim); } catch {}
      out.images = imgs;
    } catch {}

    // Variants: enable/disable, allowed fields, price normalization
    try {
      let vars = safeArr(out.variants);
      if (cfgVars.enabled === false) vars = [];
      // price normalization on each
      try {
        if (cfgVars.price && cfgVars.price.normalize_cents_when_gt) {
          const th = Number(cfgVars.price.normalize_cents_when_gt)||0;
          vars = vars.map(v => {
            const w = { ...v };
            // handle price as number or { value }
            if (w && typeof w.price === 'object' && w.price && 'value' in w.price) {
              w.price = { ...w.price, value: normCents(w.price.value, th) };
            } else if (w && (typeof w.price === 'string' || typeof w.price === 'number')) {
              w.price = normCents(w.price, th);
            }
            return w;
          });
        }
      } catch {}
      // Keep only selected fields if specified
      try {
        const fields = Array.isArray(cfgVars.fields) ? cfgVars.fields : null;
        if (fields && fields.length) {
          const set = new Set(fields.map(String));
          vars = vars.map(v => {
            const w = {};
            for (const k of Object.keys(v||{})) { if (set.has(k)) w[k] = v[k]; }
            return w;
          });
        }
      } catch {}
      out.variants = vars;
    } catch {}

    return out;
  } catch { return mappedIn || {}; }
}
// Remove any previously inlined mapProductForPresta to avoid duplicate identifier
// (No-op if not present). We keep the external module as the single source.

// Prepare a specific domain+url into the ready-to-transfer table for PrestaShop 8
// POST /api/grabbings/jerome/domains/url/prepare-presta { domain, url }
app.post('/api/grabbings/jerome/domains/url/prepare-presta', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const rawDomain = String(req.body?.domain || '').trim();
    const rawUrl = String(req.body?.url || '').trim();
    if (!rawDomain || !rawUrl) return res.status(400).json({ ok:false, error:'bad_request', message:'domain and url required' });
    let domain = rawDomain.toLowerCase();
    try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    await ensurePgTables();
    // Fetch canonical details
    const one = await pool.query(
      `select id, coalesce(page_type, type) as page_type,
              coalesce(title, (meta->>'title')) as title,
              meta, product
         from public.grabbing_jerome_domains_url
        where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2))
        limit 1`,
      [domain, rawUrl]
    );
    let page_type = '', title = '', meta = {}, product = {}, source_id = null;
    let resultJson = null;
    if (one.rows.length) {
      const r = one.rows[0];
      page_type = r.page_type || '';
      title = r.title || '';
      meta = r.meta || {};
      product = r.product || {};
      source_id = r.id || null;
    } else {
      // Fallback to history table
      const two = await pool.query(
        `select page_type, meta, product, result_json
           from public.grabbing_jerome_domains_url_page_explore
          where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2))
          limit 1`,
        [domain, rawUrl]
      );
      if (!two.rows.length) return res.status(404).json({ ok:false, error:'not_found' });
      page_type = two.rows[0].page_type || '';
      meta = two.rows[0].meta || {};
      product = two.rows[0].product || {};
      title = (meta && meta.title) ? meta.title : '';
      // capture history snapshot if present
      resultJson = two.rows[0].result_json || null;
    }
    // If we have a canonical record, try to load latest result_json snapshot from history
    if (!resultJson) {
      try {
        const h = await pool.query(
          `select result_json
             from public.grabbing_jerome_domains_url_page_explore
            where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2))
            limit 1`,
          [domain, rawUrl]
        );
        if (h.rows && h.rows.length) resultJson = h.rows[0].result_json || null;
      } catch {}
    }
    // Allow optional overrides from request
    try {
      if (req.body && typeof req.body.meta === 'object') meta = { ...meta, ...(req.body.meta||{}) };
      if (req.body && typeof req.body.product === 'object') product = { ...product, ...(req.body.product||{}) };
    } catch {}
    // Load transfer config and version, then apply to mapped payload
    let cfgTransfert = null; let cfgTransfertVersion = null;
    try {
      const rCfg = await pool.query('select config_transfert from grabbing_jerome_domains where domain=$1 limit 1', [domain]);
      const all = rCfg.rows?.[0]?.config_transfert || {};
      const t = (page_type || 'product').toLowerCase();
      if (all && typeof all === 'object') cfgTransfert = all[t] || all['product'] || null;
      try {
        const vr = await pool.query('select max(version) as v from grabbing_jerome_domain_config_transfert_history where domain=$1 and type=$2', [domain, t]);
        const v = Number(vr.rows?.[0]?.v || 0);
        if (v > 0) cfgTransfertVersion = v;
      } catch {}
    } catch {}
    const mapped = applyTransferConfig(mapProductForPresta(meta, product), meta, product, cfgTransfert || {});
    // Fallback: synthesize a compact result_json if none was found in history
    if (!resultJson) {
      try {
        resultJson = { ok:true, url: rawUrl, page_type, meta, product, preview:false };
      } catch { resultJson = null; }
    }
    // Upsert into ready_transfert
    // 1) Try update existing prepared record (case-insensitive URL match)
    const upd = await pool.query(
      `update public.grabbing_jerome_domains_url_ready_transfert
          set prepared_at = now(), source_url_id = $3, page_type = $4, title = $5,
              meta = $6::jsonb, product_raw = $7::jsonb, mapped = $8::jsonb, result_json = $9::jsonb, config_transfert_version = $10, status = 'pending'
        where domain = $1 and lower(trim(both from url)) = lower(trim(both from $2))
        returning id, prepared_at`,
      [domain, rawUrl, source_id, page_type, title, JSON.stringify(meta), JSON.stringify(product), JSON.stringify(mapped), (resultJson? JSON.stringify(resultJson): null), (cfgTransfertVersion==null? null: Number(cfgTransfertVersion))]
    );
    if (upd.rows && upd.rows.length) {
      return res.json({ ok:true, domain, url: rawUrl, prepared: { id: upd.rows[0].id, prepared_at: upd.rows[0].prepared_at }, page_type, title, mapped });
    }
    // 2) Insert if not exists (let unique index handle duplicates)
    const ins = await pool.query(
      `insert into public.grabbing_jerome_domains_url_ready_transfert(domain,url,prepared_at,source_url_id,page_type,title,meta,product_raw,mapped,result_json,config_transfert_version,status)
       values($1,$2,now(),$3,$4,$5,$6::jsonb,$7::jsonb,$8::jsonb,$9::jsonb,$10,'pending')
       on conflict do nothing
       returning id, prepared_at`,
      [domain, rawUrl, source_id, page_type, title, JSON.stringify(meta), JSON.stringify(product), JSON.stringify(mapped), (resultJson? JSON.stringify(resultJson): null), (cfgTransfertVersion==null? null: Number(cfgTransfertVersion))]
    );
  if (ins.rows && ins.rows.length) {
      return res.json({ ok:true, domain, url: rawUrl, prepared: { id: ins.rows[0].id, prepared_at: ins.rows[0].prepared_at }, page_type, title, mapped });
    }
    // 3) Fallback: select the existing row (race condition case)
    const sel = await pool.query(
      `select id, prepared_at from public.grabbing_jerome_domains_url_ready_transfert where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2)) limit 1`,
      [domain, rawUrl]
    );
    return res.json({ ok:true, domain, url: rawUrl, prepared: { id: sel.rows?.[0]?.id || null, prepared_at: sel.rows?.[0]?.prepared_at || null }, page_type, title, mapped });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'prepare_failed', message: e?.message || String(e) });
  }
});

// List ready-to-transfer items for a domain
// GET /api/grabbings/jerome/domains/ready-transfers?domain=example.com&limit=200&offset=0
app.get('/api/grabbings/jerome/domains/ready-transfers', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const raw = String(req.query?.domain || '').trim();
    if (!raw) return res.status(400).json({ ok:false, error:'bad_request', message:'domain required' });
    let domain = raw.toLowerCase();
    try { if (/^https?:\/\//i.test(raw)) { const u = new URL(raw); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const limit = Math.min(1000, Math.max(1, Number(req.query?.limit || 200)));
    const offset = Math.max(0, Number(req.query?.offset || 0));
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    const c = await pool.query('select count(*)::int as c from public.grabbing_jerome_domains_url_ready_transfert where domain=$1', [domain]);
    const total = Number(c.rows?.[0]?.c || 0);
    const { rows } = await pool.query(
      `select id,
              url,
              prepared_at,
              status,
              title,
              page_type,
              id_product,
              config_transfert_version,
              coalesce(jsonb_array_length(coalesce(mapped->'images','[]'::jsonb)),0) as mapped_images,
              coalesce(jsonb_array_length(coalesce(product_raw->'images_local','[]'::jsonb)),0) as local_images
         from public.grabbing_jerome_domains_url_ready_transfert
        where domain=$1
        order by prepared_at desc, id desc limit $2 offset $3`,
      [domain, limit, offset]
    );
    return res.json({ ok:true, domain, total, items: rows });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'list_failed', message: e?.message || String(e) });
  }
});

// Get a specific prepared record
// GET /api/grabbings/jerome/domains/url/ready?domain=example.com&url=https://...
app.get('/api/grabbings/jerome/domains/url/ready', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const rawDomain = String(req.query?.domain || '').trim();
    const rawUrl = String(req.query?.url || '').trim();
    if (!rawDomain || !rawUrl) return res.status(400).json({ ok:false, error:'bad_request', message:'domain and url required' });
    let domain = rawDomain.toLowerCase();
    try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    const q = await pool.query(
      `select id, url, prepared_at, status, title, page_type, id_product, meta, product_raw, mapped, config_transfert_version
         from public.grabbing_jerome_domains_url_ready_transfert
        where domain=$1 and lower(trim(both from url)) = lower(trim(both from $2))
        limit 1`,
      [domain, rawUrl]
    );
    if (!q.rows.length) return res.status(404).json({ ok:false, error:'not_found' });
    const r = q.rows[0];
    return res.json({ ok:true, domain, url: rawUrl, item: r });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'fetch_failed', message: e?.message || String(e) });
  }
});

// Update status/notes on a prepared record
// POST /api/grabbings/jerome/domains/url/ready/status { domain, url, status, notes }
app.post('/api/grabbings/jerome/domains/url/ready/status', async (req, res) => {
  const u = requireAdminAuth(req, res); if (!u) return;
  try {
    const rawDomain = String(req.body?.domain || '').trim();
    const rawUrl = String(req.body?.url || '').trim();
    const status = String(req.body?.status || '').trim();
    const notes = (req.body?.notes == null ? null : String(req.body?.notes));
    const idProduct = req.body?.id_product != null ? Number(req.body.id_product) : null;
    if (!rawDomain || !rawUrl || !status) return res.status(400).json({ ok:false, error:'bad_request', message:'domain, url and status required' });
    let domain = rawDomain.toLowerCase();
    try { if (/^https?:\/\//i.test(rawDomain)) { const u = new URL(rawDomain); domain = (u.hostname||'').toLowerCase(); } } catch {}
    domain = domain.replace(/^www\./,'');
    const pool = await getPg(); if (!pool) return res.status(500).json({ ok:false, error:'db_unavailable' });
    let sql = `update public.grabbing_jerome_domains_url_ready_transfert
                  set status = $3, notes = $4, prepared_at = now()`;
    const params = [domain, rawUrl, status, notes];
    if (idProduct != null && !Number.isNaN(idProduct)) { sql += `, id_product = $5`; params.push(idProduct); }
    sql += ` where domain = $1 and lower(trim(both from url)) = lower(trim(both from $2)) returning id, id_product`;
    const q = await pool.query(sql, params);
    if (!q.rows.length) return res.status(404).json({ ok:false, error:'not_found' });
    return res.json({ ok:true, updated: q.rows[0].id, id_product: q.rows[0].id_product || idProduct || null });
  } catch (e) { return res.status(500).json({ ok:false, error:'status_update_failed', message: e?.message || String(e) }); }
});

// Debug: list registered routes and current DB target (masked)
// GET /api/grabbings/jerome/debug -> { ok, routes:[{method,path}], db_url }
app.get('/api/grabbings/jerome/debug', async (_req, res) => {
  try {
    const routes = [];
    try {
      const stack = app && app._router && app._router.stack ? app._router.stack : [];
      for (const layer of stack) {
        if (layer && layer.route && layer.route.path) {
          const methods = Object.keys(layer.route.methods || {}).filter(Boolean).map(m=>m.toUpperCase());
          routes.push({ methods, path: layer.route.path });
        } else if (layer && layer.name === 'router' && layer.handle && layer.handle.stack) {
          for (const l2 of layer.handle.stack) {
            if (l2 && l2.route && l2.route.path) {
              const methods = Object.keys(l2.route.methods || {}).filter(Boolean).map(m=>m.toUpperCase());
              routes.push({ methods, path: l2.route.path });
            }
          }
        }
      }
    } catch {}
    const rawDb = String(process.env.DATABASE_URL || '');
    const maskedDb = rawDb ? rawDb.replace(/:\/\/([^:@]+):([^@]+)@/, '://$1:***@') : '';
    // quick ping
    let db_ok = false;
    try { const pool = await getPg(); if (pool) { await pool.query('select 1'); db_ok = true; } } catch {}
    return res.json({ ok:true, routes, db_url: maskedDb, db_ok });
  } catch (e) {
    return res.status(500).json({ ok:false, error:'debug_failed', message: e?.message || String(e) });
  }
});

// As the very last middleware: make unknown /api/* return JSON 404 (not HTML)
app.use('/api', (_req, res) => {
  res.status(404).json({ error: 'not_found' });
});
// Load per-domain extraction config, preferring DB over file
async function loadJeromeDomainConfigAsync(domain) {
  const norm = String(domain||'').toLowerCase().replace(/^www\./,'');
  // DB-only: read from grabbing_jerome_domains.config
  try {
    const pool = await getPg();
    if (pool) {
      const r = await pool.query('select config from grabbing_jerome_domains where domain=$1 limit 1', [norm]);
      if (r.rows && r.rows.length && r.rows[0].config) {
        const cfg = r.rows[0].config || {};
        if (cfg && typeof cfg === 'object') return cfg;
      }
    }
  } catch {}
  // No fallback to files when DB is empty
  return {};
}


